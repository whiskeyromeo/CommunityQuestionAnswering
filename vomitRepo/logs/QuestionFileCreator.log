2016-09-27 07:54:54,063 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 07:54:54,282 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 07:54:54,282 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 07:54:54,477 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 07:54:54,477 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 07:54:54,477 : INFO : PROGRESS: saving document #0
2016-09-27 07:54:54,616 : INFO : PROGRESS: saving document #1000
2016-09-27 07:54:54,759 : INFO : PROGRESS: saving document #2000
2016-09-27 07:54:54,893 : INFO : PROGRESS: saving document #3000
2016-09-27 07:54:54,905 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 07:54:54,905 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 07:54:54,906 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 07:54:54,907 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 07:54:54,908 : INFO : collecting document frequencies
2016-09-27 07:54:54,908 : INFO : PROGRESS: processing document #0
2016-09-27 07:54:54,942 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 07:54:54,955 : INFO : using serial LSI version on this node
2016-09-27 07:54:54,955 : INFO : updating model with new documents
2016-09-27 07:54:55,136 : INFO : preparing a new chunk of documents
2016-09-27 07:54:55,137 : DEBUG : converting corpus to csc format
2016-09-27 07:54:55,177 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 07:54:55,177 : INFO : 1st phase: constructing (14590, 102) action matrix
2016-09-27 07:54:55,202 : INFO : orthonormalizing (14590, 102) action matrix
2016-09-27 07:54:55,211 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:54:55,240 : DEBUG : running 2 power iterations
2016-09-27 07:54:55,269 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:54:55,310 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:54:55,340 : INFO : 2nd phase: running dense svd on (102, 3090) matrix
2016-09-27 07:54:55,356 : INFO : computing the final decomposition
2016-09-27 07:54:55,356 : INFO : keeping 2 factors (discarding 86.509% of energy spectrum)
2016-09-27 07:54:55,358 : INFO : processed documents up to #3090
2016-09-27 07:54:55,364 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.130*"any"
2016-09-27 07:54:55,364 : INFO : topic #1(3.590): -0.415*"visa" + -0.304*"visit" + 0.257*"where" + -0.238*"my" + 0.179*"buy" + -0.179*"family" + 0.150*"anyone" + 0.136*"find" + 0.131*"does" + 0.130*"know"
2016-09-27 07:54:55,369 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 07:54:55,370 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 07:54:55,370 : INFO : not storing attribute projection
2016-09-27 07:54:55,370 : INFO : not storing attribute dispatcher
2016-09-27 07:54:55,403 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 07:54:55,413 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 07:54:55,413 : INFO : setting ignored attribute projection to None
2016-09-27 07:54:55,413 : INFO : setting ignored attribute dispatcher to None
2016-09-27 07:54:55,413 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 07:54:55,413 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 07:54:55,487 : INFO : creating matrix with 3090 documents and 2 features
2016-09-27 07:54:55,493 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 07:54:55,525 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 07:54:55,565 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 07:54:55,604 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 07:59:25,527 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 07:59:25,742 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 07:59:25,742 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 07:59:25,936 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 07:59:25,936 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 07:59:25,936 : INFO : PROGRESS: saving document #0
2016-09-27 07:59:26,076 : INFO : PROGRESS: saving document #1000
2016-09-27 07:59:26,212 : INFO : PROGRESS: saving document #2000
2016-09-27 07:59:26,347 : INFO : PROGRESS: saving document #3000
2016-09-27 07:59:26,359 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 07:59:26,359 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 07:59:26,360 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 07:59:26,360 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 07:59:26,361 : INFO : collecting document frequencies
2016-09-27 07:59:26,361 : INFO : PROGRESS: processing document #0
2016-09-27 07:59:26,395 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 07:59:26,409 : INFO : using serial LSI version on this node
2016-09-27 07:59:26,409 : INFO : updating model with new documents
2016-09-27 07:59:26,585 : INFO : preparing a new chunk of documents
2016-09-27 07:59:26,586 : DEBUG : converting corpus to csc format
2016-09-27 07:59:26,624 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 07:59:26,625 : INFO : 1st phase: constructing (14590, 102) action matrix
2016-09-27 07:59:26,650 : INFO : orthonormalizing (14590, 102) action matrix
2016-09-27 07:59:26,660 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:59:26,683 : DEBUG : running 2 power iterations
2016-09-27 07:59:26,711 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:59:26,753 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 07:59:26,783 : INFO : 2nd phase: running dense svd on (102, 3090) matrix
2016-09-27 07:59:26,800 : INFO : computing the final decomposition
2016-09-27 07:59:26,800 : INFO : keeping 2 factors (discarding 86.533% of energy spectrum)
2016-09-27 07:59:26,801 : INFO : processed documents up to #3090
2016-09-27 07:59:26,807 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 07:59:26,807 : INFO : topic #1(3.591): -0.417*"visa" + -0.301*"visit" + 0.256*"where" + -0.235*"my" + 0.184*"buy" + -0.176*"family" + 0.152*"anyone" + 0.133*"find" + 0.127*"know" + 0.126*"does"
2016-09-27 07:59:26,812 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 07:59:26,813 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 07:59:26,813 : INFO : not storing attribute projection
2016-09-27 07:59:26,813 : INFO : not storing attribute dispatcher
2016-09-27 07:59:26,848 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 07:59:26,857 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 07:59:26,857 : INFO : setting ignored attribute projection to None
2016-09-27 07:59:26,857 : INFO : setting ignored attribute dispatcher to None
2016-09-27 07:59:26,857 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 07:59:26,857 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 07:59:26,930 : INFO : creating matrix with 3090 documents and 2 features
2016-09-27 07:59:26,937 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 07:59:26,969 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 07:59:27,007 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 07:59:27,046 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 07:59:27,049 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 07:59:27,050 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 08:00:57,852 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 08:00:58,068 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 08:00:58,068 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 08:00:58,316 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 08:00:58,316 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 08:00:58,316 : INFO : PROGRESS: saving document #0
2016-09-27 08:00:58,458 : INFO : PROGRESS: saving document #1000
2016-09-27 08:00:58,595 : INFO : PROGRESS: saving document #2000
2016-09-27 08:00:58,733 : INFO : PROGRESS: saving document #3000
2016-09-27 08:00:58,744 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 08:00:58,745 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 08:00:58,747 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 08:00:58,747 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 08:00:58,748 : INFO : collecting document frequencies
2016-09-27 08:00:58,749 : INFO : PROGRESS: processing document #0
2016-09-27 08:00:58,784 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 08:00:58,797 : INFO : using serial LSI version on this node
2016-09-27 08:00:58,798 : INFO : updating model with new documents
2016-09-27 08:00:58,973 : INFO : preparing a new chunk of documents
2016-09-27 08:00:58,974 : DEBUG : converting corpus to csc format
2016-09-27 08:00:59,012 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 08:00:59,012 : INFO : 1st phase: constructing (14590, 102) action matrix
2016-09-27 08:00:59,038 : INFO : orthonormalizing (14590, 102) action matrix
2016-09-27 08:00:59,049 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 08:00:59,069 : DEBUG : running 2 power iterations
2016-09-27 08:00:59,095 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 08:00:59,139 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 08:00:59,168 : INFO : 2nd phase: running dense svd on (102, 3090) matrix
2016-09-27 08:00:59,184 : INFO : computing the final decomposition
2016-09-27 08:00:59,184 : INFO : keeping 2 factors (discarding 86.517% of energy spectrum)
2016-09-27 08:00:59,186 : INFO : processed documents up to #3090
2016-09-27 08:00:59,192 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.130*"any"
2016-09-27 08:00:59,192 : INFO : topic #1(3.591): -0.415*"visa" + -0.301*"visit" + 0.256*"where" + -0.236*"my" + 0.183*"buy" + -0.178*"family" + 0.151*"anyone" + 0.132*"find" + 0.129*"know" + 0.128*"does"
2016-09-27 08:00:59,195 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 08:00:59,196 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 08:00:59,196 : INFO : not storing attribute projection
2016-09-27 08:00:59,196 : INFO : not storing attribute dispatcher
2016-09-27 08:00:59,233 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 08:00:59,243 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 08:00:59,243 : INFO : setting ignored attribute projection to None
2016-09-27 08:00:59,243 : INFO : setting ignored attribute dispatcher to None
2016-09-27 08:00:59,243 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 08:00:59,244 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 08:00:59,318 : INFO : creating matrix with 3090 documents and 2 features
2016-09-27 08:00:59,324 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 08:00:59,356 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 08:00:59,394 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 08:00:59,433 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 08:00:59,436 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 08:00:59,437 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 09:50:37,744 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 09:50:37,956 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 09:50:37,956 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 09:50:38,152 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 09:50:38,153 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 09:50:38,153 : INFO : PROGRESS: saving document #0
2016-09-27 09:50:38,287 : INFO : PROGRESS: saving document #1000
2016-09-27 09:50:38,422 : INFO : PROGRESS: saving document #2000
2016-09-27 09:50:38,562 : INFO : PROGRESS: saving document #3000
2016-09-27 09:50:38,574 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 09:50:38,574 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 09:50:38,575 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 09:50:38,575 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 09:50:38,576 : INFO : collecting document frequencies
2016-09-27 09:50:38,576 : INFO : PROGRESS: processing document #0
2016-09-27 09:50:38,616 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 09:50:38,629 : INFO : using serial LSI version on this node
2016-09-27 09:50:38,629 : INFO : updating model with new documents
2016-09-27 09:50:38,806 : INFO : preparing a new chunk of documents
2016-09-27 09:50:38,807 : DEBUG : converting corpus to csc format
2016-09-27 09:50:38,845 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 09:50:38,845 : INFO : 1st phase: constructing (14590, 102) action matrix
2016-09-27 09:50:38,870 : INFO : orthonormalizing (14590, 102) action matrix
2016-09-27 09:50:38,881 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 09:50:38,905 : DEBUG : running 2 power iterations
2016-09-27 09:50:38,936 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 09:50:38,978 : DEBUG : computing QR of (14590, 102) dense matrix
2016-09-27 09:50:39,009 : INFO : 2nd phase: running dense svd on (102, 3090) matrix
2016-09-27 09:50:39,026 : INFO : computing the final decomposition
2016-09-27 09:50:39,027 : INFO : keeping 2 factors (discarding 86.510% of energy spectrum)
2016-09-27 09:50:39,028 : INFO : processed documents up to #3090
2016-09-27 09:50:39,034 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 09:50:39,035 : INFO : topic #1(3.591): -0.417*"visa" + -0.299*"visit" + 0.255*"where" + -0.236*"my" + 0.183*"buy" + -0.177*"family" + 0.149*"anyone" + 0.134*"find" + 0.128*"does" + 0.127*"know"
2016-09-27 09:50:39,042 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 09:50:39,043 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 09:50:39,043 : INFO : not storing attribute projection
2016-09-27 09:50:39,043 : INFO : not storing attribute dispatcher
2016-09-27 09:50:39,077 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 09:50:39,087 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 09:50:39,087 : INFO : setting ignored attribute projection to None
2016-09-27 09:50:39,087 : INFO : setting ignored attribute dispatcher to None
2016-09-27 09:50:39,087 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 09:50:39,087 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 09:50:39,160 : INFO : creating matrix with 3090 documents and 2 features
2016-09-27 09:50:39,167 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 09:50:39,199 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 09:50:39,237 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 09:50:39,275 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 09:50:39,278 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 09:50:39,278 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 09:55:31,685 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 09:55:31,902 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 09:55:31,902 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 09:55:32,088 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 09:55:32,088 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 09:55:32,089 : INFO : PROGRESS: saving document #0
2016-09-27 09:55:32,226 : INFO : PROGRESS: saving document #1000
2016-09-27 09:55:32,362 : INFO : PROGRESS: saving document #2000
2016-09-27 09:55:32,496 : INFO : PROGRESS: saving document #3000
2016-09-27 09:55:32,508 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 09:55:32,508 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 09:55:32,511 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 09:55:32,511 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 09:55:32,512 : INFO : collecting document frequencies
2016-09-27 09:55:32,512 : INFO : PROGRESS: processing document #0
2016-09-27 09:55:32,546 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 09:55:32,560 : INFO : using serial LSI version on this node
2016-09-27 09:55:32,560 : INFO : updating model with new documents
2016-09-27 09:55:32,737 : INFO : preparing a new chunk of documents
2016-09-27 09:55:32,738 : DEBUG : converting corpus to csc format
2016-09-27 09:55:32,781 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 09:55:32,781 : INFO : 1st phase: constructing (14590, 300) action matrix
2016-09-27 09:55:32,856 : INFO : orthonormalizing (14590, 300) action matrix
2016-09-27 09:55:32,901 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 09:55:33,001 : DEBUG : running 2 power iterations
2016-09-27 09:55:33,084 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 09:55:33,254 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 09:55:33,380 : INFO : 2nd phase: running dense svd on (300, 3090) matrix
2016-09-27 09:55:33,449 : INFO : computing the final decomposition
2016-09-27 09:55:33,449 : INFO : keeping 200 factors (discarding 18.771% of energy spectrum)
2016-09-27 09:55:33,491 : INFO : processed documents up to #3090
2016-09-27 09:55:33,497 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 09:55:33,498 : INFO : topic #1(3.593): 0.415*"visa" + 0.302*"visit" + -0.256*"where" + 0.238*"my" + -0.181*"buy" + 0.179*"family" + -0.152*"anyone" + -0.133*"find" + -0.127*"know" + -0.127*"does"
2016-09-27 09:55:33,498 : INFO : topic #2(3.148): -0.288*"where" + -0.254*"can" + -0.252*"visa" + 0.249*"you" + 0.211*"do" + -0.205*"visit" + -0.200*"me" + -0.186*"tell" + 0.185*"are" + 0.180*"what"
2016-09-27 09:55:33,498 : INFO : topic #3(2.912): -0.359*"car" + 0.279*"does" + 0.268*"we" + 0.224*"visa" + 0.216*"know" + -0.207*"driving" + 0.181*"anyone" + 0.164*"visit" + 0.158*"are" + 0.152*"doha?"
2016-09-27 09:55:33,499 : INFO : topic #4(2.840): 0.463*"you" + 0.301*"do" + 0.203*"?" + 0.187*"what" + 0.157*"best" + 0.157*"your" + -0.153*"does" + -0.150*"anyone" + 0.148*"how" + 0.139*"buy"
2016-09-27 09:55:33,507 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 09:55:33,562 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 09:55:33,563 : INFO : not storing attribute projection
2016-09-27 09:55:33,563 : INFO : not storing attribute dispatcher
2016-09-27 09:55:33,597 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 09:55:33,608 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 09:55:33,608 : INFO : setting ignored attribute projection to None
2016-09-27 09:55:33,608 : INFO : setting ignored attribute dispatcher to None
2016-09-27 09:55:33,608 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 09:55:33,640 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 09:55:33,906 : INFO : creating matrix with 3090 documents and 200 features
2016-09-27 09:55:33,915 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 09:55:34,026 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 09:55:34,147 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 09:55:34,268 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 09:55:34,279 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 09:55:34,283 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 10:22:23,079 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 10:22:23,307 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 10:22:23,307 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 10:22:23,490 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 10:22:23,490 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 10:22:23,490 : INFO : PROGRESS: saving document #0
2016-09-27 10:22:23,629 : INFO : PROGRESS: saving document #1000
2016-09-27 10:22:23,768 : INFO : PROGRESS: saving document #2000
2016-09-27 10:22:23,908 : INFO : PROGRESS: saving document #3000
2016-09-27 10:22:23,920 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 10:22:23,920 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 10:22:23,920 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 10:22:23,920 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 10:22:23,921 : INFO : collecting document frequencies
2016-09-27 10:22:23,921 : INFO : PROGRESS: processing document #0
2016-09-27 10:22:23,958 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 10:22:23,972 : INFO : using serial LSI version on this node
2016-09-27 10:22:23,972 : INFO : updating model with new documents
2016-09-27 10:22:24,154 : INFO : preparing a new chunk of documents
2016-09-27 10:22:24,155 : DEBUG : converting corpus to csc format
2016-09-27 10:22:24,193 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 10:22:24,193 : INFO : 1st phase: constructing (14590, 300) action matrix
2016-09-27 10:22:24,265 : INFO : orthonormalizing (14590, 300) action matrix
2016-09-27 10:22:24,309 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 10:22:24,404 : DEBUG : running 2 power iterations
2016-09-27 10:22:24,487 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 10:22:24,663 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 10:22:24,790 : INFO : 2nd phase: running dense svd on (300, 3090) matrix
2016-09-27 10:22:24,864 : INFO : computing the final decomposition
2016-09-27 10:22:24,865 : INFO : keeping 200 factors (discarding 18.788% of energy spectrum)
2016-09-27 10:22:24,907 : INFO : processed documents up to #3090
2016-09-27 10:22:24,914 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 10:22:24,914 : INFO : topic #1(3.593): 0.415*"visa" + 0.302*"visit" + -0.257*"where" + 0.237*"my" + -0.181*"buy" + 0.178*"family" + -0.152*"anyone" + -0.133*"find" + -0.127*"know" + -0.127*"does"
2016-09-27 10:22:24,915 : INFO : topic #2(3.148): -0.288*"where" + -0.253*"can" + -0.252*"visa" + 0.250*"you" + 0.210*"do" + -0.206*"visit" + -0.199*"me" + -0.187*"tell" + 0.185*"are" + 0.181*"what"
2016-09-27 10:22:24,915 : INFO : topic #3(2.912): -0.358*"car" + 0.280*"does" + 0.268*"we" + 0.223*"visa" + 0.217*"know" + -0.207*"driving" + 0.181*"anyone" + 0.164*"visit" + 0.158*"are" + 0.151*"doha?"
2016-09-27 10:22:24,915 : INFO : topic #4(2.840): -0.463*"you" + -0.301*"do" + -0.203*"?" + -0.186*"what" + -0.158*"best" + 0.156*"does" + -0.156*"your" + 0.152*"anyone" + -0.145*"how" + -0.140*"buy"
2016-09-27 10:22:24,926 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 10:22:24,980 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 10:22:24,981 : INFO : not storing attribute projection
2016-09-27 10:22:24,981 : INFO : not storing attribute dispatcher
2016-09-27 10:22:25,015 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 10:22:25,025 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 10:22:25,025 : INFO : setting ignored attribute projection to None
2016-09-27 10:22:25,025 : INFO : setting ignored attribute dispatcher to None
2016-09-27 10:22:25,026 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 10:22:25,058 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 10:22:25,325 : INFO : creating matrix with 3090 documents and 200 features
2016-09-27 10:22:25,333 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 10:22:25,443 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 10:22:25,561 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 10:22:25,682 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 10:22:25,692 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 10:22:25,696 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 10:25:04,815 : INFO : collecting all words and their counts
2016-09-27 10:25:04,815 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-27 12:31:19,068 : INFO : collecting all words and their counts
2016-09-27 12:31:19,068 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-27 12:31:19,204 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-27 12:31:19,216 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-27 12:31:19,216 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-27 12:31:19,221 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-27 12:31:19,221 : INFO : sample=0 downsamples 0 most-common words
2016-09-27 12:31:19,221 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-27 12:31:19,221 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-27 12:31:19,223 : INFO : constructing a huffman tree from 1902 words
2016-09-27 12:31:19,270 : INFO : built huffman tree with maximum node depth 14
2016-09-27 12:31:19,270 : INFO : resetting layer weights
2016-09-27 12:31:19,290 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:31:19,290 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:31:19,292 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-27 12:31:19,292 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-27 12:31:19,296 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-27 12:31:19,297 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-27 12:31:19,299 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-27 12:31:19,300 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-27 12:31:19,301 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-27 12:31:19,302 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-27 12:31:19,303 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-27 12:31:19,304 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-27 12:31:19,306 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-27 12:31:19,306 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-27 12:31:19,307 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-27 12:31:19,366 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-27 12:31:19,368 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-27 12:31:19,369 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-27 12:31:19,372 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-27 12:31:19,430 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-27 12:31:19,433 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-27 12:31:19,434 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-27 12:31:19,437 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-27 12:31:19,495 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-27 12:31:19,497 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-27 12:31:19,501 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-27 12:31:19,503 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-27 12:31:19,561 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-27 12:31:19,563 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-27 12:31:19,566 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-27 12:31:19,572 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-27 12:31:19,626 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-27 12:31:19,628 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-27 12:31:19,631 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-27 12:31:19,640 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-27 12:31:19,690 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-27 12:31:19,693 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-27 12:31:19,695 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-27 12:31:19,705 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-27 12:31:19,757 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-27 12:31:19,759 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-27 12:31:19,762 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-27 12:31:19,768 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-27 12:31:19,821 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-27 12:31:19,825 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-27 12:31:19,832 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-27 12:31:19,833 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-27 12:31:19,886 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-27 12:31:19,889 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-27 12:31:19,895 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-27 12:31:19,898 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-27 12:31:19,952 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-27 12:31:19,955 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-27 12:31:19,960 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-27 12:31:19,962 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-27 12:31:20,080 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:31:20,143 : DEBUG : worker exiting, processed 13 jobs
2016-09-27 12:31:20,144 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-27 12:31:20,147 : DEBUG : worker exiting, processed 13 jobs
2016-09-27 12:31:20,147 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-27 12:31:20,149 : DEBUG : worker exiting, processed 13 jobs
2016-09-27 12:31:20,149 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-27 12:31:20,156 : DEBUG : worker exiting, processed 14 jobs
2016-09-27 12:31:20,156 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:31:20,157 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 702412 effective words/s
2016-09-27 12:33:34,413 : INFO : precomputing L2-norms of word weight vectors
2016-09-27 12:35:49,081 : INFO : saving Doc2Vec object under ./tmp/doc2vec_size100_window8_min5_work4, separately None
2016-09-27 12:35:49,081 : INFO : not storing attribute syn0norm
2016-09-27 12:35:49,082 : INFO : not storing attribute cum_table
2016-09-27 12:37:36,053 : INFO : collecting all words and their counts
2016-09-27 12:37:36,054 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 15 tags
2016-09-27 12:37:36,192 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-27 12:37:36,204 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-27 12:37:36,204 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-27 12:37:36,208 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-27 12:37:36,208 : INFO : sample=0 downsamples 0 most-common words
2016-09-27 12:37:36,209 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-27 12:37:36,209 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-27 12:45:19,186 : INFO : collecting all words and their counts
2016-09-27 12:45:19,187 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-27 12:45:19,325 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-27 12:45:19,335 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-27 12:45:19,335 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-27 12:45:19,342 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-27 12:45:19,343 : INFO : sample=0 downsamples 0 most-common words
2016-09-27 12:45:19,343 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-27 12:45:19,343 : INFO : estimated required memory for 1902 words and 300 dimensions: 5917200 bytes
2016-09-27 12:45:19,346 : INFO : constructing a huffman tree from 1902 words
2016-09-27 12:45:19,394 : INFO : built huffman tree with maximum node depth 14
2016-09-27 12:45:19,394 : INFO : resetting layer weights
2016-09-27 12:45:20,543 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:20,543 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:20,546 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-27 12:45:20,547 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:20,548 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02500
2016-09-27 12:45:20,549 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:20,590 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02500
2016-09-27 12:45:20,624 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02500
2016-09-27 12:45:20,659 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02500
2016-09-27 12:45:20,693 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02500
2016-09-27 12:45:20,727 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02500
2016-09-27 12:45:20,762 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02500
2016-09-27 12:45:20,797 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02500
2016-09-27 12:45:20,831 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02500
2016-09-27 12:45:20,866 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02500
2016-09-27 12:45:20,901 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:20,934 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02500
2016-09-27 12:45:20,967 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02500
2016-09-27 12:45:21,001 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02500
2016-09-27 12:45:21,035 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02500
2016-09-27 12:45:21,069 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02500
2016-09-27 12:45:21,104 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02500
2016-09-27 12:45:21,138 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02500
2016-09-27 12:45:21,172 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02500
2016-09-27 12:45:21,207 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02500
2016-09-27 12:45:21,242 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02500
2016-09-27 12:45:21,277 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:21,310 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02500
2016-09-27 12:45:21,343 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02500
2016-09-27 12:45:21,377 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02500
2016-09-27 12:45:21,411 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02500
2016-09-27 12:45:21,446 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02500
2016-09-27 12:45:21,481 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02500
2016-09-27 12:45:21,515 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02500
2016-09-27 12:45:21,549 : INFO : PROGRESS: at 55.17% examples, 334399 words/s, in_qsize 2, out_qsize 0
2016-09-27 12:45:21,550 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02500
2016-09-27 12:45:21,585 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02500
2016-09-27 12:45:21,620 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:21,653 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02500
2016-09-27 12:45:21,687 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02500
2016-09-27 12:45:21,720 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02500
2016-09-27 12:45:21,753 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02500
2016-09-27 12:45:21,788 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02500
2016-09-27 12:45:21,823 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02500
2016-09-27 12:45:21,857 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02500
2016-09-27 12:45:21,892 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02500
2016-09-27 12:45:21,927 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02500
2016-09-27 12:45:21,961 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02500
2016-09-27 12:45:21,996 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02500
2016-09-27 12:45:22,029 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02500
2016-09-27 12:45:22,063 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02500
2016-09-27 12:45:22,098 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02500
2016-09-27 12:45:22,132 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02500
2016-09-27 12:45:22,167 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02500
2016-09-27 12:45:22,202 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02500
2016-09-27 12:45:22,236 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02500
2016-09-27 12:45:22,303 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:22,353 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:22,353 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:22,353 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 336159 effective words/s
2016-09-27 12:45:22,353 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:22,353 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:22,355 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02300
2016-09-27 12:45:22,356 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:22,356 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02300
2016-09-27 12:45:22,357 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:22,391 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02300
2016-09-27 12:45:22,425 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02300
2016-09-27 12:45:22,459 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02300
2016-09-27 12:45:22,493 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02300
2016-09-27 12:45:22,528 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02300
2016-09-27 12:45:22,564 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02300
2016-09-27 12:45:22,600 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02300
2016-09-27 12:45:22,635 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02300
2016-09-27 12:45:22,671 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02300
2016-09-27 12:45:22,709 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:22,742 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02300
2016-09-27 12:45:22,775 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02300
2016-09-27 12:45:22,809 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02300
2016-09-27 12:45:22,842 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02300
2016-09-27 12:45:22,877 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02300
2016-09-27 12:45:22,912 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02300
2016-09-27 12:45:22,946 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02300
2016-09-27 12:45:22,980 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02300
2016-09-27 12:45:23,015 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02300
2016-09-27 12:45:23,049 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02300
2016-09-27 12:45:23,084 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:23,117 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02300
2016-09-27 12:45:23,150 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02300
2016-09-27 12:45:23,185 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02300
2016-09-27 12:45:23,218 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02300
2016-09-27 12:45:23,254 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02300
2016-09-27 12:45:23,288 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02300
2016-09-27 12:45:23,323 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02300
2016-09-27 12:45:23,358 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02300
2016-09-27 12:45:23,358 : INFO : PROGRESS: at 55.17% examples, 334403 words/s, in_qsize 2, out_qsize 0
2016-09-27 12:45:23,392 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02300
2016-09-27 12:45:23,428 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:23,461 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02300
2016-09-27 12:45:23,498 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02300
2016-09-27 12:45:23,532 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02300
2016-09-27 12:45:23,565 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02300
2016-09-27 12:45:23,603 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02300
2016-09-27 12:45:23,639 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02300
2016-09-27 12:45:23,672 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02300
2016-09-27 12:45:23,710 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02300
2016-09-27 12:45:23,745 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02300
2016-09-27 12:45:23,779 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02300
2016-09-27 12:45:23,814 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02300
2016-09-27 12:45:23,847 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02300
2016-09-27 12:45:23,881 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02300
2016-09-27 12:45:23,914 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02300
2016-09-27 12:45:23,949 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02300
2016-09-27 12:45:23,984 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02300
2016-09-27 12:45:24,018 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02300
2016-09-27 12:45:24,052 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02300
2016-09-27 12:45:24,121 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:24,170 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:24,170 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:24,171 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 334542 effective words/s
2016-09-27 12:45:24,171 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:24,171 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:24,172 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02100
2016-09-27 12:45:24,173 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:24,174 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02100
2016-09-27 12:45:24,175 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:24,211 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02100
2016-09-27 12:45:24,246 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02100
2016-09-27 12:45:24,280 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02100
2016-09-27 12:45:24,313 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02100
2016-09-27 12:45:24,348 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02100
2016-09-27 12:45:24,383 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02100
2016-09-27 12:45:24,417 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02100
2016-09-27 12:45:24,452 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02100
2016-09-27 12:45:24,487 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02100
2016-09-27 12:45:24,521 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:24,556 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02100
2016-09-27 12:45:24,589 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02100
2016-09-27 12:45:24,623 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02100
2016-09-27 12:45:24,656 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02100
2016-09-27 12:45:24,691 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02100
2016-09-27 12:45:24,726 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02100
2016-09-27 12:45:24,761 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02100
2016-09-27 12:45:24,795 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02100
2016-09-27 12:45:24,830 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02100
2016-09-27 12:45:24,865 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02100
2016-09-27 12:45:24,900 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:24,933 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02100
2016-09-27 12:45:24,966 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02100
2016-09-27 12:45:25,000 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02100
2016-09-27 12:45:25,034 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02100
2016-09-27 12:45:25,069 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02100
2016-09-27 12:45:25,106 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02100
2016-09-27 12:45:25,140 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02100
2016-09-27 12:45:25,173 : INFO : PROGRESS: at 55.17% examples, 335178 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:25,175 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02100
2016-09-27 12:45:25,209 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02100
2016-09-27 12:45:25,244 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:25,277 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02100
2016-09-27 12:45:25,311 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02100
2016-09-27 12:45:25,345 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02100
2016-09-27 12:45:25,378 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02100
2016-09-27 12:45:25,413 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02100
2016-09-27 12:45:25,448 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02100
2016-09-27 12:45:25,482 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02100
2016-09-27 12:45:25,517 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02100
2016-09-27 12:45:25,552 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02100
2016-09-27 12:45:25,589 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02100
2016-09-27 12:45:25,625 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02100
2016-09-27 12:45:25,658 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02100
2016-09-27 12:45:25,692 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02100
2016-09-27 12:45:25,726 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02100
2016-09-27 12:45:25,760 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02100
2016-09-27 12:45:25,795 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02100
2016-09-27 12:45:25,830 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02100
2016-09-27 12:45:25,864 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02100
2016-09-27 12:45:25,932 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:25,982 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:25,982 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:25,983 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 335597 effective words/s
2016-09-27 12:45:25,983 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:25,983 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:25,984 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01900
2016-09-27 12:45:25,985 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:25,986 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01900
2016-09-27 12:45:25,987 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:26,021 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01900
2016-09-27 12:45:26,057 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01900
2016-09-27 12:45:26,091 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01900
2016-09-27 12:45:26,125 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01900
2016-09-27 12:45:26,160 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01900
2016-09-27 12:45:26,195 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01900
2016-09-27 12:45:26,229 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01900
2016-09-27 12:45:26,264 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01900
2016-09-27 12:45:26,299 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01900
2016-09-27 12:45:26,334 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:26,367 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01900
2016-09-27 12:45:26,400 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01900
2016-09-27 12:45:26,434 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01900
2016-09-27 12:45:26,470 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01900
2016-09-27 12:45:26,507 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01900
2016-09-27 12:45:26,542 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01900
2016-09-27 12:45:26,576 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01900
2016-09-27 12:45:26,611 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01900
2016-09-27 12:45:26,648 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01900
2016-09-27 12:45:26,684 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01900
2016-09-27 12:45:26,719 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:26,752 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01900
2016-09-27 12:45:26,785 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01900
2016-09-27 12:45:26,819 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01900
2016-09-27 12:45:26,853 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01900
2016-09-27 12:45:26,888 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01900
2016-09-27 12:45:26,923 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01900
2016-09-27 12:45:26,958 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01900
2016-09-27 12:45:26,993 : INFO : PROGRESS: at 55.17% examples, 332904 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:26,994 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01900
2016-09-27 12:45:27,032 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01900
2016-09-27 12:45:27,067 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:27,101 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01900
2016-09-27 12:45:27,134 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01900
2016-09-27 12:45:27,168 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01900
2016-09-27 12:45:27,204 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01900
2016-09-27 12:45:27,239 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01900
2016-09-27 12:45:27,274 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01900
2016-09-27 12:45:27,308 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01900
2016-09-27 12:45:27,343 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01900
2016-09-27 12:45:27,377 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01900
2016-09-27 12:45:27,412 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01900
2016-09-27 12:45:27,447 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01900
2016-09-27 12:45:27,480 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01900
2016-09-27 12:45:27,515 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01900
2016-09-27 12:45:27,549 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01900
2016-09-27 12:45:27,583 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01900
2016-09-27 12:45:27,618 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01900
2016-09-27 12:45:27,652 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01900
2016-09-27 12:45:27,686 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01900
2016-09-27 12:45:27,754 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:27,809 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:27,809 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:27,809 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 333042 effective words/s
2016-09-27 12:45:27,809 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:27,809 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:27,810 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01700
2016-09-27 12:45:27,811 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:27,812 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01700
2016-09-27 12:45:27,813 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:27,847 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01700
2016-09-27 12:45:27,881 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01700
2016-09-27 12:45:27,917 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01700
2016-09-27 12:45:27,951 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01700
2016-09-27 12:45:27,986 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01700
2016-09-27 12:45:28,021 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01700
2016-09-27 12:45:28,055 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01700
2016-09-27 12:45:28,091 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01700
2016-09-27 12:45:28,127 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01700
2016-09-27 12:45:28,163 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:28,197 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01700
2016-09-27 12:45:28,231 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01700
2016-09-27 12:45:28,264 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01700
2016-09-27 12:45:28,298 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01700
2016-09-27 12:45:28,332 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01700
2016-09-27 12:45:28,367 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01700
2016-09-27 12:45:28,402 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01700
2016-09-27 12:45:28,436 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01700
2016-09-27 12:45:28,471 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01700
2016-09-27 12:45:28,507 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01700
2016-09-27 12:45:28,542 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:28,575 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01700
2016-09-27 12:45:28,608 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01700
2016-09-27 12:45:28,642 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01700
2016-09-27 12:45:28,676 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01700
2016-09-27 12:45:28,710 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01700
2016-09-27 12:45:28,745 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01700
2016-09-27 12:45:28,780 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01700
2016-09-27 12:45:28,817 : INFO : PROGRESS: at 55.17% examples, 333460 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:28,818 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01700
2016-09-27 12:45:28,854 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01700
2016-09-27 12:45:28,889 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:28,923 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01700
2016-09-27 12:45:28,956 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01700
2016-09-27 12:45:28,990 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01700
2016-09-27 12:45:29,023 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01700
2016-09-27 12:45:29,062 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01700
2016-09-27 12:45:29,097 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01700
2016-09-27 12:45:29,134 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01700
2016-09-27 12:45:29,171 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01700
2016-09-27 12:45:29,208 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01700
2016-09-27 12:45:29,243 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01700
2016-09-27 12:45:29,278 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01700
2016-09-27 12:45:29,312 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01700
2016-09-27 12:45:29,345 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01700
2016-09-27 12:45:29,379 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01700
2016-09-27 12:45:29,413 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01700
2016-09-27 12:45:29,447 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01700
2016-09-27 12:45:29,482 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01700
2016-09-27 12:45:29,515 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01700
2016-09-27 12:45:29,583 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:29,632 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:29,632 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:29,632 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 333464 effective words/s
2016-09-27 12:45:29,632 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:29,633 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:29,634 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01500
2016-09-27 12:45:29,635 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:29,635 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01500
2016-09-27 12:45:29,636 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:29,670 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01500
2016-09-27 12:45:29,708 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01500
2016-09-27 12:45:29,742 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01500
2016-09-27 12:45:29,776 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01500
2016-09-27 12:45:29,810 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01500
2016-09-27 12:45:29,845 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01500
2016-09-27 12:45:29,880 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01500
2016-09-27 12:45:29,914 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01500
2016-09-27 12:45:29,949 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01500
2016-09-27 12:45:29,984 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:30,018 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01500
2016-09-27 12:45:30,051 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01500
2016-09-27 12:45:30,085 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01500
2016-09-27 12:45:30,119 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01500
2016-09-27 12:45:30,154 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01500
2016-09-27 12:45:30,191 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01500
2016-09-27 12:45:30,226 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01500
2016-09-27 12:45:30,264 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01500
2016-09-27 12:45:30,303 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01500
2016-09-27 12:45:30,340 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01500
2016-09-27 12:45:30,376 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:30,409 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01500
2016-09-27 12:45:30,443 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01500
2016-09-27 12:45:30,482 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01500
2016-09-27 12:45:30,518 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01500
2016-09-27 12:45:30,555 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01500
2016-09-27 12:45:30,590 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01500
2016-09-27 12:45:30,631 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01500
2016-09-27 12:45:30,665 : INFO : PROGRESS: at 55.17% examples, 325545 words/s, in_qsize 2, out_qsize 0
2016-09-27 12:45:30,666 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01500
2016-09-27 12:45:30,701 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01500
2016-09-27 12:45:30,737 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:30,773 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01500
2016-09-27 12:45:30,810 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01500
2016-09-27 12:45:30,853 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01500
2016-09-27 12:45:30,893 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01500
2016-09-27 12:45:30,929 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01500
2016-09-27 12:45:30,966 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01500
2016-09-27 12:45:31,004 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01500
2016-09-27 12:45:31,039 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01500
2016-09-27 12:45:31,076 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01500
2016-09-27 12:45:31,111 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01500
2016-09-27 12:45:31,145 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01500
2016-09-27 12:45:31,179 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01500
2016-09-27 12:45:31,214 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01500
2016-09-27 12:45:31,248 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01500
2016-09-27 12:45:31,283 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01500
2016-09-27 12:45:31,322 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01500
2016-09-27 12:45:31,360 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01500
2016-09-27 12:45:31,398 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01500
2016-09-27 12:45:31,468 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:31,518 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:31,518 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:31,518 : INFO : training on 523455 raw words (607490 effective words) took 1.9s, 322403 effective words/s
2016-09-27 12:45:31,518 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:31,519 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:31,520 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01300
2016-09-27 12:45:31,521 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:31,522 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01300
2016-09-27 12:45:31,522 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:31,558 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01300
2016-09-27 12:45:31,594 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01300
2016-09-27 12:45:31,628 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01300
2016-09-27 12:45:31,662 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01300
2016-09-27 12:45:31,698 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01300
2016-09-27 12:45:31,733 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01300
2016-09-27 12:45:31,768 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01300
2016-09-27 12:45:31,806 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01300
2016-09-27 12:45:31,842 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01300
2016-09-27 12:45:31,878 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:31,913 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01300
2016-09-27 12:45:31,948 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01300
2016-09-27 12:45:31,983 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01300
2016-09-27 12:45:32,017 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01300
2016-09-27 12:45:32,053 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01300
2016-09-27 12:45:32,089 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01300
2016-09-27 12:45:32,125 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01300
2016-09-27 12:45:32,160 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01300
2016-09-27 12:45:32,197 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01300
2016-09-27 12:45:32,232 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01300
2016-09-27 12:45:32,269 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:32,302 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01300
2016-09-27 12:45:32,338 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01300
2016-09-27 12:45:32,374 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01300
2016-09-27 12:45:32,409 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01300
2016-09-27 12:45:32,446 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01300
2016-09-27 12:45:32,482 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01300
2016-09-27 12:45:32,517 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01300
2016-09-27 12:45:32,551 : INFO : PROGRESS: at 55.17% examples, 325461 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:32,552 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01300
2016-09-27 12:45:32,587 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01300
2016-09-27 12:45:32,623 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:32,656 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01300
2016-09-27 12:45:32,691 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01300
2016-09-27 12:45:32,726 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01300
2016-09-27 12:45:32,760 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01300
2016-09-27 12:45:32,795 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01300
2016-09-27 12:45:32,831 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01300
2016-09-27 12:45:32,866 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01300
2016-09-27 12:45:32,902 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01300
2016-09-27 12:45:32,938 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01300
2016-09-27 12:45:32,975 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01300
2016-09-27 12:45:33,011 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01300
2016-09-27 12:45:33,045 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01300
2016-09-27 12:45:33,079 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01300
2016-09-27 12:45:33,114 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01300
2016-09-27 12:45:33,149 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01300
2016-09-27 12:45:33,185 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01300
2016-09-27 12:45:33,221 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01300
2016-09-27 12:45:33,259 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01300
2016-09-27 12:45:33,329 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:33,381 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:33,381 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:33,381 : INFO : training on 523455 raw words (607490 effective words) took 1.9s, 326446 effective words/s
2016-09-27 12:45:33,381 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:33,381 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:33,382 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01100
2016-09-27 12:45:33,383 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:33,384 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01100
2016-09-27 12:45:33,385 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:33,421 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01100
2016-09-27 12:45:33,456 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01100
2016-09-27 12:45:33,490 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01100
2016-09-27 12:45:33,524 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01100
2016-09-27 12:45:33,559 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01100
2016-09-27 12:45:33,596 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01100
2016-09-27 12:45:33,630 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01100
2016-09-27 12:45:33,665 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01100
2016-09-27 12:45:33,702 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01100
2016-09-27 12:45:33,736 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:33,769 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01100
2016-09-27 12:45:33,802 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01100
2016-09-27 12:45:33,837 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01100
2016-09-27 12:45:33,871 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01100
2016-09-27 12:45:33,910 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01100
2016-09-27 12:45:33,953 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01100
2016-09-27 12:45:33,992 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01100
2016-09-27 12:45:34,028 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01100
2016-09-27 12:45:34,063 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01100
2016-09-27 12:45:34,098 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01100
2016-09-27 12:45:34,134 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:34,167 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01100
2016-09-27 12:45:34,204 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01100
2016-09-27 12:45:34,238 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01100
2016-09-27 12:45:34,272 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01100
2016-09-27 12:45:34,308 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01100
2016-09-27 12:45:34,344 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01100
2016-09-27 12:45:34,380 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01100
2016-09-27 12:45:34,418 : INFO : PROGRESS: at 55.17% examples, 324119 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:34,419 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01100
2016-09-27 12:45:34,455 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01100
2016-09-27 12:45:34,492 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:34,527 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01100
2016-09-27 12:45:34,560 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01100
2016-09-27 12:45:34,594 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01100
2016-09-27 12:45:34,628 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01100
2016-09-27 12:45:34,662 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01100
2016-09-27 12:45:34,698 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01100
2016-09-27 12:45:34,732 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01100
2016-09-27 12:45:34,766 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01100
2016-09-27 12:45:34,801 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01100
2016-09-27 12:45:34,836 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01100
2016-09-27 12:45:34,873 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01100
2016-09-27 12:45:34,907 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01100
2016-09-27 12:45:34,941 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01100
2016-09-27 12:45:34,975 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01100
2016-09-27 12:45:35,011 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01100
2016-09-27 12:45:35,045 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01100
2016-09-27 12:45:35,080 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01100
2016-09-27 12:45:35,116 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01100
2016-09-27 12:45:35,184 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:35,235 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:35,235 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:35,235 : INFO : training on 523455 raw words (607490 effective words) took 1.9s, 327884 effective words/s
2016-09-27 12:45:35,235 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:35,236 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:35,237 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.00900
2016-09-27 12:45:35,238 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:35,239 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.00900
2016-09-27 12:45:35,240 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:35,274 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.00900
2016-09-27 12:45:35,309 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.00900
2016-09-27 12:45:35,344 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.00900
2016-09-27 12:45:35,380 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.00900
2016-09-27 12:45:35,416 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.00900
2016-09-27 12:45:35,452 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.00900
2016-09-27 12:45:35,490 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.00900
2016-09-27 12:45:35,525 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.00900
2016-09-27 12:45:35,560 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.00900
2016-09-27 12:45:35,597 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:35,631 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.00900
2016-09-27 12:45:35,665 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.00900
2016-09-27 12:45:35,699 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.00900
2016-09-27 12:45:35,733 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.00900
2016-09-27 12:45:35,767 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.00900
2016-09-27 12:45:35,806 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.00900
2016-09-27 12:45:35,841 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.00900
2016-09-27 12:45:35,877 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.00900
2016-09-27 12:45:35,917 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.00900
2016-09-27 12:45:35,957 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.00900
2016-09-27 12:45:35,996 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:36,030 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.00900
2016-09-27 12:45:36,064 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.00900
2016-09-27 12:45:36,100 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.00900
2016-09-27 12:45:36,137 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.00900
2016-09-27 12:45:36,172 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.00900
2016-09-27 12:45:36,209 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.00900
2016-09-27 12:45:36,243 : INFO : PROGRESS: at 53.35% examples, 322011 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:36,244 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.00900
2016-09-27 12:45:36,280 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00900
2016-09-27 12:45:36,315 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00900
2016-09-27 12:45:36,351 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:36,386 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00900
2016-09-27 12:45:36,421 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00900
2016-09-27 12:45:36,457 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00900
2016-09-27 12:45:36,491 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00900
2016-09-27 12:45:36,526 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00900
2016-09-27 12:45:36,563 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00900
2016-09-27 12:45:36,597 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00900
2016-09-27 12:45:36,632 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00900
2016-09-27 12:45:36,667 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00900
2016-09-27 12:45:36,702 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00900
2016-09-27 12:45:36,737 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00900
2016-09-27 12:45:36,770 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00900
2016-09-27 12:45:36,804 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00900
2016-09-27 12:45:36,838 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00900
2016-09-27 12:45:36,873 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00900
2016-09-27 12:45:36,910 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00900
2016-09-27 12:45:36,949 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00900
2016-09-27 12:45:36,985 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00900
2016-09-27 12:45:37,055 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:37,106 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:37,106 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:37,106 : INFO : training on 523455 raw words (607490 effective words) took 1.9s, 325109 effective words/s
2016-09-27 12:45:37,106 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 12:45:37,106 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 12:45:37,108 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.00700
2016-09-27 12:45:37,109 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:37,110 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.00700
2016-09-27 12:45:37,110 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:37,145 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.00700
2016-09-27 12:45:37,180 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.00700
2016-09-27 12:45:37,219 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.00700
2016-09-27 12:45:37,255 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.00700
2016-09-27 12:45:37,290 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.00700
2016-09-27 12:45:37,327 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.00700
2016-09-27 12:45:37,363 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.00700
2016-09-27 12:45:37,399 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.00700
2016-09-27 12:45:37,435 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.00700
2016-09-27 12:45:37,472 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:37,506 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.00700
2016-09-27 12:45:37,540 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.00700
2016-09-27 12:45:37,577 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.00700
2016-09-27 12:45:37,613 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.00700
2016-09-27 12:45:37,647 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.00700
2016-09-27 12:45:37,683 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.00700
2016-09-27 12:45:37,717 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.00700
2016-09-27 12:45:37,752 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.00700
2016-09-27 12:45:37,787 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.00700
2016-09-27 12:45:37,823 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.00700
2016-09-27 12:45:37,859 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:37,893 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.00700
2016-09-27 12:45:37,927 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.00700
2016-09-27 12:45:37,962 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.00700
2016-09-27 12:45:37,998 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.00700
2016-09-27 12:45:38,033 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.00700
2016-09-27 12:45:38,069 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.00700
2016-09-27 12:45:38,104 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.00700
2016-09-27 12:45:38,139 : INFO : PROGRESS: at 55.17% examples, 325537 words/s, in_qsize 1, out_qsize 0
2016-09-27 12:45:38,139 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00700
2016-09-27 12:45:38,179 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00700
2016-09-27 12:45:38,218 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:38,253 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00700
2016-09-27 12:45:38,287 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00700
2016-09-27 12:45:38,323 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00700
2016-09-27 12:45:38,356 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00700
2016-09-27 12:45:38,395 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00700
2016-09-27 12:45:38,433 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00700
2016-09-27 12:45:38,468 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00700
2016-09-27 12:45:38,503 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00700
2016-09-27 12:45:38,539 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00700
2016-09-27 12:45:38,574 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00700
2016-09-27 12:45:38,610 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00700
2016-09-27 12:45:38,643 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00700
2016-09-27 12:45:38,678 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00700
2016-09-27 12:45:38,713 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00700
2016-09-27 12:45:38,747 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00700
2016-09-27 12:45:38,782 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00700
2016-09-27 12:45:38,817 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00700
2016-09-27 12:45:38,858 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00700
2016-09-27 12:45:38,929 : DEBUG : job loop exiting, total 53 jobs
2016-09-27 12:45:38,982 : DEBUG : worker exiting, processed 53 jobs
2016-09-27 12:45:38,982 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-27 12:45:38,982 : INFO : training on 523455 raw words (607490 effective words) took 1.9s, 324143 effective words/s
2016-09-27 12:45:58,885 : INFO : precomputing L2-norms of word weight vectors
2016-09-27 13:50:20,119 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 13:50:20,334 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 13:50:20,334 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 13:50:20,512 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 13:50:20,512 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 13:50:20,513 : INFO : PROGRESS: saving document #0
2016-09-27 13:50:20,651 : INFO : PROGRESS: saving document #1000
2016-09-27 13:50:20,785 : INFO : PROGRESS: saving document #2000
2016-09-27 13:50:20,921 : INFO : PROGRESS: saving document #3000
2016-09-27 13:50:20,933 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 13:50:20,933 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 13:50:20,935 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 13:50:20,935 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 13:50:20,936 : INFO : collecting document frequencies
2016-09-27 13:50:20,936 : INFO : PROGRESS: processing document #0
2016-09-27 13:50:20,970 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 13:50:20,984 : INFO : using serial LSI version on this node
2016-09-27 13:50:20,984 : INFO : updating model with new documents
2016-09-27 13:50:21,169 : INFO : preparing a new chunk of documents
2016-09-27 13:50:21,170 : DEBUG : converting corpus to csc format
2016-09-27 13:50:21,209 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 13:50:21,209 : INFO : 1st phase: constructing (14590, 300) action matrix
2016-09-27 13:50:21,282 : INFO : orthonormalizing (14590, 300) action matrix
2016-09-27 13:50:21,323 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:50:21,419 : DEBUG : running 2 power iterations
2016-09-27 13:50:21,503 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:50:21,679 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:50:21,805 : INFO : 2nd phase: running dense svd on (300, 3090) matrix
2016-09-27 13:50:21,874 : INFO : computing the final decomposition
2016-09-27 13:50:21,874 : INFO : keeping 200 factors (discarding 18.798% of energy spectrum)
2016-09-27 13:50:21,915 : INFO : processed documents up to #3090
2016-09-27 13:50:21,921 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 13:50:21,922 : INFO : topic #1(3.593): 0.416*"visa" + 0.302*"visit" + -0.256*"where" + 0.238*"my" + -0.181*"buy" + 0.179*"family" + -0.152*"anyone" + -0.134*"find" + -0.127*"know" + -0.126*"does"
2016-09-27 13:50:21,922 : INFO : topic #2(3.148): -0.288*"where" + -0.254*"can" + -0.253*"visa" + 0.250*"you" + 0.211*"do" + -0.205*"visit" + -0.200*"me" + -0.186*"tell" + 0.185*"are" + 0.179*"what"
2016-09-27 13:50:21,922 : INFO : topic #3(2.912): 0.359*"car" + -0.279*"does" + -0.267*"we" + -0.224*"visa" + -0.216*"know" + 0.208*"driving" + -0.180*"anyone" + -0.164*"visit" + -0.158*"are" + -0.152*"doha?"
2016-09-27 13:50:21,923 : INFO : topic #4(2.840): -0.461*"you" + -0.300*"do" + -0.207*"?" + -0.188*"what" + -0.158*"best" + -0.156*"your" + 0.154*"does" + 0.151*"anyone" + -0.148*"how" + -0.139*"buy"
2016-09-27 13:50:21,932 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 13:50:21,990 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 13:50:21,990 : INFO : not storing attribute projection
2016-09-27 13:50:21,991 : INFO : not storing attribute dispatcher
2016-09-27 13:50:22,024 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 13:50:22,033 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 13:50:22,034 : INFO : setting ignored attribute projection to None
2016-09-27 13:50:22,034 : INFO : setting ignored attribute dispatcher to None
2016-09-27 13:50:22,034 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 13:50:22,066 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 13:50:22,354 : INFO : creating matrix with 3090 documents and 200 features
2016-09-27 13:50:22,363 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 13:50:22,477 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 13:50:22,600 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 13:50:22,718 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 13:50:22,728 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 13:50:22,733 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 13:58:51,975 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-27 13:58:52,204 : INFO : built Dictionary(14590 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3090 documents (total 88886 corpus positions)
2016-09-27 13:58:52,205 : INFO : saving Dictionary object under ./tmp/genImp2/genImp2.dict, separately None
2016-09-27 13:58:52,404 : INFO : storing corpus in Matrix Market format to ./tmp/genImp2/genImp2.mm
2016-09-27 13:58:52,404 : INFO : saving sparse matrix to ./tmp/genImp2/genImp2.mm
2016-09-27 13:58:52,404 : INFO : PROGRESS: saving document #0
2016-09-27 13:58:52,539 : INFO : PROGRESS: saving document #1000
2016-09-27 13:58:52,674 : INFO : PROGRESS: saving document #2000
2016-09-27 13:58:52,810 : INFO : PROGRESS: saving document #3000
2016-09-27 13:58:52,822 : INFO : saved 3090x14590 matrix, density=0.176% (79267/45083100)
2016-09-27 13:58:52,822 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 13:58:52,824 : DEBUG : closing ./tmp/genImp2/genImp2.mm
2016-09-27 13:58:52,824 : INFO : saving MmCorpus index to ./tmp/genImp2/genImp2.mm.index
2016-09-27 13:58:52,825 : INFO : collecting document frequencies
2016-09-27 13:58:52,825 : INFO : PROGRESS: processing document #0
2016-09-27 13:58:52,860 : INFO : calculating IDF weights for 3090 documents and 14589 features (79267 matrix non-zeros)
2016-09-27 13:58:52,874 : INFO : using serial LSI version on this node
2016-09-27 13:58:52,874 : INFO : updating model with new documents
2016-09-27 13:58:53,051 : INFO : preparing a new chunk of documents
2016-09-27 13:58:53,052 : DEBUG : converting corpus to csc format
2016-09-27 13:58:53,091 : INFO : using 100 extra samples and 2 power iterations
2016-09-27 13:58:53,091 : INFO : 1st phase: constructing (14590, 300) action matrix
2016-09-27 13:58:53,165 : INFO : orthonormalizing (14590, 300) action matrix
2016-09-27 13:58:53,208 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:58:53,302 : DEBUG : running 2 power iterations
2016-09-27 13:58:53,389 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:58:53,558 : DEBUG : computing QR of (14590, 300) dense matrix
2016-09-27 13:58:53,682 : INFO : 2nd phase: running dense svd on (300, 3090) matrix
2016-09-27 13:58:53,753 : INFO : computing the final decomposition
2016-09-27 13:58:53,753 : INFO : keeping 200 factors (discarding 18.801% of energy spectrum)
2016-09-27 13:58:53,795 : INFO : processed documents up to #3090
2016-09-27 13:58:53,802 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 13:58:53,802 : INFO : topic #1(3.593): 0.415*"visa" + 0.302*"visit" + -0.257*"where" + 0.237*"my" + -0.181*"buy" + 0.179*"family" + -0.151*"anyone" + -0.133*"find" + -0.127*"know" + -0.127*"does"
2016-09-27 13:58:53,802 : INFO : topic #2(3.148): -0.288*"where" + -0.254*"can" + -0.252*"visa" + 0.250*"you" + 0.210*"do" + -0.205*"visit" + -0.200*"me" + -0.187*"tell" + 0.185*"are" + 0.181*"what"
2016-09-27 13:58:53,803 : INFO : topic #3(2.912): -0.358*"car" + 0.277*"does" + 0.268*"we" + 0.223*"visa" + 0.217*"know" + -0.208*"driving" + 0.182*"anyone" + 0.164*"visit" + 0.159*"are" + 0.152*"doha?"
2016-09-27 13:58:53,803 : INFO : topic #4(2.840): 0.462*"you" + 0.301*"do" + 0.205*"?" + 0.185*"what" + 0.157*"best" + 0.157*"your" + -0.156*"does" + -0.152*"anyone" + 0.146*"how" + 0.137*"buy"
2016-09-27 13:58:53,813 : INFO : saving Projection object under ./tmp/genImp2/genImp2.lsi.projection, separately None
2016-09-27 13:58:53,870 : INFO : saving LsiModel object under ./tmp/genImp2/genImp2.lsi, separately None
2016-09-27 13:58:53,870 : INFO : not storing attribute projection
2016-09-27 13:58:53,870 : INFO : not storing attribute dispatcher
2016-09-27 13:58:53,904 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi
2016-09-27 13:58:53,914 : INFO : loading id2word recursively from ./tmp/genImp2/genImp2.lsi.id2word.* with mmap=None
2016-09-27 13:58:53,914 : INFO : setting ignored attribute projection to None
2016-09-27 13:58:53,914 : INFO : setting ignored attribute dispatcher to None
2016-09-27 13:58:53,914 : INFO : loading LsiModel object from ./tmp/genImp2/genImp2.lsi.projection
2016-09-27 13:58:53,947 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-27 13:58:54,217 : INFO : creating matrix with 3090 documents and 200 features
2016-09-27 13:58:54,225 : DEBUG : PROGRESS: at document #0/3090
2016-09-27 13:58:54,337 : DEBUG : PROGRESS: at document #1000/3090
2016-09-27 13:58:54,463 : DEBUG : PROGRESS: at document #2000/3090
2016-09-27 13:58:54,582 : DEBUG : PROGRESS: at document #3000/3090
2016-09-27 13:58:54,592 : INFO : saving MatrixSimilarity object under ./tmp/genImp2/genImp2.index, separately None
2016-09-27 13:58:54,595 : INFO : loading MatrixSimilarity object from ./tmp/genImp2/genImp2.index
2016-09-27 13:59:25,147 : INFO : topic #0(7.044): 0.198*"i" + 0.175*"my" + 0.159*"can" + 0.155*"is" + 0.143*"it" + 0.141*"me" + 0.133*"you" + 0.133*"have" + 0.131*"if" + 0.131*"any"
2016-09-27 13:59:25,148 : INFO : topic #1(3.593): 0.415*"visa" + 0.302*"visit" + -0.257*"where" + 0.237*"my" + -0.181*"buy" + 0.179*"family" + -0.151*"anyone" + -0.133*"find" + -0.127*"know" + -0.127*"does"
2016-09-27 13:59:25,149 : INFO : topic #2(3.148): -0.288*"where" + -0.254*"can" + -0.252*"visa" + 0.250*"you" + 0.210*"do" + -0.205*"visit" + -0.200*"me" + -0.187*"tell" + 0.185*"are" + 0.181*"what"
2016-09-27 13:59:25,150 : INFO : topic #3(2.912): -0.358*"car" + 0.277*"does" + 0.268*"we" + 0.223*"visa" + 0.217*"know" + -0.208*"driving" + 0.182*"anyone" + 0.164*"visit" + 0.159*"are" + 0.152*"doha?"
2016-09-27 13:59:25,151 : INFO : topic #4(2.840): 0.462*"you" + 0.301*"do" + 0.205*"?" + 0.185*"what" + 0.157*"best" + 0.157*"your" + -0.156*"does" + -0.152*"anyone" + 0.146*"how" + 0.137*"buy"
2016-09-27 13:59:25,152 : INFO : topic #5(2.782): 0.406*"?" + 0.266*"how" + 0.259*"does" + 0.243*"driving" + -0.222*"me" + -0.197*"we" + 0.195*"much" + 0.194*"it" + -0.167*"tell" + -0.162*"please"
2016-09-27 13:59:25,153 : INFO : topic #6(2.716): -0.514*"we" + 0.186*"you" + 0.179*"me" + 0.177*"how" + -0.167*"?" + -0.165*"are" + -0.162*"buy" + 0.161*"much" + -0.161*"where" + -0.149*"best"
2016-09-27 13:59:25,153 : INFO : topic #7(2.666): -0.479*"driving" + 0.323*"?" + -0.210*"school" + 0.190*"car" + 0.188*"is" + 0.171*"there" + -0.170*"license" + 0.165*"one" + 0.146*"which" + 0.143*"any"
2016-09-27 13:59:25,154 : INFO : topic #8(2.648): 0.352*"driving" + -0.274*"buy" + 0.229*"school" + -0.213*"where" + 0.180*"me" + 0.174*"?" + 0.172*"please" + -0.164*"i" + -0.163*"car" + 0.157*"any"
2016-09-27 13:59:25,154 : INFO : topic #9(2.632): -0.398*"?" + 0.343*"car" + 0.320*"how" + 0.268*"we" + 0.251*"much" + -0.161*"find" + 0.139*"will" + 0.133*"it" + -0.122*";" + -0.118*"you"
2016-09-27 15:31:30,826 : INFO : collecting all words and their counts
2016-09-27 15:31:30,826 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-27 15:31:30,960 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-27 15:31:30,970 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-27 15:31:30,970 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-27 15:31:30,974 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-27 15:31:30,974 : INFO : sample=0 downsamples 0 most-common words
2016-09-27 15:31:30,974 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-27 15:31:30,974 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-27 15:31:30,976 : INFO : constructing a huffman tree from 1902 words
2016-09-27 15:31:31,023 : INFO : built huffman tree with maximum node depth 14
2016-09-27 15:31:31,023 : INFO : resetting layer weights
2016-09-27 15:31:31,044 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 15:31:31,044 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 15:31:31,046 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-27 15:31:31,047 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-27 15:31:31,047 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-27 15:31:31,048 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-27 15:31:31,049 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-27 15:31:31,049 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-27 15:31:31,050 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-27 15:31:31,050 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-27 15:31:31,051 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-27 15:32:56,937 : INFO : collecting all words and their counts
2016-09-27 15:32:56,937 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-27 15:32:57,065 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-27 15:32:57,075 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-27 15:32:57,075 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-27 15:32:57,080 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-27 15:32:57,080 : INFO : sample=0 downsamples 0 most-common words
2016-09-27 15:32:57,080 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-27 15:32:57,080 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-27 15:32:57,082 : INFO : constructing a huffman tree from 1902 words
2016-09-27 15:32:57,129 : INFO : built huffman tree with maximum node depth 14
2016-09-27 15:32:57,129 : INFO : resetting layer weights
2016-09-27 15:32:57,149 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-27 15:32:57,149 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-27 15:32:57,151 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-27 15:32:57,152 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-27 15:32:57,153 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-27 15:32:57,153 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-27 15:32:57,154 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-27 15:32:57,154 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-27 15:32:57,155 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-27 15:32:57,155 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-27 15:32:57,156 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:15:30,193 : INFO : collecting all words and their counts
2016-09-28 10:15:30,194 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:15:30,341 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:15:30,352 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:15:30,352 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:15:30,356 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:15:30,356 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:15:30,356 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:15:30,356 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:15:30,358 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:15:30,412 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:15:30,412 : INFO : resetting layer weights
2016-09-28 10:15:30,433 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:15:30,433 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:15:30,435 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:15:30,435 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:15:30,436 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:15:30,437 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:15:30,437 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:15:30,438 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:15:30,438 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:15:30,439 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:15:30,439 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:33:09,478 : INFO : collecting all words and their counts
2016-09-28 10:33:09,478 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:33:09,617 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:33:09,630 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:33:09,630 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:33:09,635 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:33:09,635 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:33:09,635 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:33:09,635 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:33:09,637 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:33:09,685 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:33:09,686 : INFO : resetting layer weights
2016-09-28 10:33:09,707 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:33:09,707 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:33:09,709 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:33:09,710 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:33:09,713 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:33:09,714 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:33:09,715 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:33:09,716 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:33:09,717 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:33:09,718 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:33:09,719 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:33:09,720 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:33:09,721 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:33:09,722 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:33:09,722 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:33:09,782 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:33:09,784 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:33:09,785 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:33:09,790 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:33:09,850 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:33:09,853 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:33:09,855 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:33:09,859 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:33:09,918 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:33:09,921 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:33:09,924 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:33:09,927 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:33:09,986 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:33:09,988 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:33:09,991 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:33:09,996 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:33:10,052 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:33:10,057 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:33:10,058 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:33:10,064 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:33:10,120 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:33:10,122 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:33:10,124 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:33:10,133 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:33:10,191 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:33:10,197 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:33:10,198 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:33:10,205 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:33:10,259 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:33:10,266 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:33:10,270 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:33:10,271 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:33:10,327 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:33:10,334 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:33:10,335 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:33:10,338 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:33:10,394 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:33:10,400 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:33:10,403 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:33:10,406 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:33:10,527 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:33:10,594 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:33:10,594 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:33:10,595 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:33:10,596 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:33:10,599 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:33:10,599 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:33:10,607 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:33:10,607 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:33:10,607 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 676540 effective words/s
2016-09-28 10:34:17,852 : INFO : collecting all words and their counts
2016-09-28 10:34:17,852 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:34:17,995 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:34:18,005 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:34:18,005 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:34:18,010 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:34:18,010 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:34:18,010 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:34:18,010 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:34:18,012 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:34:18,059 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:34:18,059 : INFO : resetting layer weights
2016-09-28 10:34:18,080 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:34:18,080 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:34:18,082 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:34:18,082 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:34:18,083 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:34:18,085 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:34:18,086 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:34:18,087 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:34:18,089 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:34:18,089 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:34:18,090 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:34:18,092 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:34:18,092 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:34:18,094 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:34:18,095 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:34:18,154 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:34:18,155 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:34:18,157 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:34:18,159 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:34:18,221 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:34:18,223 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:34:18,225 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:34:18,226 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:34:18,286 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:34:18,290 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:34:18,292 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:34:18,296 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:34:18,353 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:34:18,356 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:34:18,361 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:34:18,367 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:34:18,421 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:34:18,423 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:34:18,426 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:34:18,436 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:34:18,486 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:34:18,488 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:34:18,491 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:34:18,504 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:34:18,551 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:34:18,559 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:34:18,561 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:34:18,573 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:34:18,619 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:34:18,626 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:34:18,629 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:34:18,638 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:34:18,683 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:34:18,691 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:34:18,694 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:34:18,705 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:34:18,754 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:34:18,758 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:34:18,760 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:34:18,772 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:34:18,884 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:34:18,950 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:34:18,951 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:34:18,951 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:34:18,951 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:34:18,957 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:34:18,957 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:34:18,964 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:34:18,964 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:34:18,964 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 688751 effective words/s
2016-09-28 10:41:09,527 : INFO : collecting all words and their counts
2016-09-28 10:41:09,527 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:41:09,666 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:41:09,676 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:41:09,676 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:41:09,681 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:41:09,681 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:41:09,681 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:41:09,681 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:41:09,683 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:41:09,730 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:41:09,731 : INFO : resetting layer weights
2016-09-28 10:41:09,751 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:41:09,752 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:41:09,754 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:41:09,755 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:41:09,756 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:41:09,757 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:41:09,758 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:41:09,759 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:41:09,760 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:41:09,761 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:41:09,762 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:41:09,763 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:41:09,764 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:41:09,766 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:41:09,767 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:41:09,826 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:41:09,828 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:41:09,831 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:41:09,833 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:41:09,892 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:41:09,896 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:41:09,897 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:41:09,904 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:41:09,959 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:41:09,962 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:41:09,966 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:41:09,969 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:41:10,026 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:41:10,029 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:41:10,035 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:41:10,037 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:41:10,092 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:41:10,096 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:41:10,103 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:41:10,106 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:41:10,163 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:41:10,166 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:41:10,174 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:41:10,178 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:41:10,235 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:41:10,237 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:41:10,247 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:41:10,249 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:41:10,299 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:41:10,306 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:41:10,315 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:41:10,317 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:41:10,364 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:41:10,375 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:41:10,381 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:41:10,385 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:41:10,437 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:41:10,441 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:41:10,447 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:41:10,451 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:41:10,571 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:41:10,637 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:10,637 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:41:10,640 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:10,640 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:41:10,641 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:10,641 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:41:10,650 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:41:10,650 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:41:10,650 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 677820 effective words/s
2016-09-28 10:41:54,854 : INFO : collecting all words and their counts
2016-09-28 10:41:54,854 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:41:54,988 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:41:54,999 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:41:54,999 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:41:55,003 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:41:55,003 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:41:55,003 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:41:55,004 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:41:55,005 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:41:55,111 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:41:55,112 : INFO : resetting layer weights
2016-09-28 10:41:55,132 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:41:55,133 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:41:55,135 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:41:55,135 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:41:55,138 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:41:55,139 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:41:55,140 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:41:55,141 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:41:55,142 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:41:55,143 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:41:55,144 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:41:55,144 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:41:55,145 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:41:55,146 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:41:55,147 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:41:55,208 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:41:55,210 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:41:55,213 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:41:55,216 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:41:55,274 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:41:55,278 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:41:55,280 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:41:55,282 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:41:55,342 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:41:55,343 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:41:55,348 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:41:55,349 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:41:55,410 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:41:55,411 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:41:55,414 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:41:55,419 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:41:55,476 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:41:55,477 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:41:55,479 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:41:55,489 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:41:55,537 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:41:55,546 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:41:55,548 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:41:55,556 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:41:55,605 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:41:55,615 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:41:55,618 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:41:55,625 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:41:55,670 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:41:55,682 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:41:55,688 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:41:55,695 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:41:55,736 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:41:55,749 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:41:55,752 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:41:55,760 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:41:55,807 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:41:55,816 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:41:55,818 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:41:55,826 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:41:55,937 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:41:56,007 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:56,008 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:41:56,012 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:56,012 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:41:56,014 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:41:56,015 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:41:56,020 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:41:56,021 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:41:56,021 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 685301 effective words/s
2016-09-28 10:42:19,821 : INFO : collecting all words and their counts
2016-09-28 10:42:19,821 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:42:19,970 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:42:19,980 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:42:19,981 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:42:19,985 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:42:19,986 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:42:19,986 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:42:19,986 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:42:19,988 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:42:20,037 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:42:20,038 : INFO : resetting layer weights
2016-09-28 10:42:20,060 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:42:20,060 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:42:20,062 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:42:20,063 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:42:20,064 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:42:20,065 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:42:20,067 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:42:20,068 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:42:20,069 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:42:20,070 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:42:20,070 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:42:20,071 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:42:20,072 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:42:20,073 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:42:20,074 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:42:20,135 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:42:20,136 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:42:20,139 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:42:20,140 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:42:20,204 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:42:20,206 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:42:20,206 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:42:20,210 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:42:20,268 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:42:20,271 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:42:20,275 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:42:20,278 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:42:20,335 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:42:20,339 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:42:20,344 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:42:20,347 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:42:20,401 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:42:20,405 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:42:20,411 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:42:20,414 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:42:20,468 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:42:20,472 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:42:20,477 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:42:20,482 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:42:20,536 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:42:20,540 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:42:20,545 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:42:20,548 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:42:20,604 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:42:20,609 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:42:20,611 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:42:20,614 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:42:20,668 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:42:20,676 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:42:20,678 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:42:20,682 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:42:20,739 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:42:20,742 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:42:20,746 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:42:20,748 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:42:20,867 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:42:20,935 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:20,935 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:42:20,936 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:20,936 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:42:20,941 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:42:20,941 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:20,949 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:42:20,949 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:42:20,949 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 685350 effective words/s
2016-09-28 10:42:44,820 : INFO : collecting all words and their counts
2016-09-28 10:42:44,820 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:42:44,959 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:42:44,970 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:42:44,970 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:42:44,974 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:42:44,974 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:42:44,974 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:42:44,975 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:42:44,976 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:42:45,023 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:42:45,024 : INFO : resetting layer weights
2016-09-28 10:42:45,044 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:42:45,044 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:42:45,046 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:42:45,048 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:42:45,049 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:42:45,050 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:42:45,051 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:42:45,052 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:42:45,053 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:42:45,054 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:42:45,055 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:42:45,056 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:42:45,057 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:42:45,057 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:42:45,058 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:42:45,118 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:42:45,120 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:42:45,123 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:42:45,129 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:42:45,186 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:42:45,189 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:42:45,191 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:42:45,195 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:42:45,254 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:42:45,256 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:42:45,259 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:42:45,261 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:42:45,322 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:42:45,325 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:42:45,328 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:42:45,331 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:42:45,390 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:42:45,391 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:42:45,397 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:42:45,401 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:42:45,455 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:42:45,457 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:42:45,464 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:42:45,470 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:42:45,520 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:42:45,522 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:42:45,533 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:42:45,540 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:42:45,589 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:42:45,591 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:42:45,601 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:42:45,603 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:42:45,656 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:42:45,659 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:42:45,665 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:42:45,671 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:42:45,725 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:42:45,727 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:42:45,729 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:42:45,736 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:42:45,856 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:42:45,920 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:45,920 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:42:45,921 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:45,922 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:42:45,925 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:42:45,926 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:42:45,933 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:42:45,934 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:42:45,934 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 684833 effective words/s
2016-09-28 10:44:41,793 : INFO : collecting all words and their counts
2016-09-28 10:44:41,793 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:44:41,931 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:44:41,941 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:44:41,942 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:44:41,946 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:44:41,946 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:44:41,946 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:44:41,946 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:44:41,948 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:44:41,995 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:44:41,995 : INFO : resetting layer weights
2016-09-28 10:44:42,016 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:44:42,016 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:44:42,019 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:44:42,020 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:44:42,021 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:44:42,022 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:44:42,023 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:44:42,024 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:44:42,025 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:44:42,026 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:44:42,027 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:44:42,028 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:44:42,029 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:44:42,030 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:44:42,032 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:44:42,088 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:44:42,092 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:44:42,096 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:44:42,097 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:44:42,153 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:44:42,158 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:44:42,163 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:44:42,166 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:44:42,221 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:44:42,233 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:44:42,235 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:44:42,238 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:44:42,292 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:44:42,302 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:44:42,304 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:44:42,310 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:44:42,360 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:44:42,368 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:44:42,370 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:44:42,379 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:44:42,428 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:44:42,435 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:44:42,437 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:44:42,445 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:44:42,495 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:44:42,503 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:44:42,507 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:44:42,513 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:44:42,563 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:44:42,571 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:44:42,576 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:44:42,581 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:44:42,629 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:44:42,637 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:44:42,641 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:44:42,650 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:44:42,699 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:44:42,702 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:44:42,709 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:44:42,714 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:44:42,829 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:44:42,896 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:44:42,897 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:44:42,899 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:44:42,900 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:44:42,904 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:44:42,904 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:44:42,910 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:44:42,910 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:44:42,910 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 681681 effective words/s
2016-09-28 10:45:12,575 : INFO : collecting all words and their counts
2016-09-28 10:45:12,575 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:45:12,714 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:45:12,726 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:45:12,726 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:45:12,731 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:45:12,731 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:45:12,731 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:45:12,731 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:45:12,733 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:45:12,783 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:45:12,783 : INFO : resetting layer weights
2016-09-28 10:45:12,804 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:45:12,805 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:45:12,807 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:45:12,807 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:45:12,809 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:45:12,810 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:45:12,812 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:45:12,813 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:45:12,814 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:45:12,815 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:45:12,815 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:45:12,816 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:45:12,817 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:45:12,818 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:45:12,819 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:45:12,887 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:45:12,893 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:45:12,895 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:45:12,899 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:45:12,969 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:45:12,976 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:45:12,979 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:45:12,981 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:45:13,055 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:45:13,060 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:45:13,067 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:45:13,070 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:45:13,144 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:45:13,146 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:45:13,155 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:45:13,158 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:45:13,221 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:45:13,225 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:45:13,233 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:45:13,237 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:45:13,293 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:45:13,298 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:45:13,306 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:45:13,309 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:45:13,367 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:45:13,369 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:45:13,381 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:45:13,383 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:45:13,442 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:45:13,443 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:45:13,455 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:45:13,460 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:45:13,515 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:45:13,517 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:45:13,528 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:45:13,535 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:45:13,587 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:45:13,594 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:45:13,602 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:45:13,608 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:45:13,736 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:45:13,808 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:45:13,808 : INFO : PROGRESS: at 95.20% examples, 577522 words/s, in_qsize 3, out_qsize 1
2016-09-28 10:45:13,809 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:45:13,812 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:45:13,812 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:45:13,814 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:45:13,814 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:45:13,822 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:45:13,823 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:45:13,823 : INFO : training on 523455 raw words (607490 effective words) took 1.0s, 597710 effective words/s
2016-09-28 10:47:38,763 : INFO : collecting all words and their counts
2016-09-28 10:47:38,763 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:47:38,897 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:47:38,907 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:47:38,907 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:47:38,912 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:47:38,912 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:47:38,912 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:47:38,912 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:47:38,914 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:47:38,961 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:47:38,961 : INFO : resetting layer weights
2016-09-28 10:47:38,982 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:47:38,982 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:47:38,984 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:47:38,985 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:47:38,986 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:47:38,988 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:47:38,989 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:47:38,990 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:47:38,991 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:47:38,993 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:47:38,994 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:47:38,995 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:47:38,995 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:47:38,996 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:47:38,997 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:47:39,055 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:47:39,058 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:47:39,059 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:47:39,063 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:47:39,123 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:47:39,126 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:47:39,128 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:47:39,130 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:47:39,192 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:47:39,194 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:47:39,197 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:47:39,198 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:47:39,257 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:47:39,260 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:47:39,262 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:47:39,268 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:47:39,326 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:47:39,327 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:47:39,328 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:47:39,338 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:47:39,390 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:47:39,394 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:47:39,395 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:47:39,407 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:47:39,457 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:47:39,461 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:47:39,462 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:47:39,474 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:47:39,526 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:47:39,529 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:47:39,534 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:47:39,539 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:47:39,606 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:47:39,606 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:47:39,617 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:47:39,619 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:47:39,679 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:47:39,682 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:47:39,688 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:47:39,689 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:47:39,812 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:47:39,877 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:39,878 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:47:39,878 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:39,879 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:47:39,879 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:39,879 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:47:39,889 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:47:39,890 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:47:39,890 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 671038 effective words/s
2016-09-28 10:47:53,203 : INFO : collecting all words and their counts
2016-09-28 10:47:53,203 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:47:53,339 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:47:53,349 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:47:53,349 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:47:53,353 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:47:53,354 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:47:53,354 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:47:53,354 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:47:53,355 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:47:53,403 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:47:53,404 : INFO : resetting layer weights
2016-09-28 10:47:53,424 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:47:53,424 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:47:53,427 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:47:53,428 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:47:53,429 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:47:53,430 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:47:53,432 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:47:53,434 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:47:53,435 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:47:53,436 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:47:53,437 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:47:53,438 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:47:53,438 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:47:53,439 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:47:53,440 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:47:53,499 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:47:53,502 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:47:53,504 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:47:53,506 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:47:53,564 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:47:53,568 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:47:53,573 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:47:53,574 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:47:53,633 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:47:53,638 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:47:53,639 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:47:53,642 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:47:53,699 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:47:53,702 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:47:53,708 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:47:53,709 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:47:53,764 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:47:53,769 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:47:53,775 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:47:53,779 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:47:53,831 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:47:53,834 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:47:53,843 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:47:53,845 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:47:53,898 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:47:53,902 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:47:53,911 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:47:53,912 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:47:53,964 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:47:53,966 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:47:53,977 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:47:53,983 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:47:54,028 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:47:54,034 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:47:54,042 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:47:54,050 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:47:54,100 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:47:54,102 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:47:54,107 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:47:54,115 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:47:54,231 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:47:54,295 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:54,295 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:47:54,298 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:54,298 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:47:54,306 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:54,306 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:47:54,310 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:47:54,310 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:47:54,311 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 687468 effective words/s
2016-09-28 10:47:57,307 : INFO : collecting all words and their counts
2016-09-28 10:47:57,307 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:47:57,440 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:47:57,450 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:47:57,450 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:47:57,454 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:47:57,454 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:47:57,455 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:47:57,455 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:47:57,456 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:47:57,505 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:47:57,505 : INFO : resetting layer weights
2016-09-28 10:47:57,526 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:47:57,526 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:47:57,528 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:47:57,529 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:47:57,530 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:47:57,532 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:47:57,533 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:47:57,534 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:47:57,535 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:47:57,536 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:47:57,537 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:47:57,538 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:47:57,539 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:47:57,540 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:47:57,541 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:47:57,599 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:47:57,603 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:47:57,604 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:47:57,607 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:47:57,668 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:47:57,669 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:47:57,671 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:47:57,676 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:47:57,735 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:47:57,737 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:47:57,739 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:47:57,741 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:47:57,801 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:47:57,804 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:47:57,807 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:47:57,810 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:47:57,868 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:47:57,871 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:47:57,874 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:47:57,879 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:47:57,934 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:47:57,938 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:47:57,940 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:47:57,945 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:47:58,001 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:47:58,006 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:47:58,010 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:47:58,013 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:47:58,066 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:47:58,072 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:47:58,078 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:47:58,081 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:47:58,134 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:47:58,139 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:47:58,145 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:47:58,147 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:47:58,203 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:47:58,205 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:47:58,214 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:47:58,217 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:47:58,335 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:47:58,401 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:58,401 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:47:58,404 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:58,404 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:47:58,408 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:47:58,408 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:47:58,415 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:47:58,415 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:47:58,415 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 684864 effective words/s
2016-09-28 10:48:09,802 : INFO : collecting all words and their counts
2016-09-28 10:48:09,802 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:48:09,940 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:48:09,951 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:48:09,951 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:48:09,955 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:48:09,956 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:48:09,956 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:48:09,956 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:48:09,957 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:48:10,004 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:48:10,005 : INFO : resetting layer weights
2016-09-28 10:48:10,025 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:48:10,025 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:48:10,027 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:48:10,029 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:48:10,030 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:48:10,031 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:48:10,032 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:48:10,033 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:48:10,034 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:48:10,035 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:48:10,035 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:48:10,036 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:48:10,037 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:48:10,038 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:48:10,039 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:48:10,099 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:48:10,101 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:48:10,103 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:48:10,107 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:48:10,175 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:48:10,176 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:48:10,179 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:48:10,181 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:48:10,243 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:48:10,245 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:48:10,248 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:48:10,250 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:48:10,308 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:48:10,313 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:48:10,314 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:48:10,322 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:48:10,374 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:48:10,380 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:48:10,382 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:48:10,392 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:48:10,442 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:48:10,446 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:48:10,448 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:48:10,460 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:48:10,508 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:48:10,512 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:48:10,518 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:48:10,527 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:48:10,576 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:48:10,582 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:48:10,589 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:48:10,592 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:48:10,644 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:48:10,648 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:48:10,656 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:48:10,659 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:48:10,712 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:48:10,714 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:48:10,722 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:48:10,729 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:48:10,843 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:48:10,911 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:10,912 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:48:10,916 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:10,916 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:48:10,917 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:48:10,917 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:10,924 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:48:10,924 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:48:10,924 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 677766 effective words/s
2016-09-28 10:48:31,033 : INFO : collecting all words and their counts
2016-09-28 10:48:31,034 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:48:31,186 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:48:31,197 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:48:31,197 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:48:31,201 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:48:31,201 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:48:31,201 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:48:31,201 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:48:31,203 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:48:31,250 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:48:31,250 : INFO : resetting layer weights
2016-09-28 10:48:31,271 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:48:31,271 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:48:31,273 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:48:31,274 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:48:31,276 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:48:31,277 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:48:31,278 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:48:31,279 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:48:31,281 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:48:31,282 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:48:31,283 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:48:31,283 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:48:31,284 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:48:31,285 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:48:31,286 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:48:31,344 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:48:31,347 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:48:31,350 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:48:31,354 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:48:31,411 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:48:31,413 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:48:31,422 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:48:31,423 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:48:31,481 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:48:31,481 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:48:31,488 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:48:31,489 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:48:31,547 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:48:31,550 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:48:31,557 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:48:31,560 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:48:31,614 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:48:31,615 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:48:31,625 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:48:31,628 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:48:31,678 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:48:31,680 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:48:31,690 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:48:31,698 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:48:31,744 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:48:31,748 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:48:31,757 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:48:31,765 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:48:31,811 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:48:31,816 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:48:31,828 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:48:31,832 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:48:31,877 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:48:31,883 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:48:31,896 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:48:31,899 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:48:31,946 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:48:31,951 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:48:31,962 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:48:31,965 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:48:32,073 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:48:32,138 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:32,139 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:48:32,153 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:32,154 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:48:32,156 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:48:32,157 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:48:32,158 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:48:32,158 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:48:32,158 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 686828 effective words/s
2016-09-28 10:50:13,006 : INFO : collecting all words and their counts
2016-09-28 10:50:13,007 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:50:13,144 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:50:13,154 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:50:13,154 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:50:13,158 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:50:13,158 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:50:13,158 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:50:13,158 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:50:13,160 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:50:13,212 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:50:13,212 : INFO : resetting layer weights
2016-09-28 10:50:13,232 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:50:13,233 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:50:13,235 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:50:13,236 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:50:13,237 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:50:13,238 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:50:13,239 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:50:13,241 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:50:13,242 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:50:13,242 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:50:13,243 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:50:13,244 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:50:13,245 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:50:13,246 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:50:13,247 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:50:13,307 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:50:13,308 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:50:13,309 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:50:13,313 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:50:13,372 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:50:13,375 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:50:13,378 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:50:13,380 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:50:13,442 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:50:13,445 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:50:13,447 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:50:13,452 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:50:13,509 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:50:13,513 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:50:13,515 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:50:13,523 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:50:13,576 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:50:13,579 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:50:13,584 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:50:13,592 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:50:13,642 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:50:13,646 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:50:13,649 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:50:13,661 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:50:13,708 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:50:13,712 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:50:13,717 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:50:13,729 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:50:13,775 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:50:13,779 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:50:13,787 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:50:13,792 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:50:13,843 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:50:13,846 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:50:13,852 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:50:13,856 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:50:13,911 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:50:13,913 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:50:13,917 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:50:13,922 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:50:14,044 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:50:14,110 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:50:14,111 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:50:14,115 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:50:14,115 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:50:14,117 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:50:14,117 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:50:14,124 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:50:14,124 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:50:14,124 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 683138 effective words/s
2016-09-28 10:51:22,684 : INFO : collecting all words and their counts
2016-09-28 10:51:22,684 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:51:22,818 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:51:22,828 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:51:22,828 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:51:22,832 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:51:22,833 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:51:22,833 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:51:22,833 : INFO : estimated required memory for 1902 words and 300 dimensions: 5917200 bytes
2016-09-28 10:51:22,834 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:51:22,881 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:51:22,882 : INFO : resetting layer weights
2016-09-28 10:51:57,483 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:51:57,483 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:51:57,485 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:51:57,487 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:57,488 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02500
2016-09-28 10:51:57,489 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:57,530 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02500
2016-09-28 10:51:57,563 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02500
2016-09-28 10:51:57,598 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02500
2016-09-28 10:51:57,632 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02500
2016-09-28 10:51:57,667 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02500
2016-09-28 10:51:57,703 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02500
2016-09-28 10:51:57,737 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02500
2016-09-28 10:51:57,772 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02500
2016-09-28 10:51:57,807 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02500
2016-09-28 10:51:57,843 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:57,877 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02500
2016-09-28 10:51:57,911 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02500
2016-09-28 10:51:57,947 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02500
2016-09-28 10:51:57,980 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02500
2016-09-28 10:51:58,015 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02500
2016-09-28 10:51:58,051 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02500
2016-09-28 10:51:58,086 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02500
2016-09-28 10:51:58,120 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02500
2016-09-28 10:51:58,156 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02500
2016-09-28 10:51:58,191 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02500
2016-09-28 10:51:58,227 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:58,260 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02500
2016-09-28 10:51:58,295 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02500
2016-09-28 10:51:58,330 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02500
2016-09-28 10:51:58,364 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02500
2016-09-28 10:51:58,400 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02500
2016-09-28 10:51:58,435 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02500
2016-09-28 10:51:58,470 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02500
2016-09-28 10:51:58,504 : INFO : PROGRESS: at 55.17% examples, 329520 words/s, in_qsize 1, out_qsize 0
2016-09-28 10:51:58,505 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02500
2016-09-28 10:51:58,541 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02500
2016-09-28 10:51:58,576 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:58,610 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02500
2016-09-28 10:51:58,644 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02500
2016-09-28 10:51:58,678 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02500
2016-09-28 10:51:58,712 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02500
2016-09-28 10:51:58,747 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02500
2016-09-28 10:51:58,782 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02500
2016-09-28 10:51:58,817 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02500
2016-09-28 10:51:58,853 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02500
2016-09-28 10:51:58,888 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02500
2016-09-28 10:51:58,923 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02500
2016-09-28 10:51:58,958 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02500
2016-09-28 10:51:58,991 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02500
2016-09-28 10:51:59,025 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02500
2016-09-28 10:51:59,060 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02500
2016-09-28 10:51:59,094 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02500
2016-09-28 10:51:59,130 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02500
2016-09-28 10:51:59,165 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02500
2016-09-28 10:51:59,200 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02500
2016-09-28 10:51:59,269 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:51:59,320 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:51:59,320 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:51:59,320 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 331289 effective words/s
2016-09-28 10:51:59,320 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:51:59,320 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:51:59,321 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02300
2016-09-28 10:51:59,322 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02300
2016-09-28 10:51:59,323 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02300
2016-09-28 10:51:59,324 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02300
2016-09-28 10:51:59,358 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02300
2016-09-28 10:51:59,392 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02300
2016-09-28 10:51:59,427 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02300
2016-09-28 10:51:59,461 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02300
2016-09-28 10:51:59,497 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02300
2016-09-28 10:51:59,533 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02300
2016-09-28 10:51:59,568 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02300
2016-09-28 10:51:59,603 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02300
2016-09-28 10:51:59,638 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02300
2016-09-28 10:51:59,674 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02300
2016-09-28 10:51:59,707 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02300
2016-09-28 10:51:59,742 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02300
2016-09-28 10:51:59,776 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02300
2016-09-28 10:51:59,810 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02300
2016-09-28 10:51:59,849 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02300
2016-09-28 10:51:59,885 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02300
2016-09-28 10:51:59,919 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02300
2016-09-28 10:51:59,954 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02300
2016-09-28 10:51:59,990 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02300
2016-09-28 10:52:00,026 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02300
2016-09-28 10:52:00,062 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02300
2016-09-28 10:52:00,096 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02300
2016-09-28 10:52:00,130 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02300
2016-09-28 10:52:00,165 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02300
2016-09-28 10:52:00,200 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02300
2016-09-28 10:52:00,236 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02300
2016-09-28 10:52:00,271 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02300
2016-09-28 10:52:00,306 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02300
2016-09-28 10:52:00,341 : INFO : PROGRESS: at 55.17% examples, 329013 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:00,342 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02300
2016-09-28 10:52:00,378 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02300
2016-09-28 10:52:00,413 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02300
2016-09-28 10:52:00,447 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02300
2016-09-28 10:52:00,484 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02300
2016-09-28 10:52:00,519 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02300
2016-09-28 10:52:00,553 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02300
2016-09-28 10:52:00,588 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02300
2016-09-28 10:52:00,624 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02300
2016-09-28 10:52:00,659 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02300
2016-09-28 10:52:00,694 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02300
2016-09-28 10:52:00,730 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02300
2016-09-28 10:52:00,765 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02300
2016-09-28 10:52:00,801 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02300
2016-09-28 10:52:00,834 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02300
2016-09-28 10:52:00,868 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02300
2016-09-28 10:52:00,903 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02300
2016-09-28 10:52:00,938 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02300
2016-09-28 10:52:00,974 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02300
2016-09-28 10:52:01,008 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02300
2016-09-28 10:52:01,046 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02300
2016-09-28 10:52:01,115 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:01,168 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:01,168 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:01,168 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 328957 effective words/s
2016-09-28 10:52:01,168 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:01,168 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:01,170 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02100
2016-09-28 10:52:01,171 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:01,172 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02100
2016-09-28 10:52:01,173 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:01,206 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02100
2016-09-28 10:52:01,242 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02100
2016-09-28 10:52:01,276 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02100
2016-09-28 10:52:01,310 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02100
2016-09-28 10:52:01,346 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02100
2016-09-28 10:52:01,381 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02100
2016-09-28 10:52:01,416 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02100
2016-09-28 10:52:01,450 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.02100
2016-09-28 10:52:01,488 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.02100
2016-09-28 10:52:01,523 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:01,557 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.02100
2016-09-28 10:52:01,591 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.02100
2016-09-28 10:52:01,625 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.02100
2016-09-28 10:52:01,659 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.02100
2016-09-28 10:52:01,697 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.02100
2016-09-28 10:52:01,733 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.02100
2016-09-28 10:52:01,767 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.02100
2016-09-28 10:52:01,802 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.02100
2016-09-28 10:52:01,837 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.02100
2016-09-28 10:52:01,876 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.02100
2016-09-28 10:52:01,911 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:01,945 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.02100
2016-09-28 10:52:01,979 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.02100
2016-09-28 10:52:02,012 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.02100
2016-09-28 10:52:02,047 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.02100
2016-09-28 10:52:02,082 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.02100
2016-09-28 10:52:02,117 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.02100
2016-09-28 10:52:02,152 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.02100
2016-09-28 10:52:02,189 : INFO : PROGRESS: at 55.17% examples, 329445 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:02,190 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.02100
2016-09-28 10:52:02,227 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.02100
2016-09-28 10:52:02,263 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:02,297 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.02100
2016-09-28 10:52:02,330 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.02100
2016-09-28 10:52:02,365 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.02100
2016-09-28 10:52:02,399 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.02100
2016-09-28 10:52:02,433 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.02100
2016-09-28 10:52:02,469 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.02100
2016-09-28 10:52:02,504 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.02100
2016-09-28 10:52:02,539 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.02100
2016-09-28 10:52:02,574 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.02100
2016-09-28 10:52:02,609 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.02100
2016-09-28 10:52:02,644 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.02100
2016-09-28 10:52:02,677 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.02100
2016-09-28 10:52:02,711 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.02100
2016-09-28 10:52:02,745 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.02100
2016-09-28 10:52:02,780 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.02100
2016-09-28 10:52:02,815 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.02100
2016-09-28 10:52:02,850 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.02100
2016-09-28 10:52:02,886 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.02100
2016-09-28 10:52:02,955 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:03,004 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:03,004 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:03,004 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 331236 effective words/s
2016-09-28 10:52:03,005 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:03,005 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:03,006 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01900
2016-09-28 10:52:03,007 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:03,008 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01900
2016-09-28 10:52:03,009 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:03,042 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01900
2016-09-28 10:52:03,077 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01900
2016-09-28 10:52:03,111 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01900
2016-09-28 10:52:03,145 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01900
2016-09-28 10:52:03,183 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01900
2016-09-28 10:52:03,218 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01900
2016-09-28 10:52:03,253 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01900
2016-09-28 10:52:03,288 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01900
2016-09-28 10:52:03,326 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01900
2016-09-28 10:52:03,363 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:03,397 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01900
2016-09-28 10:52:03,431 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01900
2016-09-28 10:52:03,465 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01900
2016-09-28 10:52:03,500 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01900
2016-09-28 10:52:03,537 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01900
2016-09-28 10:52:03,573 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01900
2016-09-28 10:52:03,608 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01900
2016-09-28 10:52:03,643 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01900
2016-09-28 10:52:03,678 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01900
2016-09-28 10:52:03,713 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01900
2016-09-28 10:52:03,748 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:03,781 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01900
2016-09-28 10:52:03,815 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01900
2016-09-28 10:52:03,849 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01900
2016-09-28 10:52:03,883 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01900
2016-09-28 10:52:03,919 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01900
2016-09-28 10:52:03,957 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01900
2016-09-28 10:52:03,991 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01900
2016-09-28 10:52:04,029 : INFO : PROGRESS: at 55.17% examples, 328121 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:04,030 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01900
2016-09-28 10:52:04,065 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01900
2016-09-28 10:52:04,101 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:04,135 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01900
2016-09-28 10:52:04,169 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01900
2016-09-28 10:52:04,204 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01900
2016-09-28 10:52:04,238 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01900
2016-09-28 10:52:04,275 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01900
2016-09-28 10:52:04,311 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01900
2016-09-28 10:52:04,345 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01900
2016-09-28 10:52:04,383 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01900
2016-09-28 10:52:04,418 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01900
2016-09-28 10:52:04,453 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01900
2016-09-28 10:52:04,490 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01900
2016-09-28 10:52:04,523 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01900
2016-09-28 10:52:04,557 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01900
2016-09-28 10:52:04,591 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01900
2016-09-28 10:52:04,626 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01900
2016-09-28 10:52:04,661 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01900
2016-09-28 10:52:04,696 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01900
2016-09-28 10:52:04,731 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01900
2016-09-28 10:52:04,800 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:04,851 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:04,851 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:04,851 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 329303 effective words/s
2016-09-28 10:52:04,852 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:04,852 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:04,853 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01700
2016-09-28 10:52:04,854 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:04,855 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01700
2016-09-28 10:52:04,855 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:04,889 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01700
2016-09-28 10:52:04,924 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01700
2016-09-28 10:52:04,958 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01700
2016-09-28 10:52:04,993 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01700
2016-09-28 10:52:05,028 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01700
2016-09-28 10:52:05,064 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01700
2016-09-28 10:52:05,101 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01700
2016-09-28 10:52:05,136 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01700
2016-09-28 10:52:05,174 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01700
2016-09-28 10:52:05,210 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:05,248 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01700
2016-09-28 10:52:05,282 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01700
2016-09-28 10:52:05,319 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01700
2016-09-28 10:52:05,354 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01700
2016-09-28 10:52:05,389 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01700
2016-09-28 10:52:05,425 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01700
2016-09-28 10:52:05,459 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01700
2016-09-28 10:52:05,496 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01700
2016-09-28 10:52:05,531 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01700
2016-09-28 10:52:05,566 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01700
2016-09-28 10:52:05,601 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:05,639 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01700
2016-09-28 10:52:05,672 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01700
2016-09-28 10:52:05,707 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01700
2016-09-28 10:52:05,742 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01700
2016-09-28 10:52:05,777 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01700
2016-09-28 10:52:05,812 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01700
2016-09-28 10:52:05,847 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01700
2016-09-28 10:52:05,882 : INFO : PROGRESS: at 55.17% examples, 326211 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:05,882 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01700
2016-09-28 10:52:05,918 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01700
2016-09-28 10:52:05,954 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:05,987 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01700
2016-09-28 10:52:06,022 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01700
2016-09-28 10:52:06,056 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01700
2016-09-28 10:52:06,090 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01700
2016-09-28 10:52:06,126 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01700
2016-09-28 10:52:06,162 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01700
2016-09-28 10:52:06,196 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01700
2016-09-28 10:52:06,231 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01700
2016-09-28 10:52:06,267 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01700
2016-09-28 10:52:06,303 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01700
2016-09-28 10:52:06,338 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01700
2016-09-28 10:52:06,372 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01700
2016-09-28 10:52:06,406 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01700
2016-09-28 10:52:06,441 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01700
2016-09-28 10:52:06,475 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01700
2016-09-28 10:52:06,512 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01700
2016-09-28 10:52:06,547 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01700
2016-09-28 10:52:06,583 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01700
2016-09-28 10:52:06,652 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:06,702 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:06,703 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:06,703 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 328431 effective words/s
2016-09-28 10:52:06,703 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:06,703 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:06,704 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01500
2016-09-28 10:52:06,705 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:06,706 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01500
2016-09-28 10:52:06,707 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:06,741 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01500
2016-09-28 10:52:06,775 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01500
2016-09-28 10:52:06,810 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01500
2016-09-28 10:52:06,844 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01500
2016-09-28 10:52:06,880 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01500
2016-09-28 10:52:06,915 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01500
2016-09-28 10:52:06,950 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01500
2016-09-28 10:52:06,985 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01500
2016-09-28 10:52:07,020 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01500
2016-09-28 10:52:07,055 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:07,090 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01500
2016-09-28 10:52:07,127 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01500
2016-09-28 10:52:07,162 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01500
2016-09-28 10:52:07,198 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01500
2016-09-28 10:52:07,234 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01500
2016-09-28 10:52:07,269 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01500
2016-09-28 10:52:07,304 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01500
2016-09-28 10:52:07,339 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01500
2016-09-28 10:52:07,375 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01500
2016-09-28 10:52:07,413 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01500
2016-09-28 10:52:07,448 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:07,481 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01500
2016-09-28 10:52:07,516 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01500
2016-09-28 10:52:07,550 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01500
2016-09-28 10:52:07,584 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01500
2016-09-28 10:52:07,619 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01500
2016-09-28 10:52:07,655 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01500
2016-09-28 10:52:07,693 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01500
2016-09-28 10:52:07,729 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01500
2016-09-28 10:52:07,728 : INFO : PROGRESS: at 55.17% examples, 327819 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:07,764 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01500
2016-09-28 10:52:07,801 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:07,835 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01500
2016-09-28 10:52:07,868 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01500
2016-09-28 10:52:07,903 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01500
2016-09-28 10:52:07,937 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01500
2016-09-28 10:52:07,972 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01500
2016-09-28 10:52:08,007 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01500
2016-09-28 10:52:08,045 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01500
2016-09-28 10:52:08,080 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01500
2016-09-28 10:52:08,116 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01500
2016-09-28 10:52:08,152 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01500
2016-09-28 10:52:08,189 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01500
2016-09-28 10:52:08,222 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01500
2016-09-28 10:52:08,257 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01500
2016-09-28 10:52:08,291 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01500
2016-09-28 10:52:08,326 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01500
2016-09-28 10:52:08,361 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01500
2016-09-28 10:52:08,397 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01500
2016-09-28 10:52:08,431 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01500
2016-09-28 10:52:08,503 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:08,553 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:08,554 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:08,554 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 328502 effective words/s
2016-09-28 10:52:08,554 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:08,554 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:08,555 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01300
2016-09-28 10:52:08,556 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:08,557 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01300
2016-09-28 10:52:08,558 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:08,591 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01300
2016-09-28 10:52:08,627 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01300
2016-09-28 10:52:08,663 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01300
2016-09-28 10:52:08,697 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01300
2016-09-28 10:52:08,733 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01300
2016-09-28 10:52:08,768 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01300
2016-09-28 10:52:08,803 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01300
2016-09-28 10:52:08,839 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01300
2016-09-28 10:52:08,878 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01300
2016-09-28 10:52:08,913 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:08,947 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01300
2016-09-28 10:52:08,981 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01300
2016-09-28 10:52:09,015 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01300
2016-09-28 10:52:09,049 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01300
2016-09-28 10:52:09,084 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01300
2016-09-28 10:52:09,119 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01300
2016-09-28 10:52:09,153 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01300
2016-09-28 10:52:09,190 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01300
2016-09-28 10:52:09,225 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01300
2016-09-28 10:52:09,260 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01300
2016-09-28 10:52:09,296 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:09,329 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01300
2016-09-28 10:52:09,363 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01300
2016-09-28 10:52:09,397 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01300
2016-09-28 10:52:09,431 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01300
2016-09-28 10:52:09,466 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01300
2016-09-28 10:52:09,502 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01300
2016-09-28 10:52:09,536 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01300
2016-09-28 10:52:09,570 : INFO : PROGRESS: at 55.17% examples, 330617 words/s, in_qsize 1, out_qsize 0
2016-09-28 10:52:09,572 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01300
2016-09-28 10:52:09,606 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01300
2016-09-28 10:52:09,642 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:09,675 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01300
2016-09-28 10:52:09,709 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01300
2016-09-28 10:52:09,743 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01300
2016-09-28 10:52:09,776 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01300
2016-09-28 10:52:09,811 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01300
2016-09-28 10:52:09,847 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01300
2016-09-28 10:52:09,881 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01300
2016-09-28 10:52:09,916 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01300
2016-09-28 10:52:09,951 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01300
2016-09-28 10:52:09,986 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01300
2016-09-28 10:52:10,021 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01300
2016-09-28 10:52:10,055 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01300
2016-09-28 10:52:10,089 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01300
2016-09-28 10:52:10,123 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01300
2016-09-28 10:52:10,158 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01300
2016-09-28 10:52:10,196 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01300
2016-09-28 10:52:10,235 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01300
2016-09-28 10:52:10,269 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01300
2016-09-28 10:52:10,338 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:10,388 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:10,388 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:10,388 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 331476 effective words/s
2016-09-28 10:52:10,388 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:10,389 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:10,390 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.01100
2016-09-28 10:52:10,391 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:10,391 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.01100
2016-09-28 10:52:10,392 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:10,426 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.01100
2016-09-28 10:52:10,460 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.01100
2016-09-28 10:52:10,495 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.01100
2016-09-28 10:52:10,530 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.01100
2016-09-28 10:52:10,571 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.01100
2016-09-28 10:52:10,607 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.01100
2016-09-28 10:52:10,642 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.01100
2016-09-28 10:52:10,677 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01100
2016-09-28 10:52:10,712 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01100
2016-09-28 10:52:10,747 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:10,781 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01100
2016-09-28 10:52:10,815 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01100
2016-09-28 10:52:10,849 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01100
2016-09-28 10:52:10,883 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01100
2016-09-28 10:52:10,917 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01100
2016-09-28 10:52:10,953 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01100
2016-09-28 10:52:10,987 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01100
2016-09-28 10:52:11,022 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01100
2016-09-28 10:52:11,057 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01100
2016-09-28 10:52:11,094 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01100
2016-09-28 10:52:11,129 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:11,163 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01100
2016-09-28 10:52:11,197 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01100
2016-09-28 10:52:11,231 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01100
2016-09-28 10:52:11,266 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01100
2016-09-28 10:52:11,301 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01100
2016-09-28 10:52:11,336 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01100
2016-09-28 10:52:11,371 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01100
2016-09-28 10:52:11,405 : INFO : PROGRESS: at 55.17% examples, 330508 words/s, in_qsize 1, out_qsize 0
2016-09-28 10:52:11,407 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.01100
2016-09-28 10:52:11,441 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.01100
2016-09-28 10:52:11,480 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:11,515 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.01100
2016-09-28 10:52:11,549 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.01100
2016-09-28 10:52:11,583 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.01100
2016-09-28 10:52:11,617 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.01100
2016-09-28 10:52:11,652 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.01100
2016-09-28 10:52:11,688 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.01100
2016-09-28 10:52:11,722 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.01100
2016-09-28 10:52:11,757 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.01100
2016-09-28 10:52:11,792 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.01100
2016-09-28 10:52:11,831 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.01100
2016-09-28 10:52:11,866 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.01100
2016-09-28 10:52:11,899 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.01100
2016-09-28 10:52:11,933 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.01100
2016-09-28 10:52:11,969 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.01100
2016-09-28 10:52:12,007 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.01100
2016-09-28 10:52:12,041 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.01100
2016-09-28 10:52:12,077 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.01100
2016-09-28 10:52:12,111 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.01100
2016-09-28 10:52:12,183 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:12,235 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:12,235 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:12,235 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 329321 effective words/s
2016-09-28 10:52:12,235 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:12,235 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:12,236 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.00900
2016-09-28 10:52:12,238 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:12,238 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.00900
2016-09-28 10:52:12,239 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:12,272 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.00900
2016-09-28 10:52:12,307 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.00900
2016-09-28 10:52:12,340 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.00900
2016-09-28 10:52:12,374 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.00900
2016-09-28 10:52:12,410 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.00900
2016-09-28 10:52:12,445 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.00900
2016-09-28 10:52:12,481 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.00900
2016-09-28 10:52:12,515 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.00900
2016-09-28 10:52:12,550 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.00900
2016-09-28 10:52:12,585 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:12,619 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.00900
2016-09-28 10:52:12,653 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.00900
2016-09-28 10:52:12,687 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.00900
2016-09-28 10:52:12,721 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.00900
2016-09-28 10:52:12,756 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.00900
2016-09-28 10:52:12,791 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.00900
2016-09-28 10:52:12,825 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.00900
2016-09-28 10:52:12,860 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.00900
2016-09-28 10:52:12,895 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.00900
2016-09-28 10:52:12,930 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.00900
2016-09-28 10:52:12,965 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:12,998 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.00900
2016-09-28 10:52:13,031 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.00900
2016-09-28 10:52:13,065 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.00900
2016-09-28 10:52:13,100 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.00900
2016-09-28 10:52:13,134 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.00900
2016-09-28 10:52:13,171 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.00900
2016-09-28 10:52:13,206 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.00900
2016-09-28 10:52:13,244 : INFO : PROGRESS: at 55.17% examples, 333155 words/s, in_qsize 1, out_qsize 0
2016-09-28 10:52:13,245 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00900
2016-09-28 10:52:13,286 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00900
2016-09-28 10:52:13,321 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:13,354 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00900
2016-09-28 10:52:13,388 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00900
2016-09-28 10:52:13,422 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00900
2016-09-28 10:52:13,456 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00900
2016-09-28 10:52:13,492 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00900
2016-09-28 10:52:13,528 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00900
2016-09-28 10:52:13,563 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00900
2016-09-28 10:52:13,598 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00900
2016-09-28 10:52:13,633 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00900
2016-09-28 10:52:13,668 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00900
2016-09-28 10:52:13,703 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00900
2016-09-28 10:52:13,736 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00900
2016-09-28 10:52:13,770 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00900
2016-09-28 10:52:13,807 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00900
2016-09-28 10:52:13,845 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00900
2016-09-28 10:52:13,884 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00900
2016-09-28 10:52:13,918 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00900
2016-09-28 10:52:13,952 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00900
2016-09-28 10:52:14,021 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:14,074 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:14,074 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:14,074 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 330590 effective words/s
2016-09-28 10:52:14,074 : INFO : training model with 1 workers on 1902 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:52:14,074 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:52:14,076 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.00700
2016-09-28 10:52:14,076 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:14,077 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.00700
2016-09-28 10:52:14,078 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:14,112 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.00700
2016-09-28 10:52:14,147 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.00700
2016-09-28 10:52:14,184 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.00700
2016-09-28 10:52:14,220 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.00700
2016-09-28 10:52:14,256 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.00700
2016-09-28 10:52:14,291 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.00700
2016-09-28 10:52:14,325 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.00700
2016-09-28 10:52:14,360 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.00700
2016-09-28 10:52:14,396 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.00700
2016-09-28 10:52:14,431 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:14,465 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.00700
2016-09-28 10:52:14,500 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.00700
2016-09-28 10:52:14,534 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.00700
2016-09-28 10:52:14,567 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.00700
2016-09-28 10:52:14,605 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.00700
2016-09-28 10:52:14,641 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.00700
2016-09-28 10:52:14,675 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.00700
2016-09-28 10:52:14,710 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.00700
2016-09-28 10:52:14,746 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.00700
2016-09-28 10:52:14,781 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.00700
2016-09-28 10:52:14,816 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:14,849 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.00700
2016-09-28 10:52:14,886 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.00700
2016-09-28 10:52:14,920 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.00700
2016-09-28 10:52:14,954 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.00700
2016-09-28 10:52:14,989 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.00700
2016-09-28 10:52:15,025 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.00700
2016-09-28 10:52:15,059 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.00700
2016-09-28 10:52:15,094 : INFO : PROGRESS: at 55.17% examples, 329479 words/s, in_qsize 2, out_qsize 0
2016-09-28 10:52:15,095 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00700
2016-09-28 10:52:15,130 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00700
2016-09-28 10:52:15,166 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:15,201 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00700
2016-09-28 10:52:15,235 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00700
2016-09-28 10:52:15,268 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00700
2016-09-28 10:52:15,302 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00700
2016-09-28 10:52:15,337 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00700
2016-09-28 10:52:15,373 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00700
2016-09-28 10:52:15,407 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00700
2016-09-28 10:52:15,442 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00700
2016-09-28 10:52:15,478 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00700
2016-09-28 10:52:15,514 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00700
2016-09-28 10:52:15,550 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00700
2016-09-28 10:52:15,583 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00700
2016-09-28 10:52:15,616 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00700
2016-09-28 10:52:15,650 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00700
2016-09-28 10:52:15,688 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00700
2016-09-28 10:52:15,724 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00700
2016-09-28 10:52:15,759 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00700
2016-09-28 10:52:15,793 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00700
2016-09-28 10:52:15,865 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:52:15,915 : DEBUG : worker exiting, processed 53 jobs
2016-09-28 10:52:15,915 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:52:15,916 : INFO : training on 523455 raw words (607490 effective words) took 1.8s, 330118 effective words/s
2016-09-28 10:55:53,075 : INFO : collecting all words and their counts
2016-09-28 10:55:53,076 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:56:04,539 : INFO : collecting all words and their counts
2016-09-28 10:56:04,540 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 10:56:04,679 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 10:56:04,689 : INFO : min_count=5 retains 1902 unique words (drops 6437)
2016-09-28 10:56:04,689 : INFO : min_count leaves 94798 word corpus (90% of original 104691)
2016-09-28 10:56:04,694 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 10:56:04,694 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 10:56:04,694 : INFO : downsampling leaves estimated 94798 word corpus (100.0% of prior 94798)
2016-09-28 10:56:04,694 : INFO : estimated required memory for 1902 words and 100 dimensions: 2862000 bytes
2016-09-28 10:56:04,696 : INFO : constructing a huffman tree from 1902 words
2016-09-28 10:56:04,742 : INFO : built huffman tree with maximum node depth 14
2016-09-28 10:56:04,743 : INFO : resetting layer weights
2016-09-28 10:56:04,762 : INFO : training model with 4 workers on 1902 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 10:56:04,763 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 10:56:04,765 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 10:56:04,766 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 10:56:04,767 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 10:56:04,768 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 10:56:04,769 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 10:56:04,770 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 10:56:04,772 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 10:56:04,773 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 10:56:04,774 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 10:56:04,775 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 10:56:04,776 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 10:56:04,777 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 10:56:04,778 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 10:56:04,835 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 10:56:04,838 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 10:56:04,839 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 10:56:04,842 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 10:56:04,904 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 10:56:04,906 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 10:56:04,908 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 10:56:04,909 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 10:56:04,971 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 10:56:04,972 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 10:56:04,974 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 10:56:04,976 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 10:56:05,035 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 10:56:05,039 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 10:56:05,040 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 10:56:05,043 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 10:56:05,100 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 10:56:05,105 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 10:56:05,109 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 10:56:05,113 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 10:56:05,167 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 10:56:05,170 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 10:56:05,174 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 10:56:05,180 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 10:56:05,234 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 10:56:05,237 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 10:56:05,239 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 10:56:05,246 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 10:56:05,299 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 10:56:05,305 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 10:56:05,309 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 10:56:05,310 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 10:56:05,364 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 10:56:05,371 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 10:56:05,374 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 10:56:05,377 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 10:56:05,434 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 10:56:05,436 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 10:56:05,440 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 10:56:05,444 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 10:56:05,563 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 10:56:05,628 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:56:05,628 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 10:56:05,630 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:56:05,631 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 10:56:05,635 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 10:56:05,635 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 10:56:05,642 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 10:56:05,642 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 10:56:05,642 : INFO : training on 523455 raw words (607490 effective words) took 0.9s, 692416 effective words/s
2016-09-28 11:50:27,710 : INFO : collecting all words and their counts
2016-09-28 11:50:27,711 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 11:50:27,846 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 11:50:27,870 : INFO : min_count=1 retains 8339 unique words (drops 0)
2016-09-28 11:50:27,870 : INFO : min_count leaves 104691 word corpus (100% of original 104691)
2016-09-28 11:50:27,890 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 11:50:27,891 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 11:50:27,891 : INFO : downsampling leaves estimated 104691 word corpus (100.0% of prior 104691)
2016-09-28 11:50:27,891 : INFO : estimated required memory for 8339 words and 100 dimensions: 12517500 bytes
2016-09-28 11:50:27,901 : INFO : constructing a huffman tree from 8339 words
2016-09-28 11:50:28,155 : INFO : built huffman tree with maximum node depth 17
2016-09-28 11:50:28,157 : INFO : resetting layer weights
2016-09-28 11:50:28,265 : INFO : training model with 4 workers on 8339 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 11:50:28,265 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 11:50:28,268 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 11:50:28,269 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 11:50:28,270 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 11:50:28,271 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 11:50:28,273 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 11:50:28,275 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 11:50:28,276 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 11:50:28,277 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 11:50:28,278 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 11:50:28,279 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 11:50:28,280 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 11:50:28,281 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 11:50:28,282 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 11:50:28,343 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 11:50:28,349 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 11:50:28,350 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 11:50:28,351 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 11:50:28,417 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 11:50:28,422 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 11:50:28,424 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 11:50:28,427 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 11:50:28,486 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 11:50:28,491 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 11:50:28,499 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 11:50:28,501 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 11:50:28,559 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 11:50:28,561 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 11:50:28,572 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 11:50:28,575 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 11:50:28,630 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 11:50:28,631 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 11:50:28,644 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 11:50:28,650 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 11:50:28,699 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 11:50:28,702 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 11:50:28,716 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 11:50:28,721 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 11:50:28,770 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 11:50:28,776 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 11:50:28,789 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 11:50:28,792 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 11:50:28,842 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 11:50:28,847 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 11:50:28,862 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 11:50:28,864 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 11:50:28,913 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 11:50:28,916 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 11:50:28,933 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 11:50:28,935 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 11:50:28,985 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 11:50:28,988 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 11:50:29,005 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 11:50:29,007 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 11:50:29,128 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 11:50:29,198 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:50:29,198 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 11:50:29,206 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:50:29,207 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 11:50:29,208 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:50:29,208 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 11:50:29,215 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 11:50:29,215 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 11:50:29,215 : INFO : training on 523455 raw words (656955 effective words) took 0.9s, 694371 effective words/s
2016-09-28 11:53:59,072 : INFO : collecting all words and their counts
2016-09-28 11:53:59,072 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 11:53:59,221 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 11:53:59,245 : INFO : min_count=1 retains 8339 unique words (drops 0)
2016-09-28 11:53:59,245 : INFO : min_count leaves 104691 word corpus (100% of original 104691)
2016-09-28 11:53:59,264 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 11:53:59,264 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 11:53:59,264 : INFO : downsampling leaves estimated 104691 word corpus (100.0% of prior 104691)
2016-09-28 11:53:59,264 : INFO : estimated required memory for 8339 words and 100 dimensions: 12517500 bytes
2016-09-28 11:53:59,274 : INFO : constructing a huffman tree from 8339 words
2016-09-28 11:53:59,527 : INFO : built huffman tree with maximum node depth 17
2016-09-28 11:53:59,530 : INFO : resetting layer weights
2016-09-28 11:53:59,622 : INFO : training model with 4 workers on 8339 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 11:53:59,622 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 11:53:59,625 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 11:53:59,626 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 11:53:59,627 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 11:53:59,628 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 11:53:59,629 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 11:53:59,630 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 11:53:59,631 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 11:53:59,632 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 11:53:59,633 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 11:53:59,634 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 11:53:59,635 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 11:53:59,636 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 11:53:59,637 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 11:53:59,703 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 11:53:59,704 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 11:53:59,706 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 11:53:59,707 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 11:53:59,773 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 11:53:59,777 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 11:53:59,781 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 11:53:59,781 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 11:53:59,845 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 11:53:59,849 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 11:53:59,852 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 11:53:59,854 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 11:53:59,917 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 11:53:59,920 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 11:53:59,925 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 11:53:59,928 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 11:53:59,987 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 11:53:59,993 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 11:53:59,996 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 11:54:00,003 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 11:54:00,063 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 11:54:00,065 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 11:54:00,069 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 11:54:00,077 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 11:54:00,134 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 11:54:00,137 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 11:54:00,142 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 11:54:00,147 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 11:54:00,206 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 11:54:00,208 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 11:54:00,216 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 11:54:00,217 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 11:54:00,279 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 11:54:00,281 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 11:54:00,284 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 11:54:00,289 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 11:54:00,351 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 11:54:00,353 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 11:54:00,355 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 11:54:00,362 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 11:54:00,493 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 11:54:00,561 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:54:00,561 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 11:54:00,570 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:54:00,570 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 11:54:00,572 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 11:54:00,572 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 11:54:00,579 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 11:54:00,579 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 11:54:00,579 : INFO : training on 523455 raw words (656955 effective words) took 1.0s, 688555 effective words/s
2016-09-28 13:49:59,749 : INFO : collecting all words and their counts
2016-09-28 13:49:59,749 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 13:49:59,884 : INFO : collected 8339 word types and 15 unique tags from a corpus of 3090 examples and 104691 words
2016-09-28 13:49:59,906 : INFO : min_count=1 retains 8339 unique words (drops 0)
2016-09-28 13:49:59,906 : INFO : min_count leaves 104691 word corpus (100% of original 104691)
2016-09-28 13:49:59,924 : INFO : deleting the raw counts dictionary of 8339 items
2016-09-28 13:49:59,925 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 13:49:59,925 : INFO : downsampling leaves estimated 104691 word corpus (100.0% of prior 104691)
2016-09-28 13:49:59,925 : INFO : estimated required memory for 8339 words and 100 dimensions: 12517500 bytes
2016-09-28 13:49:59,933 : INFO : constructing a huffman tree from 8339 words
2016-09-28 13:50:00,187 : INFO : built huffman tree with maximum node depth 17
2016-09-28 13:50:00,189 : INFO : resetting layer weights
2016-09-28 13:50:00,290 : INFO : training model with 4 workers on 8339 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 13:50:00,291 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-09-28 13:50:00,293 : DEBUG : queueing job #0 (9980 words, 288 sentences) at alpha 0.02500
2016-09-28 13:50:00,294 : DEBUG : queueing job #1 (9985 words, 290 sentences) at alpha 0.02454
2016-09-28 13:50:00,295 : DEBUG : queueing job #2 (9967 words, 304 sentences) at alpha 0.02407
2016-09-28 13:50:00,297 : DEBUG : queueing job #3 (9996 words, 290 sentences) at alpha 0.02358
2016-09-28 13:50:00,298 : DEBUG : queueing job #4 (9986 words, 303 sentences) at alpha 0.02311
2016-09-28 13:50:00,299 : DEBUG : queueing job #5 (9996 words, 295 sentences) at alpha 0.02262
2016-09-28 13:50:00,300 : DEBUG : queueing job #6 (9982 words, 289 sentences) at alpha 0.02215
2016-09-28 13:50:00,301 : DEBUG : queueing job #7 (9987 words, 280 sentences) at alpha 0.02168
2016-09-28 13:50:00,302 : DEBUG : queueing job #8 (9999 words, 296 sentences) at alpha 0.02123
2016-09-28 13:50:00,303 : DEBUG : queueing job #9 (9998 words, 311 sentences) at alpha 0.02075
2016-09-28 13:50:00,304 : DEBUG : queueing job #10 (9959 words, 286 sentences) at alpha 0.02025
2016-09-28 13:50:00,305 : DEBUG : queueing job #11 (9984 words, 292 sentences) at alpha 0.01979
2016-09-28 13:50:00,306 : DEBUG : queueing job #12 (9989 words, 306 sentences) at alpha 0.01932
2016-09-28 13:50:00,369 : DEBUG : queueing job #13 (10000 words, 290 sentences) at alpha 0.01883
2016-09-28 13:50:00,372 : DEBUG : queueing job #14 (9965 words, 292 sentences) at alpha 0.01836
2016-09-28 13:50:00,373 : DEBUG : queueing job #15 (9970 words, 310 sentences) at alpha 0.01789
2016-09-28 13:50:00,376 : DEBUG : queueing job #16 (9943 words, 287 sentences) at alpha 0.01739
2016-09-28 13:50:00,441 : DEBUG : queueing job #17 (10000 words, 280 sentences) at alpha 0.01693
2016-09-28 13:50:00,443 : DEBUG : queueing job #18 (9974 words, 289 sentences) at alpha 0.01648
2016-09-28 13:50:00,445 : DEBUG : queueing job #19 (9997 words, 310 sentences) at alpha 0.01601
2016-09-28 13:50:00,448 : DEBUG : queueing job #20 (9988 words, 298 sentences) at alpha 0.01551
2016-09-28 13:50:00,511 : DEBUG : queueing job #21 (9934 words, 288 sentences) at alpha 0.01503
2016-09-28 13:50:00,515 : DEBUG : queueing job #22 (9980 words, 292 sentences) at alpha 0.01457
2016-09-28 13:50:00,516 : DEBUG : queueing job #23 (9971 words, 303 sentences) at alpha 0.01410
2016-09-28 13:50:00,521 : DEBUG : queueing job #24 (9966 words, 290 sentences) at alpha 0.01361
2016-09-28 13:50:00,585 : DEBUG : queueing job #25 (9994 words, 301 sentences) at alpha 0.01314
2016-09-28 13:50:00,587 : DEBUG : queueing job #26 (9968 words, 294 sentences) at alpha 0.01265
2016-09-28 13:50:00,589 : DEBUG : queueing job #27 (9975 words, 288 sentences) at alpha 0.01218
2016-09-28 13:50:00,590 : DEBUG : queueing job #28 (9982 words, 282 sentences) at alpha 0.01172
2016-09-28 13:50:00,654 : DEBUG : queueing job #29 (9993 words, 295 sentences) at alpha 0.01126
2016-09-28 13:50:00,658 : DEBUG : queueing job #30 (9968 words, 312 sentences) at alpha 0.01079
2016-09-28 13:50:00,659 : DEBUG : queueing job #31 (9964 words, 285 sentences) at alpha 0.01028
2016-09-28 13:50:00,664 : DEBUG : queueing job #32 (9942 words, 291 sentences) at alpha 0.00982
2016-09-28 13:50:00,725 : DEBUG : queueing job #33 (9997 words, 305 sentences) at alpha 0.00936
2016-09-28 13:50:00,728 : DEBUG : queueing job #34 (9974 words, 290 sentences) at alpha 0.00886
2016-09-28 13:50:00,729 : DEBUG : queueing job #35 (9990 words, 292 sentences) at alpha 0.00840
2016-09-28 13:50:00,735 : DEBUG : queueing job #36 (9995 words, 311 sentences) at alpha 0.00793
2016-09-28 13:50:00,793 : DEBUG : queueing job #37 (9999 words, 289 sentences) at alpha 0.00742
2016-09-28 13:50:00,797 : DEBUG : queueing job #38 (9961 words, 280 sentences) at alpha 0.00696
2016-09-28 13:50:00,802 : DEBUG : queueing job #39 (9989 words, 288 sentences) at alpha 0.00651
2016-09-28 13:50:00,805 : DEBUG : queueing job #40 (9987 words, 311 sentences) at alpha 0.00604
2016-09-28 13:50:00,863 : DEBUG : queueing job #41 (9991 words, 296 sentences) at alpha 0.00554
2016-09-28 13:50:00,870 : DEBUG : queueing job #42 (9986 words, 289 sentences) at alpha 0.00507
2016-09-28 13:50:00,874 : DEBUG : queueing job #43 (9974 words, 294 sentences) at alpha 0.00460
2016-09-28 13:50:00,878 : DEBUG : queueing job #44 (9993 words, 303 sentences) at alpha 0.00413
2016-09-28 13:50:00,931 : DEBUG : queueing job #45 (9971 words, 289 sentences) at alpha 0.00364
2016-09-28 13:50:00,942 : DEBUG : queueing job #46 (9989 words, 301 sentences) at alpha 0.00317
2016-09-28 13:50:00,944 : DEBUG : queueing job #47 (9951 words, 292 sentences) at alpha 0.00269
2016-09-28 13:50:00,948 : DEBUG : queueing job #48 (9987 words, 290 sentences) at alpha 0.00222
2016-09-28 13:50:01,004 : DEBUG : queueing job #49 (9969 words, 282 sentences) at alpha 0.00175
2016-09-28 13:50:01,012 : DEBUG : queueing job #50 (9975 words, 295 sentences) at alpha 0.00129
2016-09-28 13:50:01,014 : DEBUG : queueing job #51 (9974 words, 312 sentences) at alpha 0.00082
2016-09-28 13:50:01,019 : DEBUG : queueing job #52 (4521 words, 134 sentences) at alpha 0.00032
2016-09-28 13:50:01,143 : DEBUG : job loop exiting, total 53 jobs
2016-09-28 13:50:01,217 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 13:50:01,217 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 13:50:01,223 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 13:50:01,223 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 13:50:01,223 : DEBUG : worker exiting, processed 13 jobs
2016-09-28 13:50:01,224 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 13:50:01,232 : DEBUG : worker exiting, processed 14 jobs
2016-09-28 13:50:01,233 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 13:50:01,233 : INFO : training on 523455 raw words (656955 effective words) took 0.9s, 699639 effective words/s
2016-09-28 14:12:57,066 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-28 14:12:57,329 : INFO : built Dictionary(14577 unique tokens: [u'kitchen............', u'shaksee', u'included;plus', u'$1.94', u'50qr;']...) from 3088 documents (total 104426 corpus positions)
2016-09-28 14:12:57,341 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 14:12:57,344 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 14:12:57,348 : INFO : saving Dictionary object under ./tmp/genImp1/genImp1.dict, separately None
2016-09-28 14:12:57,359 : INFO : collecting document frequencies
2016-09-28 14:12:57,359 : INFO : PROGRESS: processing document #0
2016-09-28 14:12:57,574 : INFO : calculating IDF weights for 3088 documents and 4651 features (69245 matrix non-zeros)
2016-09-28 15:28:24,903 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:35:51,179 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:37:34,806 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:39:53,722 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:43:05,940 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:43:05,945 : INFO : Finished writing to cleanfile cleanQuestions.txt
2016-09-28 15:46:11,125 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:46:11,130 : INFO : Finished writing to cleanfile cleanQuestions.txt
2016-09-28 15:49:28,058 : INFO : Ready to write to cleanfile cleanQuestions.txt
2016-09-28 15:49:28,062 : INFO : Finished writing to cleanfile cleanQuestions.txt
2016-09-28 15:56:34,724 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 15:56:34,729 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 16:00:25,206 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-28 16:00:25,665 : INFO : built Dictionary(21611 unique tokens: [u'raining', u'kitchen............', u'shaksee', u'included;plus', u'$1.94']...) from 4822 documents (total 182255 corpus positions)
2016-09-28 16:00:25,685 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:00:25,692 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:00:25,698 : INFO : saving Dictionary object under ./tmp/genImp1/genImp1.dict, separately None
2016-09-28 16:00:25,706 : INFO : collecting document frequencies
2016-09-28 16:00:25,707 : INFO : PROGRESS: processing document #0
2016-09-28 16:00:25,927 : INFO : calculating IDF weights for 3088 documents and 7009 features (70967 matrix non-zeros)
2016-09-28 16:01:30,683 : INFO : using serial LSI version on this node
2016-09-28 16:01:30,684 : INFO : updating model with new documents
2016-09-28 16:01:31,042 : INFO : preparing a new chunk of documents
2016-09-28 16:01:31,043 : DEBUG : converting corpus to csc format
2016-09-28 16:01:31,081 : INFO : using 100 extra samples and 2 power iterations
2016-09-28 16:01:31,082 : INFO : 1st phase: constructing (7010, 102) action matrix
2016-09-28 16:01:31,109 : INFO : orthonormalizing (7010, 102) action matrix
2016-09-28 16:01:31,115 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:01:31,135 : DEBUG : running 2 power iterations
2016-09-28 16:01:31,152 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:01:31,180 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:01:31,203 : INFO : 2nd phase: running dense svd on (102, 3088) matrix
2016-09-28 16:01:31,218 : INFO : computing the final decomposition
2016-09-28 16:01:31,218 : INFO : keeping 2 factors (discarding 86.294% of energy spectrum)
2016-09-28 16:01:31,219 : INFO : processed documents up to #3088
2016-09-28 16:01:31,223 : INFO : topic #0(8.142): 0.200*"i" + 0.168*"my" + 0.167*"can" + 0.154*"is" + 0.144*"me" + 0.140*"it" + 0.136*"know" + 0.135*"you" + 0.135*"any" + 0.133*"where"
2016-09-28 16:01:31,223 : INFO : topic #1(4.228): -0.365*"where" + -0.324*"buy" + 0.322*"visa" + 0.226*"visit" + 0.219*"my" + -0.169*"anyone" + -0.164*"does" + -0.158*"can" + -0.157*"know" + -0.155*"find"
2016-09-28 16:02:03,290 : INFO : saving Projection object under ./tmp/genImp1/genImp1.lsi.projection, separately None
2016-09-28 16:02:03,292 : INFO : saving LsiModel object under ./tmp/genImp1/genImp1.lsi, separately None
2016-09-28 16:02:03,292 : INFO : not storing attribute projection
2016-09-28 16:02:03,292 : INFO : not storing attribute dispatcher
2016-09-28 16:04:45,708 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-28 16:04:46,166 : INFO : built Dictionary(21611 unique tokens: [u'raining', u'kitchen............', u'shaksee', u'included;plus', u'$1.94']...) from 4822 documents (total 182255 corpus positions)
2016-09-28 16:04:46,188 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:04:46,195 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:04:46,201 : INFO : saving Dictionary object under ./tmp/genImp1/genImp1.dict, separately None
2016-09-28 16:04:46,209 : INFO : collecting document frequencies
2016-09-28 16:04:46,209 : INFO : PROGRESS: processing document #0
2016-09-28 16:04:46,574 : INFO : calculating IDF weights for 4822 documents and 7009 features (122293 matrix non-zeros)
2016-09-28 16:04:46,580 : INFO : using serial LSI version on this node
2016-09-28 16:04:46,580 : INFO : updating model with new documents
2016-09-28 16:04:47,194 : INFO : preparing a new chunk of documents
2016-09-28 16:04:47,195 : DEBUG : converting corpus to csc format
2016-09-28 16:04:47,259 : INFO : using 100 extra samples and 2 power iterations
2016-09-28 16:04:47,259 : INFO : 1st phase: constructing (7010, 102) action matrix
2016-09-28 16:04:47,300 : INFO : orthonormalizing (7010, 102) action matrix
2016-09-28 16:04:47,305 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:04:47,320 : DEBUG : running 2 power iterations
2016-09-28 16:04:47,349 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:04:47,389 : DEBUG : computing QR of (7010, 102) dense matrix
2016-09-28 16:04:47,427 : INFO : 2nd phase: running dense svd on (102, 4822) matrix
2016-09-28 16:04:47,454 : INFO : computing the final decomposition
2016-09-28 16:04:47,454 : INFO : keeping 2 factors (discarding 85.084% of energy spectrum)
2016-09-28 16:04:47,455 : INFO : processed documents up to #4822
2016-09-28 16:04:47,460 : INFO : topic #0(10.206): 0.192*"i" + 0.164*"my" + 0.155*"can" + 0.150*"is" + 0.147*"you" + 0.138*"it" + 0.136*"me" + 0.132*"have" + 0.130*"any" + 0.125*"know"
2016-09-28 16:04:47,460 : INFO : topic #1(4.981): 0.360*"where" + -0.345*"visa" + 0.292*"buy" + -0.226*"visit" + -0.215*"my" + 0.174*"anyone" + 0.165*"does" + 0.160*"know" + 0.156*"find" + -0.147*"family"
2016-09-28 16:04:47,469 : INFO : saving Projection object under ./tmp/genImp1/genImp1.lsi.projection, separately None
2016-09-28 16:04:47,470 : INFO : saving LsiModel object under ./tmp/genImp1/genImp1.lsi, separately None
2016-09-28 16:04:47,470 : INFO : not storing attribute projection
2016-09-28 16:04:47,470 : INFO : not storing attribute dispatcher
2016-09-28 16:06:01,202 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-28 16:08:59,433 : INFO : storing corpus in Matrix Market format to ./tmp/genImp1/genImp1.mm
2016-09-28 16:08:59,434 : INFO : saving sparse matrix to ./tmp/genImp1/genImp1.mm
2016-09-28 16:08:59,434 : INFO : PROGRESS: saving document #0
2016-09-28 16:08:59,638 : INFO : PROGRESS: saving document #1000
2016-09-28 16:08:59,831 : INFO : PROGRESS: saving document #2000
2016-09-28 16:09:00,024 : INFO : PROGRESS: saving document #3000
2016-09-28 16:09:00,270 : INFO : PROGRESS: saving document #4000
2016-09-28 16:09:00,468 : INFO : saved 4822x7010 matrix, density=0.362% (122293/33802220)
2016-09-28 16:09:00,468 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:09:00,473 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:09:00,473 : INFO : saving MmCorpus index to ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:09:06,140 : INFO : loaded corpus index from ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:09:06,140 : INFO : initializing corpus reader from ./tmp/genImp1/genImp1.mm
2016-09-28 16:09:06,140 : INFO : accepted corpus with 4822 documents, 7010 features, 122293 non-zero entries
2016-09-28 16:09:18,359 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-28 16:09:19,104 : INFO : creating matrix with 4822 documents and 2 features
2016-09-28 16:09:19,169 : DEBUG : PROGRESS: at document #0/4822
2016-09-28 16:09:19,261 : DEBUG : PROGRESS: at document #1000/4822
2016-09-28 16:09:19,419 : DEBUG : PROGRESS: at document #2000/4822
2016-09-28 16:09:19,578 : DEBUG : PROGRESS: at document #3000/4822
2016-09-28 16:09:19,771 : DEBUG : PROGRESS: at document #4000/4822
2016-09-28 16:09:40,659 : INFO : saving MatrixSimilarity object under ./tmp/genImp1/genImp1.index, separately None
2016-09-28 16:09:47,342 : INFO : loading MatrixSimilarity object from ./tmp/genImp1/genImp1.index
2016-09-28 16:36:31,118 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-28 16:36:31,569 : INFO : built Dictionary(21611 unique tokens: [u'raining', u'kitchen............', u'shaksee', u'included;plus', u'$1.94']...) from 4822 documents (total 182255 corpus positions)
2016-09-28 16:36:31,593 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:36:31,601 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:36:31,607 : INFO : saving Dictionary object under ./tmp/genImp1/genImp1.dict, separately None
2016-09-28 16:36:31,615 : INFO : storing corpus in Matrix Market format to ./tmp/genImp1/genImp1.mm
2016-09-28 16:36:31,615 : INFO : saving sparse matrix to ./tmp/genImp1/genImp1.mm
2016-09-28 16:36:31,615 : INFO : PROGRESS: saving document #0
2016-09-28 16:36:31,800 : INFO : PROGRESS: saving document #1000
2016-09-28 16:36:31,987 : INFO : PROGRESS: saving document #2000
2016-09-28 16:36:32,171 : INFO : PROGRESS: saving document #3000
2016-09-28 16:36:32,397 : INFO : PROGRESS: saving document #4000
2016-09-28 16:36:32,596 : INFO : saved 4822x7010 matrix, density=0.362% (122293/33802220)
2016-09-28 16:36:32,596 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:36:32,599 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:36:32,600 : INFO : saving MmCorpus index to ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:36:32,602 : INFO : loaded corpus index from ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:36:32,603 : INFO : initializing corpus reader from ./tmp/genImp1/genImp1.mm
2016-09-28 16:36:32,603 : INFO : accepted corpus with 4822 documents, 7010 features, 122293 non-zero entries
2016-09-28 16:36:32,603 : INFO : collecting document frequencies
2016-09-28 16:36:32,603 : INFO : PROGRESS: processing document #0
2016-09-28 16:36:32,969 : INFO : calculating IDF weights for 4822 documents and 7009 features (122293 matrix non-zeros)
2016-09-28 16:36:32,975 : INFO : using serial LSI version on this node
2016-09-28 16:36:32,976 : INFO : updating model with new documents
2016-09-28 16:36:33,580 : INFO : preparing a new chunk of documents
2016-09-28 16:36:33,581 : DEBUG : converting corpus to csc format
2016-09-28 16:36:33,646 : INFO : using 100 extra samples and 2 power iterations
2016-09-28 16:36:33,646 : INFO : 1st phase: constructing (7010, 300) action matrix
2016-09-28 16:36:33,742 : INFO : orthonormalizing (7010, 300) action matrix
2016-09-28 16:36:33,761 : DEBUG : computing QR of (7010, 300) dense matrix
2016-09-28 16:36:33,850 : DEBUG : running 2 power iterations
2016-09-28 16:36:33,973 : DEBUG : computing QR of (7010, 300) dense matrix
2016-09-28 16:36:34,170 : DEBUG : computing QR of (7010, 300) dense matrix
2016-09-28 16:36:34,291 : INFO : 2nd phase: running dense svd on (300, 4822) matrix
2016-09-28 16:36:34,401 : INFO : computing the final decomposition
2016-09-28 16:36:34,401 : INFO : keeping 200 factors (discarding 17.879% of energy spectrum)
2016-09-28 16:36:34,422 : INFO : processed documents up to #4822
2016-09-28 16:36:34,427 : INFO : topic #0(10.206): 0.192*"i" + 0.164*"my" + 0.155*"can" + 0.150*"is" + 0.147*"you" + 0.138*"it" + 0.136*"me" + 0.132*"have" + 0.130*"any" + 0.125*"know"
2016-09-28 16:36:34,427 : INFO : topic #1(4.983): -0.360*"where" + 0.345*"visa" + -0.292*"buy" + 0.227*"visit" + 0.217*"my" + -0.174*"anyone" + -0.163*"does" + -0.163*"know" + -0.155*"find" + -0.147*"can"
2016-09-28 16:36:34,428 : INFO : topic #2(4.584): -0.331*"visa" + 0.330*"you" + -0.232*"where" + -0.232*"can" + -0.229*"visit" + 0.191*"do" + -0.189*"buy" + 0.186*"are" + 0.172*"what" + -0.168*"me"
2016-09-28 16:36:34,428 : INFO : topic #3(4.031): -0.479*"you" + 0.290*"does" + -0.222*"do" + 0.192*"anyone" + -0.189*"me" + -0.180*"tell" + -0.167*"your" + -0.163*"best" + -0.162*"please" + -0.155*"?"
2016-09-28 16:36:34,429 : INFO : topic #4(3.909): -0.304*"visa" + -0.267*"does" + -0.243*"you" + 0.230*"me" + -0.222*"visit" + -0.202*"know" + -0.201*"do" + 0.172*"tell" + -0.167*"where" + 0.165*"car"
2016-09-28 16:36:34,436 : INFO : saving Projection object under ./tmp/genImp1/genImp1.lsi.projection, separately None
2016-09-28 16:36:34,471 : INFO : saving LsiModel object under ./tmp/genImp1/genImp1.lsi, separately None
2016-09-28 16:36:34,471 : INFO : not storing attribute projection
2016-09-28 16:36:34,471 : INFO : not storing attribute dispatcher
2016-09-28 16:36:34,489 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-28 16:36:35,571 : INFO : creating matrix with 4822 documents and 200 features
2016-09-28 16:36:35,642 : DEBUG : PROGRESS: at document #0/4822
2016-09-28 16:36:35,816 : DEBUG : PROGRESS: at document #1000/4822
2016-09-28 16:36:36,067 : DEBUG : PROGRESS: at document #2000/4822
2016-09-28 16:36:36,306 : DEBUG : PROGRESS: at document #3000/4822
2016-09-28 16:36:36,595 : DEBUG : PROGRESS: at document #4000/4822
2016-09-28 16:36:36,816 : INFO : saving MatrixSimilarity object under ./tmp/genImp1/genImp1.index, separately None
2016-09-28 16:36:36,826 : INFO : loading MatrixSimilarity object from ./tmp/genImp1/genImp1.index
2016-09-28 16:38:10,086 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-09-28 16:38:10,529 : INFO : built Dictionary(21611 unique tokens: [u'raining', u'kitchen............', u'shaksee', u'included;plus', u'$1.94']...) from 4822 documents (total 182255 corpus positions)
2016-09-28 16:38:10,550 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:38:10,557 : DEBUG : rebuilding dictionary, shrinking gaps
2016-09-28 16:38:10,563 : INFO : saving Dictionary object under ./tmp/genImp1/genImp1.dict, separately None
2016-09-28 16:38:10,571 : INFO : storing corpus in Matrix Market format to ./tmp/genImp1/genImp1.mm
2016-09-28 16:38:10,571 : INFO : saving sparse matrix to ./tmp/genImp1/genImp1.mm
2016-09-28 16:38:10,571 : INFO : PROGRESS: saving document #0
2016-09-28 16:38:10,760 : INFO : PROGRESS: saving document #1000
2016-09-28 16:38:10,961 : INFO : PROGRESS: saving document #2000
2016-09-28 16:38:11,149 : INFO : PROGRESS: saving document #3000
2016-09-28 16:38:11,383 : INFO : PROGRESS: saving document #4000
2016-09-28 16:38:11,584 : INFO : saved 4822x7010 matrix, density=0.362% (122293/33802220)
2016-09-28 16:38:11,584 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:38:11,587 : DEBUG : closing ./tmp/genImp1/genImp1.mm
2016-09-28 16:38:11,587 : INFO : saving MmCorpus index to ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:38:11,590 : INFO : loaded corpus index from ./tmp/genImp1/genImp1.mm.index
2016-09-28 16:38:11,590 : INFO : initializing corpus reader from ./tmp/genImp1/genImp1.mm
2016-09-28 16:38:11,590 : INFO : accepted corpus with 4822 documents, 7010 features, 122293 non-zero entries
2016-09-28 16:38:11,590 : INFO : collecting document frequencies
2016-09-28 16:38:11,591 : INFO : PROGRESS: processing document #0
2016-09-28 16:38:11,967 : INFO : calculating IDF weights for 4822 documents and 7009 features (122293 matrix non-zeros)
2016-09-28 16:38:11,973 : INFO : using serial LSI version on this node
2016-09-28 16:38:11,973 : INFO : updating model with new documents
2016-09-28 16:38:12,607 : INFO : preparing a new chunk of documents
2016-09-28 16:38:12,608 : DEBUG : converting corpus to csc format
2016-09-28 16:38:12,673 : INFO : using 100 extra samples and 2 power iterations
2016-09-28 16:38:12,673 : INFO : 1st phase: constructing (7010, 500) action matrix
2016-09-28 16:38:12,840 : INFO : orthonormalizing (7010, 500) action matrix
2016-09-28 16:38:12,887 : DEBUG : computing QR of (7010, 500) dense matrix
2016-09-28 16:38:13,123 : DEBUG : running 2 power iterations
2016-09-28 16:38:13,285 : DEBUG : computing QR of (7010, 500) dense matrix
2016-09-28 16:38:13,608 : DEBUG : computing QR of (7010, 500) dense matrix
2016-09-28 16:38:13,805 : INFO : 2nd phase: running dense svd on (500, 4822) matrix
2016-09-28 16:38:14,019 : INFO : computing the final decomposition
2016-09-28 16:38:14,019 : INFO : keeping 400 factors (discarding 9.300% of energy spectrum)
2016-09-28 16:38:14,061 : INFO : processed documents up to #4822
2016-09-28 16:38:14,064 : INFO : topic #0(10.206): 0.192*"i" + 0.164*"my" + 0.155*"can" + 0.150*"is" + 0.147*"you" + 0.138*"it" + 0.136*"me" + 0.132*"have" + 0.130*"any" + 0.125*"know"
2016-09-28 16:38:14,065 : INFO : topic #1(4.983): 0.359*"where" + -0.346*"visa" + 0.292*"buy" + -0.227*"visit" + -0.217*"my" + 0.174*"anyone" + 0.163*"does" + 0.163*"know" + 0.155*"find" + 0.148*"can"
2016-09-28 16:38:14,065 : INFO : topic #2(4.584): -0.331*"visa" + 0.330*"you" + -0.232*"where" + -0.232*"can" + -0.229*"visit" + 0.191*"do" + -0.189*"buy" + 0.186*"are" + 0.171*"what" + -0.168*"me"
2016-09-28 16:38:14,065 : INFO : topic #3(4.031): -0.479*"you" + 0.290*"does" + -0.222*"do" + 0.191*"anyone" + -0.189*"me" + -0.180*"tell" + -0.167*"your" + -0.163*"please" + -0.162*"best" + -0.156*"?"
2016-09-28 16:38:14,066 : INFO : topic #4(3.910): -0.305*"visa" + -0.267*"does" + -0.243*"you" + 0.231*"me" + -0.222*"visit" + -0.201*"know" + -0.201*"do" + 0.172*"tell" + -0.167*"where" + 0.165*"car"
2016-09-28 16:38:14,071 : INFO : saving Projection object under ./tmp/genImp1/genImp1.lsi.projection, separately None
2016-09-28 16:38:14,119 : INFO : saving LsiModel object under ./tmp/genImp1/genImp1.lsi, separately None
2016-09-28 16:38:14,119 : INFO : not storing attribute projection
2016-09-28 16:38:14,119 : INFO : not storing attribute dispatcher
2016-09-28 16:38:14,137 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-09-28 16:38:15,497 : INFO : creating matrix with 4822 documents and 400 features
2016-09-28 16:38:15,567 : DEBUG : PROGRESS: at document #0/4822
2016-09-28 16:38:15,815 : DEBUG : PROGRESS: at document #1000/4822
2016-09-28 16:38:16,141 : DEBUG : PROGRESS: at document #2000/4822
2016-09-28 16:38:16,464 : DEBUG : PROGRESS: at document #3000/4822
2016-09-28 16:38:16,823 : DEBUG : PROGRESS: at document #4000/4822
2016-09-28 16:38:17,103 : INFO : saving MatrixSimilarity object under ./tmp/genImp1/genImp1.index, separately None
2016-09-28 16:38:17,120 : INFO : loading MatrixSimilarity object from ./tmp/genImp1/genImp1.index
2016-09-28 16:46:08,547 : INFO : collecting all words and their counts
2016-09-28 16:46:08,547 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 16:46:08,775 : INFO : collected 11922 word types and 15 unique tags from a corpus of 4822 examples and 185397 words
2016-09-28 16:46:08,789 : INFO : min_count=5 retains 2767 unique words (drops 9155)
2016-09-28 16:46:08,789 : INFO : min_count leaves 171408 word corpus (92% of original 185397)
2016-09-28 16:46:08,795 : INFO : deleting the raw counts dictionary of 11922 items
2016-09-28 16:46:08,796 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 16:46:08,796 : INFO : downsampling leaves estimated 171408 word corpus (100.0% of prior 171408)
2016-09-28 16:46:08,796 : INFO : estimated required memory for 2767 words and 100 dimensions: 4159500 bytes
2016-09-28 16:46:08,798 : INFO : constructing a huffman tree from 2767 words
2016-09-28 16:46:08,878 : INFO : built huffman tree with maximum node depth 15
2016-09-28 16:46:08,879 : INFO : resetting layer weights
2016-09-28 16:46:08,911 : INFO : training model with 4 workers on 2767 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 16:46:08,911 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 16:46:08,913 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02500
2016-09-28 16:46:08,915 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02471
2016-09-28 16:46:08,917 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02441
2016-09-28 16:46:08,918 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02410
2016-09-28 16:46:08,921 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02381
2016-09-28 16:46:08,922 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02350
2016-09-28 16:46:08,922 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02320
2016-09-28 16:46:08,924 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02290
2016-09-28 16:46:08,926 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02262
2016-09-28 16:46:08,927 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02233
2016-09-28 16:46:08,927 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02201
2016-09-28 16:46:08,928 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02173
2016-09-28 16:46:08,930 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02150
2016-09-28 16:46:08,986 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02126
2016-09-28 16:46:08,988 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02105
2016-09-28 16:46:08,993 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02082
2016-09-28 16:46:08,996 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02061
2016-09-28 16:46:09,053 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02037
2016-09-28 16:46:09,056 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02015
2016-09-28 16:46:09,058 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01990
2016-09-28 16:46:09,063 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01961
2016-09-28 16:46:09,115 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01930
2016-09-28 16:46:09,119 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01900
2016-09-28 16:46:09,123 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01871
2016-09-28 16:46:09,128 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01840
2016-09-28 16:46:09,172 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01810
2016-09-28 16:46:09,175 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01781
2016-09-28 16:46:09,178 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01752
2016-09-28 16:46:09,182 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01721
2016-09-28 16:46:09,229 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01690
2016-09-28 16:46:09,231 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01666
2016-09-28 16:46:09,234 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01642
2016-09-28 16:46:09,245 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01619
2016-09-28 16:46:09,295 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01598
2016-09-28 16:46:09,297 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01575
2016-09-28 16:46:09,300 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01554
2016-09-28 16:46:09,311 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01531
2016-09-28 16:46:09,361 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01508
2016-09-28 16:46:09,362 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01480
2016-09-28 16:46:09,366 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01450
2016-09-28 16:46:09,380 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01419
2016-09-28 16:46:09,421 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01390
2016-09-28 16:46:09,422 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01360
2016-09-28 16:46:09,430 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01329
2016-09-28 16:46:09,435 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01299
2016-09-28 16:46:09,475 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01272
2016-09-28 16:46:09,478 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01243
2016-09-28 16:46:09,486 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01210
2016-09-28 16:46:09,489 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01181
2016-09-28 16:46:09,532 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01158
2016-09-28 16:46:09,538 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01134
2016-09-28 16:46:09,553 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01112
2016-09-28 16:46:09,557 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01090
2016-09-28 16:46:09,597 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01069
2016-09-28 16:46:09,608 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01046
2016-09-28 16:46:09,618 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01023
2016-09-28 16:46:09,627 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.00999
2016-09-28 16:46:09,663 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.00970
2016-09-28 16:46:09,672 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.00939
2016-09-28 16:46:09,690 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.00909
2016-09-28 16:46:09,692 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.00879
2016-09-28 16:46:09,720 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.00849
2016-09-28 16:46:09,727 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.00820
2016-09-28 16:46:09,748 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.00790
2016-09-28 16:46:09,749 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.00761
2016-09-28 16:46:09,779 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.00730
2016-09-28 16:46:09,790 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.00699
2016-09-28 16:46:09,806 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.00674
2016-09-28 16:46:09,810 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.00650
2016-09-28 16:46:09,846 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.00627
2016-09-28 16:46:09,858 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.00606
2016-09-28 16:46:09,874 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.00583
2016-09-28 16:46:09,884 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.00562
2016-09-28 16:46:09,914 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.00538
2016-09-28 16:46:09,915 : INFO : PROGRESS: at 66.32% examples, 700959 words/s, in_qsize 8, out_qsize 0
2016-09-28 16:46:09,923 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.00516
2016-09-28 16:46:09,941 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.00489
2016-09-28 16:46:09,950 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.00460
2016-09-28 16:46:09,983 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.00429
2016-09-28 16:46:09,989 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.00399
2016-09-28 16:46:10,002 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.00369
2016-09-28 16:46:10,008 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.00338
2016-09-28 16:46:10,042 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.00308
2016-09-28 16:46:10,044 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.00280
2016-09-28 16:46:10,058 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.00251
2016-09-28 16:46:10,061 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.00219
2016-09-28 16:46:10,097 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.00189
2016-09-28 16:46:10,101 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.00166
2016-09-28 16:46:10,116 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.00143
2016-09-28 16:46:10,123 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.00120
2016-09-28 16:46:10,164 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.00097
2016-09-28 16:46:10,168 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.00076
2016-09-28 16:46:10,185 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.00054
2016-09-28 16:46:10,192 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.00031
2016-09-28 16:46:10,284 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 16:46:10,341 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:46:10,342 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 16:46:10,349 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:46:10,350 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 16:46:10,357 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:46:10,357 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 16:46:10,367 : DEBUG : worker exiting, processed 24 jobs
2016-09-28 16:46:10,367 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 16:46:10,367 : INFO : training on 926985 raw words (1068480 effective words) took 1.5s, 734919 effective words/s
2016-09-28 16:52:53,781 : INFO : collecting all words and their counts
2016-09-28 16:52:53,782 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 16:52:54,003 : INFO : collected 11922 word types and 15 unique tags from a corpus of 4822 examples and 185397 words
2016-09-28 16:52:54,021 : INFO : min_count=5 retains 2767 unique words (drops 9155)
2016-09-28 16:52:54,021 : INFO : min_count leaves 171408 word corpus (92% of original 185397)
2016-09-28 16:52:54,027 : INFO : deleting the raw counts dictionary of 11922 items
2016-09-28 16:52:54,028 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 16:52:54,028 : INFO : downsampling leaves estimated 171408 word corpus (100.0% of prior 171408)
2016-09-28 16:52:54,028 : INFO : estimated required memory for 2767 words and 100 dimensions: 4159500 bytes
2016-09-28 16:52:54,031 : INFO : constructing a huffman tree from 2767 words
2016-09-28 16:52:54,101 : INFO : built huffman tree with maximum node depth 15
2016-09-28 16:52:54,101 : INFO : resetting layer weights
2016-09-28 16:52:54,132 : INFO : training model with 4 workers on 2767 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 16:52:54,132 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 16:52:54,135 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02500
2016-09-28 16:52:54,135 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02471
2016-09-28 16:52:54,136 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02441
2016-09-28 16:52:54,137 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02410
2016-09-28 16:52:54,139 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02381
2016-09-28 16:52:54,140 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02350
2016-09-28 16:52:54,141 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02320
2016-09-28 16:52:54,142 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02290
2016-09-28 16:52:54,143 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02262
2016-09-28 16:52:54,144 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02233
2016-09-28 16:52:54,144 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02201
2016-09-28 16:52:54,145 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02173
2016-09-28 16:52:54,146 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02150
2016-09-28 16:52:54,204 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02126
2016-09-28 16:52:54,207 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02105
2016-09-28 16:52:54,208 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02082
2016-09-28 16:52:54,213 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02061
2016-09-28 16:52:54,271 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02037
2016-09-28 16:52:54,272 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02015
2016-09-28 16:52:54,274 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01990
2016-09-28 16:52:54,280 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01961
2016-09-28 16:52:54,334 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01930
2016-09-28 16:52:54,336 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01900
2016-09-28 16:52:54,339 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01871
2016-09-28 16:52:54,344 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01840
2016-09-28 16:52:54,389 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01810
2016-09-28 16:52:54,390 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01781
2016-09-28 16:52:54,395 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01752
2016-09-28 16:52:54,401 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01721
2016-09-28 16:52:54,444 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01690
2016-09-28 16:52:54,449 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01666
2016-09-28 16:52:54,452 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01642
2016-09-28 16:52:54,464 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01619
2016-09-28 16:52:54,508 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01598
2016-09-28 16:52:54,517 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01575
2016-09-28 16:52:54,519 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01554
2016-09-28 16:52:54,532 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01531
2016-09-28 16:52:54,572 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01508
2016-09-28 16:52:54,583 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01480
2016-09-28 16:52:54,587 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01450
2016-09-28 16:52:54,602 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01419
2016-09-28 16:52:54,637 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01390
2016-09-28 16:52:54,644 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01360
2016-09-28 16:52:54,647 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01329
2016-09-28 16:52:54,660 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01299
2016-09-28 16:52:54,690 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01272
2016-09-28 16:52:54,698 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01243
2016-09-28 16:52:54,701 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01210
2016-09-28 16:52:54,718 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01181
2016-09-28 16:52:54,748 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01158
2016-09-28 16:52:54,760 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01134
2016-09-28 16:52:54,765 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01112
2016-09-28 16:52:54,785 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01090
2016-09-28 16:52:54,814 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01069
2016-09-28 16:52:54,829 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01046
2016-09-28 16:52:54,833 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01023
2016-09-28 16:52:54,856 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.00999
2016-09-28 16:52:54,882 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.00970
2016-09-28 16:52:54,895 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.00939
2016-09-28 16:52:54,904 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.00909
2016-09-28 16:52:54,925 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.00879
2016-09-28 16:52:54,942 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.00849
2016-09-28 16:52:54,961 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.00820
2016-09-28 16:52:54,966 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.00790
2016-09-28 16:52:54,986 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.00761
2016-09-28 16:52:54,997 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.00730
2016-09-28 16:52:55,019 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.00699
2016-09-28 16:52:55,024 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.00674
2016-09-28 16:52:55,041 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.00650
2016-09-28 16:52:55,059 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.00627
2016-09-28 16:52:55,083 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.00606
2016-09-28 16:52:55,090 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.00583
2016-09-28 16:52:55,106 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.00562
2016-09-28 16:52:55,126 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.00538
2016-09-28 16:52:55,147 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.00516
2016-09-28 16:52:55,147 : INFO : PROGRESS: at 67.49% examples, 705028 words/s, in_qsize 8, out_qsize 0
2016-09-28 16:52:55,159 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.00489
2016-09-28 16:52:55,172 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.00460
2016-09-28 16:52:55,194 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.00429
2016-09-28 16:52:55,214 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.00399
2016-09-28 16:52:55,221 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.00369
2016-09-28 16:52:55,229 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.00338
2016-09-28 16:52:55,250 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.00308
2016-09-28 16:52:55,268 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.00280
2016-09-28 16:52:55,276 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.00251
2016-09-28 16:52:55,286 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.00219
2016-09-28 16:52:55,306 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.00189
2016-09-28 16:52:55,325 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.00166
2016-09-28 16:52:55,335 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.00143
2016-09-28 16:52:55,348 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.00120
2016-09-28 16:52:55,371 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.00097
2016-09-28 16:52:55,392 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.00076
2016-09-28 16:52:55,400 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.00054
2016-09-28 16:52:55,418 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.00031
2016-09-28 16:52:55,501 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 16:52:55,559 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:52:55,560 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 16:52:55,568 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:52:55,568 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 16:52:55,580 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:52:55,580 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 16:52:55,586 : DEBUG : worker exiting, processed 24 jobs
2016-09-28 16:52:55,586 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 16:52:55,586 : INFO : training on 926985 raw words (1068480 effective words) took 1.5s, 736396 effective words/s
2016-09-28 16:55:29,704 : INFO : collecting all words and their counts
2016-09-28 16:55:29,704 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 16:55:29,925 : INFO : collected 11922 word types and 15 unique tags from a corpus of 4822 examples and 185397 words
2016-09-28 16:55:29,943 : INFO : min_count=5 retains 2767 unique words (drops 9155)
2016-09-28 16:55:29,943 : INFO : min_count leaves 171408 word corpus (92% of original 185397)
2016-09-28 16:55:29,950 : INFO : deleting the raw counts dictionary of 11922 items
2016-09-28 16:55:29,950 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 16:55:29,950 : INFO : downsampling leaves estimated 171408 word corpus (100.0% of prior 171408)
2016-09-28 16:55:29,950 : INFO : estimated required memory for 2767 words and 100 dimensions: 4159500 bytes
2016-09-28 16:55:29,953 : INFO : constructing a huffman tree from 2767 words
2016-09-28 16:55:30,024 : INFO : built huffman tree with maximum node depth 15
2016-09-28 16:55:30,024 : INFO : resetting layer weights
2016-09-28 16:55:30,055 : INFO : training model with 4 workers on 2767 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 16:55:30,056 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 16:55:30,058 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02500
2016-09-28 16:55:30,059 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02471
2016-09-28 16:55:30,060 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02441
2016-09-28 16:55:30,061 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02410
2016-09-28 16:55:30,062 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02381
2016-09-28 16:55:30,064 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02350
2016-09-28 16:55:30,065 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02320
2016-09-28 16:55:30,066 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02290
2016-09-28 16:55:30,067 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02262
2016-09-28 16:55:30,068 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02233
2016-09-28 16:55:30,069 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02201
2016-09-28 16:55:30,070 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02173
2016-09-28 16:55:30,071 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02150
2016-09-28 16:55:30,129 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02126
2016-09-28 16:55:30,130 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02105
2016-09-28 16:55:30,131 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02082
2016-09-28 16:55:30,134 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02061
2016-09-28 16:55:30,193 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02037
2016-09-28 16:55:30,195 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02015
2016-09-28 16:55:30,197 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01990
2016-09-28 16:55:30,200 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01961
2016-09-28 16:55:30,251 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01930
2016-09-28 16:55:30,256 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01900
2016-09-28 16:55:30,261 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01871
2016-09-28 16:55:30,269 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01840
2016-09-28 16:55:30,309 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01810
2016-09-28 16:55:30,311 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01781
2016-09-28 16:55:30,317 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01752
2016-09-28 16:55:30,324 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01721
2016-09-28 16:55:30,364 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01690
2016-09-28 16:55:30,369 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01666
2016-09-28 16:55:30,376 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01642
2016-09-28 16:55:30,385 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01619
2016-09-28 16:55:30,429 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01598
2016-09-28 16:55:30,433 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01575
2016-09-28 16:55:30,442 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01554
2016-09-28 16:55:30,451 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01531
2016-09-28 16:55:30,492 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01508
2016-09-28 16:55:30,500 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01480
2016-09-28 16:55:30,508 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01450
2016-09-28 16:55:30,520 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01419
2016-09-28 16:55:30,556 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01390
2016-09-28 16:55:30,561 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01360
2016-09-28 16:55:30,566 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01329
2016-09-28 16:55:30,577 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01299
2016-09-28 16:55:30,610 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01272
2016-09-28 16:55:30,617 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01243
2016-09-28 16:55:30,621 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01210
2016-09-28 16:55:30,634 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01181
2016-09-28 16:55:30,666 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01158
2016-09-28 16:55:30,676 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01134
2016-09-28 16:55:30,683 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01112
2016-09-28 16:55:30,700 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01090
2016-09-28 16:55:30,733 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01069
2016-09-28 16:55:30,743 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01046
2016-09-28 16:55:30,755 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01023
2016-09-28 16:55:30,769 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.00999
2016-09-28 16:55:30,796 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.00970
2016-09-28 16:55:30,810 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.00939
2016-09-28 16:55:30,830 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.00909
2016-09-28 16:55:30,838 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.00879
2016-09-28 16:55:30,856 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.00849
2016-09-28 16:55:30,871 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.00820
2016-09-28 16:55:30,885 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.00790
2016-09-28 16:55:30,894 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.00761
2016-09-28 16:55:30,912 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.00730
2016-09-28 16:55:30,926 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.00699
2016-09-28 16:55:30,939 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.00674
2016-09-28 16:55:30,951 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.00650
2016-09-28 16:55:30,973 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.00627
2016-09-28 16:55:30,990 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.00606
2016-09-28 16:55:31,005 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.00583
2016-09-28 16:55:31,014 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.00562
2016-09-28 16:55:31,039 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.00538
2016-09-28 16:55:31,055 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.00516
2016-09-28 16:55:31,072 : INFO : PROGRESS: at 68.68% examples, 715711 words/s, in_qsize 7, out_qsize 0
2016-09-28 16:55:31,073 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.00489
2016-09-28 16:55:31,078 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.00460
2016-09-28 16:55:31,109 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.00429
2016-09-28 16:55:31,122 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.00399
2016-09-28 16:55:31,133 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.00369
2016-09-28 16:55:31,137 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.00338
2016-09-28 16:55:31,164 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.00308
2016-09-28 16:55:31,176 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.00280
2016-09-28 16:55:31,187 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.00251
2016-09-28 16:55:31,191 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.00219
2016-09-28 16:55:31,222 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.00189
2016-09-28 16:55:31,231 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.00166
2016-09-28 16:55:31,248 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.00143
2016-09-28 16:55:31,252 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.00120
2016-09-28 16:55:31,289 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.00097
2016-09-28 16:55:31,297 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.00076
2016-09-28 16:55:31,315 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.00054
2016-09-28 16:55:31,318 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.00031
2016-09-28 16:55:31,411 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 16:55:31,464 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:55:31,464 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 16:55:31,482 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:55:31,482 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 16:55:31,486 : DEBUG : worker exiting, processed 23 jobs
2016-09-28 16:55:31,486 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 16:55:31,495 : DEBUG : worker exiting, processed 24 jobs
2016-09-28 16:55:31,495 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 16:55:31,495 : INFO : training on 926985 raw words (1068480 effective words) took 1.4s, 743228 effective words/s
2016-09-28 16:55:31,496 : INFO : saving Doc2Vec object under ./tmp/doc2vec_size100window8min5work4, separately None
2016-09-28 16:55:31,496 : INFO : not storing attribute syn0norm
2016-09-28 16:55:31,496 : INFO : not storing attribute cum_table
2016-09-28 17:06:35,384 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:06:35,390 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:09:20,472 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:09:20,478 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:15:26,643 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:15:26,649 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:17:18,869 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:17:18,875 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:18:15,692 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:18:15,698 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:18:56,594 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:18:56,599 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:20:23,930 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:20:23,935 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:21:20,587 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:21:20,593 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:22:02,723 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:22:02,729 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:25:49,879 : INFO : Ready to write to cleanfile cleanQuestions
2016-09-28 17:25:49,885 : INFO : Finished writing to cleanfile cleanQuestions
2016-09-28 17:27:42,530 : INFO : collecting all words and their counts
2016-09-28 17:27:42,531 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 17:27:42,754 : INFO : collected 11922 word types and 15 unique tags from a corpus of 4822 examples and 185397 words
2016-09-28 17:27:42,786 : INFO : min_count=1 retains 11922 unique words (drops 0)
2016-09-28 17:27:42,786 : INFO : min_count leaves 185397 word corpus (100% of original 185397)
2016-09-28 17:27:42,816 : INFO : deleting the raw counts dictionary of 11922 items
2016-09-28 17:27:42,817 : INFO : sample=0.0001 downsamples 438 most-common words
2016-09-28 17:27:42,817 : INFO : downsampling leaves estimated 81701 word corpus (44.1% of prior 185397)
2016-09-28 17:27:42,817 : INFO : estimated required memory for 11922 words and 100 dimensions: 22660800 bytes
2016-09-28 17:27:42,831 : INFO : constructing a huffman tree from 11922 words
2016-09-28 17:27:43,179 : INFO : built huffman tree with maximum node depth 18
2016-09-28 17:27:43,205 : INFO : resetting layer weights
2016-09-28 17:33:17,663 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:17,663 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:17,667 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:17,668 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:17,669 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:17,671 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:17,672 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:17,673 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:17,673 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:17,675 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:17,676 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:17,677 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:17,678 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:17,678 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:17,679 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:17,680 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:17,681 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:17,681 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:17,682 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:17,683 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:17,684 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:17,684 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:17,685 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:17,686 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:17,686 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:17,687 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:17,688 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:17,850 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:17,851 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:17,856 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:17,859 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:17,862 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:17,869 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:17,874 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:17,878 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:18,020 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:18,033 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:18,034 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:18,036 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:18,037 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:18,040 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:18,048 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:18,051 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:18,200 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:18,202 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:18,204 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:18,205 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:18,214 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:18,219 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:18,225 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:18,233 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:18,363 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:18,373 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:18,377 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:18,379 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:18,392 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:18,395 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:18,399 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:18,402 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:18,544 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:18,547 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:18,551 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:18,557 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:18,558 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:18,570 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:18,577 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:18,582 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:18,715 : INFO : PROGRESS: at 44.06% examples, 260992 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:18,716 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:18,727 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:18,729 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:18,731 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:18,732 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:18,738 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:18,759 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:18,763 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:18,891 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:18,903 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:18,905 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:18,910 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:18,912 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:18,916 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:18,927 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:18,940 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:19,069 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:19,071 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:19,072 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:19,086 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:19,088 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:19,092 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:19,097 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:19,114 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:19,245 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:19,249 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:19,251 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:19,254 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:19,430 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:19,609 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:19,609 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:19,610 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:19,610 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:19,611 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:19,611 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:19,692 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:19,692 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:19,693 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:19,694 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:19,696 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:19,696 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:19,698 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:19,698 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:19,698 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:19,698 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:19,699 : INFO : training on 926985 raw words (619905 effective words) took 2.0s, 305075 effective words/s
2016-09-28 17:33:19,699 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:19,699 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:19,701 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:19,702 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:19,703 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:19,704 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:19,705 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:19,706 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:19,707 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:19,708 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:19,709 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:19,710 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:19,710 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:19,711 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:19,712 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:19,713 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:19,713 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:19,714 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:19,715 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:19,716 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:19,716 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:19,717 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:19,718 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:19,719 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:19,720 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:19,721 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:19,722 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:19,879 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:19,884 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:19,890 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:19,896 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:19,897 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:19,899 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:19,900 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:19,908 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:20,054 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:20,060 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:20,064 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:20,067 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:20,071 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:20,074 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:20,076 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:20,083 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:20,232 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:20,234 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:20,235 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:20,238 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:20,249 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:20,251 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:20,253 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:20,261 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:20,395 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:20,400 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:20,409 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:20,411 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:20,421 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:20,427 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:20,431 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:20,435 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:20,576 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:20,579 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:20,587 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:20,590 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:20,591 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:20,603 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:20,606 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:20,612 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:20,755 : INFO : PROGRESS: at 44.06% examples, 259719 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:20,756 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:20,761 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:20,764 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:20,767 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:20,769 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:20,781 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:20,788 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:20,793 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:20,933 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:20,937 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:20,941 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:20,944 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:20,955 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:20,957 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:20,962 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:20,966 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:21,109 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:21,111 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:21,120 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:21,125 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:21,128 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:21,131 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:21,132 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:21,136 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:21,276 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:21,293 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:21,297 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:21,299 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:21,472 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:21,645 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:21,645 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:21,645 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:21,645 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:21,648 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:21,648 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:21,731 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:21,732 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:21,735 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:21,736 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:21,737 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:21,737 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:21,737 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:21,738 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:21,738 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:21,738 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:21,738 : INFO : training on 926985 raw words (619965 effective words) took 2.0s, 304352 effective words/s
2016-09-28 17:33:21,739 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:21,739 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:21,743 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:21,744 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:21,746 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:21,747 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:21,748 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:21,749 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:21,750 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:21,750 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:21,751 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:21,752 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:21,753 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:21,754 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:21,755 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:21,755 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:21,756 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:21,757 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:21,758 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:21,759 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:21,760 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:21,760 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:21,761 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:21,762 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:21,763 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:21,763 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:21,764 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:21,921 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:21,922 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:21,929 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:21,931 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:21,934 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:21,940 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:21,943 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:21,948 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:22,094 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:22,104 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:22,106 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:22,107 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:22,109 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:22,113 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:22,121 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:22,126 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:22,271 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:22,273 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:22,276 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:22,281 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:22,286 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:22,292 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:22,299 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:22,301 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:22,438 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:22,443 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:22,453 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:22,459 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:22,463 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:22,466 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:22,474 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:22,480 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:22,612 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:22,622 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:22,629 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:22,632 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:22,635 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:22,643 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:22,645 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:22,654 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:22,799 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:22,799 : INFO : PROGRESS: at 44.06% examples, 259502 words/s, in_qsize 16, out_qsize 0
2016-09-28 17:33:22,806 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:22,808 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:22,810 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:22,813 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:22,819 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:22,835 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:22,842 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:22,973 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:22,976 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:22,979 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:22,983 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:22,990 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:22,993 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:23,009 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:23,017 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:23,144 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:23,149 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:23,155 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:23,160 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:23,163 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:23,169 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:23,182 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:23,186 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:23,317 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:23,327 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:23,333 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:23,337 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:23,509 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:23,690 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:23,690 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:23,693 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:23,693 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:23,696 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:23,696 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:23,776 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:23,776 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:23,778 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:23,778 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:23,780 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:23,780 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:23,781 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:23,781 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:23,783 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:23,783 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:23,783 : INFO : training on 926985 raw words (619906 effective words) took 2.0s, 304094 effective words/s
2016-09-28 17:33:23,783 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:23,783 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:23,786 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:23,787 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:23,788 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:23,789 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:23,790 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:23,791 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:23,792 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:23,792 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:23,793 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:23,794 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:23,795 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:23,796 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:23,796 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:23,797 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:23,798 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:23,798 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:23,799 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:23,800 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:23,801 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:23,801 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:23,802 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:23,803 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:23,804 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:23,804 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:23,805 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:23,959 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:23,961 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:23,971 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:23,978 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:23,979 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:23,980 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:23,983 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:23,991 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:24,133 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:24,142 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:24,143 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:24,147 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:24,154 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:24,157 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:24,159 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:24,166 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:24,308 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:24,314 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:24,317 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:24,323 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:24,329 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:24,330 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:24,341 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:24,343 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:24,472 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:24,488 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:24,494 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:24,498 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:24,507 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:24,509 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:24,513 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:24,527 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:24,650 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:24,663 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:24,671 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:24,675 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:24,677 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:24,680 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:24,689 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:24,705 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:24,836 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:24,836 : INFO : PROGRESS: at 44.19% examples, 260772 words/s, in_qsize 16, out_qsize 0
2016-09-28 17:33:24,843 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:24,845 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:24,848 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:24,850 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:24,851 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:24,870 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:24,888 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:25,007 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:25,017 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:25,020 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:25,022 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:25,026 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:25,029 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:25,048 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:25,054 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:25,181 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:25,186 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:25,188 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:25,199 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:25,201 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:25,209 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:25,218 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:25,221 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:25,352 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:25,368 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:25,370 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:25,374 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:25,547 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:25,723 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:25,723 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:25,724 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:25,724 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:25,730 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:25,731 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:25,807 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:25,807 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:25,814 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:25,814 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:25,815 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:25,815 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:25,816 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:25,816 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:25,817 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:25,817 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:25,818 : INFO : training on 926985 raw words (619595 effective words) took 2.0s, 304982 effective words/s
2016-09-28 17:33:25,818 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:25,818 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:25,820 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:25,821 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:25,822 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:25,823 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:25,824 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:25,825 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:25,826 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:25,827 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:25,828 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:25,829 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:25,830 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:25,831 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:25,831 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:25,832 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:25,832 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:25,833 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:25,834 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:25,834 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:25,835 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:25,836 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:25,836 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:25,837 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:25,837 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:25,838 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:25,839 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:25,995 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:26,002 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:26,004 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:26,011 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:26,012 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:26,015 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:26,021 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:26,023 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:26,167 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:26,176 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:26,179 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:26,181 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:26,188 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:26,190 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:26,194 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:26,196 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:26,349 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:26,350 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:26,351 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:26,360 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:26,363 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:26,365 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:26,373 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:26,385 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:26,515 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:26,521 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:26,536 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:26,539 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:26,541 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:26,544 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:26,548 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:26,552 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:26,691 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:26,702 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:26,706 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:26,713 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:26,715 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:26,717 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:26,728 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:26,731 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:26,870 : INFO : PROGRESS: at 44.06% examples, 260350 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:26,871 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:26,876 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:26,881 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:26,886 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:26,889 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:26,895 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:26,907 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:26,912 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:27,045 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:27,051 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:27,053 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:27,066 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:27,069 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:27,070 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:27,080 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:27,082 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:27,222 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:27,223 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:27,230 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:27,235 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:27,244 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:27,247 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:27,249 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:27,256 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:27,391 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:27,405 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:27,406 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:27,416 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:27,584 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:27,763 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:27,763 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:27,764 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:27,764 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:27,774 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:27,774 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:27,851 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:27,852 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:27,853 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:27,853 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:27,854 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:27,855 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:27,855 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:27,855 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:27,859 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:27,859 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:27,859 : INFO : training on 926985 raw words (619507 effective words) took 2.0s, 303757 effective words/s
2016-09-28 17:33:27,859 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:27,859 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:27,863 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:27,864 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:27,865 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:27,866 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:27,868 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:27,868 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:27,869 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:27,870 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:27,871 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:27,872 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:27,872 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:27,873 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:27,874 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:27,875 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:27,876 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:27,876 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:27,877 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:27,878 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:27,879 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:27,880 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:27,880 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:27,881 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:27,882 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:27,883 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:27,884 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:28,041 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:28,044 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:28,047 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:28,050 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:28,055 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:28,058 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:28,061 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:28,069 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:28,209 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:28,214 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:28,220 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:28,224 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:28,230 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:28,236 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:28,239 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:28,242 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:28,382 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:28,389 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:28,390 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:28,393 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:28,403 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:28,409 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:28,427 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:28,428 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:28,547 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:28,560 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:28,570 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:28,572 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:28,585 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:28,587 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:28,596 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:28,605 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:28,722 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:28,737 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:28,751 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:28,755 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:28,759 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:28,769 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:28,771 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:28,787 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:28,907 : INFO : PROGRESS: at 44.19% examples, 262357 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:28,908 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:28,910 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:28,917 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:28,926 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:28,934 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:28,941 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:28,953 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:28,966 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:29,077 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:29,087 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:29,089 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:29,105 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:29,110 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:29,117 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:29,128 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:29,136 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:29,252 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:29,256 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:29,274 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:29,277 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:29,281 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:29,284 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:29,301 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:29,303 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:29,426 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:29,444 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:29,452 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:29,454 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:29,628 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:29,807 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:29,807 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:29,811 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:29,811 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:29,814 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:29,814 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:29,890 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:29,890 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:29,894 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:29,894 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:29,896 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:29,896 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:29,896 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:29,897 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:29,898 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:29,899 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:29,899 : INFO : training on 926985 raw words (619857 effective words) took 2.0s, 304492 effective words/s
2016-09-28 17:33:29,899 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:29,899 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:29,901 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:29,902 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:29,903 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:29,904 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:29,905 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:29,906 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:29,907 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:29,908 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:29,908 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:29,909 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:29,910 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:29,911 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:29,911 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:29,912 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:29,913 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:29,914 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:29,914 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:29,915 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:29,916 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:29,917 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:29,918 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:29,919 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:29,920 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:29,920 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:29,921 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:30,077 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:30,083 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:30,088 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:30,090 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:30,094 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:30,096 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:30,101 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:30,103 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:30,249 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:30,260 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:30,262 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:30,265 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:30,268 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:30,270 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:30,273 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:30,286 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:30,431 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:30,432 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:30,435 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:30,439 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:30,447 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:30,451 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:30,453 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:30,457 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:30,595 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:30,605 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:30,614 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:30,619 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:30,621 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:30,626 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:30,628 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:30,632 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:30,774 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:30,784 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:30,794 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:30,796 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:30,798 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:30,806 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:30,808 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:30,818 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:30,954 : INFO : PROGRESS: at 44.06% examples, 259867 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:30,955 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:30,958 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:30,963 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:30,964 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:30,968 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:30,981 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:30,988 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:30,996 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:31,129 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:31,134 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:31,135 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:31,142 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:31,144 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:31,157 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:31,165 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:31,169 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:31,300 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:31,307 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:31,312 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:31,319 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:31,322 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:31,324 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:31,337 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:31,343 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:31,479 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:31,486 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:31,490 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:31,493 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:31,665 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:31,852 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:31,852 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:31,854 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:31,855 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:31,857 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:31,857 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:31,934 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:31,935 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:31,936 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:31,937 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:31,937 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:31,938 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:31,940 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:31,940 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:31,942 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:31,942 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:31,942 : INFO : training on 926985 raw words (619837 effective words) took 2.0s, 303823 effective words/s
2016-09-28 17:33:31,942 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:31,942 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:31,945 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:31,945 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:31,947 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:31,948 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:31,948 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:31,949 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:31,950 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:31,951 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:31,952 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:31,952 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:31,953 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:31,954 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:31,955 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:31,956 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:31,956 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:31,957 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:31,958 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:31,959 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:31,959 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:31,960 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:31,961 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:31,962 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:31,963 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:31,963 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:31,964 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:32,119 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:32,123 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:32,134 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:32,136 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:32,137 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:32,139 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:32,141 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:32,144 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:32,287 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:32,303 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:32,306 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:32,310 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:32,314 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:32,315 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:32,319 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:32,323 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:32,470 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:32,475 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:32,478 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:32,480 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:32,490 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:32,494 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:32,503 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:32,504 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:32,633 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:32,643 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:32,653 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:32,657 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:32,665 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:32,671 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:32,673 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:32,683 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:32,815 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:32,824 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:32,835 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:32,836 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:32,842 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:32,847 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:32,855 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:32,863 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:32,989 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:32,989 : INFO : PROGRESS: at 44.19% examples, 262479 words/s, in_qsize 16, out_qsize 0
2016-09-28 17:33:33,001 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:33,003 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:33,007 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:33,015 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:33,017 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:33,037 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:33,041 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:33,160 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:33,172 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:33,178 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:33,189 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:33,191 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:33,194 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:33,208 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:33,212 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:33,340 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:33,346 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:33,355 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:33,363 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:33,365 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:33,366 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:33,380 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:33,388 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:33,513 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:33,531 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:33,532 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:33,535 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:33,705 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:33,893 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:33,893 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:33,897 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:33,897 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:33,899 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:33,899 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:33,968 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:33,968 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:33,975 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:33,975 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:33,977 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:33,978 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:33,978 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:33,978 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:33,979 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:33,980 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:33,980 : INFO : training on 926985 raw words (620227 effective words) took 2.0s, 304781 effective words/s
2016-09-28 17:33:33,980 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:33,980 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:33,983 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:33,983 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:33,984 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:33,986 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:33,987 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:33,988 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:33,989 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:33,990 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:33,991 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:33,991 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:33,992 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:33,993 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:33,994 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:33,995 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:33,995 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:33,996 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:33,997 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:33,998 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:33,999 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:33,999 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:34,000 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:34,001 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:34,002 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:34,002 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:34,003 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:34,161 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:34,163 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:34,167 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:34,169 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:34,174 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:34,178 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:34,181 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:34,185 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:34,333 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:34,341 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:34,343 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:34,346 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:34,348 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:34,349 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:34,354 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:34,362 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:34,514 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:34,515 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:34,518 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:34,520 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:34,524 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:34,526 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:34,537 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:34,539 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:34,678 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:34,690 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:34,691 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:34,696 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:34,701 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:34,702 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:34,704 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:34,716 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:34,860 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:34,870 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:34,872 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:34,876 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:34,877 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:34,881 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:34,888 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:34,890 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:35,033 : INFO : PROGRESS: at 44.06% examples, 260223 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:35,034 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:35,036 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:35,045 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:35,046 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:35,049 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:35,052 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:35,063 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:35,077 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:35,203 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:35,213 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:35,214 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:35,222 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:35,225 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:35,234 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:35,239 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:35,249 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:35,375 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:35,386 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:35,392 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:35,398 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:35,400 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:35,403 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:35,410 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:35,424 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:35,551 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:35,564 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:35,566 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:35,572 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:35,748 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:35,925 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:35,925 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:35,930 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:35,930 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:35,935 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:35,935 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:36,013 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:36,013 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:36,014 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:36,015 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:36,016 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:36,016 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:36,018 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:36,019 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:36,021 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:36,021 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:36,021 : INFO : training on 926985 raw words (619582 effective words) took 2.0s, 303944 effective words/s
2016-09-28 17:33:36,021 : INFO : training model with 8 workers on 11922 vocabulary and 100 features, using sg=0 hs=1 sample=0.0001 negative=5
2016-09-28 17:33:36,021 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:33:36,024 : DEBUG : queueing job #0 (9997 words, 267 sentences) at alpha 0.02500
2016-09-28 17:33:36,025 : DEBUG : queueing job #1 (9929 words, 244 sentences) at alpha 0.02472
2016-09-28 17:33:36,026 : DEBUG : queueing job #2 (9972 words, 272 sentences) at alpha 0.02447
2016-09-28 17:33:36,028 : DEBUG : queueing job #3 (9957 words, 274 sentences) at alpha 0.02419
2016-09-28 17:33:36,029 : DEBUG : queueing job #4 (9993 words, 259 sentences) at alpha 0.02391
2016-09-28 17:33:36,030 : DEBUG : queueing job #5 (9986 words, 243 sentences) at alpha 0.02364
2016-09-28 17:33:36,030 : DEBUG : queueing job #6 (9998 words, 251 sentences) at alpha 0.02339
2016-09-28 17:33:36,031 : DEBUG : queueing job #7 (9975 words, 254 sentences) at alpha 0.02313
2016-09-28 17:33:36,032 : DEBUG : queueing job #8 (9975 words, 253 sentences) at alpha 0.02287
2016-09-28 17:33:36,033 : DEBUG : queueing job #9 (9986 words, 273 sentences) at alpha 0.02261
2016-09-28 17:33:36,034 : DEBUG : queueing job #10 (9991 words, 262 sentences) at alpha 0.02233
2016-09-28 17:33:36,035 : DEBUG : queueing job #11 (9978 words, 264 sentences) at alpha 0.02205
2016-09-28 17:33:36,036 : DEBUG : queueing job #12 (9994 words, 258 sentences) at alpha 0.02178
2016-09-28 17:33:36,036 : DEBUG : queueing job #13 (9991 words, 252 sentences) at alpha 0.02152
2016-09-28 17:33:36,037 : DEBUG : queueing job #14 (9983 words, 270 sentences) at alpha 0.02126
2016-09-28 17:33:36,038 : DEBUG : queueing job #15 (9960 words, 254 sentences) at alpha 0.02098
2016-09-28 17:33:36,039 : DEBUG : queueing job #16 (9988 words, 269 sentences) at alpha 0.02071
2016-09-28 17:33:36,040 : DEBUG : queueing job #17 (9989 words, 255 sentences) at alpha 0.02044
2016-09-28 17:33:36,041 : DEBUG : queueing job #18 (9957 words, 255 sentences) at alpha 0.02017
2016-09-28 17:33:36,041 : DEBUG : queueing job #19 (9976 words, 270 sentences) at alpha 0.01991
2016-09-28 17:33:36,042 : DEBUG : queueing job #20 (9996 words, 247 sentences) at alpha 0.01963
2016-09-28 17:33:36,043 : DEBUG : queueing job #21 (9979 words, 278 sentences) at alpha 0.01938
2016-09-28 17:33:36,044 : DEBUG : queueing job #22 (9983 words, 268 sentences) at alpha 0.01909
2016-09-28 17:33:36,044 : DEBUG : queueing job #23 (9974 words, 246 sentences) at alpha 0.01881
2016-09-28 17:33:36,045 : DEBUG : queueing job #24 (9991 words, 240 sentences) at alpha 0.01856
2016-09-28 17:33:36,195 : DEBUG : queueing job #25 (9965 words, 267 sentences) at alpha 0.01831
2016-09-28 17:33:36,202 : DEBUG : queueing job #26 (9993 words, 254 sentences) at alpha 0.01803
2016-09-28 17:33:36,211 : DEBUG : queueing job #27 (9993 words, 262 sentences) at alpha 0.01777
2016-09-28 17:33:36,214 : DEBUG : queueing job #28 (9952 words, 264 sentences) at alpha 0.01750
2016-09-28 17:33:36,215 : DEBUG : queueing job #29 (10000 words, 264 sentences) at alpha 0.01723
2016-09-28 17:33:36,220 : DEBUG : queueing job #30 (9931 words, 263 sentences) at alpha 0.01696
2016-09-28 17:33:36,226 : DEBUG : queueing job #31 (9960 words, 246 sentences) at alpha 0.01668
2016-09-28 17:33:36,233 : DEBUG : queueing job #32 (9982 words, 261 sentences) at alpha 0.01643
2016-09-28 17:33:36,368 : DEBUG : queueing job #33 (9982 words, 265 sentences) at alpha 0.01616
2016-09-28 17:33:36,386 : DEBUG : queueing job #34 (9968 words, 263 sentences) at alpha 0.01589
2016-09-28 17:33:36,387 : DEBUG : queueing job #35 (9998 words, 262 sentences) at alpha 0.01562
2016-09-28 17:33:36,388 : DEBUG : queueing job #36 (9958 words, 251 sentences) at alpha 0.01534
2016-09-28 17:33:36,392 : DEBUG : queueing job #37 (9994 words, 266 sentences) at alpha 0.01509
2016-09-28 17:33:36,394 : DEBUG : queueing job #38 (9969 words, 253 sentences) at alpha 0.01481
2016-09-28 17:33:36,403 : DEBUG : queueing job #39 (9928 words, 264 sentences) at alpha 0.01455
2016-09-28 17:33:36,414 : DEBUG : queueing job #40 (9966 words, 271 sentences) at alpha 0.01428
2016-09-28 17:33:36,552 : DEBUG : queueing job #41 (9996 words, 267 sentences) at alpha 0.01400
2016-09-28 17:33:36,554 : DEBUG : queueing job #42 (9940 words, 240 sentences) at alpha 0.01372
2016-09-28 17:33:36,565 : DEBUG : queueing job #43 (9967 words, 247 sentences) at alpha 0.01347
2016-09-28 17:33:36,571 : DEBUG : queueing job #44 (9984 words, 256 sentences) at alpha 0.01322
2016-09-28 17:33:36,574 : DEBUG : queueing job #45 (9998 words, 251 sentences) at alpha 0.01295
2016-09-28 17:33:36,579 : DEBUG : queueing job #46 (9970 words, 274 sentences) at alpha 0.01269
2016-09-28 17:33:36,584 : DEBUG : queueing job #47 (9968 words, 264 sentences) at alpha 0.01241
2016-09-28 17:33:36,585 : DEBUG : queueing job #48 (9968 words, 260 sentences) at alpha 0.01214
2016-09-28 17:33:36,715 : DEBUG : queueing job #49 (9975 words, 259 sentences) at alpha 0.01187
2016-09-28 17:33:36,731 : DEBUG : queueing job #50 (9974 words, 251 sentences) at alpha 0.01160
2016-09-28 17:33:36,736 : DEBUG : queueing job #51 (9985 words, 270 sentences) at alpha 0.01134
2016-09-28 17:33:36,748 : DEBUG : queueing job #52 (9953 words, 260 sentences) at alpha 0.01106
2016-09-28 17:33:36,756 : DEBUG : queueing job #53 (9994 words, 258 sentences) at alpha 0.01080
2016-09-28 17:33:36,758 : DEBUG : queueing job #54 (9988 words, 263 sentences) at alpha 0.01053
2016-09-28 17:33:36,761 : DEBUG : queueing job #55 (9995 words, 254 sentences) at alpha 0.01026
2016-09-28 17:33:36,771 : DEBUG : queueing job #56 (9973 words, 265 sentences) at alpha 0.01000
2016-09-28 17:33:36,893 : DEBUG : queueing job #57 (9956 words, 251 sentences) at alpha 0.00972
2016-09-28 17:33:36,910 : DEBUG : queueing job #58 (9947 words, 274 sentences) at alpha 0.00946
2016-09-28 17:33:36,917 : DEBUG : queueing job #59 (9989 words, 264 sentences) at alpha 0.00918
2016-09-28 17:33:36,927 : DEBUG : queueing job #60 (9971 words, 260 sentences) at alpha 0.00891
2016-09-28 17:33:36,928 : DEBUG : queueing job #61 (9960 words, 238 sentences) at alpha 0.00864
2016-09-28 17:33:36,930 : DEBUG : queueing job #62 (9930 words, 260 sentences) at alpha 0.00839
2016-09-28 17:33:36,938 : DEBUG : queueing job #63 (9960 words, 249 sentences) at alpha 0.00812
2016-09-28 17:33:36,946 : DEBUG : queueing job #64 (9995 words, 257 sentences) at alpha 0.00787
2016-09-28 17:33:37,070 : INFO : PROGRESS: at 44.06% examples, 262116 words/s, in_qsize 15, out_qsize 0
2016-09-28 17:33:37,071 : DEBUG : queueing job #65 (9972 words, 272 sentences) at alpha 0.00760
2016-09-28 17:33:37,075 : DEBUG : queueing job #66 (9983 words, 268 sentences) at alpha 0.00732
2016-09-28 17:33:37,092 : DEBUG : queueing job #67 (9996 words, 263 sentences) at alpha 0.00704
2016-09-28 17:33:37,094 : DEBUG : queueing job #68 (9981 words, 250 sentences) at alpha 0.00677
2016-09-28 17:33:37,096 : DEBUG : queueing job #69 (9978 words, 258 sentences) at alpha 0.00651
2016-09-28 17:33:37,099 : DEBUG : queueing job #70 (9985 words, 259 sentences) at alpha 0.00625
2016-09-28 17:33:37,120 : DEBUG : queueing job #71 (9996 words, 269 sentences) at alpha 0.00598
2016-09-28 17:33:37,124 : DEBUG : queueing job #72 (9984 words, 266 sentences) at alpha 0.00570
2016-09-28 17:33:37,248 : DEBUG : queueing job #73 (9983 words, 245 sentences) at alpha 0.00543
2016-09-28 17:33:37,250 : DEBUG : queueing job #74 (9986 words, 265 sentences) at alpha 0.00518
2016-09-28 17:33:37,264 : DEBUG : queueing job #75 (9945 words, 257 sentences) at alpha 0.00490
2016-09-28 17:33:37,269 : DEBUG : queueing job #76 (9985 words, 263 sentences) at alpha 0.00464
2016-09-28 17:33:37,275 : DEBUG : queueing job #77 (9946 words, 271 sentences) at alpha 0.00436
2016-09-28 17:33:37,278 : DEBUG : queueing job #78 (9985 words, 270 sentences) at alpha 0.00408
2016-09-28 17:33:37,293 : DEBUG : queueing job #79 (9953 words, 239 sentences) at alpha 0.00381
2016-09-28 17:33:37,296 : DEBUG : queueing job #80 (9992 words, 249 sentences) at alpha 0.00356
2016-09-28 17:33:37,418 : DEBUG : queueing job #81 (9917 words, 257 sentences) at alpha 0.00330
2016-09-28 17:33:37,426 : DEBUG : queueing job #82 (9993 words, 249 sentences) at alpha 0.00304
2016-09-28 17:33:37,440 : DEBUG : queueing job #83 (9972 words, 267 sentences) at alpha 0.00278
2016-09-28 17:33:37,447 : DEBUG : queueing job #84 (9942 words, 266 sentences) at alpha 0.00250
2016-09-28 17:33:37,451 : DEBUG : queueing job #85 (9983 words, 266 sentences) at alpha 0.00223
2016-09-28 17:33:37,459 : DEBUG : queueing job #86 (9980 words, 255 sentences) at alpha 0.00195
2016-09-28 17:33:37,463 : DEBUG : queueing job #87 (9977 words, 248 sentences) at alpha 0.00169
2016-09-28 17:33:37,473 : DEBUG : queueing job #88 (9992 words, 269 sentences) at alpha 0.00143
2016-09-28 17:33:37,595 : DEBUG : queueing job #89 (9941 words, 262 sentences) at alpha 0.00116
2016-09-28 17:33:37,612 : DEBUG : queueing job #90 (9990 words, 261 sentences) at alpha 0.00089
2016-09-28 17:33:37,614 : DEBUG : queueing job #91 (9971 words, 261 sentences) at alpha 0.00062
2016-09-28 17:33:37,621 : DEBUG : queueing job #92 (9304 words, 239 sentences) at alpha 0.00035
2016-09-28 17:33:37,797 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:33:37,970 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:37,971 : INFO : worker thread finished; awaiting finish of 7 more threads
2016-09-28 17:33:37,977 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:37,977 : INFO : worker thread finished; awaiting finish of 6 more threads
2016-09-28 17:33:37,980 : DEBUG : worker exiting, processed 11 jobs
2016-09-28 17:33:37,980 : INFO : worker thread finished; awaiting finish of 5 more threads
2016-09-28 17:33:38,056 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:38,056 : INFO : worker thread finished; awaiting finish of 4 more threads
2016-09-28 17:33:38,058 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:38,058 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-09-28 17:33:38,061 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:38,062 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-09-28 17:33:38,063 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:38,063 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-09-28 17:33:38,066 : DEBUG : worker exiting, processed 12 jobs
2016-09-28 17:33:38,066 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:33:38,066 : INFO : training on 926985 raw words (619962 effective words) took 2.0s, 303901 effective words/s
2016-09-28 17:34:51,091 : INFO : saving Doc2Vec object under ./tmp/doc2vec_size100window10,min5work4samp1e-4, separately None
2016-09-28 17:34:51,092 : INFO : not storing attribute syn0norm
2016-09-28 17:34:51,092 : INFO : not storing attribute cum_table
2016-09-28 17:35:51,738 : INFO : precomputing L2-norms of word weight vectors
2016-09-28 17:43:02,011 : INFO : collecting all words and their counts
2016-09-28 17:43:02,011 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-09-28 17:43:02,232 : INFO : collected 11922 word types and 15 unique tags from a corpus of 4822 examples and 185397 words
2016-09-28 17:43:02,248 : INFO : min_count=5 retains 2767 unique words (drops 9155)
2016-09-28 17:43:02,248 : INFO : min_count leaves 171408 word corpus (92% of original 185397)
2016-09-28 17:43:02,255 : INFO : deleting the raw counts dictionary of 11922 items
2016-09-28 17:43:02,255 : INFO : sample=0 downsamples 0 most-common words
2016-09-28 17:43:02,255 : INFO : downsampling leaves estimated 171408 word corpus (100.0% of prior 171408)
2016-09-28 17:43:02,255 : INFO : estimated required memory for 2767 words and 300 dimensions: 8598700 bytes
2016-09-28 17:43:02,259 : INFO : constructing a huffman tree from 2767 words
2016-09-28 17:43:02,336 : INFO : built huffman tree with maximum node depth 15
2016-09-28 17:43:02,337 : INFO : resetting layer weights
2016-09-28 17:43:13,178 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:13,178 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:13,180 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02500
2016-09-28 17:43:13,182 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02500
2016-09-28 17:43:13,183 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02500
2016-09-28 17:43:13,184 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02500
2016-09-28 17:43:13,218 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02500
2016-09-28 17:43:13,254 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02500
2016-09-28 17:43:13,293 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02500
2016-09-28 17:43:13,331 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02500
2016-09-28 17:43:13,369 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02500
2016-09-28 17:43:13,406 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02500
2016-09-28 17:43:13,442 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02500
2016-09-28 17:43:13,479 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02500
2016-09-28 17:43:13,516 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02500
2016-09-28 17:43:13,554 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02500
2016-09-28 17:43:13,590 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02500
2016-09-28 17:43:13,624 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02500
2016-09-28 17:43:13,663 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02500
2016-09-28 17:43:13,699 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02500
2016-09-28 17:43:13,738 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02500
2016-09-28 17:43:13,773 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.02500
2016-09-28 17:43:13,808 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.02500
2016-09-28 17:43:13,843 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.02500
2016-09-28 17:43:13,877 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.02500
2016-09-28 17:43:13,913 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.02500
2016-09-28 17:43:13,948 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.02500
2016-09-28 17:43:13,983 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.02500
2016-09-28 17:43:14,019 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.02500
2016-09-28 17:43:14,057 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.02500
2016-09-28 17:43:14,093 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.02500
2016-09-28 17:43:14,130 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.02500
2016-09-28 17:43:14,166 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.02500
2016-09-28 17:43:14,203 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.02500
2016-09-28 17:43:14,204 : INFO : PROGRESS: at 31.30% examples, 316954 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:14,241 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.02500
2016-09-28 17:43:14,276 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.02500
2016-09-28 17:43:14,311 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.02500
2016-09-28 17:43:14,346 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.02500
2016-09-28 17:43:14,380 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.02500
2016-09-28 17:43:14,418 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.02500
2016-09-28 17:43:14,457 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.02500
2016-09-28 17:43:14,492 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.02500
2016-09-28 17:43:14,527 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.02500
2016-09-28 17:43:14,561 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.02500
2016-09-28 17:43:14,597 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.02500
2016-09-28 17:43:14,632 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.02500
2016-09-28 17:43:14,668 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.02500
2016-09-28 17:43:14,705 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.02500
2016-09-28 17:43:14,742 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.02500
2016-09-28 17:43:14,782 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.02500
2016-09-28 17:43:14,818 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.02500
2016-09-28 17:43:14,855 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.02500
2016-09-28 17:43:14,893 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.02500
2016-09-28 17:43:14,930 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.02500
2016-09-28 17:43:14,965 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.02500
2016-09-28 17:43:15,000 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.02500
2016-09-28 17:43:15,035 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.02500
2016-09-28 17:43:15,070 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.02500
2016-09-28 17:43:15,104 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.02500
2016-09-28 17:43:15,140 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.02500
2016-09-28 17:43:15,175 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.02500
2016-09-28 17:43:15,209 : INFO : PROGRESS: at 60.28% examples, 317553 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:15,210 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.02500
2016-09-28 17:43:15,244 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.02500
2016-09-28 17:43:15,280 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.02500
2016-09-28 17:43:15,316 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.02500
2016-09-28 17:43:15,353 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.02500
2016-09-28 17:43:15,390 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.02500
2016-09-28 17:43:15,427 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.02500
2016-09-28 17:43:15,464 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.02500
2016-09-28 17:43:15,502 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.02500
2016-09-28 17:43:15,539 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.02500
2016-09-28 17:43:15,576 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.02500
2016-09-28 17:43:15,612 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.02500
2016-09-28 17:43:15,646 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.02500
2016-09-28 17:43:15,681 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.02500
2016-09-28 17:43:15,717 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.02500
2016-09-28 17:43:15,756 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.02500
2016-09-28 17:43:15,790 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.02500
2016-09-28 17:43:15,825 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.02500
2016-09-28 17:43:15,865 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.02500
2016-09-28 17:43:15,899 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.02500
2016-09-28 17:43:15,935 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.02500
2016-09-28 17:43:15,971 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.02500
2016-09-28 17:43:16,008 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.02500
2016-09-28 17:43:16,045 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.02500
2016-09-28 17:43:16,083 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.02500
2016-09-28 17:43:16,123 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.02500
2016-09-28 17:43:16,159 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.02500
2016-09-28 17:43:16,199 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.02500
2016-09-28 17:43:16,236 : INFO : PROGRESS: at 91.61% examples, 316886 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:16,237 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.02500
2016-09-28 17:43:16,274 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.02500
2016-09-28 17:43:16,308 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.02500
2016-09-28 17:43:16,343 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.02500
2016-09-28 17:43:16,378 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.02500
2016-09-28 17:43:16,416 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.02500
2016-09-28 17:43:16,484 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:16,556 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:16,556 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:16,556 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 316653 effective words/s
2016-09-28 17:43:16,557 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:16,557 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:16,558 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02300
2016-09-28 17:43:16,559 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02300
2016-09-28 17:43:16,560 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02300
2016-09-28 17:43:16,561 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02300
2016-09-28 17:43:16,596 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02300
2016-09-28 17:43:16,636 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02300
2016-09-28 17:43:16,675 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02300
2016-09-28 17:43:16,712 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02300
2016-09-28 17:43:16,751 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02300
2016-09-28 17:43:16,789 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02300
2016-09-28 17:43:16,826 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02300
2016-09-28 17:43:16,863 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02300
2016-09-28 17:43:16,900 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02300
2016-09-28 17:43:16,938 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02300
2016-09-28 17:43:16,975 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02300
2016-09-28 17:43:17,009 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02300
2016-09-28 17:43:17,044 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02300
2016-09-28 17:43:17,082 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02300
2016-09-28 17:43:17,117 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02300
2016-09-28 17:43:17,152 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.02300
2016-09-28 17:43:17,188 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.02300
2016-09-28 17:43:17,223 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.02300
2016-09-28 17:43:17,258 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.02300
2016-09-28 17:43:17,293 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.02300
2016-09-28 17:43:17,330 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.02300
2016-09-28 17:43:17,365 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.02300
2016-09-28 17:43:17,403 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.02300
2016-09-28 17:43:17,442 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.02300
2016-09-28 17:43:17,479 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.02300
2016-09-28 17:43:17,515 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.02300
2016-09-28 17:43:17,555 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.02300
2016-09-28 17:43:17,592 : INFO : PROGRESS: at 31.30% examples, 313402 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:17,593 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.02300
2016-09-28 17:43:17,630 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.02300
2016-09-28 17:43:17,666 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.02300
2016-09-28 17:43:17,701 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.02300
2016-09-28 17:43:17,741 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.02300
2016-09-28 17:43:17,776 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.02300
2016-09-28 17:43:17,814 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.02300
2016-09-28 17:43:17,850 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.02300
2016-09-28 17:43:17,885 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.02300
2016-09-28 17:43:17,920 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.02300
2016-09-28 17:43:17,955 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.02300
2016-09-28 17:43:17,990 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.02300
2016-09-28 17:43:18,029 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.02300
2016-09-28 17:43:18,065 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.02300
2016-09-28 17:43:18,102 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.02300
2016-09-28 17:43:18,140 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.02300
2016-09-28 17:43:18,177 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.02300
2016-09-28 17:43:18,213 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.02300
2016-09-28 17:43:18,250 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.02300
2016-09-28 17:43:18,288 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.02300
2016-09-28 17:43:18,324 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.02300
2016-09-28 17:43:18,359 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.02300
2016-09-28 17:43:18,394 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.02300
2016-09-28 17:43:18,429 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.02300
2016-09-28 17:43:18,464 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.02300
2016-09-28 17:43:18,499 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.02300
2016-09-28 17:43:18,535 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.02300
2016-09-28 17:43:18,569 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.02300
2016-09-28 17:43:18,604 : INFO : PROGRESS: at 60.28% examples, 314767 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:18,605 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.02300
2016-09-28 17:43:18,640 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.02300
2016-09-28 17:43:18,677 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.02300
2016-09-28 17:43:18,712 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.02300
2016-09-28 17:43:18,750 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.02300
2016-09-28 17:43:18,787 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.02300
2016-09-28 17:43:18,823 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.02300
2016-09-28 17:43:18,861 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.02300
2016-09-28 17:43:18,897 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.02300
2016-09-28 17:43:18,935 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.02300
2016-09-28 17:43:18,972 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.02300
2016-09-28 17:43:19,008 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.02300
2016-09-28 17:43:19,043 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.02300
2016-09-28 17:43:19,078 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.02300
2016-09-28 17:43:19,116 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.02300
2016-09-28 17:43:19,151 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.02300
2016-09-28 17:43:19,188 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.02300
2016-09-28 17:43:19,222 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.02300
2016-09-28 17:43:19,258 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.02300
2016-09-28 17:43:19,292 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.02300
2016-09-28 17:43:19,331 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.02300
2016-09-28 17:43:19,368 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.02300
2016-09-28 17:43:19,404 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.02300
2016-09-28 17:43:19,441 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.02300
2016-09-28 17:43:19,478 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.02300
2016-09-28 17:43:19,515 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.02300
2016-09-28 17:43:19,551 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.02300
2016-09-28 17:43:19,588 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.02300
2016-09-28 17:43:19,627 : INFO : PROGRESS: at 91.61% examples, 315397 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:19,628 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.02300
2016-09-28 17:43:19,668 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.02300
2016-09-28 17:43:19,706 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.02300
2016-09-28 17:43:19,741 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.02300
2016-09-28 17:43:19,776 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.02300
2016-09-28 17:43:19,814 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.02300
2016-09-28 17:43:19,883 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:19,950 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:19,950 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:19,950 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 315081 effective words/s
2016-09-28 17:43:19,950 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:19,950 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:19,952 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.02100
2016-09-28 17:43:19,952 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.02100
2016-09-28 17:43:19,953 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.02100
2016-09-28 17:43:19,954 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.02100
2016-09-28 17:43:19,989 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.02100
2016-09-28 17:43:20,025 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.02100
2016-09-28 17:43:20,062 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.02100
2016-09-28 17:43:20,098 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.02100
2016-09-28 17:43:20,135 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.02100
2016-09-28 17:43:20,173 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.02100
2016-09-28 17:43:20,209 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.02100
2016-09-28 17:43:20,246 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.02100
2016-09-28 17:43:20,283 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.02100
2016-09-28 17:43:20,324 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.02100
2016-09-28 17:43:20,360 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.02100
2016-09-28 17:43:20,395 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.02100
2016-09-28 17:43:20,431 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.02100
2016-09-28 17:43:20,468 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.02100
2016-09-28 17:43:20,503 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.02100
2016-09-28 17:43:20,539 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.02100
2016-09-28 17:43:20,574 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.02100
2016-09-28 17:43:20,609 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.02100
2016-09-28 17:43:20,644 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.02100
2016-09-28 17:43:20,679 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.02100
2016-09-28 17:43:20,715 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.02100
2016-09-28 17:43:20,753 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.02100
2016-09-28 17:43:20,789 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.02100
2016-09-28 17:43:20,826 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.02100
2016-09-28 17:43:20,863 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.02100
2016-09-28 17:43:20,900 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.02100
2016-09-28 17:43:20,940 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.02100
2016-09-28 17:43:20,977 : INFO : PROGRESS: at 31.30% examples, 315645 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:20,978 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.02100
2016-09-28 17:43:21,015 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.02100
2016-09-28 17:43:21,051 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.02100
2016-09-28 17:43:21,085 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.02100
2016-09-28 17:43:21,121 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.02100
2016-09-28 17:43:21,156 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.02100
2016-09-28 17:43:21,191 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.02100
2016-09-28 17:43:21,226 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.02100
2016-09-28 17:43:21,261 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.02100
2016-09-28 17:43:21,296 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.02100
2016-09-28 17:43:21,334 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.02100
2016-09-28 17:43:21,370 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.02100
2016-09-28 17:43:21,407 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.02100
2016-09-28 17:43:21,443 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.02100
2016-09-28 17:43:21,480 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.02100
2016-09-28 17:43:21,518 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.02100
2016-09-28 17:43:21,555 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.02100
2016-09-28 17:43:21,592 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.02100
2016-09-28 17:43:21,630 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.02100
2016-09-28 17:43:21,668 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.02100
2016-09-28 17:43:21,707 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.02100
2016-09-28 17:43:21,744 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.02100
2016-09-28 17:43:21,779 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.02100
2016-09-28 17:43:21,816 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.02100
2016-09-28 17:43:21,852 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.02100
2016-09-28 17:43:21,887 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.02100
2016-09-28 17:43:21,926 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.02100
2016-09-28 17:43:21,961 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.02100
2016-09-28 17:43:21,996 : INFO : PROGRESS: at 60.28% examples, 314815 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:21,997 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.02100
2016-09-28 17:43:22,032 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.02100
2016-09-28 17:43:22,068 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.02100
2016-09-28 17:43:22,104 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.02100
2016-09-28 17:43:22,140 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.02100
2016-09-28 17:43:22,178 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.02100
2016-09-28 17:43:22,215 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.02100
2016-09-28 17:43:22,252 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.02100
2016-09-28 17:43:22,289 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.02100
2016-09-28 17:43:22,326 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.02100
2016-09-28 17:43:22,363 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.02100
2016-09-28 17:43:22,399 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.02100
2016-09-28 17:43:22,435 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.02100
2016-09-28 17:43:22,472 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.02100
2016-09-28 17:43:22,507 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.02100
2016-09-28 17:43:22,542 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.02100
2016-09-28 17:43:22,577 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.02100
2016-09-28 17:43:22,612 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.02100
2016-09-28 17:43:22,647 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.02100
2016-09-28 17:43:22,685 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.02100
2016-09-28 17:43:22,723 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.02100
2016-09-28 17:43:22,760 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.02100
2016-09-28 17:43:22,797 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.02100
2016-09-28 17:43:22,837 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.02100
2016-09-28 17:43:22,878 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.02100
2016-09-28 17:43:22,918 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.02100
2016-09-28 17:43:22,954 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.02100
2016-09-28 17:43:22,992 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.02100
2016-09-28 17:43:23,029 : INFO : PROGRESS: at 91.61% examples, 314404 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:23,030 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.02100
2016-09-28 17:43:23,068 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.02100
2016-09-28 17:43:23,103 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.02100
2016-09-28 17:43:23,138 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.02100
2016-09-28 17:43:23,173 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.02100
2016-09-28 17:43:23,208 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.02100
2016-09-28 17:43:23,277 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:23,347 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:23,348 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:23,348 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 314559 effective words/s
2016-09-28 17:43:23,348 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:23,348 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:23,350 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.01900
2016-09-28 17:43:23,351 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.01900
2016-09-28 17:43:23,352 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.01900
2016-09-28 17:43:23,352 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.01900
2016-09-28 17:43:23,388 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.01900
2016-09-28 17:43:23,424 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.01900
2016-09-28 17:43:23,461 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.01900
2016-09-28 17:43:23,497 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.01900
2016-09-28 17:43:23,534 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.01900
2016-09-28 17:43:23,571 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.01900
2016-09-28 17:43:23,608 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.01900
2016-09-28 17:43:23,644 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.01900
2016-09-28 17:43:23,681 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.01900
2016-09-28 17:43:23,723 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.01900
2016-09-28 17:43:23,759 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.01900
2016-09-28 17:43:23,794 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.01900
2016-09-28 17:43:23,829 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.01900
2016-09-28 17:43:23,867 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.01900
2016-09-28 17:43:23,903 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.01900
2016-09-28 17:43:23,939 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01900
2016-09-28 17:43:23,975 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01900
2016-09-28 17:43:24,015 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01900
2016-09-28 17:43:24,052 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01900
2016-09-28 17:43:24,088 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01900
2016-09-28 17:43:24,124 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01900
2016-09-28 17:43:24,160 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01900
2016-09-28 17:43:24,197 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01900
2016-09-28 17:43:24,235 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01900
2016-09-28 17:43:24,272 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01900
2016-09-28 17:43:24,308 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01900
2016-09-28 17:43:24,345 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01900
2016-09-28 17:43:24,381 : INFO : PROGRESS: at 31.30% examples, 314110 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:24,382 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01900
2016-09-28 17:43:24,419 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01900
2016-09-28 17:43:24,457 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01900
2016-09-28 17:43:24,492 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01900
2016-09-28 17:43:24,527 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01900
2016-09-28 17:43:24,562 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01900
2016-09-28 17:43:24,597 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01900
2016-09-28 17:43:24,632 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01900
2016-09-28 17:43:24,668 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01900
2016-09-28 17:43:24,706 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01900
2016-09-28 17:43:24,742 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01900
2016-09-28 17:43:24,777 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01900
2016-09-28 17:43:24,813 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01900
2016-09-28 17:43:24,849 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01900
2016-09-28 17:43:24,886 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01900
2016-09-28 17:43:24,923 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01900
2016-09-28 17:43:24,960 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01900
2016-09-28 17:43:24,996 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01900
2016-09-28 17:43:25,033 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01900
2016-09-28 17:43:25,070 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01900
2016-09-28 17:43:25,106 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01900
2016-09-28 17:43:25,141 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01900
2016-09-28 17:43:25,176 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01900
2016-09-28 17:43:25,211 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01900
2016-09-28 17:43:25,245 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01900
2016-09-28 17:43:25,280 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.01900
2016-09-28 17:43:25,316 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.01900
2016-09-28 17:43:25,350 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.01900
2016-09-28 17:43:25,385 : INFO : PROGRESS: at 60.28% examples, 316424 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:25,385 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.01900
2016-09-28 17:43:25,421 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.01900
2016-09-28 17:43:25,458 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.01900
2016-09-28 17:43:25,494 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.01900
2016-09-28 17:43:25,531 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.01900
2016-09-28 17:43:25,568 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.01900
2016-09-28 17:43:25,605 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.01900
2016-09-28 17:43:25,641 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.01900
2016-09-28 17:43:25,678 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.01900
2016-09-28 17:43:25,715 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.01900
2016-09-28 17:43:25,755 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.01900
2016-09-28 17:43:25,791 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.01900
2016-09-28 17:43:25,826 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.01900
2016-09-28 17:43:25,861 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.01900
2016-09-28 17:43:25,895 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.01900
2016-09-28 17:43:25,931 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.01900
2016-09-28 17:43:25,966 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.01900
2016-09-28 17:43:26,001 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.01900
2016-09-28 17:43:26,036 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.01900
2016-09-28 17:43:26,070 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.01900
2016-09-28 17:43:26,109 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.01900
2016-09-28 17:43:26,145 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.01900
2016-09-28 17:43:26,181 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.01900
2016-09-28 17:43:26,218 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.01900
2016-09-28 17:43:26,255 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.01900
2016-09-28 17:43:26,292 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.01900
2016-09-28 17:43:26,328 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.01900
2016-09-28 17:43:26,366 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.01900
2016-09-28 17:43:26,404 : INFO : PROGRESS: at 91.61% examples, 316952 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:26,405 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.01900
2016-09-28 17:43:26,442 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.01900
2016-09-28 17:43:26,480 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.01900
2016-09-28 17:43:26,518 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.01900
2016-09-28 17:43:26,556 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.01900
2016-09-28 17:43:26,591 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.01900
2016-09-28 17:43:26,659 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:26,728 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:26,728 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:26,729 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 316285 effective words/s
2016-09-28 17:43:26,729 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:26,729 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:26,731 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.01700
2016-09-28 17:43:26,732 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.01700
2016-09-28 17:43:26,732 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.01700
2016-09-28 17:43:26,733 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.01700
2016-09-28 17:43:26,769 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.01700
2016-09-28 17:43:26,805 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.01700
2016-09-28 17:43:26,840 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.01700
2016-09-28 17:43:26,880 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.01700
2016-09-28 17:43:26,920 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.01700
2016-09-28 17:43:26,960 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.01700
2016-09-28 17:43:26,997 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.01700
2016-09-28 17:43:27,033 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.01700
2016-09-28 17:43:27,071 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.01700
2016-09-28 17:43:27,112 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.01700
2016-09-28 17:43:27,148 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.01700
2016-09-28 17:43:27,183 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.01700
2016-09-28 17:43:27,217 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.01700
2016-09-28 17:43:27,252 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.01700
2016-09-28 17:43:27,287 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.01700
2016-09-28 17:43:27,323 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01700
2016-09-28 17:43:27,358 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01700
2016-09-28 17:43:27,393 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01700
2016-09-28 17:43:27,428 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01700
2016-09-28 17:43:27,463 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01700
2016-09-28 17:43:27,499 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01700
2016-09-28 17:43:27,535 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01700
2016-09-28 17:43:27,572 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01700
2016-09-28 17:43:27,609 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01700
2016-09-28 17:43:27,649 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01700
2016-09-28 17:43:27,685 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01700
2016-09-28 17:43:27,722 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01700
2016-09-28 17:43:27,760 : INFO : PROGRESS: at 31.30% examples, 314558 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:27,761 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01700
2016-09-28 17:43:27,798 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01700
2016-09-28 17:43:27,833 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01700
2016-09-28 17:43:27,868 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01700
2016-09-28 17:43:27,903 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01700
2016-09-28 17:43:27,938 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01700
2016-09-28 17:43:27,973 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01700
2016-09-28 17:43:28,008 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01700
2016-09-28 17:43:28,043 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01700
2016-09-28 17:43:28,080 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01700
2016-09-28 17:43:28,115 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01700
2016-09-28 17:43:28,151 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01700
2016-09-28 17:43:28,186 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01700
2016-09-28 17:43:28,222 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01700
2016-09-28 17:43:28,258 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01700
2016-09-28 17:43:28,296 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01700
2016-09-28 17:43:28,334 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01700
2016-09-28 17:43:28,370 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01700
2016-09-28 17:43:28,407 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01700
2016-09-28 17:43:28,444 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01700
2016-09-28 17:43:28,481 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01700
2016-09-28 17:43:28,516 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01700
2016-09-28 17:43:28,551 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01700
2016-09-28 17:43:28,585 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01700
2016-09-28 17:43:28,620 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01700
2016-09-28 17:43:28,656 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.01700
2016-09-28 17:43:28,691 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.01700
2016-09-28 17:43:28,728 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.01700
2016-09-28 17:43:28,762 : INFO : PROGRESS: at 60.28% examples, 316892 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:28,763 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.01700
2016-09-28 17:43:28,799 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.01700
2016-09-28 17:43:28,843 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.01700
2016-09-28 17:43:28,886 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.01700
2016-09-28 17:43:28,927 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.01700
2016-09-28 17:43:28,967 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.01700
2016-09-28 17:43:29,007 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.01700
2016-09-28 17:43:29,052 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.01700
2016-09-28 17:43:29,097 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.01700
2016-09-28 17:43:29,142 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.01700
2016-09-28 17:43:29,182 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.01700
2016-09-28 17:43:29,220 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.01700
2016-09-28 17:43:29,263 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.01700
2016-09-28 17:43:29,300 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.01700
2016-09-28 17:43:29,341 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.01700
2016-09-28 17:43:29,383 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.01700
2016-09-28 17:43:29,423 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.01700
2016-09-28 17:43:29,464 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.01700
2016-09-28 17:43:29,499 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.01700
2016-09-28 17:43:29,534 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.01700
2016-09-28 17:43:29,570 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.01700
2016-09-28 17:43:29,609 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.01700
2016-09-28 17:43:29,645 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.01700
2016-09-28 17:43:29,685 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.01700
2016-09-28 17:43:29,725 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.01700
2016-09-28 17:43:29,762 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.01700
2016-09-28 17:43:29,798 : INFO : PROGRESS: at 89.15% examples, 307836 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:29,798 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.01700
2016-09-28 17:43:29,836 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.01700
2016-09-28 17:43:29,873 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.01700
2016-09-28 17:43:29,909 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.01700
2016-09-28 17:43:29,945 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.01700
2016-09-28 17:43:29,980 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.01700
2016-09-28 17:43:30,015 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.01700
2016-09-28 17:43:30,050 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.01700
2016-09-28 17:43:30,118 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:30,185 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:30,185 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:30,185 : INFO : training on 926985 raw words (1068480 effective words) took 3.5s, 309316 effective words/s
2016-09-28 17:43:30,185 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:30,185 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:30,187 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.01500
2016-09-28 17:43:30,188 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.01500
2016-09-28 17:43:30,189 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.01500
2016-09-28 17:43:30,189 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.01500
2016-09-28 17:43:30,224 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.01500
2016-09-28 17:43:30,261 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.01500
2016-09-28 17:43:30,297 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.01500
2016-09-28 17:43:30,334 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.01500
2016-09-28 17:43:30,371 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.01500
2016-09-28 17:43:30,409 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.01500
2016-09-28 17:43:30,446 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.01500
2016-09-28 17:43:30,483 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.01500
2016-09-28 17:43:30,519 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.01500
2016-09-28 17:43:30,557 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.01500
2016-09-28 17:43:30,593 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.01500
2016-09-28 17:43:30,628 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.01500
2016-09-28 17:43:30,664 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.01500
2016-09-28 17:43:30,698 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.01500
2016-09-28 17:43:30,734 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.01500
2016-09-28 17:43:30,769 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01500
2016-09-28 17:43:30,804 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01500
2016-09-28 17:43:30,839 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01500
2016-09-28 17:43:30,875 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01500
2016-09-28 17:43:30,911 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01500
2016-09-28 17:43:30,947 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01500
2016-09-28 17:43:30,983 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01500
2016-09-28 17:43:31,019 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01500
2016-09-28 17:43:31,058 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01500
2016-09-28 17:43:31,095 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01500
2016-09-28 17:43:31,134 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01500
2016-09-28 17:43:31,172 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01500
2016-09-28 17:43:31,209 : INFO : PROGRESS: at 31.30% examples, 316797 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:31,210 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01500
2016-09-28 17:43:31,248 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01500
2016-09-28 17:43:31,285 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01500
2016-09-28 17:43:31,320 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01500
2016-09-28 17:43:31,355 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01500
2016-09-28 17:43:31,390 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01500
2016-09-28 17:43:31,425 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01500
2016-09-28 17:43:31,461 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01500
2016-09-28 17:43:31,496 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01500
2016-09-28 17:43:31,532 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01500
2016-09-28 17:43:31,566 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01500
2016-09-28 17:43:31,602 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01500
2016-09-28 17:43:31,638 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01500
2016-09-28 17:43:31,676 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01500
2016-09-28 17:43:31,713 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01500
2016-09-28 17:43:31,751 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01500
2016-09-28 17:43:31,788 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01500
2016-09-28 17:43:31,824 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01500
2016-09-28 17:43:31,862 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01500
2016-09-28 17:43:31,900 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01500
2016-09-28 17:43:31,936 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01500
2016-09-28 17:43:31,971 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01500
2016-09-28 17:43:32,007 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01500
2016-09-28 17:43:32,042 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01500
2016-09-28 17:43:32,077 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01500
2016-09-28 17:43:32,111 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.01500
2016-09-28 17:43:32,147 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.01500
2016-09-28 17:43:32,182 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.01500
2016-09-28 17:43:32,217 : INFO : PROGRESS: at 60.28% examples, 317139 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:32,218 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.01500
2016-09-28 17:43:32,253 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.01500
2016-09-28 17:43:32,289 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.01500
2016-09-28 17:43:32,325 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.01500
2016-09-28 17:43:32,362 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.01500
2016-09-28 17:43:32,399 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.01500
2016-09-28 17:43:32,436 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.01500
2016-09-28 17:43:32,473 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.01500
2016-09-28 17:43:32,510 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.01500
2016-09-28 17:43:32,549 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.01500
2016-09-28 17:43:32,585 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.01500
2016-09-28 17:43:32,621 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.01500
2016-09-28 17:43:32,656 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.01500
2016-09-28 17:43:32,691 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.01500
2016-09-28 17:43:32,726 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.01500
2016-09-28 17:43:32,765 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.01500
2016-09-28 17:43:32,804 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.01500
2016-09-28 17:43:32,842 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.01500
2016-09-28 17:43:32,877 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.01500
2016-09-28 17:43:32,912 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.01500
2016-09-28 17:43:32,948 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.01500
2016-09-28 17:43:32,984 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.01500
2016-09-28 17:43:33,020 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.01500
2016-09-28 17:43:33,057 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.01500
2016-09-28 17:43:33,094 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.01500
2016-09-28 17:43:33,132 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.01500
2016-09-28 17:43:33,168 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.01500
2016-09-28 17:43:33,205 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.01500
2016-09-28 17:43:33,245 : INFO : PROGRESS: at 91.61% examples, 316484 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:33,246 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.01500
2016-09-28 17:43:33,282 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.01500
2016-09-28 17:43:33,317 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.01500
2016-09-28 17:43:33,352 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.01500
2016-09-28 17:43:33,387 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.01500
2016-09-28 17:43:33,423 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.01500
2016-09-28 17:43:33,491 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:33,559 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:33,559 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:33,559 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 316858 effective words/s
2016-09-28 17:43:33,559 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:33,559 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:33,561 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.01300
2016-09-28 17:43:33,562 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.01300
2016-09-28 17:43:33,563 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.01300
2016-09-28 17:43:33,564 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.01300
2016-09-28 17:43:33,598 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.01300
2016-09-28 17:43:33,634 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.01300
2016-09-28 17:43:33,669 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.01300
2016-09-28 17:43:33,709 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.01300
2016-09-28 17:43:33,747 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.01300
2016-09-28 17:43:33,783 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.01300
2016-09-28 17:43:33,820 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.01300
2016-09-28 17:43:33,857 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.01300
2016-09-28 17:43:33,894 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.01300
2016-09-28 17:43:33,933 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.01300
2016-09-28 17:43:33,970 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.01300
2016-09-28 17:43:34,005 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.01300
2016-09-28 17:43:34,039 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.01300
2016-09-28 17:43:34,074 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.01300
2016-09-28 17:43:34,109 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.01300
2016-09-28 17:43:34,145 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01300
2016-09-28 17:43:34,180 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01300
2016-09-28 17:43:34,214 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01300
2016-09-28 17:43:34,249 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01300
2016-09-28 17:43:34,284 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01300
2016-09-28 17:43:34,320 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01300
2016-09-28 17:43:34,356 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01300
2016-09-28 17:43:34,393 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01300
2016-09-28 17:43:34,431 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01300
2016-09-28 17:43:34,467 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01300
2016-09-28 17:43:34,504 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01300
2016-09-28 17:43:34,541 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01300
2016-09-28 17:43:34,578 : INFO : PROGRESS: at 31.30% examples, 318453 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:34,579 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01300
2016-09-28 17:43:34,618 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01300
2016-09-28 17:43:34,656 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01300
2016-09-28 17:43:34,692 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01300
2016-09-28 17:43:34,730 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01300
2016-09-28 17:43:34,765 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01300
2016-09-28 17:43:34,801 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01300
2016-09-28 17:43:34,836 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01300
2016-09-28 17:43:34,873 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01300
2016-09-28 17:43:34,910 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01300
2016-09-28 17:43:34,944 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01300
2016-09-28 17:43:34,981 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01300
2016-09-28 17:43:35,018 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01300
2016-09-28 17:43:35,055 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01300
2016-09-28 17:43:35,093 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01300
2016-09-28 17:43:35,132 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01300
2016-09-28 17:43:35,169 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01300
2016-09-28 17:43:35,206 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01300
2016-09-28 17:43:35,244 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01300
2016-09-28 17:43:35,282 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01300
2016-09-28 17:43:35,319 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01300
2016-09-28 17:43:35,355 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01300
2016-09-28 17:43:35,391 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01300
2016-09-28 17:43:35,426 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01300
2016-09-28 17:43:35,463 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01300
2016-09-28 17:43:35,499 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.01300
2016-09-28 17:43:35,536 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.01300
2016-09-28 17:43:35,573 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.01300
2016-09-28 17:43:35,608 : INFO : PROGRESS: at 60.28% examples, 314524 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:35,609 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.01300
2016-09-28 17:43:35,644 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.01300
2016-09-28 17:43:35,681 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.01300
2016-09-28 17:43:35,718 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.01300
2016-09-28 17:43:35,757 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.01300
2016-09-28 17:43:35,795 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.01300
2016-09-28 17:43:35,834 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.01300
2016-09-28 17:43:35,872 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.01300
2016-09-28 17:43:35,909 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.01300
2016-09-28 17:43:35,947 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.01300
2016-09-28 17:43:35,985 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.01300
2016-09-28 17:43:36,021 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.01300
2016-09-28 17:43:36,058 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.01300
2016-09-28 17:43:36,095 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.01300
2016-09-28 17:43:36,131 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.01300
2016-09-28 17:43:36,167 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.01300
2016-09-28 17:43:36,203 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.01300
2016-09-28 17:43:36,239 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.01300
2016-09-28 17:43:36,276 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.01300
2016-09-28 17:43:36,311 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.01300
2016-09-28 17:43:36,349 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.01300
2016-09-28 17:43:36,388 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.01300
2016-09-28 17:43:36,428 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.01300
2016-09-28 17:43:36,465 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.01300
2016-09-28 17:43:36,504 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.01300
2016-09-28 17:43:36,542 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.01300
2016-09-28 17:43:36,579 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.01300
2016-09-28 17:43:36,618 : INFO : PROGRESS: at 90.33% examples, 312719 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:36,618 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.01300
2016-09-28 17:43:36,656 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.01300
2016-09-28 17:43:36,694 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.01300
2016-09-28 17:43:36,730 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.01300
2016-09-28 17:43:36,766 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.01300
2016-09-28 17:43:36,801 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.01300
2016-09-28 17:43:36,839 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.01300
2016-09-28 17:43:36,910 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:36,977 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:36,977 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:36,977 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 312757 effective words/s
2016-09-28 17:43:36,978 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:36,978 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:36,979 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.01100
2016-09-28 17:43:36,980 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.01100
2016-09-28 17:43:36,981 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.01100
2016-09-28 17:43:36,982 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.01100
2016-09-28 17:43:37,017 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.01100
2016-09-28 17:43:37,054 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.01100
2016-09-28 17:43:37,091 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.01100
2016-09-28 17:43:37,128 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.01100
2016-09-28 17:43:37,166 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.01100
2016-09-28 17:43:37,203 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.01100
2016-09-28 17:43:37,241 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.01100
2016-09-28 17:43:37,278 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.01100
2016-09-28 17:43:37,315 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.01100
2016-09-28 17:43:37,354 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.01100
2016-09-28 17:43:37,391 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.01100
2016-09-28 17:43:37,426 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.01100
2016-09-28 17:43:37,462 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.01100
2016-09-28 17:43:37,498 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.01100
2016-09-28 17:43:37,537 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.01100
2016-09-28 17:43:37,573 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.01100
2016-09-28 17:43:37,609 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.01100
2016-09-28 17:43:37,644 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.01100
2016-09-28 17:43:37,679 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.01100
2016-09-28 17:43:37,718 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.01100
2016-09-28 17:43:37,756 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.01100
2016-09-28 17:43:37,792 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.01100
2016-09-28 17:43:37,829 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.01100
2016-09-28 17:43:37,867 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.01100
2016-09-28 17:43:37,905 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.01100
2016-09-28 17:43:37,942 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.01100
2016-09-28 17:43:37,979 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.01100
2016-09-28 17:43:38,017 : INFO : PROGRESS: at 31.30% examples, 312346 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:38,017 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.01100
2016-09-28 17:43:38,055 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.01100
2016-09-28 17:43:38,094 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.01100
2016-09-28 17:43:38,129 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.01100
2016-09-28 17:43:38,165 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.01100
2016-09-28 17:43:38,200 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.01100
2016-09-28 17:43:38,239 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.01100
2016-09-28 17:43:38,278 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.01100
2016-09-28 17:43:38,317 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.01100
2016-09-28 17:43:38,355 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.01100
2016-09-28 17:43:38,391 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.01100
2016-09-28 17:43:38,427 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.01100
2016-09-28 17:43:38,465 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.01100
2016-09-28 17:43:38,502 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.01100
2016-09-28 17:43:38,540 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.01100
2016-09-28 17:43:38,578 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.01100
2016-09-28 17:43:38,615 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.01100
2016-09-28 17:43:38,652 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.01100
2016-09-28 17:43:38,689 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.01100
2016-09-28 17:43:38,729 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.01100
2016-09-28 17:43:38,767 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.01100
2016-09-28 17:43:38,803 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.01100
2016-09-28 17:43:38,838 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.01100
2016-09-28 17:43:38,873 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.01100
2016-09-28 17:43:38,908 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.01100
2016-09-28 17:43:38,944 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.01100
2016-09-28 17:43:38,979 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.01100
2016-09-28 17:43:39,014 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.01100
2016-09-28 17:43:39,053 : INFO : PROGRESS: at 60.28% examples, 310556 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:39,053 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.01100
2016-09-28 17:43:39,089 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.01100
2016-09-28 17:43:39,125 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.01100
2016-09-28 17:43:39,162 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.01100
2016-09-28 17:43:39,198 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.01100
2016-09-28 17:43:39,239 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.01100
2016-09-28 17:43:39,276 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.01100
2016-09-28 17:43:39,313 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.01100
2016-09-28 17:43:39,351 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.01100
2016-09-28 17:43:39,389 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.01100
2016-09-28 17:43:39,426 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.01100
2016-09-28 17:43:39,463 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.01100
2016-09-28 17:43:39,503 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.01100
2016-09-28 17:43:39,540 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.01100
2016-09-28 17:43:39,575 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.01100
2016-09-28 17:43:39,611 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.01100
2016-09-28 17:43:39,646 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.01100
2016-09-28 17:43:39,682 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.01100
2016-09-28 17:43:39,718 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.01100
2016-09-28 17:43:39,754 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.01100
2016-09-28 17:43:39,790 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.01100
2016-09-28 17:43:39,830 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.01100
2016-09-28 17:43:39,866 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.01100
2016-09-28 17:43:39,905 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.01100
2016-09-28 17:43:39,944 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.01100
2016-09-28 17:43:39,981 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.01100
2016-09-28 17:43:40,018 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.01100
2016-09-28 17:43:40,056 : INFO : PROGRESS: at 90.33% examples, 310803 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:40,056 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.01100
2016-09-28 17:43:40,094 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.01100
2016-09-28 17:43:40,132 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.01100
2016-09-28 17:43:40,170 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.01100
2016-09-28 17:43:40,205 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.01100
2016-09-28 17:43:40,246 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.01100
2016-09-28 17:43:40,285 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.01100
2016-09-28 17:43:40,354 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:40,423 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:40,423 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:40,424 : INFO : training on 926985 raw words (1068480 effective words) took 3.4s, 310288 effective words/s
2016-09-28 17:43:40,424 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:40,424 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:40,425 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.00900
2016-09-28 17:43:40,426 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.00900
2016-09-28 17:43:40,427 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.00900
2016-09-28 17:43:40,427 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.00900
2016-09-28 17:43:40,463 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.00900
2016-09-28 17:43:40,499 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.00900
2016-09-28 17:43:40,536 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.00900
2016-09-28 17:43:40,572 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.00900
2016-09-28 17:43:40,609 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.00900
2016-09-28 17:43:40,647 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.00900
2016-09-28 17:43:40,683 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.00900
2016-09-28 17:43:40,722 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.00900
2016-09-28 17:43:40,759 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.00900
2016-09-28 17:43:40,797 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.00900
2016-09-28 17:43:40,834 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.00900
2016-09-28 17:43:40,872 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.00900
2016-09-28 17:43:40,907 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.00900
2016-09-28 17:43:40,942 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.00900
2016-09-28 17:43:40,978 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.00900
2016-09-28 17:43:41,013 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.00900
2016-09-28 17:43:41,050 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.00900
2016-09-28 17:43:41,085 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.00900
2016-09-28 17:43:41,119 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.00900
2016-09-28 17:43:41,157 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.00900
2016-09-28 17:43:41,193 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.00900
2016-09-28 17:43:41,228 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.00900
2016-09-28 17:43:41,266 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.00900
2016-09-28 17:43:41,305 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.00900
2016-09-28 17:43:41,344 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.00900
2016-09-28 17:43:41,385 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.00900
2016-09-28 17:43:41,426 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.00900
2016-09-28 17:43:41,466 : INFO : PROGRESS: at 31.30% examples, 311303 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:41,466 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.00900
2016-09-28 17:43:41,503 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.00900
2016-09-28 17:43:41,545 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.00900
2016-09-28 17:43:41,583 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.00900
2016-09-28 17:43:41,622 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.00900
2016-09-28 17:43:41,664 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.00900
2016-09-28 17:43:41,700 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.00900
2016-09-28 17:43:41,743 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.00900
2016-09-28 17:43:41,784 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.00900
2016-09-28 17:43:41,823 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.00900
2016-09-28 17:43:41,858 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.00900
2016-09-28 17:43:41,904 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.00900
2016-09-28 17:43:41,942 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.00900
2016-09-28 17:43:41,983 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.00900
2016-09-28 17:43:42,023 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.00900
2016-09-28 17:43:42,070 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.00900
2016-09-28 17:43:42,112 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.00900
2016-09-28 17:43:42,159 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.00900
2016-09-28 17:43:42,196 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.00900
2016-09-28 17:43:42,235 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.00900
2016-09-28 17:43:42,272 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.00900
2016-09-28 17:43:42,307 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.00900
2016-09-28 17:43:42,343 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.00900
2016-09-28 17:43:42,378 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.00900
2016-09-28 17:43:42,415 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.00900
2016-09-28 17:43:42,451 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.00900
2016-09-28 17:43:42,485 : INFO : PROGRESS: at 58.40% examples, 301625 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:42,487 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.00900
2016-09-28 17:43:42,525 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.00900
2016-09-28 17:43:42,560 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.00900
2016-09-28 17:43:42,596 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.00900
2016-09-28 17:43:42,633 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.00900
2016-09-28 17:43:42,675 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.00900
2016-09-28 17:43:42,717 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.00900
2016-09-28 17:43:42,755 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.00900
2016-09-28 17:43:42,792 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.00900
2016-09-28 17:43:42,830 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.00900
2016-09-28 17:43:42,867 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.00900
2016-09-28 17:43:42,905 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.00900
2016-09-28 17:43:42,942 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.00900
2016-09-28 17:43:42,978 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.00900
2016-09-28 17:43:43,013 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.00900
2016-09-28 17:43:43,049 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.00900
2016-09-28 17:43:43,084 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.00900
2016-09-28 17:43:43,119 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.00900
2016-09-28 17:43:43,155 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.00900
2016-09-28 17:43:43,193 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.00900
2016-09-28 17:43:43,237 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.00900
2016-09-28 17:43:43,272 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.00900
2016-09-28 17:43:43,309 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.00900
2016-09-28 17:43:43,347 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.00900
2016-09-28 17:43:43,393 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.00900
2016-09-28 17:43:43,436 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.00900
2016-09-28 17:43:43,475 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.00900
2016-09-28 17:43:43,513 : INFO : PROGRESS: at 88.02% examples, 302001 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:43,514 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.00900
2016-09-28 17:43:43,553 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.00900
2016-09-28 17:43:43,591 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.00900
2016-09-28 17:43:43,628 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.00900
2016-09-28 17:43:43,670 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.00900
2016-09-28 17:43:43,709 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.00900
2016-09-28 17:43:43,748 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.00900
2016-09-28 17:43:43,792 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.00900
2016-09-28 17:43:43,830 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.00900
2016-09-28 17:43:43,908 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:43,975 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:43,975 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:43,975 : INFO : training on 926985 raw words (1068480 effective words) took 3.5s, 301003 effective words/s
2016-09-28 17:43:43,975 : INFO : training model with 1 workers on 2767 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-09-28 17:43:43,975 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-09-28 17:43:43,977 : DEBUG : queueing job #0 (9954 words, 284 sentences) at alpha 0.00700
2016-09-28 17:43:43,978 : DEBUG : queueing job #1 (9960 words, 286 sentences) at alpha 0.00700
2016-09-28 17:43:43,978 : DEBUG : queueing job #2 (9988 words, 299 sentences) at alpha 0.00700
2016-09-28 17:43:43,979 : DEBUG : queueing job #3 (9971 words, 288 sentences) at alpha 0.00700
2016-09-28 17:43:44,015 : DEBUG : queueing job #4 (9942 words, 297 sentences) at alpha 0.00700
2016-09-28 17:43:44,058 : DEBUG : queueing job #5 (9938 words, 288 sentences) at alpha 0.00700
2016-09-28 17:43:44,103 : DEBUG : queueing job #6 (9942 words, 287 sentences) at alpha 0.00700
2016-09-28 17:43:44,143 : DEBUG : queueing job #7 (10000 words, 276 sentences) at alpha 0.00700
2016-09-28 17:43:44,184 : DEBUG : queueing job #8 (9980 words, 279 sentences) at alpha 0.00700
2016-09-28 17:43:44,232 : DEBUG : queueing job #9 (9989 words, 315 sentences) at alpha 0.00700
2016-09-28 17:43:44,270 : DEBUG : queueing job #10 (9958 words, 266 sentences) at alpha 0.00700
2016-09-28 17:43:44,307 : DEBUG : queueing job #11 (9989 words, 224 sentences) at alpha 0.00700
2016-09-28 17:43:44,345 : DEBUG : queueing job #12 (9947 words, 228 sentences) at alpha 0.00700
2016-09-28 17:43:44,383 : DEBUG : queueing job #13 (9980 words, 206 sentences) at alpha 0.00700
2016-09-28 17:43:44,424 : DEBUG : queueing job #14 (9998 words, 220 sentences) at alpha 0.00700
2016-09-28 17:43:44,459 : DEBUG : queueing job #15 (9996 words, 204 sentences) at alpha 0.00700
2016-09-28 17:43:44,498 : DEBUG : queueing job #16 (9978 words, 232 sentences) at alpha 0.00700
2016-09-28 17:43:44,533 : DEBUG : queueing job #17 (9964 words, 218 sentences) at alpha 0.00700
2016-09-28 17:43:44,568 : DEBUG : queueing job #18 (9961 words, 237 sentences) at alpha 0.00700
2016-09-28 17:43:44,604 : DEBUG : queueing job #19 (9968 words, 286 sentences) at alpha 0.00700
2016-09-28 17:43:44,640 : DEBUG : queueing job #20 (9969 words, 298 sentences) at alpha 0.00700
2016-09-28 17:43:44,675 : DEBUG : queueing job #21 (9939 words, 291 sentences) at alpha 0.00700
2016-09-28 17:43:44,709 : DEBUG : queueing job #22 (9986 words, 285 sentences) at alpha 0.00700
2016-09-28 17:43:44,745 : DEBUG : queueing job #23 (9978 words, 301 sentences) at alpha 0.00700
2016-09-28 17:43:44,780 : DEBUG : queueing job #24 (9987 words, 285 sentences) at alpha 0.00700
2016-09-28 17:43:44,816 : DEBUG : queueing job #25 (9948 words, 280 sentences) at alpha 0.00700
2016-09-28 17:43:44,852 : DEBUG : queueing job #26 (9997 words, 283 sentences) at alpha 0.00700
2016-09-28 17:43:44,890 : DEBUG : queueing job #27 (9995 words, 303 sentences) at alpha 0.00700
2016-09-28 17:43:44,926 : DEBUG : queueing job #28 (9978 words, 293 sentences) at alpha 0.00700
2016-09-28 17:43:44,963 : DEBUG : queueing job #29 (9924 words, 239 sentences) at alpha 0.00700
2016-09-28 17:43:45,002 : INFO : PROGRESS: at 30.04% examples, 304362 words/s, in_qsize 2, out_qsize 0
2016-09-28 17:43:45,002 : DEBUG : queueing job #30 (9972 words, 228 sentences) at alpha 0.00700
2016-09-28 17:43:45,040 : DEBUG : queueing job #31 (9981 words, 220 sentences) at alpha 0.00700
2016-09-28 17:43:45,077 : DEBUG : queueing job #32 (9988 words, 210 sentences) at alpha 0.00700
2016-09-28 17:43:45,113 : DEBUG : queueing job #33 (9989 words, 219 sentences) at alpha 0.00700
2016-09-28 17:43:45,148 : DEBUG : queueing job #34 (9962 words, 207 sentences) at alpha 0.00700
2016-09-28 17:43:45,182 : DEBUG : queueing job #35 (9952 words, 222 sentences) at alpha 0.00700
2016-09-28 17:43:45,217 : DEBUG : queueing job #36 (9992 words, 221 sentences) at alpha 0.00700
2016-09-28 17:43:45,252 : DEBUG : queueing job #37 (9980 words, 269 sentences) at alpha 0.00700
2016-09-28 17:43:45,287 : DEBUG : queueing job #38 (9992 words, 290 sentences) at alpha 0.00700
2016-09-28 17:43:45,323 : DEBUG : queueing job #39 (9963 words, 299 sentences) at alpha 0.00700
2016-09-28 17:43:45,361 : DEBUG : queueing job #40 (9981 words, 288 sentences) at alpha 0.00700
2016-09-28 17:43:45,396 : DEBUG : queueing job #41 (9968 words, 290 sentences) at alpha 0.00700
2016-09-28 17:43:45,432 : DEBUG : queueing job #42 (9995 words, 293 sentences) at alpha 0.00700
2016-09-28 17:43:45,470 : DEBUG : queueing job #43 (9983 words, 293 sentences) at alpha 0.00700
2016-09-28 17:43:45,508 : DEBUG : queueing job #44 (9967 words, 268 sentences) at alpha 0.00700
2016-09-28 17:43:45,547 : DEBUG : queueing job #45 (9969 words, 281 sentences) at alpha 0.00700
2016-09-28 17:43:45,588 : DEBUG : queueing job #46 (9987 words, 319 sentences) at alpha 0.00700
2016-09-28 17:43:45,626 : DEBUG : queueing job #47 (9986 words, 276 sentences) at alpha 0.00700
2016-09-28 17:43:45,663 : DEBUG : queueing job #48 (9982 words, 224 sentences) at alpha 0.00700
2016-09-28 17:43:45,702 : DEBUG : queueing job #49 (9985 words, 228 sentences) at alpha 0.00700
2016-09-28 17:43:45,739 : DEBUG : queueing job #50 (9938 words, 212 sentences) at alpha 0.00700
2016-09-28 17:43:45,776 : DEBUG : queueing job #51 (9959 words, 215 sentences) at alpha 0.00700
2016-09-28 17:43:45,812 : DEBUG : queueing job #52 (9985 words, 206 sentences) at alpha 0.00700
2016-09-28 17:43:45,848 : DEBUG : queueing job #53 (9982 words, 224 sentences) at alpha 0.00700
2016-09-28 17:43:45,887 : DEBUG : queueing job #54 (9983 words, 224 sentences) at alpha 0.00700
2016-09-28 17:43:45,923 : DEBUG : queueing job #55 (9993 words, 229 sentences) at alpha 0.00700
2016-09-28 17:43:45,958 : DEBUG : queueing job #56 (9999 words, 283 sentences) at alpha 0.00700
2016-09-28 17:43:45,996 : DEBUG : queueing job #57 (9991 words, 295 sentences) at alpha 0.00700
2016-09-28 17:43:46,034 : INFO : PROGRESS: at 59.33% examples, 307465 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:46,036 : DEBUG : queueing job #58 (9960 words, 298 sentences) at alpha 0.00700
2016-09-28 17:43:46,073 : DEBUG : queueing job #59 (9972 words, 283 sentences) at alpha 0.00700
2016-09-28 17:43:46,112 : DEBUG : queueing job #60 (9978 words, 297 sentences) at alpha 0.00700
2016-09-28 17:43:46,148 : DEBUG : queueing job #61 (9949 words, 282 sentences) at alpha 0.00700
2016-09-28 17:43:46,184 : DEBUG : queueing job #62 (9968 words, 288 sentences) at alpha 0.00700
2016-09-28 17:43:46,223 : DEBUG : queueing job #63 (9992 words, 277 sentences) at alpha 0.00700
2016-09-28 17:43:46,261 : DEBUG : queueing job #64 (9958 words, 299 sentences) at alpha 0.00700
2016-09-28 17:43:46,299 : DEBUG : queueing job #65 (9933 words, 299 sentences) at alpha 0.00700
2016-09-28 17:43:46,337 : DEBUG : queueing job #66 (9965 words, 251 sentences) at alpha 0.00700
2016-09-28 17:43:46,374 : DEBUG : queueing job #67 (9959 words, 227 sentences) at alpha 0.00700
2016-09-28 17:43:46,411 : DEBUG : queueing job #68 (9966 words, 221 sentences) at alpha 0.00700
2016-09-28 17:43:46,448 : DEBUG : queueing job #69 (9997 words, 210 sentences) at alpha 0.00700
2016-09-28 17:43:46,483 : DEBUG : queueing job #70 (9982 words, 218 sentences) at alpha 0.00700
2016-09-28 17:43:46,519 : DEBUG : queueing job #71 (9965 words, 205 sentences) at alpha 0.00700
2016-09-28 17:43:46,554 : DEBUG : queueing job #72 (9977 words, 229 sentences) at alpha 0.00700
2016-09-28 17:43:46,588 : DEBUG : queueing job #73 (9999 words, 215 sentences) at alpha 0.00700
2016-09-28 17:43:46,623 : DEBUG : queueing job #74 (9963 words, 258 sentences) at alpha 0.00700
2016-09-28 17:43:46,661 : DEBUG : queueing job #75 (9993 words, 287 sentences) at alpha 0.00700
2016-09-28 17:43:46,697 : DEBUG : queueing job #76 (9980 words, 298 sentences) at alpha 0.00700
2016-09-28 17:43:46,732 : DEBUG : queueing job #77 (9982 words, 288 sentences) at alpha 0.00700
2016-09-28 17:43:46,766 : DEBUG : queueing job #78 (9992 words, 290 sentences) at alpha 0.00700
2016-09-28 17:43:46,802 : DEBUG : queueing job #79 (9983 words, 301 sentences) at alpha 0.00700
2016-09-28 17:43:46,839 : DEBUG : queueing job #80 (9992 words, 289 sentences) at alpha 0.00700
2016-09-28 17:43:46,874 : DEBUG : queueing job #81 (9948 words, 272 sentences) at alpha 0.00700
2016-09-28 17:43:46,913 : DEBUG : queueing job #82 (9994 words, 285 sentences) at alpha 0.00700
2016-09-28 17:43:46,951 : DEBUG : queueing job #83 (9986 words, 308 sentences) at alpha 0.00700
2016-09-28 17:43:46,987 : DEBUG : queueing job #84 (9972 words, 293 sentences) at alpha 0.00700
2016-09-28 17:43:47,024 : DEBUG : queueing job #85 (9959 words, 218 sentences) at alpha 0.00700
2016-09-28 17:43:47,061 : INFO : PROGRESS: at 90.33% examples, 309978 words/s, in_qsize 1, out_qsize 0
2016-09-28 17:43:47,062 : DEBUG : queueing job #86 (9980 words, 230 sentences) at alpha 0.00700
2016-09-28 17:43:47,099 : DEBUG : queueing job #87 (9979 words, 216 sentences) at alpha 0.00700
2016-09-28 17:43:47,140 : DEBUG : queueing job #88 (9993 words, 220 sentences) at alpha 0.00700
2016-09-28 17:43:47,182 : DEBUG : queueing job #89 (9997 words, 207 sentences) at alpha 0.00700
2016-09-28 17:43:47,221 : DEBUG : queueing job #90 (9962 words, 216 sentences) at alpha 0.00700
2016-09-28 17:43:47,261 : DEBUG : queueing job #91 (9931 words, 224 sentences) at alpha 0.00700
2016-09-28 17:43:47,297 : DEBUG : queueing job #92 (9371 words, 200 sentences) at alpha 0.00700
2016-09-28 17:43:47,381 : DEBUG : job loop exiting, total 93 jobs
2016-09-28 17:43:47,452 : DEBUG : worker exiting, processed 93 jobs
2016-09-28 17:43:47,453 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-09-28 17:43:47,453 : INFO : training on 926985 raw words (1068480 effective words) took 3.5s, 307403 effective words/s
2016-09-28 17:45:49,796 : INFO : precomputing L2-norms of word weight vectors
2016-10-02 13:55:29,994 : INFO : collecting all words and their counts
2016-10-02 13:55:29,995 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-02 13:55:30,197 : INFO : collected 11775 word types and 15 unique tags from a corpus of 4822 examples and 95251 words
2016-10-02 13:55:30,213 : INFO : min_count=5 retains 2630 unique words (drops 9145)
2016-10-02 13:55:30,213 : INFO : min_count leaves 81280 word corpus (85% of original 95251)
2016-10-02 13:55:30,219 : INFO : deleting the raw counts dictionary of 11775 items
2016-10-02 13:55:30,219 : INFO : sample=0 downsamples 0 most-common words
2016-10-02 13:55:30,219 : INFO : downsampling leaves estimated 81280 word corpus (100.0% of prior 81280)
2016-10-02 13:55:30,219 : INFO : estimated required memory for 2630 words and 100 dimensions: 3954000 bytes
2016-10-02 13:55:30,222 : INFO : constructing a huffman tree from 2630 words
2016-10-02 13:55:30,297 : INFO : built huffman tree with maximum node depth 14
2016-10-02 13:55:30,298 : INFO : resetting layer weights
2016-10-02 13:55:30,329 : INFO : training model with 4 workers on 2630 vocabulary and 100 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 13:55:30,329 : INFO : expecting 4822 sentences, matching count from corpus used for vocabulary survey
2016-10-02 13:55:30,332 : DEBUG : queueing job #0 (9993 words, 557 sentences) at alpha 0.02500
2016-10-02 13:55:30,335 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02442
2016-10-02 13:55:30,337 : DEBUG : queueing job #2 (9976 words, 563 sentences) at alpha 0.02384
2016-10-02 13:55:30,339 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02326
2016-10-02 13:55:30,341 : DEBUG : queueing job #4 (9982 words, 580 sentences) at alpha 0.02270
2016-10-02 13:55:30,343 : DEBUG : queueing job #5 (9974 words, 495 sentences) at alpha 0.02210
2016-10-02 13:55:30,344 : DEBUG : queueing job #6 (9983 words, 437 sentences) at alpha 0.02159
2016-10-02 13:55:30,345 : DEBUG : queueing job #7 (9977 words, 420 sentences) at alpha 0.02114
2016-10-02 13:55:30,347 : DEBUG : queueing job #8 (10000 words, 432 sentences) at alpha 0.02070
2016-10-02 13:55:30,348 : DEBUG : queueing job #9 (10000 words, 483 sentences) at alpha 0.02026
2016-10-02 13:55:30,349 : DEBUG : queueing job #10 (9994 words, 572 sentences) at alpha 0.01976
2016-10-02 13:55:30,350 : DEBUG : queueing job #11 (9999 words, 554 sentences) at alpha 0.01917
2016-10-02 13:55:30,351 : DEBUG : queueing job #12 (9965 words, 561 sentences) at alpha 0.01859
2016-10-02 13:55:30,453 : DEBUG : queueing job #13 (10000 words, 546 sentences) at alpha 0.01802
2016-10-02 13:55:30,457 : DEBUG : queueing job #14 (9992 words, 581 sentences) at alpha 0.01745
2016-10-02 13:55:30,460 : DEBUG : queueing job #15 (9999 words, 444 sentences) at alpha 0.01685
2016-10-02 13:55:30,463 : DEBUG : queueing job #16 (9969 words, 424 sentences) at alpha 0.01639
2016-10-02 13:55:30,549 : DEBUG : queueing job #17 (9983 words, 418 sentences) at alpha 0.01596
2016-10-02 13:55:30,556 : DEBUG : queueing job #18 (9990 words, 439 sentences) at alpha 0.01552
2016-10-02 13:55:30,560 : DEBUG : queueing job #19 (9999 words, 545 sentences) at alpha 0.01507
2016-10-02 13:55:30,575 : DEBUG : queueing job #20 (9986 words, 557 sentences) at alpha 0.01451
2016-10-02 13:55:30,643 : DEBUG : queueing job #21 (9985 words, 572 sentences) at alpha 0.01393
2016-10-02 13:55:30,657 : DEBUG : queueing job #22 (9998 words, 543 sentences) at alpha 0.01334
2016-10-02 13:55:30,677 : DEBUG : queueing job #23 (9998 words, 579 sentences) at alpha 0.01278
2016-10-02 13:55:30,691 : DEBUG : queueing job #24 (9978 words, 507 sentences) at alpha 0.01218
2016-10-02 13:55:30,755 : DEBUG : queueing job #25 (9991 words, 441 sentences) at alpha 0.01166
2016-10-02 13:55:30,768 : DEBUG : queueing job #26 (9994 words, 423 sentences) at alpha 0.01120
2016-10-02 13:55:30,781 : DEBUG : queueing job #27 (9985 words, 424 sentences) at alpha 0.01077
2016-10-02 13:55:30,794 : DEBUG : queueing job #28 (9981 words, 477 sentences) at alpha 0.01033
2016-10-02 13:55:30,845 : DEBUG : queueing job #29 (9992 words, 564 sentences) at alpha 0.00984
2016-10-02 13:55:30,857 : DEBUG : queueing job #30 (9986 words, 555 sentences) at alpha 0.00925
2016-10-02 13:55:30,875 : DEBUG : queueing job #31 (10000 words, 560 sentences) at alpha 0.00868
2016-10-02 13:55:30,904 : DEBUG : queueing job #32 (9987 words, 554 sentences) at alpha 0.00810
2016-10-02 13:55:30,957 : DEBUG : queueing job #33 (10000 words, 575 sentences) at alpha 0.00753
2016-10-02 13:55:30,967 : DEBUG : queueing job #34 (9980 words, 457 sentences) at alpha 0.00694
2016-10-02 13:55:30,985 : DEBUG : queueing job #35 (10000 words, 425 sentences) at alpha 0.00646
2016-10-02 13:55:31,022 : DEBUG : queueing job #36 (9994 words, 415 sentences) at alpha 0.00602
2016-10-02 13:55:31,058 : DEBUG : queueing job #37 (10000 words, 440 sentences) at alpha 0.00560
2016-10-02 13:55:31,065 : DEBUG : queueing job #38 (9980 words, 536 sentences) at alpha 0.00514
2016-10-02 13:55:31,075 : DEBUG : queueing job #39 (9997 words, 560 sentences) at alpha 0.00459
2016-10-02 13:55:31,116 : DEBUG : queueing job #40 (10000 words, 576 sentences) at alpha 0.00401
2016-10-02 13:55:31,159 : DEBUG : queueing job #41 (9999 words, 540 sentences) at alpha 0.00342
2016-10-02 13:55:31,178 : DEBUG : queueing job #42 (9996 words, 573 sentences) at alpha 0.00286
2016-10-02 13:55:31,181 : DEBUG : queueing job #43 (9989 words, 520 sentences) at alpha 0.00227
2016-10-02 13:55:31,232 : DEBUG : queueing job #44 (9984 words, 440 sentences) at alpha 0.00173
2016-10-02 13:55:31,268 : DEBUG : queueing job #45 (9974 words, 423 sentences) at alpha 0.00127
2016-10-02 13:55:31,274 : DEBUG : queueing job #46 (9976 words, 426 sentences) at alpha 0.00084
2016-10-02 13:55:31,301 : DEBUG : queueing job #47 (6777 words, 288 sentences) at alpha 0.00040
2016-10-02 13:55:31,356 : INFO : PROGRESS: at 77.93% examples, 469094 words/s, in_qsize 8, out_qsize 0
2016-10-02 13:55:31,426 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 13:55:31,552 : DEBUG : worker exiting, processed 12 jobs
2016-10-02 13:55:31,553 : INFO : worker thread finished; awaiting finish of 3 more threads
2016-10-02 13:55:31,559 : DEBUG : worker exiting, processed 12 jobs
2016-10-02 13:55:31,559 : INFO : worker thread finished; awaiting finish of 2 more threads
2016-10-02 13:55:31,571 : DEBUG : worker exiting, processed 12 jobs
2016-10-02 13:55:31,571 : INFO : worker thread finished; awaiting finish of 1 more threads
2016-10-02 13:55:31,578 : DEBUG : worker exiting, processed 12 jobs
2016-10-02 13:55:31,578 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 13:55:31,578 : INFO : training on 476255 raw words (617840 effective words) took 1.2s, 495995 effective words/s
2016-10-02 13:55:31,578 : INFO : saving Doc2Vec object under ./tmp/doc2vec_size100window8min5work4, separately None
2016-10-02 13:55:31,579 : INFO : not storing attribute syn0norm
2016-10-02 13:55:31,579 : INFO : not storing attribute cum_table
2016-10-02 15:00:21,084 : INFO : collecting all words and their counts
2016-10-02 15:00:21,085 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-02 15:00:21,177 : INFO : collected 21416 word types and 13 unique tags from a corpus of 4880 examples and 99775 words
2016-10-02 15:00:21,191 : INFO : min_count=5 retains 2830 unique words (drops 18586)
2016-10-02 15:00:21,191 : INFO : min_count leaves 74276 word corpus (74% of original 99775)
2016-10-02 15:00:21,196 : INFO : deleting the raw counts dictionary of 21416 items
2016-10-02 15:00:21,197 : INFO : sample=0 downsamples 0 most-common words
2016-10-02 15:00:21,197 : INFO : downsampling leaves estimated 74276 word corpus (100.0% of prior 74276)
2016-10-02 15:00:21,197 : INFO : estimated required memory for 2830 words and 300 dimensions: 8791200 bytes
2016-10-02 15:00:21,199 : INFO : constructing a huffman tree from 2830 words
2016-10-02 15:00:21,264 : INFO : built huffman tree with maximum node depth 14
2016-10-02 15:00:21,265 : INFO : resetting layer weights
2016-10-02 15:08:46,137 : INFO : collecting all words and their counts
2016-10-02 15:08:46,138 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-02 15:08:46,234 : INFO : collected 21416 word types and 13 unique tags from a corpus of 4880 examples and 99775 words
2016-10-02 15:08:46,249 : INFO : min_count=5 retains 2830 unique words (drops 18586)
2016-10-02 15:08:46,249 : INFO : min_count leaves 74276 word corpus (74% of original 99775)
2016-10-02 15:08:46,255 : INFO : deleting the raw counts dictionary of 21416 items
2016-10-02 15:08:46,256 : INFO : sample=0 downsamples 0 most-common words
2016-10-02 15:08:46,256 : INFO : downsampling leaves estimated 74276 word corpus (100.0% of prior 74276)
2016-10-02 15:08:46,256 : INFO : estimated required memory for 2830 words and 300 dimensions: 8791200 bytes
2016-10-02 15:08:46,258 : INFO : constructing a huffman tree from 2830 words
2016-10-02 15:08:46,322 : INFO : built huffman tree with maximum node depth 14
2016-10-02 15:08:46,322 : INFO : resetting layer weights
2016-10-02 15:08:46,360 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:46,360 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:46,361 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.02500
2016-10-02 15:08:46,362 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.02500
2016-10-02 15:08:46,363 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.02500
2016-10-02 15:08:46,365 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.02500
2016-10-02 15:08:46,399 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.02500
2016-10-02 15:08:46,430 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.02500
2016-10-02 15:08:46,462 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.02500
2016-10-02 15:08:46,494 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.02500
2016-10-02 15:08:46,528 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.02500
2016-10-02 15:08:46,566 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.02500
2016-10-02 15:08:46,600 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.02500
2016-10-02 15:08:46,634 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.02500
2016-10-02 15:08:46,667 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.02500
2016-10-02 15:08:46,702 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.02500
2016-10-02 15:08:46,734 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.02500
2016-10-02 15:08:46,767 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.02500
2016-10-02 15:08:46,799 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.02500
2016-10-02 15:08:46,832 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.02500
2016-10-02 15:08:46,865 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.02500
2016-10-02 15:08:46,899 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.02500
2016-10-02 15:08:46,936 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.02500
2016-10-02 15:08:46,970 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.02500
2016-10-02 15:08:47,003 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.02500
2016-10-02 15:08:47,038 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.02500
2016-10-02 15:08:47,071 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.02500
2016-10-02 15:08:47,103 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.02500
2016-10-02 15:08:47,135 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.02500
2016-10-02 15:08:47,172 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.02500
2016-10-02 15:08:47,209 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.02500
2016-10-02 15:08:47,243 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.02500
2016-10-02 15:08:47,276 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.02500
2016-10-02 15:08:47,310 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.02500
2016-10-02 15:08:47,343 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.02500
2016-10-02 15:08:47,377 : INFO : PROGRESS: at 60.05% examples, 301244 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:47,378 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.02500
2016-10-02 15:08:47,411 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.02500
2016-10-02 15:08:47,443 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.02500
2016-10-02 15:08:47,475 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.02500
2016-10-02 15:08:47,508 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.02500
2016-10-02 15:08:47,543 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.02500
2016-10-02 15:08:47,578 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.02500
2016-10-02 15:08:47,612 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.02500
2016-10-02 15:08:47,646 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.02500
2016-10-02 15:08:47,679 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.02500
2016-10-02 15:08:47,713 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.02500
2016-10-02 15:08:47,746 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.02500
2016-10-02 15:08:47,781 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.02500
2016-10-02 15:08:47,813 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.02500
2016-10-02 15:08:47,846 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.02500
2016-10-02 15:08:47,882 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.02500
2016-10-02 15:08:47,919 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.02500
2016-10-02 15:08:47,983 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:48,047 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:48,047 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:48,047 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 302089 effective words/s
2016-10-02 15:08:48,047 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:48,047 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:48,049 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.02300
2016-10-02 15:08:48,049 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.02300
2016-10-02 15:08:48,050 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.02300
2016-10-02 15:08:48,051 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.02300
2016-10-02 15:08:48,083 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.02300
2016-10-02 15:08:48,115 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.02300
2016-10-02 15:08:48,147 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.02300
2016-10-02 15:08:48,180 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.02300
2016-10-02 15:08:48,213 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.02300
2016-10-02 15:08:48,246 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.02300
2016-10-02 15:08:48,280 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.02300
2016-10-02 15:08:48,313 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.02300
2016-10-02 15:08:48,347 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.02300
2016-10-02 15:08:48,382 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.02300
2016-10-02 15:08:48,415 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.02300
2016-10-02 15:08:48,447 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.02300
2016-10-02 15:08:48,480 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.02300
2016-10-02 15:08:48,512 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.02300
2016-10-02 15:08:48,547 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.02300
2016-10-02 15:08:48,580 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.02300
2016-10-02 15:08:48,614 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.02300
2016-10-02 15:08:48,647 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.02300
2016-10-02 15:08:48,681 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.02300
2016-10-02 15:08:48,715 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.02300
2016-10-02 15:08:48,748 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.02300
2016-10-02 15:08:48,780 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.02300
2016-10-02 15:08:48,812 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.02300
2016-10-02 15:08:48,849 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.02300
2016-10-02 15:08:48,882 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.02300
2016-10-02 15:08:48,916 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.02300
2016-10-02 15:08:48,950 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.02300
2016-10-02 15:08:48,983 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.02300
2016-10-02 15:08:49,017 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.02300
2016-10-02 15:08:49,051 : INFO : PROGRESS: at 60.05% examples, 305400 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:49,052 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.02300
2016-10-02 15:08:49,084 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.02300
2016-10-02 15:08:49,116 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.02300
2016-10-02 15:08:49,149 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.02300
2016-10-02 15:08:49,182 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.02300
2016-10-02 15:08:49,215 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.02300
2016-10-02 15:08:49,249 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.02300
2016-10-02 15:08:49,283 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.02300
2016-10-02 15:08:49,316 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.02300
2016-10-02 15:08:49,350 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.02300
2016-10-02 15:08:49,385 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.02300
2016-10-02 15:08:49,417 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.02300
2016-10-02 15:08:49,449 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.02300
2016-10-02 15:08:49,481 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.02300
2016-10-02 15:08:49,514 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.02300
2016-10-02 15:08:49,549 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.02300
2016-10-02 15:08:49,583 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.02300
2016-10-02 15:08:49,648 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:49,713 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:49,713 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:49,713 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 305959 effective words/s
2016-10-02 15:08:49,713 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:49,713 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:49,715 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.02100
2016-10-02 15:08:49,715 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.02100
2016-10-02 15:08:49,716 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.02100
2016-10-02 15:08:49,717 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.02100
2016-10-02 15:08:49,750 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.02100
2016-10-02 15:08:49,781 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.02100
2016-10-02 15:08:49,813 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.02100
2016-10-02 15:08:49,846 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.02100
2016-10-02 15:08:49,879 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.02100
2016-10-02 15:08:49,916 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.02100
2016-10-02 15:08:49,952 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.02100
2016-10-02 15:08:49,986 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.02100
2016-10-02 15:08:50,020 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.02100
2016-10-02 15:08:50,054 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.02100
2016-10-02 15:08:50,086 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.02100
2016-10-02 15:08:50,117 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.02100
2016-10-02 15:08:50,150 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.02100
2016-10-02 15:08:50,182 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.02100
2016-10-02 15:08:50,216 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.02100
2016-10-02 15:08:50,249 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.02100
2016-10-02 15:08:50,283 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.02100
2016-10-02 15:08:50,316 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.02100
2016-10-02 15:08:50,352 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.02100
2016-10-02 15:08:50,386 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.02100
2016-10-02 15:08:50,419 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.02100
2016-10-02 15:08:50,453 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.02100
2016-10-02 15:08:50,485 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.02100
2016-10-02 15:08:50,517 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.02100
2016-10-02 15:08:50,551 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.02100
2016-10-02 15:08:50,585 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.02100
2016-10-02 15:08:50,618 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.02100
2016-10-02 15:08:50,652 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.02100
2016-10-02 15:08:50,686 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.02100
2016-10-02 15:08:50,722 : INFO : PROGRESS: at 60.05% examples, 303496 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:50,723 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.02100
2016-10-02 15:08:50,756 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.02100
2016-10-02 15:08:50,787 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.02100
2016-10-02 15:08:50,818 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.02100
2016-10-02 15:08:50,851 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.02100
2016-10-02 15:08:50,885 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.02100
2016-10-02 15:08:50,918 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.02100
2016-10-02 15:08:50,951 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.02100
2016-10-02 15:08:50,985 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.02100
2016-10-02 15:08:51,018 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.02100
2016-10-02 15:08:51,052 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.02100
2016-10-02 15:08:51,085 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.02100
2016-10-02 15:08:51,117 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.02100
2016-10-02 15:08:51,153 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.02100
2016-10-02 15:08:51,186 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.02100
2016-10-02 15:08:51,220 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.02100
2016-10-02 15:08:51,253 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.02100
2016-10-02 15:08:51,319 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:51,384 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:51,385 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:51,385 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 304826 effective words/s
2016-10-02 15:08:51,385 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:51,385 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:51,386 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.01900
2016-10-02 15:08:51,387 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.01900
2016-10-02 15:08:51,387 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.01900
2016-10-02 15:08:51,388 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.01900
2016-10-02 15:08:51,421 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.01900
2016-10-02 15:08:51,453 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.01900
2016-10-02 15:08:51,485 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.01900
2016-10-02 15:08:51,518 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.01900
2016-10-02 15:08:51,553 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.01900
2016-10-02 15:08:51,587 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.01900
2016-10-02 15:08:51,621 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.01900
2016-10-02 15:08:51,655 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.01900
2016-10-02 15:08:51,689 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.01900
2016-10-02 15:08:51,723 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.01900
2016-10-02 15:08:51,756 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.01900
2016-10-02 15:08:51,788 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.01900
2016-10-02 15:08:51,820 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.01900
2016-10-02 15:08:51,853 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.01900
2016-10-02 15:08:51,886 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.01900
2016-10-02 15:08:51,919 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.01900
2016-10-02 15:08:51,953 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.01900
2016-10-02 15:08:51,987 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.01900
2016-10-02 15:08:52,020 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.01900
2016-10-02 15:08:52,055 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.01900
2016-10-02 15:08:52,087 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.01900
2016-10-02 15:08:52,119 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.01900
2016-10-02 15:08:52,152 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.01900
2016-10-02 15:08:52,185 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.01900
2016-10-02 15:08:52,219 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.01900
2016-10-02 15:08:52,253 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.01900
2016-10-02 15:08:52,286 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.01900
2016-10-02 15:08:52,319 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.01900
2016-10-02 15:08:52,353 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.01900
2016-10-02 15:08:52,390 : INFO : PROGRESS: at 60.05% examples, 304766 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:52,391 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.01900
2016-10-02 15:08:52,423 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.01900
2016-10-02 15:08:52,456 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.01900
2016-10-02 15:08:52,488 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.01900
2016-10-02 15:08:52,521 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.01900
2016-10-02 15:08:52,556 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.01900
2016-10-02 15:08:52,589 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.01900
2016-10-02 15:08:52,624 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.01900
2016-10-02 15:08:52,658 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.01900
2016-10-02 15:08:52,692 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.01900
2016-10-02 15:08:52,726 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.01900
2016-10-02 15:08:52,759 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.01900
2016-10-02 15:08:52,791 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.01900
2016-10-02 15:08:52,823 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.01900
2016-10-02 15:08:52,856 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.01900
2016-10-02 15:08:52,889 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.01900
2016-10-02 15:08:52,923 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.01900
2016-10-02 15:08:52,989 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:53,054 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:53,054 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:53,054 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 305336 effective words/s
2016-10-02 15:08:53,054 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:53,054 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:53,055 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.01700
2016-10-02 15:08:53,056 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.01700
2016-10-02 15:08:53,057 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.01700
2016-10-02 15:08:53,058 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.01700
2016-10-02 15:08:53,090 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.01700
2016-10-02 15:08:53,122 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.01700
2016-10-02 15:08:53,155 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.01700
2016-10-02 15:08:53,187 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.01700
2016-10-02 15:08:53,223 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.01700
2016-10-02 15:08:53,257 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.01700
2016-10-02 15:08:53,291 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.01700
2016-10-02 15:08:53,324 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.01700
2016-10-02 15:08:53,357 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.01700
2016-10-02 15:08:53,392 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.01700
2016-10-02 15:08:53,424 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.01700
2016-10-02 15:08:53,456 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.01700
2016-10-02 15:08:53,488 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.01700
2016-10-02 15:08:53,524 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.01700
2016-10-02 15:08:53,560 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.01700
2016-10-02 15:08:53,593 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.01700
2016-10-02 15:08:53,627 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.01700
2016-10-02 15:08:53,660 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.01700
2016-10-02 15:08:53,693 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.01700
2016-10-02 15:08:53,728 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.01700
2016-10-02 15:08:53,761 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.01700
2016-10-02 15:08:53,793 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.01700
2016-10-02 15:08:53,824 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.01700
2016-10-02 15:08:53,858 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.01700
2016-10-02 15:08:53,891 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.01700
2016-10-02 15:08:53,925 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.01700
2016-10-02 15:08:53,958 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.01700
2016-10-02 15:08:53,991 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.01700
2016-10-02 15:08:54,025 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.01700
2016-10-02 15:08:54,058 : INFO : PROGRESS: at 60.05% examples, 305295 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:54,059 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.01700
2016-10-02 15:08:54,091 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.01700
2016-10-02 15:08:54,122 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.01700
2016-10-02 15:08:54,154 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.01700
2016-10-02 15:08:54,187 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.01700
2016-10-02 15:08:54,223 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.01700
2016-10-02 15:08:54,260 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.01700
2016-10-02 15:08:54,293 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.01700
2016-10-02 15:08:54,327 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.01700
2016-10-02 15:08:54,361 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.01700
2016-10-02 15:08:54,396 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.01700
2016-10-02 15:08:54,428 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.01700
2016-10-02 15:08:54,461 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.01700
2016-10-02 15:08:54,494 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.01700
2016-10-02 15:08:54,529 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.01700
2016-10-02 15:08:54,566 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.01700
2016-10-02 15:08:54,599 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.01700
2016-10-02 15:08:54,664 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:54,728 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:54,728 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:54,728 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 304376 effective words/s
2016-10-02 15:08:54,729 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:54,729 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:54,730 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.01500
2016-10-02 15:08:54,731 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.01500
2016-10-02 15:08:54,731 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.01500
2016-10-02 15:08:54,732 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.01500
2016-10-02 15:08:54,764 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.01500
2016-10-02 15:08:54,796 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.01500
2016-10-02 15:08:54,828 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.01500
2016-10-02 15:08:54,861 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.01500
2016-10-02 15:08:54,893 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.01500
2016-10-02 15:08:54,927 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.01500
2016-10-02 15:08:54,964 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.01500
2016-10-02 15:08:54,997 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.01500
2016-10-02 15:08:55,030 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.01500
2016-10-02 15:08:55,065 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.01500
2016-10-02 15:08:55,101 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.01500
2016-10-02 15:08:55,132 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.01500
2016-10-02 15:08:55,165 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.01500
2016-10-02 15:08:55,198 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.01500
2016-10-02 15:08:55,231 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.01500
2016-10-02 15:08:55,266 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.01500
2016-10-02 15:08:55,300 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.01500
2016-10-02 15:08:55,334 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.01500
2016-10-02 15:08:55,367 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.01500
2016-10-02 15:08:55,402 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.01500
2016-10-02 15:08:55,435 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.01500
2016-10-02 15:08:55,466 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.01500
2016-10-02 15:08:55,498 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.01500
2016-10-02 15:08:55,530 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.01500
2016-10-02 15:08:55,564 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.01500
2016-10-02 15:08:55,598 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.01500
2016-10-02 15:08:55,632 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.01500
2016-10-02 15:08:55,665 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.01500
2016-10-02 15:08:55,699 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.01500
2016-10-02 15:08:55,732 : INFO : PROGRESS: at 60.05% examples, 304824 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:55,733 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.01500
2016-10-02 15:08:55,766 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.01500
2016-10-02 15:08:55,797 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.01500
2016-10-02 15:08:55,829 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.01500
2016-10-02 15:08:55,862 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.01500
2016-10-02 15:08:55,894 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.01500
2016-10-02 15:08:55,927 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.01500
2016-10-02 15:08:55,962 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.01500
2016-10-02 15:08:55,995 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.01500
2016-10-02 15:08:56,028 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.01500
2016-10-02 15:08:56,063 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.01500
2016-10-02 15:08:56,096 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.01500
2016-10-02 15:08:56,127 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.01500
2016-10-02 15:08:56,160 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.01500
2016-10-02 15:08:56,192 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.01500
2016-10-02 15:08:56,230 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.01500
2016-10-02 15:08:56,263 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.01500
2016-10-02 15:08:56,328 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:56,392 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:56,393 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:56,393 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 306027 effective words/s
2016-10-02 15:08:56,393 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:56,393 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:56,394 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.01300
2016-10-02 15:08:56,395 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.01300
2016-10-02 15:08:56,395 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.01300
2016-10-02 15:08:56,396 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.01300
2016-10-02 15:08:56,429 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.01300
2016-10-02 15:08:56,460 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.01300
2016-10-02 15:08:56,495 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.01300
2016-10-02 15:08:56,529 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.01300
2016-10-02 15:08:56,563 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.01300
2016-10-02 15:08:56,596 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.01300
2016-10-02 15:08:56,630 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.01300
2016-10-02 15:08:56,664 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.01300
2016-10-02 15:08:56,697 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.01300
2016-10-02 15:08:56,732 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.01300
2016-10-02 15:08:56,764 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.01300
2016-10-02 15:08:56,795 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.01300
2016-10-02 15:08:56,828 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.01300
2016-10-02 15:08:56,861 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.01300
2016-10-02 15:08:56,894 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.01300
2016-10-02 15:08:56,928 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.01300
2016-10-02 15:08:56,962 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.01300
2016-10-02 15:08:56,998 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.01300
2016-10-02 15:08:57,034 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.01300
2016-10-02 15:08:57,068 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.01300
2016-10-02 15:08:57,101 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.01300
2016-10-02 15:08:57,133 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.01300
2016-10-02 15:08:57,165 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.01300
2016-10-02 15:08:57,198 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.01300
2016-10-02 15:08:57,231 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.01300
2016-10-02 15:08:57,265 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.01300
2016-10-02 15:08:57,299 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.01300
2016-10-02 15:08:57,333 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.01300
2016-10-02 15:08:57,366 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.01300
2016-10-02 15:08:57,400 : INFO : PROGRESS: at 60.05% examples, 304211 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:57,401 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.01300
2016-10-02 15:08:57,434 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.01300
2016-10-02 15:08:57,466 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.01300
2016-10-02 15:08:57,498 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.01300
2016-10-02 15:08:57,533 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.01300
2016-10-02 15:08:57,567 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.01300
2016-10-02 15:08:57,600 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.01300
2016-10-02 15:08:57,634 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.01300
2016-10-02 15:08:57,667 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.01300
2016-10-02 15:08:57,701 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.01300
2016-10-02 15:08:57,735 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.01300
2016-10-02 15:08:57,768 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.01300
2016-10-02 15:08:57,799 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.01300
2016-10-02 15:08:57,833 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.01300
2016-10-02 15:08:57,865 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.01300
2016-10-02 15:08:57,898 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.01300
2016-10-02 15:08:57,932 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.01300
2016-10-02 15:08:57,997 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:58,068 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:58,069 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:58,069 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 304110 effective words/s
2016-10-02 15:08:58,069 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:58,069 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:58,070 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.01100
2016-10-02 15:08:58,071 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.01100
2016-10-02 15:08:58,071 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.01100
2016-10-02 15:08:58,072 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.01100
2016-10-02 15:08:58,105 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.01100
2016-10-02 15:08:58,136 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.01100
2016-10-02 15:08:58,169 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.01100
2016-10-02 15:08:58,201 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.01100
2016-10-02 15:08:58,235 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.01100
2016-10-02 15:08:58,268 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.01100
2016-10-02 15:08:58,302 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.01100
2016-10-02 15:08:58,336 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.01100
2016-10-02 15:08:58,370 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.01100
2016-10-02 15:08:58,405 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.01100
2016-10-02 15:08:58,437 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.01100
2016-10-02 15:08:58,469 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.01100
2016-10-02 15:08:58,501 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.01100
2016-10-02 15:08:58,537 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.01100
2016-10-02 15:08:58,569 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.01100
2016-10-02 15:08:58,603 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.01100
2016-10-02 15:08:58,641 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.01100
2016-10-02 15:08:58,674 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.01100
2016-10-02 15:08:58,707 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.01100
2016-10-02 15:08:58,742 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.01100
2016-10-02 15:08:58,774 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.01100
2016-10-02 15:08:58,805 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.01100
2016-10-02 15:08:58,838 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.01100
2016-10-02 15:08:58,870 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.01100
2016-10-02 15:08:58,903 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.01100
2016-10-02 15:08:58,937 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.01100
2016-10-02 15:08:58,972 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.01100
2016-10-02 15:08:59,005 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.01100
2016-10-02 15:08:59,039 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.01100
2016-10-02 15:08:59,074 : INFO : PROGRESS: at 60.05% examples, 304879 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:08:59,075 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.01100
2016-10-02 15:08:59,107 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.01100
2016-10-02 15:08:59,139 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.01100
2016-10-02 15:08:59,172 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.01100
2016-10-02 15:08:59,204 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.01100
2016-10-02 15:08:59,238 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.01100
2016-10-02 15:08:59,271 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.01100
2016-10-02 15:08:59,305 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.01100
2016-10-02 15:08:59,338 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.01100
2016-10-02 15:08:59,376 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.01100
2016-10-02 15:08:59,411 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.01100
2016-10-02 15:08:59,447 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.01100
2016-10-02 15:08:59,479 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.01100
2016-10-02 15:08:59,511 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.01100
2016-10-02 15:08:59,546 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.01100
2016-10-02 15:08:59,579 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.01100
2016-10-02 15:08:59,612 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.01100
2016-10-02 15:08:59,678 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:08:59,743 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:08:59,744 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:08:59,744 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 304251 effective words/s
2016-10-02 15:08:59,744 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:08:59,744 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:08:59,745 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.00900
2016-10-02 15:08:59,746 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.00900
2016-10-02 15:08:59,747 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.00900
2016-10-02 15:08:59,747 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.00900
2016-10-02 15:08:59,781 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.00900
2016-10-02 15:08:59,812 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.00900
2016-10-02 15:08:59,844 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.00900
2016-10-02 15:08:59,876 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.00900
2016-10-02 15:08:59,910 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.00900
2016-10-02 15:08:59,944 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.00900
2016-10-02 15:08:59,978 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.00900
2016-10-02 15:09:00,013 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.00900
2016-10-02 15:09:00,050 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.00900
2016-10-02 15:09:00,084 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.00900
2016-10-02 15:09:00,122 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.00900
2016-10-02 15:09:00,153 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.00900
2016-10-02 15:09:00,188 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.00900
2016-10-02 15:09:00,223 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.00900
2016-10-02 15:09:00,256 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.00900
2016-10-02 15:09:00,289 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.00900
2016-10-02 15:09:00,323 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.00900
2016-10-02 15:09:00,356 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.00900
2016-10-02 15:09:00,389 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.00900
2016-10-02 15:09:00,424 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.00900
2016-10-02 15:09:00,457 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.00900
2016-10-02 15:09:00,487 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.00900
2016-10-02 15:09:00,519 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.00900
2016-10-02 15:09:00,554 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.00900
2016-10-02 15:09:00,587 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.00900
2016-10-02 15:09:00,620 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.00900
2016-10-02 15:09:00,654 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.00900
2016-10-02 15:09:00,687 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.00900
2016-10-02 15:09:00,721 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.00900
2016-10-02 15:09:00,754 : INFO : PROGRESS: at 60.05% examples, 303240 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:09:00,755 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.00900
2016-10-02 15:09:00,788 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.00900
2016-10-02 15:09:00,819 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.00900
2016-10-02 15:09:00,851 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.00900
2016-10-02 15:09:00,884 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.00900
2016-10-02 15:09:00,918 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.00900
2016-10-02 15:09:00,951 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.00900
2016-10-02 15:09:00,984 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.00900
2016-10-02 15:09:01,018 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.00900
2016-10-02 15:09:01,051 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.00900
2016-10-02 15:09:01,086 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.00900
2016-10-02 15:09:01,119 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.00900
2016-10-02 15:09:01,152 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.00900
2016-10-02 15:09:01,186 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.00900
2016-10-02 15:09:01,221 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.00900
2016-10-02 15:09:01,255 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.00900
2016-10-02 15:09:01,288 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.00900
2016-10-02 15:09:01,361 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:09:01,426 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:09:01,427 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:09:01,427 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 302844 effective words/s
2016-10-02 15:09:01,427 : INFO : training model with 1 workers on 2830 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:09:01,427 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:09:01,428 : DEBUG : queueing job #0 (9997 words, 538 sentences) at alpha 0.00700
2016-10-02 15:09:01,429 : DEBUG : queueing job #1 (9993 words, 537 sentences) at alpha 0.00700
2016-10-02 15:09:01,430 : DEBUG : queueing job #2 (9996 words, 553 sentences) at alpha 0.00700
2016-10-02 15:09:01,430 : DEBUG : queueing job #3 (9971 words, 518 sentences) at alpha 0.00700
2016-10-02 15:09:01,463 : DEBUG : queueing job #4 (9990 words, 543 sentences) at alpha 0.00700
2016-10-02 15:09:01,494 : DEBUG : queueing job #5 (9997 words, 520 sentences) at alpha 0.00700
2016-10-02 15:09:01,527 : DEBUG : queueing job #6 (9997 words, 437 sentences) at alpha 0.00700
2016-10-02 15:09:01,562 : DEBUG : queueing job #7 (9963 words, 404 sentences) at alpha 0.00700
2016-10-02 15:09:01,594 : DEBUG : queueing job #8 (9988 words, 413 sentences) at alpha 0.00700
2016-10-02 15:09:01,627 : DEBUG : queueing job #9 (9985 words, 421 sentences) at alpha 0.00700
2016-10-02 15:09:01,661 : DEBUG : queueing job #10 (9989 words, 539 sentences) at alpha 0.00700
2016-10-02 15:09:01,694 : DEBUG : queueing job #11 (9974 words, 537 sentences) at alpha 0.00700
2016-10-02 15:09:01,728 : DEBUG : queueing job #12 (9997 words, 551 sentences) at alpha 0.00700
2016-10-02 15:09:01,762 : DEBUG : queueing job #13 (9995 words, 520 sentences) at alpha 0.00700
2016-10-02 15:09:01,795 : DEBUG : queueing job #14 (9998 words, 542 sentences) at alpha 0.00700
2016-10-02 15:09:01,828 : DEBUG : queueing job #15 (9976 words, 520 sentences) at alpha 0.00700
2016-10-02 15:09:01,860 : DEBUG : queueing job #16 (9993 words, 436 sentences) at alpha 0.00700
2016-10-02 15:09:01,892 : DEBUG : queueing job #17 (9975 words, 404 sentences) at alpha 0.00700
2016-10-02 15:09:01,925 : DEBUG : queueing job #18 (9990 words, 413 sentences) at alpha 0.00700
2016-10-02 15:09:01,958 : DEBUG : queueing job #19 (9979 words, 422 sentences) at alpha 0.00700
2016-10-02 15:09:01,991 : DEBUG : queueing job #20 (9969 words, 540 sentences) at alpha 0.00700
2016-10-02 15:09:02,024 : DEBUG : queueing job #21 (9975 words, 536 sentences) at alpha 0.00700
2016-10-02 15:09:02,057 : DEBUG : queueing job #22 (9998 words, 552 sentences) at alpha 0.00700
2016-10-02 15:09:02,091 : DEBUG : queueing job #23 (9986 words, 518 sentences) at alpha 0.00700
2016-10-02 15:09:02,124 : DEBUG : queueing job #24 (9997 words, 543 sentences) at alpha 0.00700
2016-10-02 15:09:02,155 : DEBUG : queueing job #25 (9989 words, 519 sentences) at alpha 0.00700
2016-10-02 15:09:02,187 : DEBUG : queueing job #26 (9994 words, 436 sentences) at alpha 0.00700
2016-10-02 15:09:02,224 : DEBUG : queueing job #27 (9993 words, 404 sentences) at alpha 0.00700
2016-10-02 15:09:02,257 : DEBUG : queueing job #28 (9985 words, 413 sentences) at alpha 0.00700
2016-10-02 15:09:02,291 : DEBUG : queueing job #29 (9982 words, 424 sentences) at alpha 0.00700
2016-10-02 15:09:02,324 : DEBUG : queueing job #30 (9984 words, 540 sentences) at alpha 0.00700
2016-10-02 15:09:02,357 : DEBUG : queueing job #31 (10000 words, 540 sentences) at alpha 0.00700
2016-10-02 15:09:02,394 : DEBUG : queueing job #32 (10000 words, 547 sentences) at alpha 0.00700
2016-10-02 15:09:02,428 : DEBUG : queueing job #33 (9999 words, 519 sentences) at alpha 0.00700
2016-10-02 15:09:02,460 : INFO : PROGRESS: at 62.27% examples, 306429 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:09:02,461 : DEBUG : queueing job #34 (9982 words, 545 sentences) at alpha 0.00700
2016-10-02 15:09:02,492 : DEBUG : queueing job #35 (9986 words, 517 sentences) at alpha 0.00700
2016-10-02 15:09:02,523 : DEBUG : queueing job #36 (9986 words, 435 sentences) at alpha 0.00700
2016-10-02 15:09:02,557 : DEBUG : queueing job #37 (9986 words, 405 sentences) at alpha 0.00700
2016-10-02 15:09:02,593 : DEBUG : queueing job #38 (9990 words, 412 sentences) at alpha 0.00700
2016-10-02 15:09:02,626 : DEBUG : queueing job #39 (9995 words, 428 sentences) at alpha 0.00700
2016-10-02 15:09:02,660 : DEBUG : queueing job #40 (9988 words, 540 sentences) at alpha 0.00700
2016-10-02 15:09:02,693 : DEBUG : queueing job #41 (10000 words, 542 sentences) at alpha 0.00700
2016-10-02 15:09:02,726 : DEBUG : queueing job #42 (9998 words, 544 sentences) at alpha 0.00700
2016-10-02 15:09:02,761 : DEBUG : queueing job #43 (9976 words, 518 sentences) at alpha 0.00700
2016-10-02 15:09:02,797 : DEBUG : queueing job #44 (9991 words, 548 sentences) at alpha 0.00700
2016-10-02 15:09:02,828 : DEBUG : queueing job #45 (9986 words, 513 sentences) at alpha 0.00700
2016-10-02 15:09:02,862 : DEBUG : queueing job #46 (9995 words, 435 sentences) at alpha 0.00700
2016-10-02 15:09:02,894 : DEBUG : queueing job #47 (9971 words, 403 sentences) at alpha 0.00700
2016-10-02 15:09:02,927 : DEBUG : queueing job #48 (9976 words, 413 sentences) at alpha 0.00700
2016-10-02 15:09:02,961 : DEBUG : queueing job #49 (9475 words, 403 sentences) at alpha 0.00700
2016-10-02 15:09:03,029 : DEBUG : job loop exiting, total 50 jobs
2016-10-02 15:09:03,093 : DEBUG : worker exiting, processed 50 jobs
2016-10-02 15:09:03,093 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:09:03,093 : INFO : training on 498875 raw words (508855 effective words) took 1.7s, 305837 effective words/s
2016-10-02 15:09:03,094 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-02 15:09:03,094 : INFO : not storing attribute cum_table
2016-10-02 15:09:03,094 : INFO : not storing attribute syn0norm
2016-10-02 15:25:49,514 : INFO : collecting all words and their counts
2016-10-02 15:25:49,514 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-02 15:25:49,602 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-02 15:25:49,612 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-02 15:25:49,612 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-02 15:25:49,616 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-02 15:25:49,617 : INFO : sample=0 downsamples 0 most-common words
2016-10-02 15:25:49,617 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-02 15:25:49,617 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-02 15:25:49,619 : INFO : constructing a huffman tree from 2637 words
2016-10-02 15:25:49,674 : INFO : built huffman tree with maximum node depth 14
2016-10-02 15:25:49,675 : INFO : resetting layer weights
2016-10-02 15:25:49,709 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:49,709 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:49,711 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-02 15:25:49,712 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-02 15:25:49,712 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-02 15:25:49,713 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-02 15:25:49,751 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-02 15:25:49,789 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-02 15:25:49,825 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-02 15:25:49,861 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-02 15:25:49,897 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-02 15:25:49,935 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-02 15:25:49,972 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-02 15:25:50,009 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-02 15:25:50,047 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-02 15:25:50,084 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-02 15:25:50,120 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-02 15:25:50,155 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-02 15:25:50,191 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-02 15:25:50,228 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-02 15:25:50,264 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-02 15:25:50,302 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-02 15:25:50,342 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-02 15:25:50,379 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-02 15:25:50,417 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-02 15:25:50,455 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-02 15:25:50,490 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-02 15:25:50,528 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-02 15:25:50,566 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-02 15:25:50,603 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-02 15:25:50,642 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-02 15:25:50,679 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-02 15:25:50,716 : INFO : PROGRESS: at 56.90% examples, 305921 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:50,717 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-02 15:25:50,755 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-02 15:25:50,791 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-02 15:25:50,828 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-02 15:25:50,862 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-02 15:25:50,901 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-02 15:25:50,937 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-02 15:25:50,973 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-02 15:25:51,011 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-02 15:25:51,048 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-02 15:25:51,085 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-02 15:25:51,123 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-02 15:25:51,159 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-02 15:25:51,197 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-02 15:25:51,232 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-02 15:25:51,268 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-02 15:25:51,304 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-02 15:25:51,341 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-02 15:25:51,413 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:25:51,482 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:25:51,483 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:25:51,483 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308196 effective words/s
2016-10-02 15:25:51,483 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:51,483 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:51,484 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-02 15:25:51,485 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-02 15:25:51,486 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-02 15:25:51,487 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-02 15:25:51,525 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-02 15:25:51,563 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-02 15:25:51,598 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-02 15:25:51,633 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-02 15:25:51,669 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-02 15:25:51,706 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-02 15:25:51,744 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-02 15:25:51,784 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-02 15:25:51,822 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-02 15:25:51,858 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-02 15:25:51,894 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-02 15:25:51,929 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-02 15:25:51,965 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-02 15:25:52,001 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-02 15:25:52,037 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-02 15:25:52,074 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-02 15:25:52,111 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-02 15:25:52,148 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-02 15:25:52,186 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-02 15:25:52,223 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-02 15:25:52,258 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-02 15:25:52,293 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-02 15:25:52,329 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-02 15:25:52,365 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-02 15:25:52,401 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-02 15:25:52,438 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-02 15:25:52,476 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-02 15:25:52,515 : INFO : PROGRESS: at 58.68% examples, 309597 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:52,516 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-02 15:25:52,553 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-02 15:25:52,589 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-02 15:25:52,623 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-02 15:25:52,659 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-02 15:25:52,695 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-02 15:25:52,732 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-02 15:25:52,770 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-02 15:25:52,807 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-02 15:25:52,844 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-02 15:25:52,886 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-02 15:25:52,922 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-02 15:25:52,957 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-02 15:25:52,992 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-02 15:25:53,028 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-02 15:25:53,064 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-02 15:25:53,100 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-02 15:25:53,173 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:25:53,243 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:25:53,244 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:25:53,244 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310326 effective words/s
2016-10-02 15:25:53,244 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:53,244 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:53,245 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-02 15:25:53,246 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-02 15:25:53,246 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-02 15:25:53,247 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-02 15:25:53,284 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-02 15:25:53,319 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-02 15:25:53,354 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-02 15:25:53,390 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-02 15:25:53,426 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-02 15:25:53,467 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-02 15:25:53,508 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-02 15:25:53,546 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-02 15:25:53,583 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-02 15:25:53,620 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-02 15:25:53,656 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-02 15:25:53,690 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-02 15:25:53,725 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-02 15:25:53,762 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-02 15:25:53,797 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-02 15:25:53,835 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-02 15:25:53,872 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-02 15:25:53,909 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-02 15:25:53,947 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-02 15:25:53,983 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-02 15:25:54,018 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-02 15:25:54,053 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-02 15:25:54,089 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-02 15:25:54,125 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-02 15:25:54,162 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-02 15:25:54,202 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-02 15:25:54,241 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-02 15:25:54,278 : INFO : PROGRESS: at 58.68% examples, 309000 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:54,279 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-02 15:25:54,316 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-02 15:25:54,353 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-02 15:25:54,387 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-02 15:25:54,423 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-02 15:25:54,459 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-02 15:25:54,495 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-02 15:25:54,535 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-02 15:25:54,572 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-02 15:25:54,609 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-02 15:25:54,647 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-02 15:25:54,683 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-02 15:25:54,718 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-02 15:25:54,752 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-02 15:25:54,788 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-02 15:25:54,825 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-02 15:25:54,861 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-02 15:25:54,934 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:25:55,003 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:25:55,003 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:25:55,003 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310624 effective words/s
2016-10-02 15:25:55,003 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:55,003 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:55,004 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-02 15:25:55,005 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-02 15:25:55,006 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-02 15:25:55,007 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-02 15:25:55,043 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-02 15:25:55,078 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-02 15:25:55,114 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-02 15:25:55,150 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-02 15:25:55,188 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-02 15:25:55,226 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-02 15:25:55,263 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-02 15:25:55,300 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-02 15:25:55,337 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-02 15:25:55,374 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-02 15:25:55,410 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-02 15:25:55,445 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-02 15:25:55,480 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-02 15:25:55,522 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-02 15:25:55,558 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-02 15:25:55,595 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-02 15:25:55,632 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-02 15:25:55,669 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-02 15:25:55,707 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-02 15:25:55,743 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-02 15:25:55,778 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-02 15:25:55,813 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-02 15:25:55,853 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-02 15:25:55,890 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-02 15:25:55,926 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-02 15:25:55,963 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-02 15:25:56,000 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-02 15:25:56,038 : INFO : PROGRESS: at 58.68% examples, 308859 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:56,039 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-02 15:25:56,075 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-02 15:25:56,111 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-02 15:25:56,146 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-02 15:25:56,187 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-02 15:25:56,224 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-02 15:25:56,260 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-02 15:25:56,297 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-02 15:25:56,335 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-02 15:25:56,372 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-02 15:25:56,409 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-02 15:25:56,445 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-02 15:25:56,480 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-02 15:25:56,518 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-02 15:25:56,555 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-02 15:25:56,591 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-02 15:25:56,628 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-02 15:25:56,701 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:25:56,770 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:25:56,771 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:25:56,771 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309113 effective words/s
2016-10-02 15:25:56,771 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:56,771 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:56,772 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-02 15:25:56,773 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-02 15:25:56,774 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-02 15:25:56,774 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-02 15:25:56,814 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-02 15:25:56,852 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-02 15:25:56,888 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-02 15:25:56,923 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-02 15:25:56,959 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-02 15:25:56,997 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-02 15:25:57,034 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-02 15:25:57,070 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-02 15:25:57,108 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-02 15:25:57,148 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-02 15:25:57,185 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-02 15:25:57,220 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-02 15:25:57,256 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-02 15:25:57,292 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-02 15:25:57,331 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-02 15:25:57,372 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-02 15:25:57,416 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-02 15:25:57,453 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-02 15:25:57,492 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-02 15:25:57,530 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-02 15:25:57,566 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-02 15:25:57,601 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-02 15:25:57,638 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-02 15:25:57,674 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-02 15:25:57,711 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-02 15:25:57,748 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-02 15:25:57,785 : INFO : PROGRESS: at 56.90% examples, 303537 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:57,786 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-02 15:25:57,826 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-02 15:25:57,863 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-02 15:25:57,899 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-02 15:25:57,934 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-02 15:25:57,970 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-02 15:25:58,006 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-02 15:25:58,042 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-02 15:25:58,079 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-02 15:25:58,116 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-02 15:25:58,153 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-02 15:25:58,192 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-02 15:25:58,229 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-02 15:25:58,267 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-02 15:25:58,302 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-02 15:25:58,338 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-02 15:25:58,374 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-02 15:25:58,410 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-02 15:25:58,484 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:25:58,555 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:25:58,556 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:25:58,556 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 306130 effective words/s
2016-10-02 15:25:58,556 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:25:58,556 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:25:58,557 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-02 15:25:58,558 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-02 15:25:58,559 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-02 15:25:58,559 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-02 15:25:58,598 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-02 15:25:58,635 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-02 15:25:58,670 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-02 15:25:58,706 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-02 15:25:58,743 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-02 15:25:58,781 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-02 15:25:58,822 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-02 15:25:58,859 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-02 15:25:58,897 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-02 15:25:58,934 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-02 15:25:58,970 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-02 15:25:59,004 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-02 15:25:59,039 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-02 15:25:59,076 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-02 15:25:59,116 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-02 15:25:59,154 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-02 15:25:59,191 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-02 15:25:59,228 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-02 15:25:59,267 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-02 15:25:59,303 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-02 15:25:59,343 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-02 15:25:59,379 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-02 15:25:59,415 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-02 15:25:59,453 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-02 15:25:59,493 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-02 15:25:59,535 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-02 15:25:59,572 : INFO : PROGRESS: at 56.90% examples, 302728 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:25:59,573 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-02 15:25:59,611 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-02 15:25:59,648 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-02 15:25:59,684 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-02 15:25:59,719 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-02 15:25:59,754 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-02 15:25:59,790 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-02 15:25:59,827 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-02 15:25:59,865 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-02 15:25:59,902 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-02 15:25:59,939 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-02 15:25:59,980 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-02 15:26:00,017 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-02 15:26:00,053 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-02 15:26:00,091 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-02 15:26:00,127 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-02 15:26:00,163 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-02 15:26:00,204 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-02 15:26:00,276 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:26:00,345 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:26:00,345 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:26:00,345 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 305334 effective words/s
2016-10-02 15:26:00,345 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:26:00,346 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:26:00,347 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-02 15:26:00,347 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-02 15:26:00,348 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-02 15:26:00,349 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-02 15:26:00,386 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-02 15:26:00,424 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-02 15:26:00,459 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-02 15:26:00,496 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-02 15:26:00,538 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-02 15:26:00,575 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-02 15:26:00,612 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-02 15:26:00,649 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-02 15:26:00,689 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-02 15:26:00,726 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-02 15:26:00,765 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-02 15:26:00,800 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-02 15:26:00,836 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-02 15:26:00,872 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-02 15:26:00,908 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-02 15:26:00,946 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-02 15:26:00,982 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-02 15:26:01,019 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-02 15:26:01,057 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-02 15:26:01,093 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-02 15:26:01,131 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-02 15:26:01,166 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-02 15:26:01,209 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-02 15:26:01,245 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-02 15:26:01,282 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-02 15:26:01,319 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-02 15:26:01,358 : INFO : PROGRESS: at 56.90% examples, 303775 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:26:01,359 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-02 15:26:01,397 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-02 15:26:01,434 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-02 15:26:01,470 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-02 15:26:01,507 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-02 15:26:01,544 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-02 15:26:01,581 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-02 15:26:01,617 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-02 15:26:01,658 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-02 15:26:01,694 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-02 15:26:01,731 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-02 15:26:01,769 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-02 15:26:01,805 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-02 15:26:01,841 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-02 15:26:01,875 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-02 15:26:01,911 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-02 15:26:01,948 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-02 15:26:01,984 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-02 15:26:02,063 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:26:02,132 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:26:02,132 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:26:02,132 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 305799 effective words/s
2016-10-02 15:26:02,132 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:26:02,132 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:26:02,134 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-02 15:26:02,134 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-02 15:26:02,135 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-02 15:26:02,136 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-02 15:26:02,172 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-02 15:26:02,208 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-02 15:26:02,244 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-02 15:26:02,280 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-02 15:26:02,316 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-02 15:26:02,354 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-02 15:26:02,391 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-02 15:26:02,428 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-02 15:26:02,466 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-02 15:26:02,505 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-02 15:26:02,546 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-02 15:26:02,581 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-02 15:26:02,617 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-02 15:26:02,653 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-02 15:26:02,689 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-02 15:26:02,728 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-02 15:26:02,765 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-02 15:26:02,802 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-02 15:26:02,840 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-02 15:26:02,877 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-02 15:26:02,913 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-02 15:26:02,948 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-02 15:26:02,984 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-02 15:26:03,020 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-02 15:26:03,057 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-02 15:26:03,095 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-02 15:26:03,133 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-02 15:26:03,171 : INFO : PROGRESS: at 58.68% examples, 307602 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:26:03,172 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-02 15:26:03,210 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-02 15:26:03,246 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-02 15:26:03,281 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-02 15:26:03,316 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-02 15:26:03,353 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-02 15:26:03,389 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-02 15:26:03,427 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-02 15:26:03,465 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-02 15:26:03,505 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-02 15:26:03,547 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-02 15:26:03,585 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-02 15:26:03,621 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-02 15:26:03,655 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-02 15:26:03,691 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-02 15:26:03,728 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-02 15:26:03,764 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-02 15:26:03,837 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:26:03,908 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:26:03,908 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:26:03,908 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307658 effective words/s
2016-10-02 15:26:03,909 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:26:03,909 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:26:03,910 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-02 15:26:03,911 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-02 15:26:03,911 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-02 15:26:03,912 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-02 15:26:03,948 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-02 15:26:03,983 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-02 15:26:04,018 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-02 15:26:04,054 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-02 15:26:04,089 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-02 15:26:04,126 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-02 15:26:04,163 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-02 15:26:04,201 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-02 15:26:04,238 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-02 15:26:04,274 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-02 15:26:04,310 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-02 15:26:04,344 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-02 15:26:04,380 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-02 15:26:04,416 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-02 15:26:04,452 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-02 15:26:04,489 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-02 15:26:04,529 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-02 15:26:04,569 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-02 15:26:04,607 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-02 15:26:04,643 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-02 15:26:04,681 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-02 15:26:04,716 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-02 15:26:04,751 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-02 15:26:04,787 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-02 15:26:04,824 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-02 15:26:04,861 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-02 15:26:04,898 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-02 15:26:04,935 : INFO : PROGRESS: at 58.68% examples, 311413 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:26:04,936 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-02 15:26:04,972 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-02 15:26:05,008 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-02 15:26:05,043 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-02 15:26:05,078 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-02 15:26:05,116 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-02 15:26:05,152 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-02 15:26:05,191 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-02 15:26:05,227 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-02 15:26:05,264 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-02 15:26:05,301 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-02 15:26:05,338 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-02 15:26:05,373 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-02 15:26:05,408 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-02 15:26:05,444 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-02 15:26:05,480 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-02 15:26:05,518 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-02 15:26:05,592 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:26:05,662 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:26:05,662 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:26:05,662 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311598 effective words/s
2016-10-02 15:26:05,662 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-02 15:26:05,662 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-02 15:26:05,664 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-02 15:26:05,664 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-02 15:26:05,665 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-02 15:26:05,666 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-02 15:26:05,702 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-02 15:26:05,737 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-02 15:26:05,773 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-02 15:26:05,815 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-02 15:26:05,854 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-02 15:26:05,890 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-02 15:26:05,927 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-02 15:26:05,963 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-02 15:26:06,001 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-02 15:26:06,037 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-02 15:26:06,073 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-02 15:26:06,107 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-02 15:26:06,143 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-02 15:26:06,181 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-02 15:26:06,219 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-02 15:26:06,256 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-02 15:26:06,292 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-02 15:26:06,329 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-02 15:26:06,367 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-02 15:26:06,403 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-02 15:26:06,438 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-02 15:26:06,472 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-02 15:26:06,510 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-02 15:26:06,547 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-02 15:26:06,584 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-02 15:26:06,621 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-02 15:26:06,658 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-02 15:26:06,696 : INFO : PROGRESS: at 58.68% examples, 309124 words/s, in_qsize 1, out_qsize 0
2016-10-02 15:26:06,697 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-02 15:26:06,735 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-02 15:26:06,772 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-02 15:26:06,806 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-02 15:26:06,842 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-02 15:26:06,878 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-02 15:26:06,914 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-02 15:26:06,952 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-02 15:26:06,988 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-02 15:26:07,026 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-02 15:26:07,064 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-02 15:26:07,101 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-02 15:26:07,136 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-02 15:26:07,171 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-02 15:26:07,209 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-02 15:26:07,245 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-02 15:26:07,281 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-02 15:26:07,353 : DEBUG : job loop exiting, total 48 jobs
2016-10-02 15:26:07,422 : DEBUG : worker exiting, processed 48 jobs
2016-10-02 15:26:07,423 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-02 15:26:07,423 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310388 effective words/s
2016-10-02 15:26:07,423 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-02 15:26:07,423 : INFO : not storing attribute syn0norm
2016-10-02 15:26:07,423 : INFO : not storing attribute cum_table
2016-10-02 15:31:23,067 : INFO : loading Doc2Vec object from ./tmp/RareModel
2016-10-02 15:31:23,135 : INFO : loading docvecs recursively from ./tmp/RareModel.docvecs.* with mmap=None
2016-10-02 15:31:23,136 : INFO : setting ignored attribute syn0norm to None
2016-10-02 15:31:23,136 : INFO : setting ignored attribute cum_table to None
2016-10-02 15:45:18,596 : INFO : precomputing L2-norms of doc weight vectors
2016-10-02 15:48:54,750 : INFO : precomputing L2-norms of doc weight vectors
2016-10-02 15:53:23,326 : INFO : precomputing L2-norms of word weight vectors
2016-10-02 16:24:47,441 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:24:47,679 : INFO : built Dictionary(11949 unique tokens: ['consistent', 'anymore', 'women', 'dolls', 'shoud']...) from 4880 documents (total 186045 corpus positions)
2016-10-02 16:30:26,929 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:30:27,174 : INFO : built Dictionary(11949 unique tokens: ['bearings', 'khattab', 'lead', 'presume', 'fiat']...) from 4880 documents (total 186045 corpus positions)
2016-10-02 16:30:27,179 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:30:27,182 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:30:27,184 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-02 16:30:27,187 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:27,187 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:27,187 : INFO : PROGRESS: saving document #0
2016-10-02 16:30:27,244 : INFO : PROGRESS: saving document #1000
2016-10-02 16:30:27,301 : INFO : PROGRESS: saving document #2000
2016-10-02 16:30:27,353 : INFO : PROGRESS: saving document #3000
2016-10-02 16:30:27,420 : INFO : PROGRESS: saving document #4000
2016-10-02 16:30:27,478 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-02 16:30:27,478 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:27,481 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:27,482 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:30:27,484 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:30:27,484 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:27,485 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-02 16:30:27,485 : INFO : collecting document frequencies
2016-10-02 16:30:27,485 : INFO : PROGRESS: processing document #0
2016-10-02 16:30:27,658 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-02 16:30:50,957 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:30:51,202 : INFO : built Dictionary(11949 unique tokens: ['bearings', 'khattab', 'lead', 'presume', 'fiat']...) from 4880 documents (total 186045 corpus positions)
2016-10-02 16:30:51,207 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:30:51,210 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:30:51,212 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-02 16:30:51,215 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:51,215 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:51,215 : INFO : PROGRESS: saving document #0
2016-10-02 16:30:51,273 : INFO : PROGRESS: saving document #1000
2016-10-02 16:30:51,327 : INFO : PROGRESS: saving document #2000
2016-10-02 16:30:51,380 : INFO : PROGRESS: saving document #3000
2016-10-02 16:30:51,451 : INFO : PROGRESS: saving document #4000
2016-10-02 16:30:51,509 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-02 16:30:51,509 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:51,512 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:51,512 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:30:51,515 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:30:51,515 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:30:51,515 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-02 16:30:51,515 : INFO : collecting document frequencies
2016-10-02 16:30:51,515 : INFO : PROGRESS: processing document #0
2016-10-02 16:30:51,680 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-02 16:30:51,683 : INFO : using serial LSI version on this node
2016-10-02 16:30:51,683 : INFO : updating model with new documents
2016-10-02 16:30:51,955 : INFO : preparing a new chunk of documents
2016-10-02 16:30:51,956 : DEBUG : converting corpus to csc format
2016-10-02 16:30:51,989 : INFO : using 100 extra samples and 2 power iterations
2016-10-02 16:30:51,989 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-02 16:30:52,079 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-02 16:30:52,094 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:30:52,148 : DEBUG : running 2 power iterations
2016-10-02 16:30:52,212 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:30:52,310 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:30:52,376 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-02 16:30:52,463 : INFO : computing the final decomposition
2016-10-02 16:30:52,463 : INFO : keeping 200 factors (discarding 18.890% of energy spectrum)
2016-10-02 16:30:52,477 : INFO : processed documents up to #4880
2016-10-02 16:30:52,479 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-02 16:30:52,479 : INFO : topic #1(5.571): -0.613*"visa" + -0.342*"visit" + -0.210*"family" + 0.166*"buy" + 0.164*"doha" + 0.146*"good" + 0.138*"anyone" + 0.132*"know" + -0.130*"wife" + 0.117*"find"
2016-10-02 16:30:52,479 : INFO : topic #2(4.311): -0.275*"doha" + 0.258*"driving" + 0.253*"car" + -0.247*"visa" + 0.227*"company" + 0.204*"qatar" + -0.203*"visit" + 0.198*"license" + -0.194*"buy" + -0.194*"anyone"
2016-10-02 16:30:52,479 : INFO : topic #3(4.144): -0.552*"car" + -0.440*"buy" + 0.200*"school" + -0.163*"one" + 0.156*"would" + -0.133*"driving" + 0.127*"like" + -0.118*"license" + 0.109*"job" + -0.100*"need"
2016-10-02 16:30:52,480 : INFO : topic #4(4.124): -0.583*"driving" + -0.404*"school" + -0.394*"license" + 0.209*"company" + -0.118*"international" + -0.117*"test" + 0.102*"buy" + 0.095*"bank" + 0.089*"job" + -0.088*"visit"
2016-10-02 16:30:52,485 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-02 16:30:53,029 : INFO : creating matrix with 4880 documents and 200 features
2016-10-02 16:30:53,052 : DEBUG : PROGRESS: at document #0/4880
2016-10-02 16:30:53,185 : DEBUG : PROGRESS: at document #1000/4880
2016-10-02 16:30:53,343 : DEBUG : PROGRESS: at document #2000/4880
2016-10-02 16:30:53,498 : DEBUG : PROGRESS: at document #3000/4880
2016-10-02 16:30:53,664 : DEBUG : PROGRESS: at document #4000/4880
2016-10-02 16:33:10,934 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:33:10,974 : INFO : built Dictionary(4869 unique tokens: ['doyoubelievethatgloballyweareoverpopulatedbasicallywhatimaskingisifyoubelievethatthemodernworldneedstostartintroducingpopulationcontrolmeasuresthinkchinaorjustcarryonthewaywehaveforcenturyshopetechnologycankeepmakingbreakthroughswecanstartburningthroughresourcesweneverknewcouldbeharnessedimsureyoucanguessmyopiniononthesubject', 'hiqlerpleaseiwouldliketoknowsomemajorbasicswhichdivideshiaandsunnimuslimsmostimportantiwouldliketoknowwhichoneofthemistherealislamthanksforyourpeacefulcomments', 'itookmyfirstdrivingtestthismorningandmanagedtopassthesignallandparkingtestshoweverigotscrewedintheroadtestdontaskimplanningtoretakethetestsometimethismonthbydoingsodoyougooverthetestfromthestartordoyoustartwhereyouleftofffailedlikemeforexampleifailedtheroadtestsodoesthatmeanionlydotheroadtestthanks', 'hiallmyfirstposthavebeenreadingforawhilemyhusbandandiarecomingtoqatarashehasbeenofferedajobandwearebriningourdogwithusheisalargebreedandspecialrestirctionsareneededforustobringhiminiwantedtocheckwithotherswhohavecomefromtheukhowyourpethasadaptedtolifeinqatararethereareastheycanrunfreearevillasokforthemthanksinadvance', 'doprisonbuseshaveemergencyexits']...) from 4880 documents (total 4875 corpus positions)
2016-10-02 16:33:10,976 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:33:10,976 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:33:10,976 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-02 16:33:10,976 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:10,976 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:10,977 : INFO : PROGRESS: saving document #0
2016-10-02 16:33:10,984 : INFO : PROGRESS: saving document #1000
2016-10-02 16:33:10,991 : INFO : PROGRESS: saving document #2000
2016-10-02 16:33:10,998 : INFO : PROGRESS: saving document #3000
2016-10-02 16:33:11,005 : INFO : PROGRESS: saving document #4000
2016-10-02 16:33:11,012 : INFO : saved 4880x6 matrix, density=0.041% (12/29280)
2016-10-02 16:33:11,012 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:11,012 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:11,012 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:33:11,014 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:33:11,014 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:11,014 : INFO : accepted corpus with 4880 documents, 6 features, 12 non-zero entries
2016-10-02 16:33:11,014 : INFO : collecting document frequencies
2016-10-02 16:33:11,014 : INFO : PROGRESS: processing document #0
2016-10-02 16:33:11,039 : INFO : calculating IDF weights for 4880 documents and 5 features (12 matrix non-zeros)
2016-10-02 16:33:11,039 : INFO : using serial LSI version on this node
2016-10-02 16:33:11,039 : INFO : updating model with new documents
2016-10-02 16:33:11,087 : INFO : preparing a new chunk of documents
2016-10-02 16:33:11,087 : DEBUG : converting corpus to csc format
2016-10-02 16:33:11,098 : INFO : using 100 extra samples and 2 power iterations
2016-10-02 16:33:11,098 : INFO : 1st phase: constructing (6, 300) action matrix
2016-10-02 16:33:11,163 : INFO : orthonormalizing (6, 300) action matrix
2016-10-02 16:33:11,164 : DEBUG : computing QR of (6, 300) dense matrix
2016-10-02 16:33:11,168 : DEBUG : running 2 power iterations
2016-10-02 16:33:11,169 : DEBUG : computing QR of (6, 6) dense matrix
2016-10-02 16:33:11,169 : DEBUG : computing QR of (6, 6) dense matrix
2016-10-02 16:33:11,169 : INFO : 2nd phase: running dense svd on (6, 4880) matrix
2016-10-02 16:33:11,173 : INFO : computing the final decomposition
2016-10-02 16:33:11,173 : INFO : keeping 6 factors (discarding 0.000% of energy spectrum)
2016-10-02 16:33:11,173 : INFO : processed documents up to #4880
2016-10-02 16:33:11,173 : INFO : topic #0(1.414): -0.718*"toallmyfellowfilipinospleaseadviceijustaskedmywifeshesaiditwilltaketimeforustogetansoauthenticatedmarriagecertificateweonlyhavetheoriginalmarriagecertificatefromourlocalcivilregistrarcanweusedthistogetavisitvisaforherwhatareouroptions" + 0.580*"lol" + 0.277*"hiimnewtotheqlandthiswillbemy1sttopicinforumshopeyouguyscanhelpmeouthereifanyoneknowapersonwhoteachesphotographyforfreeinhereqatarpleasementionheretheircontactdetailspleaseiwouldliketolearnphotographyandilivenearkahramaaheadofficethanks" + 0.232*"iwanttoquitsmokingwherecanigetnicotinepatchindohaisthereanyprescriptionrequirefromdoctorifsomebodyisalsointherapythenpleaseshareyourexperienceisthereanyotheralternativeavailable" + 0.130*"higuysurgentpleasewherecanifoundhtcdroiddnaphoneinqatarthanksinadvance" + -0.022*"ihavefewcomplicationswithmyhealthconditionsandhavelost3babiespreviouslyivemovedtodohaafewmonthsbackandwewantedtobepreparedforafuturepregnancyihaveheardthatalahliisthebesthospitalherecomparedtohmcbutiwantedtoknowwhichgynecologistisbestforhighriskpregnanciesthanksinadvance"
2016-10-02 16:33:11,174 : INFO : topic #1(1.414): 0.759*"hiimnewtotheqlandthiswillbemy1sttopicinforumshopeyouguyscanhelpmeouthereifanyoneknowapersonwhoteachesphotographyforfreeinhereqatarpleasementionheretheircontactdetailspleaseiwouldliketolearnphotographyandilivenearkahramaaheadofficethanks" + -0.430*"iwanttoquitsmokingwherecanigetnicotinepatchindohaisthereanyprescriptionrequirefromdoctorifsomebodyisalsointherapythenpleaseshareyourexperienceisthereanyotheralternativeavailable" + 0.373*"ihavefewcomplicationswithmyhealthconditionsandhavelost3babiespreviouslyivemovedtodohaafewmonthsbackandwewantedtobepreparedforafuturepregnancyihaveheardthatalahliisthebesthospitalherecomparedtohmcbutiwantedtoknowwhichgynecologistisbestforhighriskpregnanciesthanksinadvance" + -0.288*"lol" + -0.104*"toallmyfellowfilipinospleaseadviceijustaskedmywifeshesaiditwilltaketimeforustogetansoauthenticatedmarriagecertificateweonlyhavetheoriginalmarriagecertificatefromourlocalcivilregistrarcanweusedthistogetavisitvisaforherwhatareouroptions" + -0.074*"higuysurgentpleasewherecanifoundhtcdroiddnaphoneinqatarthanksinadvance"
2016-10-02 16:33:11,174 : INFO : topic #2(1.414): 0.725*"ihavefewcomplicationswithmyhealthconditionsandhavelost3babiespreviouslyivemovedtodohaafewmonthsbackandwewantedtobepreparedforafuturepregnancyihaveheardthatalahliisthebesthospitalherecomparedtohmcbutiwantedtoknowwhichgynecologistisbestforhighriskpregnanciesthanksinadvance" + -0.539*"hiimnewtotheqlandthiswillbemy1sttopicinforumshopeyouguyscanhelpmeouthereifanyoneknowapersonwhoteachesphotographyforfreeinhereqatarpleasementionheretheircontactdetailspleaseiwouldliketolearnphotographyandilivenearkahramaaheadofficethanks" + -0.360*"toallmyfellowfilipinospleaseadviceijustaskedmywifeshesaiditwilltaketimeforustogetansoauthenticatedmarriagecertificateweonlyhavetheoriginalmarriagecertificatefromourlocalcivilregistrarcanweusedthistogetavisitvisaforherwhatareouroptions" + -0.169*"iwanttoquitsmokingwherecanigetnicotinepatchindohaisthereanyprescriptionrequirefromdoctorifsomebodyisalsointherapythenpleaseshareyourexperienceisthereanyotheralternativeavailable" + -0.150*"higuysurgentpleasewherecanifoundhtcdroiddnaphoneinqatarthanksinadvance" + -0.059*"lol"
2016-10-02 16:33:11,174 : INFO : topic #3(1.414): 0.734*"iwanttoquitsmokingwherecanigetnicotinepatchindohaisthereanyprescriptionrequirefromdoctorifsomebodyisalsointherapythenpleaseshareyourexperienceisthereanyotheralternativeavailable" + 0.508*"ihavefewcomplicationswithmyhealthconditionsandhavelost3babiespreviouslyivemovedtodohaafewmonthsbackandwewantedtobepreparedforafuturepregnancyihaveheardthatalahliisthebesthospitalherecomparedtohmcbutiwantedtoknowwhichgynecologistisbestforhighriskpregnanciesthanksinadvance" + 0.279*"toallmyfellowfilipinospleaseadviceijustaskedmywifeshesaiditwilltaketimeforustogetansoauthenticatedmarriagecertificateweonlyhavetheoriginalmarriagecertificatefromourlocalcivilregistrarcanweusedthistogetavisitvisaforherwhatareouroptions" + 0.278*"higuysurgentpleasewherecanifoundhtcdroiddnaphoneinqatarthanksinadvance" + 0.199*"hiimnewtotheqlandthiswillbemy1sttopicinforumshopeyouguyscanhelpmeouthereifanyoneknowapersonwhoteachesphotographyforfreeinhereqatarpleasementionheretheircontactdetailspleaseiwouldliketolearnphotographyandilivenearkahramaaheadofficethanks" + -0.087*"lol"
2016-10-02 16:33:11,174 : INFO : topic #4(1.414): -0.733*"lol" + -0.503*"toallmyfellowfilipinospleaseadviceijustaskedmywifeshesaiditwilltaketimeforustogetansoauthenticatedmarriagecertificateweonlyhavetheoriginalmarriagecertificatefromourlocalcivilregistrarcanweusedthistogetavisitvisaforherwhatareouroptions" + 0.347*"iwanttoquitsmokingwherecanigetnicotinepatchindohaisthereanyprescriptionrequirefromdoctorifsomebodyisalsointherapythenpleaseshareyourexperienceisthereanyotheralternativeavailable" + -0.274*"ihavefewcomplicationswithmyhealthconditionsandhavelost3babiespreviouslyivemovedtodohaafewmonthsbackandwewantedtobepreparedforafuturepregnancyihaveheardthatalahliisthebesthospitalherecomparedtohmcbutiwantedtoknowwhichgynecologistisbestforhighriskpregnanciesthanksinadvance" + -0.118*"higuysurgentpleasewherecanifoundhtcdroiddnaphoneinqatarthanksinadvance" + -0.027*"hiimnewtotheqlandthiswillbemy1sttopicinforumshopeyouguyscanhelpmeouthereifanyoneknowapersonwhoteachesphotographyforfreeinhereqatarpleasementionheretheircontactdetailspleaseiwouldliketolearnphotographyandilivenearkahramaaheadofficethanks"
2016-10-02 16:33:11,174 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-02 16:33:11,229 : INFO : creating matrix with 4880 documents and 6 features
2016-10-02 16:33:11,230 : DEBUG : PROGRESS: at document #0/4880
2016-10-02 16:33:11,253 : DEBUG : PROGRESS: at document #1000/4880
2016-10-02 16:33:11,276 : DEBUG : PROGRESS: at document #2000/4880
2016-10-02 16:33:11,299 : DEBUG : PROGRESS: at document #3000/4880
2016-10-02 16:33:11,322 : DEBUG : PROGRESS: at document #4000/4880
2016-10-02 16:33:30,075 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:33:30,307 : INFO : built Dictionary(13577 unique tokens: ['browse', 'waited', 'transliteration', 'nicer', 'headset']...) from 4880 documents (total 181075 corpus positions)
2016-10-02 16:33:30,312 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:33:30,315 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:33:30,317 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-02 16:33:30,318 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:30,318 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:30,318 : INFO : PROGRESS: saving document #0
2016-10-02 16:33:30,374 : INFO : PROGRESS: saving document #1000
2016-10-02 16:33:30,426 : INFO : PROGRESS: saving document #2000
2016-10-02 16:33:30,477 : INFO : PROGRESS: saving document #3000
2016-10-02 16:33:30,542 : INFO : PROGRESS: saving document #4000
2016-10-02 16:33:30,598 : INFO : saved 4880x5311 matrix, density=0.303% (78403/25917680)
2016-10-02 16:33:30,598 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:30,598 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:30,598 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:33:30,601 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:33:30,601 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:33:30,601 : INFO : accepted corpus with 4880 documents, 5311 features, 78403 non-zero entries
2016-10-02 16:33:30,601 : INFO : collecting document frequencies
2016-10-02 16:33:30,602 : INFO : PROGRESS: processing document #0
2016-10-02 16:33:30,758 : INFO : calculating IDF weights for 4880 documents and 5310 features (78403 matrix non-zeros)
2016-10-02 16:33:30,761 : INFO : using serial LSI version on this node
2016-10-02 16:33:30,761 : INFO : updating model with new documents
2016-10-02 16:33:31,024 : INFO : preparing a new chunk of documents
2016-10-02 16:33:31,025 : DEBUG : converting corpus to csc format
2016-10-02 16:33:31,056 : INFO : using 100 extra samples and 2 power iterations
2016-10-02 16:33:31,057 : INFO : 1st phase: constructing (5311, 300) action matrix
2016-10-02 16:33:31,151 : INFO : orthonormalizing (5311, 300) action matrix
2016-10-02 16:33:31,166 : DEBUG : computing QR of (5311, 300) dense matrix
2016-10-02 16:33:31,215 : DEBUG : running 2 power iterations
2016-10-02 16:33:31,278 : DEBUG : computing QR of (5311, 300) dense matrix
2016-10-02 16:33:31,370 : DEBUG : computing QR of (5311, 300) dense matrix
2016-10-02 16:33:31,437 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-02 16:33:31,521 : INFO : computing the final decomposition
2016-10-02 16:33:31,521 : INFO : keeping 200 factors (discarding 18.865% of energy spectrum)
2016-10-02 16:33:31,534 : INFO : processed documents up to #4880
2016-10-02 16:33:31,535 : INFO : topic #0(8.354): 0.243*"visa" + 0.207*"qatar" + 0.182*"know" + 0.177*"doha" + 0.165*"thanks" + 0.161*"anyone" + 0.160*"please" + 0.150*"hi" + 0.147*"get" + 0.140*"one"
2016-10-02 16:33:31,536 : INFO : topic #1(5.509): 0.614*"visa" + 0.360*"visit" + 0.218*"family" + -0.164*"buy" + -0.151*"doha" + -0.143*"good" + -0.132*"anyone" + -0.128*"know" + 0.123*"wife" + -0.118*"find"
2016-10-02 16:33:31,536 : INFO : topic #2(4.300): -0.277*"driving" + 0.265*"doha" + -0.239*"car" + 0.237*"visa" + 0.235*"anybody" + -0.225*"qatar" + -0.209*"license" + 0.205*"buy" + 0.205*"visit" + -0.196*"company"
2016-10-02 16:33:31,536 : INFO : topic #3(4.191): 0.536*"car" + 0.478*"buy" + -0.157*"school" + -0.157*"would" + 0.154*"one" + 0.153*"driving" + 0.132*"anybody" + 0.128*"license" + -0.125*"like" + -0.108*"job"
2016-10-02 16:33:31,536 : INFO : topic #4(4.075): 0.566*"driving" + 0.399*"school" + 0.382*"license" + -0.209*"company" + -0.127*"buy" + 0.119*"anyone" + 0.117*"international" + 0.112*"test" + -0.098*"job" + 0.095*"know"
2016-10-02 16:33:31,542 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-02 16:33:32,127 : INFO : creating matrix with 4880 documents and 200 features
2016-10-02 16:33:32,150 : DEBUG : PROGRESS: at document #0/4880
2016-10-02 16:33:32,292 : DEBUG : PROGRESS: at document #1000/4880
2016-10-02 16:33:32,468 : DEBUG : PROGRESS: at document #2000/4880
2016-10-02 16:33:32,631 : DEBUG : PROGRESS: at document #3000/4880
2016-10-02 16:33:32,800 : DEBUG : PROGRESS: at document #4000/4880
2016-10-02 16:34:34,115 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-02 16:34:34,364 : INFO : built Dictionary(11949 unique tokens: ['reccomendations', 'responding', 'loose', 'speeding', 'g683r']...) from 4880 documents (total 186045 corpus positions)
2016-10-02 16:34:34,369 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:34:34,372 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-02 16:34:34,374 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-02 16:34:34,377 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:34:34,377 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:34:34,377 : INFO : PROGRESS: saving document #0
2016-10-02 16:34:34,432 : INFO : PROGRESS: saving document #1000
2016-10-02 16:34:34,483 : INFO : PROGRESS: saving document #2000
2016-10-02 16:34:34,535 : INFO : PROGRESS: saving document #3000
2016-10-02 16:34:34,598 : INFO : PROGRESS: saving document #4000
2016-10-02 16:34:34,655 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-02 16:34:34,655 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:34:34,658 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:34:34,658 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:34:34,661 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-02 16:34:34,661 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-02 16:34:34,661 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-02 16:34:34,661 : INFO : collecting document frequencies
2016-10-02 16:34:34,661 : INFO : PROGRESS: processing document #0
2016-10-02 16:34:34,823 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-02 16:34:34,826 : INFO : using serial LSI version on this node
2016-10-02 16:34:34,827 : INFO : updating model with new documents
2016-10-02 16:34:35,107 : INFO : preparing a new chunk of documents
2016-10-02 16:34:35,108 : DEBUG : converting corpus to csc format
2016-10-02 16:34:35,145 : INFO : using 100 extra samples and 2 power iterations
2016-10-02 16:34:35,145 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-02 16:34:35,232 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-02 16:34:35,246 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:34:35,295 : DEBUG : running 2 power iterations
2016-10-02 16:34:35,361 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:34:35,466 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-02 16:34:35,532 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-02 16:34:35,615 : INFO : computing the final decomposition
2016-10-02 16:34:35,615 : INFO : keeping 200 factors (discarding 18.926% of energy spectrum)
2016-10-02 16:34:35,628 : INFO : processed documents up to #4880
2016-10-02 16:34:35,630 : INFO : topic #0(8.383): -0.259*"visa" + -0.206*"qatar" + -0.177*"know" + -0.177*"doha" + -0.166*"thanks" + -0.159*"please" + -0.159*"anyone" + -0.148*"hi" + -0.145*"get" + -0.140*"one"
2016-10-02 16:34:35,630 : INFO : topic #1(5.571): 0.613*"visa" + 0.342*"visit" + 0.210*"family" + -0.166*"buy" + -0.164*"doha" + -0.146*"good" + -0.138*"anyone" + -0.132*"know" + 0.130*"wife" + -0.117*"find"
2016-10-02 16:34:35,630 : INFO : topic #2(4.311): -0.275*"doha" + 0.257*"driving" + 0.253*"car" + -0.247*"visa" + 0.228*"company" + 0.204*"qatar" + -0.203*"visit" + 0.199*"license" + -0.194*"buy" + -0.193*"anyone"
2016-10-02 16:34:35,631 : INFO : topic #3(4.144): 0.552*"car" + 0.441*"buy" + -0.205*"school" + 0.164*"one" + -0.155*"would" + 0.127*"driving" + -0.126*"like" + 0.114*"license" + -0.108*"job" + 0.100*"need"
2016-10-02 16:34:35,631 : INFO : topic #4(4.124): -0.584*"driving" + -0.403*"school" + -0.395*"license" + 0.210*"company" + -0.119*"test" + -0.116*"international" + 0.097*"buy" + 0.094*"bank" + 0.091*"job" + -0.090*"visit"
2016-10-02 16:34:35,636 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-02 16:34:36,213 : INFO : creating matrix with 4880 documents and 200 features
2016-10-02 16:34:36,238 : DEBUG : PROGRESS: at document #0/4880
2016-10-02 16:34:36,371 : DEBUG : PROGRESS: at document #1000/4880
2016-10-02 16:34:36,535 : DEBUG : PROGRESS: at document #2000/4880
2016-10-02 16:34:36,690 : DEBUG : PROGRESS: at document #3000/4880
2016-10-02 16:34:36,854 : DEBUG : PROGRESS: at document #4000/4880
2016-10-06 12:32:13,234 : INFO : collecting all words and their counts
2016-10-06 12:32:13,235 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-06 12:32:13,327 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-06 12:32:13,336 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-06 12:32:13,336 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-06 12:32:13,341 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-06 12:32:13,342 : INFO : sample=0 downsamples 0 most-common words
2016-10-06 12:32:13,342 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-06 12:32:13,342 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-06 12:32:13,344 : INFO : constructing a huffman tree from 2637 words
2016-10-06 12:32:13,401 : INFO : built huffman tree with maximum node depth 14
2016-10-06 12:32:13,402 : INFO : resetting layer weights
2016-10-06 12:32:13,440 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:13,440 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:13,441 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-06 12:32:13,442 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-06 12:32:13,442 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-06 12:32:13,445 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-06 12:32:13,484 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-06 12:32:13,518 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-06 12:32:13,554 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-06 12:32:13,590 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-06 12:32:13,626 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-06 12:32:13,663 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-06 12:32:13,700 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-06 12:32:13,738 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-06 12:32:13,776 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-06 12:32:13,813 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-06 12:32:13,849 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-06 12:32:13,887 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-06 12:32:13,923 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-06 12:32:13,962 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-06 12:32:13,999 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-06 12:32:14,037 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-06 12:32:14,074 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-06 12:32:14,113 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-06 12:32:14,152 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-06 12:32:14,189 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-06 12:32:14,224 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-06 12:32:14,259 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-06 12:32:14,296 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-06 12:32:14,332 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-06 12:32:14,369 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-06 12:32:14,407 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-06 12:32:14,444 : INFO : PROGRESS: at 56.90% examples, 306454 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:14,445 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-06 12:32:14,483 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-06 12:32:14,520 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-06 12:32:14,556 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-06 12:32:14,591 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-06 12:32:14,627 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-06 12:32:14,664 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-06 12:32:14,700 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-06 12:32:14,738 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-06 12:32:14,775 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-06 12:32:14,813 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-06 12:32:14,851 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-06 12:32:14,893 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-06 12:32:14,929 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-06 12:32:14,964 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-06 12:32:15,000 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-06 12:32:15,037 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-06 12:32:15,077 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-06 12:32:15,150 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:15,220 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:15,220 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:15,220 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 306948 effective words/s
2016-10-06 12:32:15,220 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:15,220 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:15,221 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-06 12:32:15,222 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-06 12:32:15,223 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-06 12:32:15,224 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-06 12:32:15,260 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-06 12:32:15,295 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-06 12:32:15,331 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-06 12:32:15,367 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-06 12:32:15,403 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-06 12:32:15,441 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-06 12:32:15,478 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-06 12:32:15,516 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-06 12:32:15,554 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-06 12:32:15,591 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-06 12:32:15,627 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-06 12:32:15,662 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-06 12:32:15,702 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-06 12:32:15,738 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-06 12:32:15,775 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-06 12:32:15,814 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-06 12:32:15,851 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-06 12:32:15,889 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-06 12:32:15,927 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-06 12:32:15,964 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-06 12:32:15,999 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-06 12:32:16,034 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-06 12:32:16,070 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-06 12:32:16,107 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-06 12:32:16,144 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-06 12:32:16,182 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-06 12:32:16,222 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-06 12:32:16,260 : INFO : PROGRESS: at 58.68% examples, 307333 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:16,261 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-06 12:32:16,298 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-06 12:32:16,334 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-06 12:32:16,369 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-06 12:32:16,405 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-06 12:32:16,441 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-06 12:32:16,478 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-06 12:32:16,516 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-06 12:32:16,553 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-06 12:32:16,591 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-06 12:32:16,629 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-06 12:32:16,666 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-06 12:32:16,702 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-06 12:32:16,737 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-06 12:32:16,773 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-06 12:32:16,811 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-06 12:32:16,848 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-06 12:32:16,923 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:16,993 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:16,993 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:16,993 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308210 effective words/s
2016-10-06 12:32:16,993 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:16,993 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:16,994 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-06 12:32:16,995 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-06 12:32:16,996 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-06 12:32:16,997 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-06 12:32:17,033 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-06 12:32:17,069 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-06 12:32:17,104 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-06 12:32:17,140 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-06 12:32:17,180 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-06 12:32:17,217 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-06 12:32:17,255 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-06 12:32:17,292 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-06 12:32:17,330 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-06 12:32:17,368 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-06 12:32:17,404 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-06 12:32:17,439 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-06 12:32:17,474 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-06 12:32:17,511 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-06 12:32:17,547 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-06 12:32:17,585 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-06 12:32:17,622 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-06 12:32:17,659 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-06 12:32:17,697 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-06 12:32:17,734 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-06 12:32:17,770 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-06 12:32:17,806 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-06 12:32:17,842 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-06 12:32:17,879 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-06 12:32:17,919 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-06 12:32:17,959 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-06 12:32:17,997 : INFO : PROGRESS: at 56.90% examples, 306542 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:17,998 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-06 12:32:18,035 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-06 12:32:18,072 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-06 12:32:18,109 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-06 12:32:18,144 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-06 12:32:18,179 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-06 12:32:18,216 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-06 12:32:18,252 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-06 12:32:18,290 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-06 12:32:18,327 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-06 12:32:18,364 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-06 12:32:18,403 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-06 12:32:18,439 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-06 12:32:18,474 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-06 12:32:18,513 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-06 12:32:18,549 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-06 12:32:18,586 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-06 12:32:18,623 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-06 12:32:18,696 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:18,766 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:18,766 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:18,766 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308151 effective words/s
2016-10-06 12:32:18,766 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:18,766 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:18,767 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-06 12:32:18,768 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-06 12:32:18,769 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-06 12:32:18,770 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-06 12:32:18,808 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-06 12:32:18,843 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-06 12:32:18,878 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-06 12:32:18,914 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-06 12:32:18,951 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-06 12:32:18,988 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-06 12:32:19,025 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-06 12:32:19,062 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-06 12:32:19,100 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-06 12:32:19,137 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-06 12:32:19,173 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-06 12:32:19,207 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-06 12:32:19,243 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-06 12:32:19,279 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-06 12:32:19,315 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-06 12:32:19,353 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-06 12:32:19,390 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-06 12:32:19,427 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-06 12:32:19,465 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-06 12:32:19,501 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-06 12:32:19,537 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-06 12:32:19,572 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-06 12:32:19,608 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-06 12:32:19,644 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-06 12:32:19,682 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-06 12:32:19,719 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-06 12:32:19,755 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-06 12:32:19,794 : INFO : PROGRESS: at 58.68% examples, 310961 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:19,795 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-06 12:32:19,832 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-06 12:32:19,870 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-06 12:32:19,905 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-06 12:32:19,941 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-06 12:32:19,978 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-06 12:32:20,014 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-06 12:32:20,052 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-06 12:32:20,089 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-06 12:32:20,126 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-06 12:32:20,164 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-06 12:32:20,201 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-06 12:32:20,236 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-06 12:32:20,271 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-06 12:32:20,307 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-06 12:32:20,343 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-06 12:32:20,380 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-06 12:32:20,453 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:20,523 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:20,523 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:20,523 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311045 effective words/s
2016-10-06 12:32:20,523 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:20,523 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:20,524 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-06 12:32:20,525 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-06 12:32:20,526 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-06 12:32:20,527 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-06 12:32:20,563 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-06 12:32:20,599 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-06 12:32:20,634 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-06 12:32:20,670 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-06 12:32:20,707 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-06 12:32:20,744 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-06 12:32:20,785 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-06 12:32:20,823 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-06 12:32:20,861 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-06 12:32:20,898 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-06 12:32:20,937 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-06 12:32:20,973 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-06 12:32:21,009 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-06 12:32:21,045 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-06 12:32:21,082 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-06 12:32:21,120 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-06 12:32:21,158 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-06 12:32:21,195 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-06 12:32:21,234 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-06 12:32:21,270 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-06 12:32:21,305 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-06 12:32:21,340 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-06 12:32:21,376 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-06 12:32:21,413 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-06 12:32:21,450 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-06 12:32:21,489 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-06 12:32:21,526 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-06 12:32:21,564 : INFO : PROGRESS: at 58.68% examples, 307049 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:21,565 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-06 12:32:21,602 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-06 12:32:21,639 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-06 12:32:21,674 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-06 12:32:21,710 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-06 12:32:21,746 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-06 12:32:21,784 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-06 12:32:21,822 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-06 12:32:21,860 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-06 12:32:21,897 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-06 12:32:21,935 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-06 12:32:21,972 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-06 12:32:22,008 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-06 12:32:22,044 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-06 12:32:22,082 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-06 12:32:22,118 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-06 12:32:22,155 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-06 12:32:22,228 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:22,298 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:22,299 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:22,299 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307752 effective words/s
2016-10-06 12:32:22,299 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:22,299 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:22,300 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-06 12:32:22,301 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-06 12:32:22,301 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-06 12:32:22,302 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-06 12:32:22,339 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-06 12:32:22,374 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-06 12:32:22,410 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-06 12:32:22,446 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-06 12:32:22,485 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-06 12:32:22,522 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-06 12:32:22,559 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-06 12:32:22,597 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-06 12:32:22,634 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-06 12:32:22,671 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-06 12:32:22,707 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-06 12:32:22,742 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-06 12:32:22,777 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-06 12:32:22,814 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-06 12:32:22,851 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-06 12:32:22,889 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-06 12:32:22,926 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-06 12:32:22,963 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-06 12:32:23,002 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-06 12:32:23,038 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-06 12:32:23,076 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-06 12:32:23,112 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-06 12:32:23,147 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-06 12:32:23,184 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-06 12:32:23,221 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-06 12:32:23,259 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-06 12:32:23,296 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-06 12:32:23,334 : INFO : PROGRESS: at 58.68% examples, 308780 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:23,335 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-06 12:32:23,372 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-06 12:32:23,410 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-06 12:32:23,445 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-06 12:32:23,484 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-06 12:32:23,520 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-06 12:32:23,556 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-06 12:32:23,595 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-06 12:32:23,632 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-06 12:32:23,669 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-06 12:32:23,707 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-06 12:32:23,744 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-06 12:32:23,779 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-06 12:32:23,814 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-06 12:32:23,850 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-06 12:32:23,887 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-06 12:32:23,923 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-06 12:32:23,997 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:24,066 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:24,066 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:24,067 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309085 effective words/s
2016-10-06 12:32:24,067 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:24,067 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:24,068 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-06 12:32:24,069 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-06 12:32:24,069 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-06 12:32:24,070 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-06 12:32:24,107 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-06 12:32:24,142 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-06 12:32:24,180 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-06 12:32:24,216 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-06 12:32:24,252 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-06 12:32:24,290 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-06 12:32:24,327 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-06 12:32:24,366 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-06 12:32:24,407 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-06 12:32:24,444 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-06 12:32:24,480 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-06 12:32:24,515 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-06 12:32:24,550 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-06 12:32:24,587 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-06 12:32:24,623 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-06 12:32:24,660 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-06 12:32:24,697 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-06 12:32:24,734 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-06 12:32:24,772 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-06 12:32:24,809 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-06 12:32:24,844 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-06 12:32:24,879 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-06 12:32:24,915 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-06 12:32:24,953 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-06 12:32:24,990 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-06 12:32:25,030 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-06 12:32:25,068 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-06 12:32:25,105 : INFO : PROGRESS: at 58.68% examples, 307695 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:25,106 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-06 12:32:25,143 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-06 12:32:25,179 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-06 12:32:25,214 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-06 12:32:25,249 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-06 12:32:25,286 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-06 12:32:25,322 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-06 12:32:25,360 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-06 12:32:25,396 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-06 12:32:25,433 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-06 12:32:25,471 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-06 12:32:25,507 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-06 12:32:25,542 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-06 12:32:25,577 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-06 12:32:25,613 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-06 12:32:25,649 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-06 12:32:25,686 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-06 12:32:25,759 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:25,828 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:25,828 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:25,828 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310175 effective words/s
2016-10-06 12:32:25,828 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:25,829 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:25,830 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-06 12:32:25,830 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-06 12:32:25,831 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-06 12:32:25,832 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-06 12:32:25,869 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-06 12:32:25,904 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-06 12:32:25,939 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-06 12:32:25,977 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-06 12:32:26,013 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-06 12:32:26,051 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-06 12:32:26,088 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-06 12:32:26,126 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-06 12:32:26,163 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-06 12:32:26,200 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-06 12:32:26,237 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-06 12:32:26,271 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-06 12:32:26,307 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-06 12:32:26,344 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-06 12:32:26,380 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-06 12:32:26,418 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-06 12:32:26,455 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-06 12:32:26,493 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-06 12:32:26,531 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-06 12:32:26,568 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-06 12:32:26,603 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-06 12:32:26,638 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-06 12:32:26,674 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-06 12:32:26,711 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-06 12:32:26,748 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-06 12:32:26,786 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-06 12:32:26,826 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-06 12:32:26,863 : INFO : PROGRESS: at 58.68% examples, 308735 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:26,864 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-06 12:32:26,902 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-06 12:32:26,938 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-06 12:32:26,977 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-06 12:32:27,012 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-06 12:32:27,048 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-06 12:32:27,086 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-06 12:32:27,124 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-06 12:32:27,161 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-06 12:32:27,198 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-06 12:32:27,236 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-06 12:32:27,277 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-06 12:32:27,313 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-06 12:32:27,348 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-06 12:32:27,385 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-06 12:32:27,423 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-06 12:32:27,460 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-06 12:32:27,534 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:27,604 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:27,604 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:27,604 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307750 effective words/s
2016-10-06 12:32:27,604 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:27,604 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:27,605 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-06 12:32:27,606 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-06 12:32:27,607 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-06 12:32:27,608 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-06 12:32:27,644 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-06 12:32:27,679 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-06 12:32:27,714 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-06 12:32:27,750 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-06 12:32:27,788 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-06 12:32:27,826 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-06 12:32:27,863 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-06 12:32:27,901 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-06 12:32:27,939 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-06 12:32:27,977 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-06 12:32:28,013 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-06 12:32:28,048 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-06 12:32:28,084 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-06 12:32:28,121 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-06 12:32:28,159 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-06 12:32:28,199 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-06 12:32:28,236 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-06 12:32:28,273 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-06 12:32:28,312 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-06 12:32:28,348 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-06 12:32:28,383 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-06 12:32:28,419 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-06 12:32:28,455 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-06 12:32:28,492 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-06 12:32:28,529 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-06 12:32:28,566 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-06 12:32:28,604 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-06 12:32:28,641 : INFO : PROGRESS: at 58.68% examples, 308062 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:28,642 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-06 12:32:28,679 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-06 12:32:28,716 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-06 12:32:28,751 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-06 12:32:28,787 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-06 12:32:28,824 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-06 12:32:28,863 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-06 12:32:28,908 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-06 12:32:28,950 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-06 12:32:28,994 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-06 12:32:29,034 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-06 12:32:29,071 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-06 12:32:29,114 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-06 12:32:29,156 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-06 12:32:29,202 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-06 12:32:29,246 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-06 12:32:29,290 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-06 12:32:29,365 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:29,442 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:29,443 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:29,443 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 297148 effective words/s
2016-10-06 12:32:29,443 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 12:32:29,443 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 12:32:29,444 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-06 12:32:29,445 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-06 12:32:29,446 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-06 12:32:29,447 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-06 12:32:29,487 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-06 12:32:29,526 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-06 12:32:29,565 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-06 12:32:29,602 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-06 12:32:29,639 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-06 12:32:29,676 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-06 12:32:29,713 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-06 12:32:29,750 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-06 12:32:29,790 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-06 12:32:29,842 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-06 12:32:29,886 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-06 12:32:29,925 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-06 12:32:29,962 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-06 12:32:29,999 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-06 12:32:30,035 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-06 12:32:30,073 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-06 12:32:30,113 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-06 12:32:30,150 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-06 12:32:30,189 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-06 12:32:30,225 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-06 12:32:30,260 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-06 12:32:30,296 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-06 12:32:30,332 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-06 12:32:30,368 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-06 12:32:30,409 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-06 12:32:30,446 : INFO : PROGRESS: at 55.16% examples, 295331 words/s, in_qsize 1, out_qsize 0
2016-10-06 12:32:30,447 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-06 12:32:30,486 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-06 12:32:30,533 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-06 12:32:30,575 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-06 12:32:30,613 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-06 12:32:30,648 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-06 12:32:30,684 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-06 12:32:30,720 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-06 12:32:30,758 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-06 12:32:30,796 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-06 12:32:30,834 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-06 12:32:30,874 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-06 12:32:30,913 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-06 12:32:30,951 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-06 12:32:30,992 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-06 12:32:31,031 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-06 12:32:31,074 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-06 12:32:31,120 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-06 12:32:31,159 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-06 12:32:31,242 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 12:32:31,322 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 12:32:31,322 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 12:32:31,322 : INFO : training on 478080 raw words (545575 effective words) took 1.9s, 290718 effective words/s
2016-10-06 12:32:31,322 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-06 12:32:31,322 : INFO : not storing attribute syn0norm
2016-10-06 12:32:31,323 : INFO : not storing attribute cum_table
2016-10-06 14:37:23,629 : INFO : collecting all words and their counts
2016-10-06 14:37:23,629 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-06 14:37:23,726 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-06 14:37:23,739 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-06 14:37:23,739 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-06 14:37:23,744 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-06 14:37:23,744 : INFO : sample=0 downsamples 0 most-common words
2016-10-06 14:37:23,744 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-06 14:37:23,744 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-06 14:37:23,746 : INFO : constructing a huffman tree from 2637 words
2016-10-06 14:37:23,801 : INFO : built huffman tree with maximum node depth 14
2016-10-06 14:37:23,802 : INFO : resetting layer weights
2016-10-06 14:37:23,835 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:23,835 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:23,836 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-06 14:37:23,837 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-06 14:37:23,838 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-06 14:37:23,839 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-06 14:37:23,878 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-06 14:37:23,911 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-06 14:37:23,945 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-06 14:37:23,980 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-06 14:37:24,015 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-06 14:37:24,052 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-06 14:37:24,088 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-06 14:37:24,125 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-06 14:37:24,162 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-06 14:37:24,197 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-06 14:37:24,232 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-06 14:37:24,266 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-06 14:37:24,301 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-06 14:37:24,339 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-06 14:37:24,375 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-06 14:37:24,411 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-06 14:37:24,448 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-06 14:37:24,484 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-06 14:37:24,521 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-06 14:37:24,557 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-06 14:37:24,591 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-06 14:37:24,626 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-06 14:37:24,662 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-06 14:37:24,697 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-06 14:37:24,734 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-06 14:37:24,770 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-06 14:37:24,806 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-06 14:37:24,843 : INFO : PROGRESS: at 58.68% examples, 317088 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:24,844 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-06 14:37:24,882 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-06 14:37:24,917 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-06 14:37:24,951 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-06 14:37:24,986 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-06 14:37:25,021 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-06 14:37:25,058 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-06 14:37:25,096 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-06 14:37:25,133 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-06 14:37:25,169 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-06 14:37:25,207 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-06 14:37:25,246 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-06 14:37:25,280 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-06 14:37:25,315 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-06 14:37:25,350 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-06 14:37:25,386 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-06 14:37:25,422 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-06 14:37:25,493 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:25,565 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:25,565 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:25,566 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315752 effective words/s
2016-10-06 14:37:25,566 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:25,566 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:25,567 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-06 14:37:25,568 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-06 14:37:25,568 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-06 14:37:25,569 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-06 14:37:25,604 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-06 14:37:25,638 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-06 14:37:25,673 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-06 14:37:25,708 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-06 14:37:25,744 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-06 14:37:25,780 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-06 14:37:25,816 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-06 14:37:25,855 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-06 14:37:25,893 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-06 14:37:25,929 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-06 14:37:25,964 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-06 14:37:25,998 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-06 14:37:26,032 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-06 14:37:26,068 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-06 14:37:26,103 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-06 14:37:26,141 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-06 14:37:26,178 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-06 14:37:26,214 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-06 14:37:26,251 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-06 14:37:26,287 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-06 14:37:26,321 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-06 14:37:26,355 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-06 14:37:26,390 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-06 14:37:26,425 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-06 14:37:26,462 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-06 14:37:26,498 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-06 14:37:26,534 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-06 14:37:26,575 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-06 14:37:26,575 : INFO : PROGRESS: at 58.68% examples, 316624 words/s, in_qsize 2, out_qsize 0
2016-10-06 14:37:26,619 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-06 14:37:26,665 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-06 14:37:26,707 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-06 14:37:26,745 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-06 14:37:26,784 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-06 14:37:26,822 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-06 14:37:26,863 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-06 14:37:26,901 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-06 14:37:26,940 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-06 14:37:26,978 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-06 14:37:27,023 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-06 14:37:27,061 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-06 14:37:27,104 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-06 14:37:27,144 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-06 14:37:27,181 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-06 14:37:27,226 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-06 14:37:27,308 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:27,387 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:27,388 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:27,388 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 299895 effective words/s
2016-10-06 14:37:27,388 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:27,388 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:27,389 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-06 14:37:27,390 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-06 14:37:27,391 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-06 14:37:27,392 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-06 14:37:27,428 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-06 14:37:27,463 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-06 14:37:27,501 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-06 14:37:27,537 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-06 14:37:27,572 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-06 14:37:27,609 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-06 14:37:27,646 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-06 14:37:27,682 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-06 14:37:27,719 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-06 14:37:27,756 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-06 14:37:27,791 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-06 14:37:27,827 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-06 14:37:27,864 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-06 14:37:27,900 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-06 14:37:27,935 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-06 14:37:27,973 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-06 14:37:28,010 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-06 14:37:28,049 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-06 14:37:28,087 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-06 14:37:28,123 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-06 14:37:28,160 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-06 14:37:28,195 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-06 14:37:28,230 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-06 14:37:28,269 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-06 14:37:28,306 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-06 14:37:28,343 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-06 14:37:28,380 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-06 14:37:28,416 : INFO : PROGRESS: at 58.68% examples, 311150 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:28,417 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-06 14:37:28,454 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-06 14:37:28,489 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-06 14:37:28,523 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-06 14:37:28,558 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-06 14:37:28,593 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-06 14:37:28,632 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-06 14:37:28,670 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-06 14:37:28,706 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-06 14:37:28,743 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-06 14:37:28,781 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-06 14:37:28,816 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-06 14:37:28,853 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-06 14:37:28,889 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-06 14:37:28,924 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-06 14:37:28,959 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-06 14:37:28,995 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-06 14:37:29,067 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:29,135 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:29,136 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:29,136 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312825 effective words/s
2016-10-06 14:37:29,136 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:29,136 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:29,137 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-06 14:37:29,138 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-06 14:37:29,138 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-06 14:37:29,139 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-06 14:37:29,179 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-06 14:37:29,213 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-06 14:37:29,251 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-06 14:37:29,285 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-06 14:37:29,321 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-06 14:37:29,357 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-06 14:37:29,394 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-06 14:37:29,431 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-06 14:37:29,467 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-06 14:37:29,503 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-06 14:37:29,541 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-06 14:37:29,575 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-06 14:37:29,610 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-06 14:37:29,645 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-06 14:37:29,681 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-06 14:37:29,718 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-06 14:37:29,754 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-06 14:37:29,790 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-06 14:37:29,827 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-06 14:37:29,863 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-06 14:37:29,898 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-06 14:37:29,932 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-06 14:37:29,967 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-06 14:37:30,003 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-06 14:37:30,042 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-06 14:37:30,078 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-06 14:37:30,115 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-06 14:37:30,154 : INFO : PROGRESS: at 58.68% examples, 313931 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:30,155 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-06 14:37:30,192 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-06 14:37:30,227 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-06 14:37:30,261 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-06 14:37:30,296 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-06 14:37:30,332 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-06 14:37:30,367 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-06 14:37:30,404 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-06 14:37:30,440 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-06 14:37:30,476 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-06 14:37:30,513 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-06 14:37:30,549 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-06 14:37:30,584 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-06 14:37:30,618 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-06 14:37:30,653 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-06 14:37:30,689 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-06 14:37:30,724 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-06 14:37:30,805 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:30,873 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:30,873 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:30,873 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 314460 effective words/s
2016-10-06 14:37:30,873 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:30,874 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:30,875 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-06 14:37:30,875 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-06 14:37:30,876 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-06 14:37:30,877 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-06 14:37:30,913 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-06 14:37:30,947 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-06 14:37:30,982 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-06 14:37:31,019 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-06 14:37:31,055 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-06 14:37:31,092 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-06 14:37:31,128 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-06 14:37:31,165 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-06 14:37:31,205 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-06 14:37:31,242 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-06 14:37:31,279 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-06 14:37:31,314 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-06 14:37:31,351 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-06 14:37:31,387 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-06 14:37:31,423 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-06 14:37:31,462 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-06 14:37:31,500 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-06 14:37:31,537 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-06 14:37:31,575 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-06 14:37:31,611 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-06 14:37:31,646 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-06 14:37:31,683 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-06 14:37:31,719 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-06 14:37:31,760 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-06 14:37:31,798 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-06 14:37:31,839 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-06 14:37:31,877 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-06 14:37:31,913 : INFO : PROGRESS: at 58.68% examples, 307270 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:31,914 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-06 14:37:31,952 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-06 14:37:31,989 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-06 14:37:32,026 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-06 14:37:32,061 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-06 14:37:32,097 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-06 14:37:32,137 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-06 14:37:32,176 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-06 14:37:32,212 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-06 14:37:32,248 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-06 14:37:32,288 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-06 14:37:32,324 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-06 14:37:32,360 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-06 14:37:32,396 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-06 14:37:32,433 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-06 14:37:32,469 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-06 14:37:32,505 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-06 14:37:32,580 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:32,652 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:32,652 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:32,652 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307230 effective words/s
2016-10-06 14:37:32,652 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:32,652 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:32,653 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-06 14:37:32,654 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-06 14:37:32,655 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-06 14:37:32,656 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-06 14:37:32,692 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-06 14:37:32,725 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-06 14:37:32,760 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-06 14:37:32,795 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-06 14:37:32,830 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-06 14:37:32,867 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-06 14:37:32,904 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-06 14:37:32,940 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-06 14:37:32,977 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-06 14:37:33,022 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-06 14:37:33,065 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-06 14:37:33,103 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-06 14:37:33,141 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-06 14:37:33,184 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-06 14:37:33,226 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-06 14:37:33,270 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-06 14:37:33,309 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-06 14:37:33,353 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-06 14:37:33,391 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-06 14:37:33,439 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-06 14:37:33,474 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-06 14:37:33,510 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-06 14:37:33,545 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-06 14:37:33,584 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-06 14:37:33,627 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-06 14:37:33,667 : INFO : PROGRESS: at 55.16% examples, 291873 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:33,668 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-06 14:37:33,708 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-06 14:37:33,746 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-06 14:37:33,786 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-06 14:37:33,822 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-06 14:37:33,857 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-06 14:37:33,893 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-06 14:37:33,931 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-06 14:37:33,967 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-06 14:37:34,004 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-06 14:37:34,044 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-06 14:37:34,083 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-06 14:37:34,123 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-06 14:37:34,163 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-06 14:37:34,204 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-06 14:37:34,248 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-06 14:37:34,288 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-06 14:37:34,324 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-06 14:37:34,360 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-06 14:37:34,432 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:34,510 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:34,510 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:34,510 : INFO : training on 478080 raw words (545575 effective words) took 1.9s, 294040 effective words/s
2016-10-06 14:37:34,510 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:34,510 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:34,512 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-06 14:37:34,512 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-06 14:37:34,513 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-06 14:37:34,514 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-06 14:37:34,551 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-06 14:37:34,586 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-06 14:37:34,622 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-06 14:37:34,661 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-06 14:37:34,697 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-06 14:37:34,734 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-06 14:37:34,771 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-06 14:37:34,807 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-06 14:37:34,844 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-06 14:37:34,886 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-06 14:37:34,922 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-06 14:37:34,957 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-06 14:37:34,995 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-06 14:37:35,034 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-06 14:37:35,069 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-06 14:37:35,107 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-06 14:37:35,146 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-06 14:37:35,183 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-06 14:37:35,221 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-06 14:37:35,256 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-06 14:37:35,291 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-06 14:37:35,325 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-06 14:37:35,359 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-06 14:37:35,395 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-06 14:37:35,431 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-06 14:37:35,468 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-06 14:37:35,504 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-06 14:37:35,542 : INFO : PROGRESS: at 58.68% examples, 309913 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:35,543 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-06 14:37:35,582 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-06 14:37:35,616 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-06 14:37:35,654 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-06 14:37:35,689 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-06 14:37:35,724 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-06 14:37:35,759 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-06 14:37:35,796 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-06 14:37:35,832 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-06 14:37:35,870 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-06 14:37:35,907 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-06 14:37:35,943 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-06 14:37:35,977 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-06 14:37:36,011 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-06 14:37:36,046 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-06 14:37:36,082 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-06 14:37:36,117 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-06 14:37:36,188 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:36,256 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:36,256 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:36,256 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 313055 effective words/s
2016-10-06 14:37:36,257 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:36,257 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:36,258 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-06 14:37:36,259 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-06 14:37:36,260 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-06 14:37:36,261 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-06 14:37:36,296 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-06 14:37:36,330 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-06 14:37:36,364 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-06 14:37:36,399 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-06 14:37:36,435 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-06 14:37:36,472 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-06 14:37:36,511 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-06 14:37:36,548 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-06 14:37:36,585 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-06 14:37:36,621 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-06 14:37:36,656 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-06 14:37:36,690 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-06 14:37:36,725 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-06 14:37:36,761 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-06 14:37:36,797 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-06 14:37:36,837 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-06 14:37:36,874 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-06 14:37:36,910 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-06 14:37:36,948 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-06 14:37:36,984 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-06 14:37:37,018 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-06 14:37:37,052 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-06 14:37:37,087 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-06 14:37:37,123 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-06 14:37:37,160 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-06 14:37:37,197 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-06 14:37:37,233 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-06 14:37:37,269 : INFO : PROGRESS: at 58.68% examples, 315645 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:37,270 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-06 14:37:37,307 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-06 14:37:37,342 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-06 14:37:37,376 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-06 14:37:37,411 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-06 14:37:37,448 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-06 14:37:37,484 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-06 14:37:37,528 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-06 14:37:37,565 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-06 14:37:37,608 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-06 14:37:37,646 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-06 14:37:37,693 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-06 14:37:37,738 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-06 14:37:37,774 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-06 14:37:37,812 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-06 14:37:37,862 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-06 14:37:37,903 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-06 14:37:37,975 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:38,043 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:38,043 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:38,043 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 305867 effective words/s
2016-10-06 14:37:38,044 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:38,044 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:38,045 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-06 14:37:38,046 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-06 14:37:38,046 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-06 14:37:38,047 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-06 14:37:38,083 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-06 14:37:38,117 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-06 14:37:38,151 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-06 14:37:38,187 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-06 14:37:38,222 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-06 14:37:38,259 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-06 14:37:38,295 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-06 14:37:38,334 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-06 14:37:38,376 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-06 14:37:38,416 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-06 14:37:38,456 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-06 14:37:38,490 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-06 14:37:38,525 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-06 14:37:38,561 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-06 14:37:38,597 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-06 14:37:38,633 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-06 14:37:38,670 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-06 14:37:38,706 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-06 14:37:38,744 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-06 14:37:38,779 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-06 14:37:38,813 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-06 14:37:38,848 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-06 14:37:38,884 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-06 14:37:38,919 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-06 14:37:38,956 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-06 14:37:38,992 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-06 14:37:39,028 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-06 14:37:39,064 : INFO : PROGRESS: at 58.68% examples, 313122 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:39,065 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-06 14:37:39,104 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-06 14:37:39,140 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-06 14:37:39,174 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-06 14:37:39,208 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-06 14:37:39,244 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-06 14:37:39,279 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-06 14:37:39,316 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-06 14:37:39,352 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-06 14:37:39,388 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-06 14:37:39,429 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-06 14:37:39,466 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-06 14:37:39,500 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-06 14:37:39,536 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-06 14:37:39,573 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-06 14:37:39,610 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-06 14:37:39,646 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-06 14:37:39,717 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:39,784 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:39,784 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:39,784 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 313868 effective words/s
2016-10-06 14:37:39,785 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-06 14:37:39,785 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-06 14:37:39,786 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-06 14:37:39,787 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-06 14:37:39,787 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-06 14:37:39,788 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-06 14:37:39,824 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-06 14:37:39,858 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-06 14:37:39,892 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-06 14:37:39,927 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-06 14:37:39,963 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-06 14:37:39,999 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-06 14:37:40,041 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-06 14:37:40,077 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-06 14:37:40,113 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-06 14:37:40,150 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-06 14:37:40,188 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-06 14:37:40,222 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-06 14:37:40,257 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-06 14:37:40,292 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-06 14:37:40,328 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-06 14:37:40,366 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-06 14:37:40,402 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-06 14:37:40,438 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-06 14:37:40,476 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-06 14:37:40,512 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-06 14:37:40,549 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-06 14:37:40,583 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-06 14:37:40,618 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-06 14:37:40,654 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-06 14:37:40,690 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-06 14:37:40,727 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-06 14:37:40,763 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-06 14:37:40,799 : INFO : PROGRESS: at 58.68% examples, 314993 words/s, in_qsize 1, out_qsize 0
2016-10-06 14:37:40,800 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-06 14:37:40,836 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-06 14:37:40,872 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-06 14:37:40,905 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-06 14:37:40,940 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-06 14:37:40,979 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-06 14:37:41,014 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-06 14:37:41,051 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-06 14:37:41,087 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-06 14:37:41,123 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-06 14:37:41,160 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-06 14:37:41,196 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-06 14:37:41,230 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-06 14:37:41,264 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-06 14:37:41,299 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-06 14:37:41,334 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-06 14:37:41,370 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-06 14:37:41,445 : DEBUG : job loop exiting, total 48 jobs
2016-10-06 14:37:41,513 : DEBUG : worker exiting, processed 48 jobs
2016-10-06 14:37:41,513 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-06 14:37:41,513 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316128 effective words/s
2016-10-06 14:37:41,513 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-06 14:37:41,513 : INFO : not storing attribute cum_table
2016-10-06 14:37:41,514 : INFO : not storing attribute syn0norm
2016-10-08 20:45:32,476 : INFO : collecting all words and their counts
2016-10-08 20:45:32,476 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-08 20:45:32,562 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-08 20:45:32,571 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-08 20:45:32,572 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-08 20:45:32,576 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-08 20:45:32,577 : INFO : sample=0 downsamples 0 most-common words
2016-10-08 20:45:32,577 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-08 20:45:32,577 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-08 20:45:32,579 : INFO : constructing a huffman tree from 2637 words
2016-10-08 20:45:32,635 : INFO : built huffman tree with maximum node depth 14
2016-10-08 20:45:32,636 : INFO : resetting layer weights
2016-10-08 20:45:32,670 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:32,670 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:32,672 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-08 20:45:32,672 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-08 20:45:32,673 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-08 20:45:32,675 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-08 20:45:32,713 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-08 20:45:32,747 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-08 20:45:32,782 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-08 20:45:32,817 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-08 20:45:32,853 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-08 20:45:32,893 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-08 20:45:32,929 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-08 20:45:32,966 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-08 20:45:33,004 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-08 20:45:33,040 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-08 20:45:33,076 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-08 20:45:33,110 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-08 20:45:33,146 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-08 20:45:33,182 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-08 20:45:33,218 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-08 20:45:33,256 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-08 20:45:33,292 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-08 20:45:33,329 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-08 20:45:33,368 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-08 20:45:33,407 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-08 20:45:33,443 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-08 20:45:33,478 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-08 20:45:33,513 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-08 20:45:33,550 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-08 20:45:33,590 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-08 20:45:33,627 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-08 20:45:33,663 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-08 20:45:33,701 : INFO : PROGRESS: at 58.68% examples, 310201 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:33,701 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-08 20:45:33,738 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-08 20:45:33,775 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-08 20:45:33,809 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-08 20:45:33,845 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-08 20:45:33,881 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-08 20:45:33,918 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-08 20:45:33,958 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-08 20:45:33,994 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-08 20:45:34,032 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-08 20:45:34,073 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-08 20:45:34,110 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-08 20:45:34,145 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-08 20:45:34,179 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-08 20:45:34,215 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-08 20:45:34,251 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-08 20:45:34,288 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-08 20:45:34,360 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:34,429 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:34,430 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:34,430 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310569 effective words/s
2016-10-08 20:45:34,430 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:34,430 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:34,431 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-08 20:45:34,432 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-08 20:45:34,433 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-08 20:45:34,434 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-08 20:45:34,469 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-08 20:45:34,504 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-08 20:45:34,539 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-08 20:45:34,574 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-08 20:45:34,614 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-08 20:45:34,650 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-08 20:45:34,687 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-08 20:45:34,724 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-08 20:45:34,764 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-08 20:45:34,800 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-08 20:45:34,836 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-08 20:45:34,871 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-08 20:45:34,906 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-08 20:45:34,942 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-08 20:45:34,978 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-08 20:45:35,015 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-08 20:45:35,053 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-08 20:45:35,089 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-08 20:45:35,127 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-08 20:45:35,163 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-08 20:45:35,200 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-08 20:45:35,235 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-08 20:45:35,271 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-08 20:45:35,306 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-08 20:45:35,343 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-08 20:45:35,379 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-08 20:45:35,416 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-08 20:45:35,456 : INFO : PROGRESS: at 58.68% examples, 311595 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:35,457 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-08 20:45:35,496 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-08 20:45:35,532 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-08 20:45:35,566 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-08 20:45:35,604 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-08 20:45:35,643 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-08 20:45:35,685 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-08 20:45:35,728 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-08 20:45:35,769 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-08 20:45:35,811 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-08 20:45:35,851 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-08 20:45:35,887 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-08 20:45:35,924 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-08 20:45:35,961 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-08 20:45:35,997 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-08 20:45:36,034 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-08 20:45:36,070 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-08 20:45:36,142 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:36,209 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:36,210 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:36,210 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307029 effective words/s
2016-10-08 20:45:36,210 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:36,210 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:36,211 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-08 20:45:36,212 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-08 20:45:36,213 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-08 20:45:36,214 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-08 20:45:36,250 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-08 20:45:36,285 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-08 20:45:36,320 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-08 20:45:36,356 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-08 20:45:36,391 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-08 20:45:36,429 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-08 20:45:36,465 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-08 20:45:36,502 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-08 20:45:36,539 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-08 20:45:36,575 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-08 20:45:36,611 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-08 20:45:36,645 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-08 20:45:36,680 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-08 20:45:36,716 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-08 20:45:36,752 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-08 20:45:36,790 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-08 20:45:36,827 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-08 20:45:36,863 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-08 20:45:36,902 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-08 20:45:36,938 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-08 20:45:36,972 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-08 20:45:37,007 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-08 20:45:37,042 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-08 20:45:37,078 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-08 20:45:37,115 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-08 20:45:37,152 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-08 20:45:37,188 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-08 20:45:37,225 : INFO : PROGRESS: at 58.68% examples, 314839 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:37,226 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-08 20:45:37,263 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-08 20:45:37,299 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-08 20:45:37,333 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-08 20:45:37,369 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-08 20:45:37,404 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-08 20:45:37,441 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-08 20:45:37,480 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-08 20:45:37,516 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-08 20:45:37,552 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-08 20:45:37,590 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-08 20:45:37,626 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-08 20:45:37,661 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-08 20:45:37,695 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-08 20:45:37,731 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-08 20:45:37,767 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-08 20:45:37,803 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-08 20:45:37,875 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:37,944 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:37,944 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:37,944 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315079 effective words/s
2016-10-08 20:45:37,944 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:37,944 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:37,946 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-08 20:45:37,946 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-08 20:45:37,947 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-08 20:45:37,948 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-08 20:45:37,985 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-08 20:45:38,019 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-08 20:45:38,055 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-08 20:45:38,091 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-08 20:45:38,128 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-08 20:45:38,165 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-08 20:45:38,202 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-08 20:45:38,239 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-08 20:45:38,276 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-08 20:45:38,314 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-08 20:45:38,352 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-08 20:45:38,387 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-08 20:45:38,423 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-08 20:45:38,460 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-08 20:45:38,496 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-08 20:45:38,534 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-08 20:45:38,570 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-08 20:45:38,607 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-08 20:45:38,646 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-08 20:45:38,685 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-08 20:45:38,719 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-08 20:45:38,755 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-08 20:45:38,791 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-08 20:45:38,828 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-08 20:45:38,865 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-08 20:45:38,902 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-08 20:45:38,943 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-08 20:45:38,980 : INFO : PROGRESS: at 58.68% examples, 308589 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:38,981 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-08 20:45:39,017 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-08 20:45:39,054 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-08 20:45:39,088 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-08 20:45:39,124 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-08 20:45:39,160 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-08 20:45:39,196 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-08 20:45:39,235 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-08 20:45:39,271 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-08 20:45:39,308 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-08 20:45:39,346 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-08 20:45:39,382 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-08 20:45:39,418 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-08 20:45:39,453 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-08 20:45:39,489 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-08 20:45:39,525 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-08 20:45:39,562 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-08 20:45:39,634 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:39,703 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:39,704 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:39,704 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310574 effective words/s
2016-10-08 20:45:39,704 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:39,704 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:39,705 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-08 20:45:39,706 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-08 20:45:39,706 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-08 20:45:39,707 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-08 20:45:39,744 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-08 20:45:39,778 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-08 20:45:39,814 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-08 20:45:39,850 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-08 20:45:39,887 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-08 20:45:39,928 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-08 20:45:39,965 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-08 20:45:40,002 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-08 20:45:40,040 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-08 20:45:40,076 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-08 20:45:40,112 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-08 20:45:40,147 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-08 20:45:40,182 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-08 20:45:40,219 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-08 20:45:40,255 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-08 20:45:40,293 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-08 20:45:40,330 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-08 20:45:40,367 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-08 20:45:40,405 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-08 20:45:40,442 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-08 20:45:40,477 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-08 20:45:40,512 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-08 20:45:40,548 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-08 20:45:40,584 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-08 20:45:40,621 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-08 20:45:40,659 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-08 20:45:40,695 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-08 20:45:40,733 : INFO : PROGRESS: at 58.68% examples, 310601 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:40,733 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-08 20:45:40,770 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-08 20:45:40,807 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-08 20:45:40,841 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-08 20:45:40,877 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-08 20:45:40,913 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-08 20:45:40,950 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-08 20:45:40,989 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-08 20:45:41,025 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-08 20:45:41,062 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-08 20:45:41,101 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-08 20:45:41,138 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-08 20:45:41,173 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-08 20:45:41,208 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-08 20:45:41,244 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-08 20:45:41,283 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-08 20:45:41,320 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-08 20:45:41,392 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:41,461 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:41,462 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:41,462 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310800 effective words/s
2016-10-08 20:45:41,462 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:41,462 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:41,463 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-08 20:45:41,464 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-08 20:45:41,465 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-08 20:45:41,465 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-08 20:45:41,502 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-08 20:45:41,537 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-08 20:45:41,572 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-08 20:45:41,608 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-08 20:45:41,645 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-08 20:45:41,682 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-08 20:45:41,719 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-08 20:45:41,756 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-08 20:45:41,794 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-08 20:45:41,835 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-08 20:45:41,871 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-08 20:45:41,905 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-08 20:45:41,942 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-08 20:45:41,978 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-08 20:45:42,017 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-08 20:45:42,059 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-08 20:45:42,097 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-08 20:45:42,136 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-08 20:45:42,173 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-08 20:45:42,210 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-08 20:45:42,245 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-08 20:45:42,280 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-08 20:45:42,320 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-08 20:45:42,356 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-08 20:45:42,393 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-08 20:45:42,433 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-08 20:45:42,469 : INFO : PROGRESS: at 56.90% examples, 305438 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:42,470 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-08 20:45:42,508 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-08 20:45:42,545 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-08 20:45:42,581 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-08 20:45:42,615 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-08 20:45:42,651 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-08 20:45:42,688 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-08 20:45:42,725 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-08 20:45:42,764 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-08 20:45:42,801 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-08 20:45:42,838 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-08 20:45:42,876 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-08 20:45:42,912 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-08 20:45:42,948 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-08 20:45:42,985 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-08 20:45:43,021 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-08 20:45:43,057 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-08 20:45:43,094 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-08 20:45:43,166 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:43,236 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:43,236 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:43,236 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307913 effective words/s
2016-10-08 20:45:43,236 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:43,237 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:43,238 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-08 20:45:43,239 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-08 20:45:43,239 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-08 20:45:43,240 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-08 20:45:43,276 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-08 20:45:43,311 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-08 20:45:43,346 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-08 20:45:43,382 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-08 20:45:43,418 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-08 20:45:43,456 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-08 20:45:43,492 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-08 20:45:43,529 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-08 20:45:43,567 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-08 20:45:43,604 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-08 20:45:43,640 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-08 20:45:43,675 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-08 20:45:43,710 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-08 20:45:43,746 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-08 20:45:43,782 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-08 20:45:43,823 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-08 20:45:43,861 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-08 20:45:43,898 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-08 20:45:43,940 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-08 20:45:43,977 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-08 20:45:44,012 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-08 20:45:44,048 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-08 20:45:44,087 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-08 20:45:44,123 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-08 20:45:44,160 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-08 20:45:44,197 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-08 20:45:44,237 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-08 20:45:44,274 : INFO : PROGRESS: at 58.68% examples, 307893 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:44,275 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-08 20:45:44,312 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-08 20:45:44,348 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-08 20:45:44,383 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-08 20:45:44,418 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-08 20:45:44,454 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-08 20:45:44,490 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-08 20:45:44,528 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-08 20:45:44,567 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-08 20:45:44,606 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-08 20:45:44,649 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-08 20:45:44,686 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-08 20:45:44,723 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-08 20:45:44,758 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-08 20:45:44,794 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-08 20:45:44,831 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-08 20:45:44,867 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-08 20:45:44,943 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:45,016 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:45,016 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:45,016 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307043 effective words/s
2016-10-08 20:45:45,016 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:45,016 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:45,018 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-08 20:45:45,018 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-08 20:45:45,019 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-08 20:45:45,020 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-08 20:45:45,056 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-08 20:45:45,091 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-08 20:45:45,125 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-08 20:45:45,161 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-08 20:45:45,197 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-08 20:45:45,238 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-08 20:45:45,275 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-08 20:45:45,312 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-08 20:45:45,349 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-08 20:45:45,385 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-08 20:45:45,421 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-08 20:45:45,456 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-08 20:45:45,491 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-08 20:45:45,527 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-08 20:45:45,563 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-08 20:45:45,600 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-08 20:45:45,636 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-08 20:45:45,673 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-08 20:45:45,711 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-08 20:45:45,747 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-08 20:45:45,781 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-08 20:45:45,816 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-08 20:45:45,852 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-08 20:45:45,888 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-08 20:45:45,924 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-08 20:45:45,962 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-08 20:45:45,998 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-08 20:45:46,035 : INFO : PROGRESS: at 58.68% examples, 313654 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:46,036 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-08 20:45:46,072 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-08 20:45:46,108 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-08 20:45:46,142 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-08 20:45:46,177 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-08 20:45:46,213 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-08 20:45:46,248 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-08 20:45:46,286 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-08 20:45:46,323 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-08 20:45:46,360 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-08 20:45:46,397 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-08 20:45:46,433 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-08 20:45:46,468 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-08 20:45:46,502 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-08 20:45:46,538 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-08 20:45:46,574 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-08 20:45:46,610 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-08 20:45:46,682 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:46,751 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:46,751 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:46,751 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 314987 effective words/s
2016-10-08 20:45:46,751 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:46,751 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:46,752 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-08 20:45:46,753 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-08 20:45:46,754 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-08 20:45:46,755 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-08 20:45:46,791 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-08 20:45:46,826 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-08 20:45:46,862 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-08 20:45:46,898 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-08 20:45:46,935 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-08 20:45:46,972 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-08 20:45:47,010 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-08 20:45:47,047 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-08 20:45:47,084 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-08 20:45:47,120 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-08 20:45:47,156 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-08 20:45:47,191 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-08 20:45:47,227 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-08 20:45:47,263 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-08 20:45:47,300 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-08 20:45:47,337 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-08 20:45:47,374 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-08 20:45:47,411 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-08 20:45:47,449 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-08 20:45:47,485 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-08 20:45:47,520 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-08 20:45:47,555 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-08 20:45:47,591 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-08 20:45:47,627 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-08 20:45:47,664 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-08 20:45:47,701 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-08 20:45:47,738 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-08 20:45:47,775 : INFO : PROGRESS: at 58.68% examples, 312166 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:47,776 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-08 20:45:47,812 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-08 20:45:47,849 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-08 20:45:47,884 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-08 20:45:47,920 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-08 20:45:47,956 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-08 20:45:47,992 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-08 20:45:48,030 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-08 20:45:48,067 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-08 20:45:48,107 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-08 20:45:48,145 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-08 20:45:48,181 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-08 20:45:48,216 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-08 20:45:48,251 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-08 20:45:48,287 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-08 20:45:48,324 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-08 20:45:48,361 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-08 20:45:48,441 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:48,510 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:48,510 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:48,510 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310666 effective words/s
2016-10-08 20:45:48,510 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 20:45:48,510 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 20:45:48,511 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-08 20:45:48,512 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-08 20:45:48,513 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-08 20:45:48,514 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-08 20:45:48,549 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-08 20:45:48,584 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-08 20:45:48,620 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-08 20:45:48,656 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-08 20:45:48,692 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-08 20:45:48,729 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-08 20:45:48,765 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-08 20:45:48,801 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-08 20:45:48,839 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-08 20:45:48,875 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-08 20:45:48,911 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-08 20:45:48,948 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-08 20:45:48,983 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-08 20:45:49,019 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-08 20:45:49,055 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-08 20:45:49,092 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-08 20:45:49,128 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-08 20:45:49,164 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-08 20:45:49,202 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-08 20:45:49,239 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-08 20:45:49,273 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-08 20:45:49,308 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-08 20:45:49,343 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-08 20:45:49,379 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-08 20:45:49,415 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-08 20:45:49,452 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-08 20:45:49,488 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-08 20:45:49,524 : INFO : PROGRESS: at 58.68% examples, 314982 words/s, in_qsize 1, out_qsize 0
2016-10-08 20:45:49,525 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-08 20:45:49,562 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-08 20:45:49,598 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-08 20:45:49,632 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-08 20:45:49,667 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-08 20:45:49,702 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-08 20:45:49,738 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-08 20:45:49,776 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-08 20:45:49,812 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-08 20:45:49,848 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-08 20:45:49,885 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-08 20:45:49,922 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-08 20:45:49,957 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-08 20:45:49,992 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-08 20:45:50,027 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-08 20:45:50,062 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-08 20:45:50,098 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-08 20:45:50,179 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 20:45:50,247 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 20:45:50,247 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 20:45:50,247 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 314541 effective words/s
2016-10-08 20:45:50,247 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-08 20:45:50,247 : INFO : not storing attribute cum_table
2016-10-08 20:45:50,248 : INFO : not storing attribute syn0norm
2016-10-08 21:53:43,289 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-08 21:53:43,542 : INFO : built Dictionary(11949 unique tokens: ['yr', 'charging', 'ego', 'inch', 'lankas']...) from 4880 documents (total 186045 corpus positions)
2016-10-08 21:53:43,547 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-08 21:53:43,550 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-08 21:53:43,552 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-08 21:53:43,556 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-08 21:53:43,557 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-08 21:53:43,557 : INFO : PROGRESS: saving document #0
2016-10-08 21:53:43,608 : INFO : PROGRESS: saving document #1000
2016-10-08 21:53:43,660 : INFO : PROGRESS: saving document #2000
2016-10-08 21:53:43,716 : INFO : PROGRESS: saving document #3000
2016-10-08 21:53:43,778 : INFO : PROGRESS: saving document #4000
2016-10-08 21:53:43,835 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-08 21:53:43,835 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-08 21:53:43,838 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-08 21:53:43,839 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-08 21:53:43,842 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-08 21:53:43,842 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-08 21:53:43,842 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-08 21:53:43,842 : INFO : collecting document frequencies
2016-10-08 21:53:43,842 : INFO : PROGRESS: processing document #0
2016-10-08 21:53:44,010 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-08 21:53:44,014 : INFO : using serial LSI version on this node
2016-10-08 21:53:44,014 : INFO : updating model with new documents
2016-10-08 21:53:44,284 : INFO : preparing a new chunk of documents
2016-10-08 21:53:44,285 : DEBUG : converting corpus to csc format
2016-10-08 21:53:44,318 : INFO : using 100 extra samples and 2 power iterations
2016-10-08 21:53:44,318 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-08 21:53:44,413 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-08 21:53:44,429 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-08 21:53:44,511 : DEBUG : running 2 power iterations
2016-10-08 21:53:44,575 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-08 21:53:44,674 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-08 21:53:44,740 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-08 21:53:44,835 : INFO : computing the final decomposition
2016-10-08 21:53:44,835 : INFO : keeping 200 factors (discarding 18.904% of energy spectrum)
2016-10-08 21:53:44,851 : INFO : processed documents up to #4880
2016-10-08 21:53:44,854 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-08 21:53:44,854 : INFO : topic #1(5.571): 0.613*"visa" + 0.342*"visit" + 0.210*"family" + -0.166*"buy" + -0.164*"doha" + -0.146*"good" + -0.138*"anyone" + -0.132*"know" + 0.129*"wife" + -0.117*"find"
2016-10-08 21:53:44,856 : INFO : topic #2(4.311): -0.276*"doha" + 0.257*"driving" + 0.253*"car" + -0.247*"visa" + 0.227*"company" + -0.204*"visit" + 0.204*"qatar" + 0.198*"license" + -0.194*"anyone" + -0.193*"buy"
2016-10-08 21:53:44,856 : INFO : topic #3(4.144): 0.552*"car" + 0.443*"buy" + -0.209*"school" + 0.165*"one" + -0.153*"would" + -0.127*"like" + 0.120*"driving" + 0.109*"license" + -0.107*"job" + 0.100*"need"
2016-10-08 21:53:44,856 : INFO : topic #4(4.124): 0.586*"driving" + 0.400*"school" + 0.397*"license" + -0.210*"company" + 0.118*"test" + 0.114*"international" + -0.094*"bank" + -0.092*"job" + -0.091*"buy" + 0.091*"visit"
2016-10-08 21:53:44,863 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-08 21:53:45,367 : INFO : creating matrix with 4880 documents and 200 features
2016-10-08 21:53:45,389 : DEBUG : PROGRESS: at document #0/4880
2016-10-08 21:53:45,520 : DEBUG : PROGRESS: at document #1000/4880
2016-10-08 21:53:45,674 : DEBUG : PROGRESS: at document #2000/4880
2016-10-08 21:53:45,829 : DEBUG : PROGRESS: at document #3000/4880
2016-10-08 21:53:45,997 : DEBUG : PROGRESS: at document #4000/4880
2016-10-08 22:29:12,727 : INFO : collecting all words and their counts
2016-10-08 22:29:12,727 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-08 22:29:12,833 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-08 22:29:12,843 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-08 22:29:12,843 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-08 22:29:12,848 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-08 22:29:12,849 : INFO : sample=0 downsamples 0 most-common words
2016-10-08 22:29:12,849 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-08 22:29:12,849 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-08 22:29:12,851 : INFO : constructing a huffman tree from 2637 words
2016-10-08 22:29:12,910 : INFO : built huffman tree with maximum node depth 14
2016-10-08 22:29:12,911 : INFO : resetting layer weights
2016-10-08 22:29:12,957 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:12,957 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:12,958 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-08 22:29:12,959 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-08 22:29:12,960 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-08 22:29:12,961 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-08 22:29:12,998 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-08 22:29:13,034 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-08 22:29:13,068 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-08 22:29:13,107 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-08 22:29:13,145 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-08 22:29:13,185 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-08 22:29:13,221 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-08 22:29:13,259 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-08 22:29:13,300 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-08 22:29:13,336 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-08 22:29:13,371 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-08 22:29:13,405 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-08 22:29:13,440 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-08 22:29:13,476 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-08 22:29:13,512 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-08 22:29:13,549 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-08 22:29:13,586 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-08 22:29:13,626 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-08 22:29:13,666 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-08 22:29:13,702 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-08 22:29:13,738 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-08 22:29:13,777 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-08 22:29:13,812 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-08 22:29:13,847 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-08 22:29:13,884 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-08 22:29:13,920 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-08 22:29:13,957 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-08 22:29:13,993 : INFO : PROGRESS: at 58.68% examples, 308390 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:13,994 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-08 22:29:14,031 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-08 22:29:14,067 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-08 22:29:14,104 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-08 22:29:14,139 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-08 22:29:14,178 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-08 22:29:14,217 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-08 22:29:14,258 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-08 22:29:14,295 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-08 22:29:14,331 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-08 22:29:14,369 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-08 22:29:14,405 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-08 22:29:14,444 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-08 22:29:14,482 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-08 22:29:14,521 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-08 22:29:14,560 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-08 22:29:14,596 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-08 22:29:14,672 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:14,748 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:14,748 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:14,748 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 305047 effective words/s
2016-10-08 22:29:14,748 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:14,748 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:14,750 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-08 22:29:14,750 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-08 22:29:14,751 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-08 22:29:14,752 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-08 22:29:14,789 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-08 22:29:14,823 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-08 22:29:14,859 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-08 22:29:14,895 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-08 22:29:14,931 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-08 22:29:14,972 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-08 22:29:15,010 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-08 22:29:15,049 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-08 22:29:15,088 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-08 22:29:15,125 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-08 22:29:15,161 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-08 22:29:15,199 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-08 22:29:15,234 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-08 22:29:15,271 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-08 22:29:15,307 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-08 22:29:15,351 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-08 22:29:15,388 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-08 22:29:15,425 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-08 22:29:15,463 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-08 22:29:15,500 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-08 22:29:15,540 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-08 22:29:15,576 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-08 22:29:15,618 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-08 22:29:15,666 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-08 22:29:15,714 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-08 22:29:15,753 : INFO : PROGRESS: at 55.16% examples, 294742 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:15,754 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-08 22:29:15,793 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-08 22:29:15,836 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-08 22:29:15,880 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-08 22:29:15,920 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-08 22:29:15,955 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-08 22:29:15,991 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-08 22:29:16,027 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-08 22:29:16,063 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-08 22:29:16,101 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-08 22:29:16,138 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-08 22:29:16,175 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-08 22:29:16,213 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-08 22:29:16,250 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-08 22:29:16,285 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-08 22:29:16,321 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-08 22:29:16,359 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-08 22:29:16,395 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-08 22:29:16,431 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-08 22:29:16,504 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:16,574 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:16,574 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:16,574 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 299313 effective words/s
2016-10-08 22:29:16,574 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:16,574 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:16,575 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-08 22:29:16,576 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-08 22:29:16,577 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-08 22:29:16,578 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-08 22:29:16,614 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-08 22:29:16,648 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-08 22:29:16,682 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-08 22:29:16,722 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-08 22:29:16,758 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-08 22:29:16,794 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-08 22:29:16,831 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-08 22:29:16,869 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-08 22:29:16,906 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-08 22:29:16,942 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-08 22:29:16,977 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-08 22:29:17,011 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-08 22:29:17,047 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-08 22:29:17,083 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-08 22:29:17,122 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-08 22:29:17,159 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-08 22:29:17,196 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-08 22:29:17,232 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-08 22:29:17,278 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-08 22:29:17,324 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-08 22:29:17,367 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-08 22:29:17,408 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-08 22:29:17,447 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-08 22:29:17,493 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-08 22:29:17,537 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-08 22:29:17,580 : INFO : PROGRESS: at 55.16% examples, 294524 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:17,581 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-08 22:29:17,629 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-08 22:29:17,667 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-08 22:29:17,708 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-08 22:29:17,744 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-08 22:29:17,779 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-08 22:29:17,813 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-08 22:29:17,849 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-08 22:29:17,885 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-08 22:29:17,922 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-08 22:29:17,959 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-08 22:29:17,996 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-08 22:29:18,037 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-08 22:29:18,074 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-08 22:29:18,108 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-08 22:29:18,143 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-08 22:29:18,179 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-08 22:29:18,215 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-08 22:29:18,251 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-08 22:29:18,322 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:18,391 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:18,391 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:18,391 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 300702 effective words/s
2016-10-08 22:29:18,391 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:18,391 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:18,392 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-08 22:29:18,393 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-08 22:29:18,394 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-08 22:29:18,395 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-08 22:29:18,431 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-08 22:29:18,465 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-08 22:29:18,499 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-08 22:29:18,535 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-08 22:29:18,570 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-08 22:29:18,607 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-08 22:29:18,643 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-08 22:29:18,679 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-08 22:29:18,716 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-08 22:29:18,754 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-08 22:29:18,790 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-08 22:29:18,824 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-08 22:29:18,859 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-08 22:29:18,894 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-08 22:29:18,930 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-08 22:29:18,970 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-08 22:29:19,006 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-08 22:29:19,044 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-08 22:29:19,082 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-08 22:29:19,117 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-08 22:29:19,151 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-08 22:29:19,186 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-08 22:29:19,221 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-08 22:29:19,257 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-08 22:29:19,293 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-08 22:29:19,330 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-08 22:29:19,366 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-08 22:29:19,402 : INFO : PROGRESS: at 58.68% examples, 316024 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:19,403 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-08 22:29:19,439 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-08 22:29:19,475 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-08 22:29:19,509 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-08 22:29:19,544 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-08 22:29:19,579 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-08 22:29:19,615 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-08 22:29:19,653 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-08 22:29:19,689 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-08 22:29:19,725 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-08 22:29:19,766 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-08 22:29:19,802 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-08 22:29:19,836 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-08 22:29:19,870 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-08 22:29:19,906 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-08 22:29:19,941 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-08 22:29:19,977 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-08 22:29:20,049 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:20,118 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:20,118 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:20,118 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316382 effective words/s
2016-10-08 22:29:20,118 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:20,118 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:20,120 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-08 22:29:20,120 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-08 22:29:20,121 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-08 22:29:20,122 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-08 22:29:20,158 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-08 22:29:20,193 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-08 22:29:20,227 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-08 22:29:20,263 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-08 22:29:20,300 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-08 22:29:20,337 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-08 22:29:20,374 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-08 22:29:20,411 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-08 22:29:20,450 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-08 22:29:20,487 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-08 22:29:20,523 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-08 22:29:20,558 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-08 22:29:20,593 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-08 22:29:20,629 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-08 22:29:20,665 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-08 22:29:20,703 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-08 22:29:20,741 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-08 22:29:20,778 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-08 22:29:20,817 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-08 22:29:20,853 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-08 22:29:20,888 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-08 22:29:20,922 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-08 22:29:20,958 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-08 22:29:20,994 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-08 22:29:21,032 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-08 22:29:21,069 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-08 22:29:21,106 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-08 22:29:21,143 : INFO : PROGRESS: at 58.68% examples, 311865 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:21,144 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-08 22:29:21,181 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-08 22:29:21,217 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-08 22:29:21,251 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-08 22:29:21,289 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-08 22:29:21,325 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-08 22:29:21,361 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-08 22:29:21,399 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-08 22:29:21,435 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-08 22:29:21,472 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-08 22:29:21,510 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-08 22:29:21,546 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-08 22:29:21,581 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-08 22:29:21,616 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-08 22:29:21,655 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-08 22:29:21,691 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-08 22:29:21,728 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-08 22:29:21,801 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:21,871 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:21,871 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:21,871 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311739 effective words/s
2016-10-08 22:29:21,871 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:21,871 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:21,873 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-08 22:29:21,873 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-08 22:29:21,874 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-08 22:29:21,875 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-08 22:29:21,911 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-08 22:29:21,945 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-08 22:29:21,979 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-08 22:29:22,015 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-08 22:29:22,052 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-08 22:29:22,090 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-08 22:29:22,129 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-08 22:29:22,170 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-08 22:29:22,210 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-08 22:29:22,252 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-08 22:29:22,295 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-08 22:29:22,335 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-08 22:29:22,377 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-08 22:29:22,417 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-08 22:29:22,458 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-08 22:29:22,501 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-08 22:29:22,539 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-08 22:29:22,580 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-08 22:29:22,620 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-08 22:29:22,657 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-08 22:29:22,694 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-08 22:29:22,730 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-08 22:29:22,767 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-08 22:29:22,814 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-08 22:29:22,860 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-08 22:29:22,898 : INFO : PROGRESS: at 55.16% examples, 288372 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:22,899 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-08 22:29:22,940 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-08 22:29:22,979 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-08 22:29:23,018 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-08 22:29:23,057 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-08 22:29:23,092 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-08 22:29:23,131 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-08 22:29:23,170 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-08 22:29:23,212 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-08 22:29:23,254 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-08 22:29:23,299 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-08 22:29:23,340 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-08 22:29:23,382 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-08 22:29:23,421 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-08 22:29:23,462 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-08 22:29:23,506 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-08 22:29:23,550 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-08 22:29:23,590 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-08 22:29:23,632 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-08 22:29:23,719 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:23,794 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:23,794 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:23,794 : INFO : training on 478080 raw words (545575 effective words) took 1.9s, 284098 effective words/s
2016-10-08 22:29:23,794 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:23,794 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:23,796 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-08 22:29:23,796 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-08 22:29:23,797 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-08 22:29:23,798 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-08 22:29:23,836 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-08 22:29:23,870 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-08 22:29:23,905 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-08 22:29:23,940 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-08 22:29:23,976 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-08 22:29:24,013 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-08 22:29:24,050 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-08 22:29:24,086 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-08 22:29:24,124 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-08 22:29:24,161 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-08 22:29:24,197 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-08 22:29:24,235 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-08 22:29:24,271 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-08 22:29:24,308 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-08 22:29:24,343 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-08 22:29:24,381 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-08 22:29:24,418 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-08 22:29:24,455 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-08 22:29:24,492 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-08 22:29:24,528 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-08 22:29:24,563 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-08 22:29:24,597 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-08 22:29:24,632 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-08 22:29:24,668 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-08 22:29:24,705 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-08 22:29:24,742 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-08 22:29:24,780 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-08 22:29:24,818 : INFO : PROGRESS: at 58.68% examples, 312365 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:24,818 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-08 22:29:24,856 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-08 22:29:24,892 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-08 22:29:24,930 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-08 22:29:24,965 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-08 22:29:25,000 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-08 22:29:25,037 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-08 22:29:25,075 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-08 22:29:25,111 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-08 22:29:25,148 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-08 22:29:25,186 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-08 22:29:25,222 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-08 22:29:25,258 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-08 22:29:25,293 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-08 22:29:25,328 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-08 22:29:25,366 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-08 22:29:25,403 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-08 22:29:25,474 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:25,545 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:25,545 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:25,545 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312157 effective words/s
2016-10-08 22:29:25,545 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:25,545 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:25,546 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-08 22:29:25,547 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-08 22:29:25,548 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-08 22:29:25,549 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-08 22:29:25,585 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-08 22:29:25,620 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-08 22:29:25,655 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-08 22:29:25,690 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-08 22:29:25,730 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-08 22:29:25,768 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-08 22:29:25,806 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-08 22:29:25,846 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-08 22:29:25,886 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-08 22:29:25,923 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-08 22:29:25,959 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-08 22:29:25,994 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-08 22:29:26,031 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-08 22:29:26,070 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-08 22:29:26,106 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-08 22:29:26,144 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-08 22:29:26,181 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-08 22:29:26,219 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-08 22:29:26,258 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-08 22:29:26,296 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-08 22:29:26,331 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-08 22:29:26,370 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-08 22:29:26,405 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-08 22:29:26,444 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-08 22:29:26,481 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-08 22:29:26,522 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-08 22:29:26,558 : INFO : PROGRESS: at 56.90% examples, 303829 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:26,559 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-08 22:29:26,596 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-08 22:29:26,633 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-08 22:29:26,670 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-08 22:29:26,705 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-08 22:29:26,741 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-08 22:29:26,777 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-08 22:29:26,814 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-08 22:29:26,853 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-08 22:29:26,892 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-08 22:29:26,930 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-08 22:29:26,968 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-08 22:29:27,005 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-08 22:29:27,044 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-08 22:29:27,078 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-08 22:29:27,114 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-08 22:29:27,151 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-08 22:29:27,188 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-08 22:29:27,264 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:27,334 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:27,334 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:27,334 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 305353 effective words/s
2016-10-08 22:29:27,335 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:27,335 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:27,336 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-08 22:29:27,337 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-08 22:29:27,337 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-08 22:29:27,338 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-08 22:29:27,374 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-08 22:29:27,408 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-08 22:29:27,443 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-08 22:29:27,482 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-08 22:29:27,518 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-08 22:29:27,555 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-08 22:29:27,591 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-08 22:29:27,627 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-08 22:29:27,665 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-08 22:29:27,702 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-08 22:29:27,737 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-08 22:29:27,774 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-08 22:29:27,809 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-08 22:29:27,845 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-08 22:29:27,882 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-08 22:29:27,922 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-08 22:29:27,959 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-08 22:29:27,996 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-08 22:29:28,034 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-08 22:29:28,070 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-08 22:29:28,108 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-08 22:29:28,143 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-08 22:29:28,179 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-08 22:29:28,218 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-08 22:29:28,256 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-08 22:29:28,294 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-08 22:29:28,332 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-08 22:29:28,370 : INFO : PROGRESS: at 58.68% examples, 308342 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:28,370 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-08 22:29:28,407 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-08 22:29:28,442 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-08 22:29:28,476 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-08 22:29:28,512 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-08 22:29:28,547 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-08 22:29:28,583 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-08 22:29:28,620 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-08 22:29:28,657 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-08 22:29:28,693 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-08 22:29:28,732 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-08 22:29:28,769 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-08 22:29:28,805 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-08 22:29:28,843 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-08 22:29:28,879 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-08 22:29:28,915 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-08 22:29:28,951 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-08 22:29:29,023 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:29,091 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:29,092 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:29,092 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310723 effective words/s
2016-10-08 22:29:29,092 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:29:29,092 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:29:29,093 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-08 22:29:29,094 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-08 22:29:29,095 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-08 22:29:29,095 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-08 22:29:29,132 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-08 22:29:29,169 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-08 22:29:29,204 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-08 22:29:29,240 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-08 22:29:29,283 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-08 22:29:29,321 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-08 22:29:29,358 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-08 22:29:29,394 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-08 22:29:29,431 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-08 22:29:29,467 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-08 22:29:29,502 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-08 22:29:29,537 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-08 22:29:29,572 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-08 22:29:29,607 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-08 22:29:29,643 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-08 22:29:29,680 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-08 22:29:29,717 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-08 22:29:29,755 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-08 22:29:29,793 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-08 22:29:29,829 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-08 22:29:29,866 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-08 22:29:29,902 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-08 22:29:29,937 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-08 22:29:29,973 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-08 22:29:30,011 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-08 22:29:30,048 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-08 22:29:30,084 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-08 22:29:30,124 : INFO : PROGRESS: at 58.68% examples, 309471 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:29:30,125 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-08 22:29:30,162 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-08 22:29:30,199 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-08 22:29:30,236 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-08 22:29:30,272 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-08 22:29:30,308 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-08 22:29:30,344 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-08 22:29:30,382 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-08 22:29:30,417 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-08 22:29:30,454 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-08 22:29:30,491 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-08 22:29:30,527 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-08 22:29:30,561 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-08 22:29:30,595 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-08 22:29:30,630 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-08 22:29:30,666 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-08 22:29:30,702 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-08 22:29:30,781 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:29:30,851 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:29:30,851 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:29:30,852 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310502 effective words/s
2016-10-08 22:29:30,852 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-08 22:29:30,852 : INFO : not storing attribute cum_table
2016-10-08 22:29:30,852 : INFO : not storing attribute syn0norm
2016-10-08 22:31:59,055 : INFO : collecting all words and their counts
2016-10-08 22:31:59,055 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-08 22:31:59,142 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-08 22:31:59,152 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-08 22:31:59,152 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-08 22:31:59,157 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-08 22:31:59,157 : INFO : sample=0 downsamples 0 most-common words
2016-10-08 22:31:59,158 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-08 22:31:59,158 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-08 22:31:59,159 : INFO : constructing a huffman tree from 2637 words
2016-10-08 22:31:59,216 : INFO : built huffman tree with maximum node depth 14
2016-10-08 22:31:59,217 : INFO : resetting layer weights
2016-10-08 22:31:59,250 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:31:59,250 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:31:59,251 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-08 22:31:59,252 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-08 22:31:59,253 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-08 22:31:59,254 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-08 22:31:59,291 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-08 22:31:59,325 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-08 22:31:59,360 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-08 22:31:59,395 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-08 22:31:59,431 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-08 22:31:59,468 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-08 22:31:59,504 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-08 22:31:59,541 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-08 22:31:59,578 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-08 22:31:59,618 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-08 22:31:59,654 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-08 22:31:59,691 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-08 22:31:59,726 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-08 22:31:59,763 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-08 22:31:59,799 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-08 22:31:59,837 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-08 22:31:59,873 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-08 22:31:59,913 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-08 22:31:59,951 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-08 22:31:59,987 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-08 22:32:00,022 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-08 22:32:00,057 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-08 22:32:00,092 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-08 22:32:00,127 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-08 22:32:00,164 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-08 22:32:00,201 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-08 22:32:00,238 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-08 22:32:00,276 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-08 22:32:00,276 : INFO : PROGRESS: at 58.68% examples, 311389 words/s, in_qsize 2, out_qsize 0
2016-10-08 22:32:00,313 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-08 22:32:00,349 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-08 22:32:00,383 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-08 22:32:00,420 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-08 22:32:00,456 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-08 22:32:00,491 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-08 22:32:00,529 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-08 22:32:00,565 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-08 22:32:00,601 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-08 22:32:00,639 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-08 22:32:00,675 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-08 22:32:00,709 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-08 22:32:00,745 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-08 22:32:00,780 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-08 22:32:00,816 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-08 22:32:00,853 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-08 22:32:00,935 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:01,003 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:01,003 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:01,003 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311718 effective words/s
2016-10-08 22:32:01,003 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:01,003 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:01,004 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-08 22:32:01,005 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:01,006 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-08 22:32:01,007 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-08 22:32:01,043 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-08 22:32:01,077 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-08 22:32:01,111 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-08 22:32:01,148 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-08 22:32:01,184 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-08 22:32:01,220 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-08 22:32:01,256 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-08 22:32:01,292 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-08 22:32:01,333 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-08 22:32:01,369 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-08 22:32:01,404 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-08 22:32:01,439 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-08 22:32:01,474 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-08 22:32:01,509 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-08 22:32:01,544 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-08 22:32:01,582 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-08 22:32:01,622 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:01,658 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-08 22:32:01,695 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-08 22:32:01,734 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-08 22:32:01,768 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-08 22:32:01,808 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-08 22:32:01,844 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-08 22:32:01,880 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-08 22:32:01,916 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-08 22:32:01,952 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-08 22:32:01,988 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:02,024 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:02,025 : INFO : PROGRESS: at 58.68% examples, 312717 words/s, in_qsize 2, out_qsize 0
2016-10-08 22:32:02,064 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-08 22:32:02,099 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-08 22:32:02,133 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-08 22:32:02,168 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-08 22:32:02,203 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-08 22:32:02,238 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-08 22:32:02,276 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-08 22:32:02,312 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-08 22:32:02,348 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:02,385 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-08 22:32:02,423 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:02,457 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-08 22:32:02,491 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-08 22:32:02,526 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-08 22:32:02,562 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-08 22:32:02,597 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-08 22:32:02,668 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:02,736 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:02,736 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:02,736 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315221 effective words/s
2016-10-08 22:32:02,737 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:02,737 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:02,738 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-08 22:32:02,739 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-08 22:32:02,739 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-08 22:32:02,740 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-08 22:32:02,776 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-08 22:32:02,810 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-08 22:32:02,844 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-08 22:32:02,879 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-08 22:32:02,915 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-08 22:32:02,951 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-08 22:32:02,988 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-08 22:32:03,027 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-08 22:32:03,064 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-08 22:32:03,100 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-08 22:32:03,135 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-08 22:32:03,169 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-08 22:32:03,204 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-08 22:32:03,240 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-08 22:32:03,275 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-08 22:32:03,312 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-08 22:32:03,348 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-08 22:32:03,384 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-08 22:32:03,421 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-08 22:32:03,457 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-08 22:32:03,491 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-08 22:32:03,525 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-08 22:32:03,560 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-08 22:32:03,596 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-08 22:32:03,632 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-08 22:32:03,668 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-08 22:32:03,704 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-08 22:32:03,741 : INFO : PROGRESS: at 58.68% examples, 318023 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:03,742 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-08 22:32:03,778 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-08 22:32:03,817 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-08 22:32:03,854 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-08 22:32:03,888 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-08 22:32:03,923 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-08 22:32:03,959 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-08 22:32:03,996 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-08 22:32:04,033 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-08 22:32:04,069 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-08 22:32:04,107 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-08 22:32:04,144 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-08 22:32:04,178 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-08 22:32:04,212 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-08 22:32:04,248 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-08 22:32:04,283 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-08 22:32:04,319 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-08 22:32:04,390 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:04,458 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:04,458 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:04,458 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 317391 effective words/s
2016-10-08 22:32:04,458 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:04,458 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:04,460 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-08 22:32:04,460 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-08 22:32:04,461 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-08 22:32:04,462 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-08 22:32:04,497 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-08 22:32:04,532 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-08 22:32:04,567 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-08 22:32:04,602 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-08 22:32:04,640 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-08 22:32:04,677 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-08 22:32:04,714 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-08 22:32:04,750 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-08 22:32:04,788 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-08 22:32:04,824 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-08 22:32:04,860 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-08 22:32:04,894 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-08 22:32:04,929 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-08 22:32:04,965 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-08 22:32:05,000 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-08 22:32:05,039 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-08 22:32:05,076 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-08 22:32:05,116 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-08 22:32:05,154 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-08 22:32:05,190 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-08 22:32:05,225 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-08 22:32:05,260 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-08 22:32:05,295 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-08 22:32:05,331 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-08 22:32:05,368 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-08 22:32:05,405 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-08 22:32:05,441 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-08 22:32:05,478 : INFO : PROGRESS: at 58.68% examples, 313344 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:05,479 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-08 22:32:05,517 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-08 22:32:05,553 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-08 22:32:05,588 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-08 22:32:05,622 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-08 22:32:05,658 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-08 22:32:05,697 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-08 22:32:05,735 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-08 22:32:05,772 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-08 22:32:05,809 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-08 22:32:05,847 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-08 22:32:05,883 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-08 22:32:05,917 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-08 22:32:05,952 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-08 22:32:05,987 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-08 22:32:06,022 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-08 22:32:06,059 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-08 22:32:06,131 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:06,199 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:06,200 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:06,200 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 313783 effective words/s
2016-10-08 22:32:06,200 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:06,200 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:06,201 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-08 22:32:06,202 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-08 22:32:06,202 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-08 22:32:06,203 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-08 22:32:06,239 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-08 22:32:06,273 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-08 22:32:06,307 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-08 22:32:06,342 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-08 22:32:06,378 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-08 22:32:06,414 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-08 22:32:06,450 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-08 22:32:06,486 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-08 22:32:06,523 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-08 22:32:06,560 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-08 22:32:06,595 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-08 22:32:06,629 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-08 22:32:06,664 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-08 22:32:06,700 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-08 22:32:06,739 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-08 22:32:06,777 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-08 22:32:06,812 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-08 22:32:06,849 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-08 22:32:06,886 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-08 22:32:06,921 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-08 22:32:06,956 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-08 22:32:06,990 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-08 22:32:07,026 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-08 22:32:07,062 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-08 22:32:07,098 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-08 22:32:07,137 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-08 22:32:07,174 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-08 22:32:07,210 : INFO : PROGRESS: at 58.68% examples, 316297 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:07,211 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-08 22:32:07,247 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-08 22:32:07,283 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-08 22:32:07,316 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-08 22:32:07,351 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-08 22:32:07,386 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-08 22:32:07,422 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-08 22:32:07,459 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-08 22:32:07,495 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-08 22:32:07,531 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-08 22:32:07,569 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-08 22:32:07,605 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-08 22:32:07,639 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-08 22:32:07,674 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-08 22:32:07,711 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-08 22:32:07,750 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-08 22:32:07,786 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-08 22:32:07,861 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:07,929 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:07,929 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:07,929 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315959 effective words/s
2016-10-08 22:32:07,929 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:07,929 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:07,931 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-08 22:32:07,931 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-08 22:32:07,932 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-08 22:32:07,933 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-08 22:32:07,970 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-08 22:32:08,004 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-08 22:32:08,049 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-08 22:32:08,084 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-08 22:32:08,121 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-08 22:32:08,157 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-08 22:32:08,195 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-08 22:32:08,232 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-08 22:32:08,270 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-08 22:32:08,306 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-08 22:32:08,345 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-08 22:32:08,380 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-08 22:32:08,415 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-08 22:32:08,452 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-08 22:32:08,488 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-08 22:32:08,525 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-08 22:32:08,562 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-08 22:32:08,599 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-08 22:32:08,637 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-08 22:32:08,673 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-08 22:32:08,707 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-08 22:32:08,743 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-08 22:32:08,779 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-08 22:32:08,814 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-08 22:32:08,851 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-08 22:32:08,888 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-08 22:32:08,925 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-08 22:32:08,962 : INFO : PROGRESS: at 58.68% examples, 309493 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:08,963 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-08 22:32:08,999 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-08 22:32:09,036 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-08 22:32:09,070 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-08 22:32:09,105 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-08 22:32:09,141 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-08 22:32:09,177 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-08 22:32:09,214 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-08 22:32:09,251 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-08 22:32:09,288 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-08 22:32:09,325 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-08 22:32:09,362 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-08 22:32:09,397 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-08 22:32:09,431 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-08 22:32:09,467 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-08 22:32:09,502 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-08 22:32:09,538 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-08 22:32:09,610 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:09,678 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:09,678 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:09,679 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312382 effective words/s
2016-10-08 22:32:09,679 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:09,679 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:09,680 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-08 22:32:09,681 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-08 22:32:09,681 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-08 22:32:09,682 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-08 22:32:09,718 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-08 22:32:09,753 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-08 22:32:09,788 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-08 22:32:09,823 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-08 22:32:09,858 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-08 22:32:09,895 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-08 22:32:09,931 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-08 22:32:09,967 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-08 22:32:10,003 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-08 22:32:10,040 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-08 22:32:10,075 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-08 22:32:10,109 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-08 22:32:10,144 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-08 22:32:10,179 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-08 22:32:10,214 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-08 22:32:10,251 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-08 22:32:10,287 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-08 22:32:10,326 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-08 22:32:10,364 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-08 22:32:10,399 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-08 22:32:10,434 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-08 22:32:10,469 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-08 22:32:10,504 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-08 22:32:10,539 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-08 22:32:10,575 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-08 22:32:10,611 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-08 22:32:10,648 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-08 22:32:10,684 : INFO : PROGRESS: at 58.68% examples, 317914 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:10,685 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-08 22:32:10,724 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-08 22:32:10,759 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-08 22:32:10,793 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-08 22:32:10,828 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-08 22:32:10,863 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-08 22:32:10,898 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-08 22:32:10,935 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-08 22:32:10,972 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-08 22:32:11,007 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-08 22:32:11,045 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-08 22:32:11,081 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-08 22:32:11,115 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-08 22:32:11,149 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-08 22:32:11,184 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-08 22:32:11,223 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-08 22:32:11,259 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-08 22:32:11,340 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:11,407 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:11,407 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:11,407 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316123 effective words/s
2016-10-08 22:32:11,407 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:11,407 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:11,409 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-08 22:32:11,409 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-08 22:32:11,410 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-08 22:32:11,411 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-08 22:32:11,447 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-08 22:32:11,481 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-08 22:32:11,515 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-08 22:32:11,550 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-08 22:32:11,586 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-08 22:32:11,624 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-08 22:32:11,660 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-08 22:32:11,699 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-08 22:32:11,740 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-08 22:32:11,776 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-08 22:32:11,815 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-08 22:32:11,849 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-08 22:32:11,884 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-08 22:32:11,919 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-08 22:32:11,954 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-08 22:32:11,991 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-08 22:32:12,029 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-08 22:32:12,066 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-08 22:32:12,103 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-08 22:32:12,138 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-08 22:32:12,172 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-08 22:32:12,206 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-08 22:32:12,241 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-08 22:32:12,277 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-08 22:32:12,313 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-08 22:32:12,349 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-08 22:32:12,385 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-08 22:32:12,425 : INFO : PROGRESS: at 58.68% examples, 314065 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:12,426 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-08 22:32:12,462 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-08 22:32:12,498 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-08 22:32:12,533 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-08 22:32:12,569 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-08 22:32:12,606 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-08 22:32:12,641 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-08 22:32:12,679 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-08 22:32:12,716 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-08 22:32:12,753 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-08 22:32:12,805 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-08 22:32:12,843 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-08 22:32:12,878 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-08 22:32:12,912 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-08 22:32:12,959 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-08 22:32:12,998 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-08 22:32:13,041 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-08 22:32:13,121 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:13,192 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:13,192 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:13,192 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 306191 effective words/s
2016-10-08 22:32:13,192 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:13,192 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:13,193 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-08 22:32:13,194 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-08 22:32:13,195 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-08 22:32:13,196 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-08 22:32:13,231 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-08 22:32:13,266 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-08 22:32:13,300 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-08 22:32:13,336 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-08 22:32:13,372 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-08 22:32:13,408 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-08 22:32:13,445 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-08 22:32:13,482 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-08 22:32:13,519 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-08 22:32:13,556 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-08 22:32:13,591 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-08 22:32:13,629 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-08 22:32:13,664 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-08 22:32:13,700 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-08 22:32:13,736 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-08 22:32:13,773 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-08 22:32:13,810 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-08 22:32:13,848 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-08 22:32:13,885 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-08 22:32:13,921 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-08 22:32:13,957 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-08 22:32:13,992 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-08 22:32:14,030 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-08 22:32:14,069 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-08 22:32:14,106 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-08 22:32:14,143 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-08 22:32:14,180 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-08 22:32:14,216 : INFO : PROGRESS: at 58.68% examples, 312028 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:14,217 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-08 22:32:14,255 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-08 22:32:14,290 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-08 22:32:14,325 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-08 22:32:14,360 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-08 22:32:14,397 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-08 22:32:14,435 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-08 22:32:14,472 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-08 22:32:14,508 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-08 22:32:14,545 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-08 22:32:14,582 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-08 22:32:14,619 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-08 22:32:14,655 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-08 22:32:14,689 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-08 22:32:14,725 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-08 22:32:14,760 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-08 22:32:14,796 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-08 22:32:14,871 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:14,940 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:14,940 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:14,940 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312583 effective words/s
2016-10-08 22:32:14,940 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:14,940 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:14,941 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-08 22:32:14,942 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-08 22:32:14,943 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-08 22:32:14,944 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-08 22:32:14,980 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-08 22:32:15,014 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-08 22:32:15,049 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-08 22:32:15,085 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-08 22:32:15,121 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-08 22:32:15,157 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-08 22:32:15,194 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-08 22:32:15,234 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-08 22:32:15,271 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-08 22:32:15,307 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-08 22:32:15,342 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-08 22:32:15,377 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-08 22:32:15,412 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-08 22:32:15,448 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-08 22:32:15,484 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-08 22:32:15,522 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-08 22:32:15,558 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-08 22:32:15,595 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-08 22:32:15,633 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-08 22:32:15,669 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-08 22:32:15,704 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-08 22:32:15,740 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-08 22:32:15,775 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-08 22:32:15,811 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-08 22:32:15,848 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-08 22:32:15,885 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-08 22:32:15,921 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-08 22:32:15,958 : INFO : PROGRESS: at 58.68% examples, 314016 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:15,959 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-08 22:32:15,995 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-08 22:32:16,031 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-08 22:32:16,065 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-08 22:32:16,100 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-08 22:32:16,135 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-08 22:32:16,171 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-08 22:32:16,209 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-08 22:32:16,246 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-08 22:32:16,282 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-08 22:32:16,320 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-08 22:32:16,362 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-08 22:32:16,397 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-08 22:32:16,431 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-08 22:32:16,466 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-08 22:32:16,502 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-08 22:32:16,538 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-08 22:32:16,611 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:16,680 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:16,680 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:16,680 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 314042 effective words/s
2016-10-08 22:32:16,680 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-08 22:32:16,680 : INFO : not storing attribute syn0norm
2016-10-08 22:32:16,680 : INFO : not storing attribute cum_table
2016-10-08 22:32:54,982 : INFO : collecting all words and their counts
2016-10-08 22:32:54,982 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-08 22:32:55,068 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-08 22:32:55,077 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-08 22:32:55,077 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-08 22:32:55,082 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-08 22:32:55,082 : INFO : sample=0 downsamples 0 most-common words
2016-10-08 22:32:55,083 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-08 22:32:55,083 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-08 22:32:55,084 : INFO : constructing a huffman tree from 2637 words
2016-10-08 22:32:55,140 : INFO : built huffman tree with maximum node depth 14
2016-10-08 22:32:55,140 : INFO : resetting layer weights
2016-10-08 22:32:55,174 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:55,175 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:55,176 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-08 22:32:55,176 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-08 22:32:55,177 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-08 22:32:55,178 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-08 22:32:55,215 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-08 22:32:55,250 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-08 22:32:55,284 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-08 22:32:55,323 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-08 22:32:55,359 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-08 22:32:55,395 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-08 22:32:55,432 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-08 22:32:55,468 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-08 22:32:55,506 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-08 22:32:55,542 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-08 22:32:55,577 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-08 22:32:55,615 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-08 22:32:55,650 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-08 22:32:55,686 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-08 22:32:55,722 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-08 22:32:55,759 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-08 22:32:55,795 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-08 22:32:55,832 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-08 22:32:55,871 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-08 22:32:55,906 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-08 22:32:55,941 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-08 22:32:55,976 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-08 22:32:56,011 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-08 22:32:56,047 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-08 22:32:56,083 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-08 22:32:56,120 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-08 22:32:56,157 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-08 22:32:56,193 : INFO : PROGRESS: at 58.68% examples, 313620 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:56,194 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-08 22:32:56,231 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-08 22:32:56,267 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-08 22:32:56,301 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-08 22:32:56,336 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-08 22:32:56,372 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-08 22:32:56,411 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-08 22:32:56,449 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-08 22:32:56,486 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-08 22:32:56,522 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-08 22:32:56,560 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-08 22:32:56,596 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-08 22:32:56,631 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-08 22:32:56,669 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-08 22:32:56,704 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-08 22:32:56,743 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-08 22:32:56,780 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-08 22:32:56,855 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:56,927 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:56,927 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:56,927 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311740 effective words/s
2016-10-08 22:32:56,927 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:56,927 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:56,929 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-08 22:32:56,929 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:56,930 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-08 22:32:56,931 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-08 22:32:56,967 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-08 22:32:57,001 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-08 22:32:57,037 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-08 22:32:57,072 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-08 22:32:57,108 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-08 22:32:57,145 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-08 22:32:57,182 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-08 22:32:57,219 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-08 22:32:57,257 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-08 22:32:57,294 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-08 22:32:57,334 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-08 22:32:57,368 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-08 22:32:57,404 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-08 22:32:57,440 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-08 22:32:57,476 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-08 22:32:57,513 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-08 22:32:57,550 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:57,587 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-08 22:32:57,625 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-08 22:32:57,661 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-08 22:32:57,696 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-08 22:32:57,731 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-08 22:32:57,770 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-08 22:32:57,809 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-08 22:32:57,847 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-08 22:32:57,884 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-08 22:32:57,921 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:57,958 : INFO : PROGRESS: at 58.68% examples, 310077 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:57,959 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:57,996 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-08 22:32:58,032 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-08 22:32:58,067 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-08 22:32:58,102 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-08 22:32:58,139 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-08 22:32:58,174 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-08 22:32:58,212 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-08 22:32:58,249 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-08 22:32:58,286 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-08 22:32:58,324 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-08 22:32:58,360 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-08 22:32:58,396 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-08 22:32:58,430 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-08 22:32:58,466 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-08 22:32:58,502 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-08 22:32:58,539 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-08 22:32:58,611 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:32:58,680 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:32:58,681 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:32:58,681 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311647 effective words/s
2016-10-08 22:32:58,681 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:32:58,681 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:32:58,682 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-08 22:32:58,683 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-08 22:32:58,683 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-08 22:32:58,684 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-08 22:32:58,721 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-08 22:32:58,755 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-08 22:32:58,790 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-08 22:32:58,825 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-08 22:32:58,860 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-08 22:32:58,897 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-08 22:32:58,933 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-08 22:32:58,969 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-08 22:32:59,007 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-08 22:32:59,043 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-08 22:32:59,079 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-08 22:32:59,113 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-08 22:32:59,148 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-08 22:32:59,183 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-08 22:32:59,219 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-08 22:32:59,256 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-08 22:32:59,293 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-08 22:32:59,331 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-08 22:32:59,369 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-08 22:32:59,404 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-08 22:32:59,439 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-08 22:32:59,473 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-08 22:32:59,508 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-08 22:32:59,544 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-08 22:32:59,583 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-08 22:32:59,619 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-08 22:32:59,655 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-08 22:32:59,691 : INFO : PROGRESS: at 58.68% examples, 316174 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:32:59,693 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-08 22:32:59,730 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-08 22:32:59,765 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-08 22:32:59,799 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-08 22:32:59,834 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-08 22:32:59,870 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-08 22:32:59,905 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-08 22:32:59,946 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-08 22:32:59,982 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-08 22:33:00,019 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-08 22:33:00,056 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-08 22:33:00,092 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-08 22:33:00,127 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-08 22:33:00,161 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-08 22:33:00,196 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-08 22:33:00,231 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-08 22:33:00,267 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-08 22:33:00,338 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:00,406 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:00,406 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:00,406 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316762 effective words/s
2016-10-08 22:33:00,406 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:00,406 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:00,407 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-08 22:33:00,408 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-08 22:33:00,409 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-08 22:33:00,409 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-08 22:33:00,445 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-08 22:33:00,480 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-08 22:33:00,514 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-08 22:33:00,550 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-08 22:33:00,586 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-08 22:33:00,623 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-08 22:33:00,660 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-08 22:33:00,696 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-08 22:33:00,737 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-08 22:33:00,775 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-08 22:33:00,811 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-08 22:33:00,849 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-08 22:33:00,884 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-08 22:33:00,924 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-08 22:33:00,962 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-08 22:33:01,004 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-08 22:33:01,046 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-08 22:33:01,086 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-08 22:33:01,127 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-08 22:33:01,168 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-08 22:33:01,204 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-08 22:33:01,241 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-08 22:33:01,279 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-08 22:33:01,319 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-08 22:33:01,363 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-08 22:33:01,402 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-08 22:33:01,444 : INFO : PROGRESS: at 56.90% examples, 296419 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:01,445 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-08 22:33:01,483 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-08 22:33:01,522 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-08 22:33:01,560 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-08 22:33:01,595 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-08 22:33:01,632 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-08 22:33:01,672 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-08 22:33:01,711 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-08 22:33:01,753 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-08 22:33:01,796 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-08 22:33:01,834 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-08 22:33:01,887 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-08 22:33:01,924 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-08 22:33:01,961 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-08 22:33:01,996 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-08 22:33:02,036 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-08 22:33:02,074 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-08 22:33:02,114 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-08 22:33:02,188 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:02,259 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:02,259 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:02,259 : INFO : training on 478080 raw words (545575 effective words) took 1.9s, 294841 effective words/s
2016-10-08 22:33:02,259 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:02,259 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:02,260 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-08 22:33:02,261 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-08 22:33:02,262 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-08 22:33:02,263 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-08 22:33:02,299 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-08 22:33:02,334 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-08 22:33:02,369 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-08 22:33:02,406 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-08 22:33:02,442 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-08 22:33:02,479 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-08 22:33:02,516 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-08 22:33:02,553 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-08 22:33:02,593 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-08 22:33:02,631 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-08 22:33:02,671 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-08 22:33:02,708 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-08 22:33:02,745 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-08 22:33:02,782 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-08 22:33:02,819 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-08 22:33:02,859 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-08 22:33:02,900 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-08 22:33:02,938 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-08 22:33:02,978 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-08 22:33:03,019 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-08 22:33:03,058 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-08 22:33:03,097 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-08 22:33:03,135 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-08 22:33:03,173 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-08 22:33:03,218 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-08 22:33:03,256 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-08 22:33:03,298 : INFO : PROGRESS: at 56.90% examples, 296142 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:03,299 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-08 22:33:03,341 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-08 22:33:03,381 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-08 22:33:03,423 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-08 22:33:03,462 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-08 22:33:03,498 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-08 22:33:03,536 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-08 22:33:03,576 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-08 22:33:03,614 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-08 22:33:03,659 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-08 22:33:03,700 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-08 22:33:03,740 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-08 22:33:03,777 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-08 22:33:03,812 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-08 22:33:03,849 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-08 22:33:03,885 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-08 22:33:03,922 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-08 22:33:03,958 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-08 22:33:04,042 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:04,114 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:04,114 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:04,115 : INFO : training on 478080 raw words (545575 effective words) took 1.9s, 294452 effective words/s
2016-10-08 22:33:04,115 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:04,115 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:04,116 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-08 22:33:04,117 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-08 22:33:04,117 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-08 22:33:04,118 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-08 22:33:04,154 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-08 22:33:04,189 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-08 22:33:04,223 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-08 22:33:04,259 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-08 22:33:04,296 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-08 22:33:04,333 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-08 22:33:04,370 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-08 22:33:04,407 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-08 22:33:04,444 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-08 22:33:04,481 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-08 22:33:04,517 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-08 22:33:04,551 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-08 22:33:04,586 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-08 22:33:04,622 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-08 22:33:04,660 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-08 22:33:04,697 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-08 22:33:04,733 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-08 22:33:04,770 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-08 22:33:04,810 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-08 22:33:04,846 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-08 22:33:04,880 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-08 22:33:04,915 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-08 22:33:04,953 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-08 22:33:04,989 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-08 22:33:05,029 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-08 22:33:05,066 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-08 22:33:05,102 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-08 22:33:05,139 : INFO : PROGRESS: at 58.68% examples, 312027 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:05,140 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-08 22:33:05,177 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-08 22:33:05,213 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-08 22:33:05,247 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-08 22:33:05,284 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-08 22:33:05,323 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-08 22:33:05,359 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-08 22:33:05,397 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-08 22:33:05,433 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-08 22:33:05,470 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-08 22:33:05,507 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-08 22:33:05,543 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-08 22:33:05,578 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-08 22:33:05,612 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-08 22:33:05,648 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-08 22:33:05,683 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-08 22:33:05,720 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-08 22:33:05,795 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:05,864 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:05,864 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:05,864 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312358 effective words/s
2016-10-08 22:33:05,864 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:05,864 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:05,865 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-08 22:33:05,866 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-08 22:33:05,867 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-08 22:33:05,868 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-08 22:33:05,904 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-08 22:33:05,939 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-08 22:33:05,973 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-08 22:33:06,009 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-08 22:33:06,045 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-08 22:33:06,082 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-08 22:33:06,119 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-08 22:33:06,157 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-08 22:33:06,195 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-08 22:33:06,231 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-08 22:33:06,267 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-08 22:33:06,306 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-08 22:33:06,343 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-08 22:33:06,379 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-08 22:33:06,416 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-08 22:33:06,455 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-08 22:33:06,491 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-08 22:33:06,528 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-08 22:33:06,565 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-08 22:33:06,601 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-08 22:33:06,636 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-08 22:33:06,672 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-08 22:33:06,708 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-08 22:33:06,744 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-08 22:33:06,780 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-08 22:33:06,817 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-08 22:33:06,853 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-08 22:33:06,890 : INFO : PROGRESS: at 58.68% examples, 311542 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:06,891 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-08 22:33:06,928 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-08 22:33:06,971 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-08 22:33:07,005 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-08 22:33:07,040 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-08 22:33:07,076 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-08 22:33:07,112 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-08 22:33:07,149 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-08 22:33:07,185 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-08 22:33:07,225 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-08 22:33:07,263 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-08 22:33:07,299 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-08 22:33:07,334 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-08 22:33:07,368 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-08 22:33:07,404 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-08 22:33:07,440 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-08 22:33:07,476 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-08 22:33:07,551 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:07,619 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:07,619 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:07,619 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311302 effective words/s
2016-10-08 22:33:07,619 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:07,619 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:07,621 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-08 22:33:07,621 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-08 22:33:07,622 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-08 22:33:07,623 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-08 22:33:07,659 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-08 22:33:07,694 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-08 22:33:07,729 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-08 22:33:07,765 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-08 22:33:07,802 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-08 22:33:07,839 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-08 22:33:07,876 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-08 22:33:07,913 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-08 22:33:07,951 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-08 22:33:07,987 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-08 22:33:08,023 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-08 22:33:08,057 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-08 22:33:08,093 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-08 22:33:08,130 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-08 22:33:08,168 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-08 22:33:08,205 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-08 22:33:08,242 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-08 22:33:08,279 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-08 22:33:08,317 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-08 22:33:08,353 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-08 22:33:08,388 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-08 22:33:08,423 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-08 22:33:08,459 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-08 22:33:08,495 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-08 22:33:08,532 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-08 22:33:08,569 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-08 22:33:08,606 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-08 22:33:08,643 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-08 22:33:08,643 : INFO : PROGRESS: at 58.68% examples, 312080 words/s, in_qsize 2, out_qsize 0
2016-10-08 22:33:08,684 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-08 22:33:08,721 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-08 22:33:08,758 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-08 22:33:08,793 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-08 22:33:08,832 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-08 22:33:08,869 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-08 22:33:08,907 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-08 22:33:08,946 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-08 22:33:08,983 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-08 22:33:09,021 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-08 22:33:09,057 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-08 22:33:09,093 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-08 22:33:09,130 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-08 22:33:09,166 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-08 22:33:09,202 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-08 22:33:09,238 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-08 22:33:09,311 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:09,380 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:09,380 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:09,380 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310330 effective words/s
2016-10-08 22:33:09,380 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:09,380 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:09,382 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-08 22:33:09,382 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-08 22:33:09,383 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-08 22:33:09,384 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-08 22:33:09,423 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-08 22:33:09,458 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-08 22:33:09,493 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-08 22:33:09,528 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-08 22:33:09,564 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-08 22:33:09,601 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-08 22:33:09,638 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-08 22:33:09,674 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-08 22:33:09,711 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-08 22:33:09,749 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-08 22:33:09,784 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-08 22:33:09,819 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-08 22:33:09,854 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-08 22:33:09,890 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-08 22:33:09,926 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-08 22:33:09,963 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-08 22:33:10,000 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-08 22:33:10,036 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-08 22:33:10,074 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-08 22:33:10,110 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-08 22:33:10,144 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-08 22:33:10,179 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-08 22:33:10,214 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-08 22:33:10,250 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-08 22:33:10,287 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-08 22:33:10,324 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-08 22:33:10,360 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-08 22:33:10,397 : INFO : PROGRESS: at 58.68% examples, 314303 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:10,398 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-08 22:33:10,435 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-08 22:33:10,470 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-08 22:33:10,505 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-08 22:33:10,540 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-08 22:33:10,575 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-08 22:33:10,611 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-08 22:33:10,649 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-08 22:33:10,685 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-08 22:33:10,722 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-08 22:33:10,760 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-08 22:33:10,796 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-08 22:33:10,831 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-08 22:33:10,866 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-08 22:33:10,901 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-08 22:33:10,937 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-08 22:33:10,973 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-08 22:33:11,045 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:11,114 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:11,114 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:11,114 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315184 effective words/s
2016-10-08 22:33:11,114 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:33:11,114 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:33:11,115 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-08 22:33:11,116 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-08 22:33:11,117 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-08 22:33:11,118 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-08 22:33:11,154 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-08 22:33:11,190 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-08 22:33:11,225 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-08 22:33:11,260 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-08 22:33:11,296 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-08 22:33:11,333 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-08 22:33:11,370 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-08 22:33:11,406 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-08 22:33:11,443 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-08 22:33:11,480 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-08 22:33:11,516 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-08 22:33:11,550 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-08 22:33:11,585 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-08 22:33:11,621 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-08 22:33:11,657 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-08 22:33:11,697 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-08 22:33:11,737 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-08 22:33:11,774 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-08 22:33:11,811 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-08 22:33:11,847 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-08 22:33:11,882 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-08 22:33:11,917 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-08 22:33:11,953 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-08 22:33:11,989 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-08 22:33:12,025 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-08 22:33:12,062 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-08 22:33:12,099 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-08 22:33:12,135 : INFO : PROGRESS: at 58.68% examples, 313005 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:33:12,136 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-08 22:33:12,172 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-08 22:33:12,208 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-08 22:33:12,243 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-08 22:33:12,278 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-08 22:33:12,314 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-08 22:33:12,349 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-08 22:33:12,387 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-08 22:33:12,423 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-08 22:33:12,459 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-08 22:33:12,497 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-08 22:33:12,533 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-08 22:33:12,570 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-08 22:33:12,604 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-08 22:33:12,639 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-08 22:33:12,675 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-08 22:33:12,711 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-08 22:33:12,807 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:33:12,879 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:33:12,879 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:33:12,879 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309571 effective words/s
2016-10-08 22:33:12,879 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-08 22:33:12,880 : INFO : not storing attribute cum_table
2016-10-08 22:33:12,880 : INFO : not storing attribute syn0norm
2016-10-08 22:34:45,761 : INFO : collecting all words and their counts
2016-10-08 22:34:45,761 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-08 22:34:45,846 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-08 22:34:45,855 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-08 22:34:45,855 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-08 22:34:45,860 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-08 22:34:45,860 : INFO : sample=0 downsamples 0 most-common words
2016-10-08 22:34:45,860 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-08 22:34:45,860 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-08 22:34:45,862 : INFO : constructing a huffman tree from 2637 words
2016-10-08 22:34:45,917 : INFO : built huffman tree with maximum node depth 14
2016-10-08 22:34:45,917 : INFO : resetting layer weights
2016-10-08 22:34:45,952 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:45,952 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:45,953 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-08 22:34:45,954 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-08 22:34:45,954 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-08 22:34:45,955 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-08 22:34:45,992 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-08 22:34:46,026 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-08 22:34:46,060 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-08 22:34:46,095 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-08 22:34:46,131 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-08 22:34:46,167 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-08 22:34:46,203 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-08 22:34:46,239 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-08 22:34:46,276 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-08 22:34:46,312 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-08 22:34:46,348 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-08 22:34:46,383 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-08 22:34:46,418 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-08 22:34:46,453 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-08 22:34:46,489 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-08 22:34:46,525 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-08 22:34:46,562 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-08 22:34:46,598 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-08 22:34:46,635 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-08 22:34:46,670 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-08 22:34:46,704 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-08 22:34:46,739 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-08 22:34:46,774 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-08 22:34:46,812 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-08 22:34:46,849 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-08 22:34:46,885 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-08 22:34:46,924 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-08 22:34:46,960 : INFO : PROGRESS: at 58.68% examples, 316796 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:46,961 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-08 22:34:46,997 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-08 22:34:47,036 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-08 22:34:47,070 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-08 22:34:47,104 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-08 22:34:47,140 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-08 22:34:47,175 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-08 22:34:47,212 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-08 22:34:47,252 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-08 22:34:47,288 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-08 22:34:47,325 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-08 22:34:47,362 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-08 22:34:47,398 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-08 22:34:47,436 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-08 22:34:47,471 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-08 22:34:47,506 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-08 22:34:47,544 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-08 22:34:47,615 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:47,682 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:47,682 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:47,682 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315785 effective words/s
2016-10-08 22:34:47,682 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:47,682 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:47,683 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-08 22:34:47,684 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-08 22:34:47,685 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-08 22:34:47,686 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-08 22:34:47,726 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-08 22:34:47,761 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-08 22:34:47,795 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-08 22:34:47,831 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-08 22:34:47,867 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-08 22:34:47,903 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-08 22:34:47,940 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-08 22:34:47,977 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-08 22:34:48,015 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-08 22:34:48,051 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-08 22:34:48,087 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-08 22:34:48,121 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-08 22:34:48,157 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-08 22:34:48,192 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-08 22:34:48,228 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-08 22:34:48,266 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-08 22:34:48,302 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-08 22:34:48,339 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-08 22:34:48,377 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-08 22:34:48,413 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-08 22:34:48,448 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-08 22:34:48,489 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-08 22:34:48,531 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-08 22:34:48,567 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-08 22:34:48,603 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-08 22:34:48,641 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-08 22:34:48,678 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-08 22:34:48,715 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-08 22:34:48,716 : INFO : PROGRESS: at 58.68% examples, 309159 words/s, in_qsize 2, out_qsize 0
2016-10-08 22:34:48,754 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-08 22:34:48,790 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-08 22:34:48,825 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-08 22:34:48,860 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-08 22:34:48,896 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-08 22:34:48,932 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-08 22:34:48,971 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-08 22:34:49,007 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-08 22:34:49,045 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-08 22:34:49,082 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-08 22:34:49,119 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-08 22:34:49,154 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-08 22:34:49,188 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-08 22:34:49,224 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-08 22:34:49,260 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-08 22:34:49,300 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-08 22:34:49,373 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:49,442 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:49,443 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:49,443 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310382 effective words/s
2016-10-08 22:34:49,443 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:49,443 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:49,444 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-08 22:34:49,445 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-08 22:34:49,446 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-08 22:34:49,446 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-08 22:34:49,482 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-08 22:34:49,516 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-08 22:34:49,550 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-08 22:34:49,585 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-08 22:34:49,621 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-08 22:34:49,657 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-08 22:34:49,693 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-08 22:34:49,731 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-08 22:34:49,768 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-08 22:34:49,804 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-08 22:34:49,840 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-08 22:34:49,874 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-08 22:34:49,908 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-08 22:34:49,943 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-08 22:34:49,979 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-08 22:34:50,016 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-08 22:34:50,052 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-08 22:34:50,088 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-08 22:34:50,125 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-08 22:34:50,161 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-08 22:34:50,195 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-08 22:34:50,232 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-08 22:34:50,268 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-08 22:34:50,303 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-08 22:34:50,339 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-08 22:34:50,376 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-08 22:34:50,412 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-08 22:34:50,448 : INFO : PROGRESS: at 58.68% examples, 317646 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:50,449 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-08 22:34:50,485 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-08 22:34:50,520 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-08 22:34:50,554 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-08 22:34:50,589 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-08 22:34:50,624 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-08 22:34:50,660 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-08 22:34:50,700 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-08 22:34:50,740 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-08 22:34:50,776 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-08 22:34:50,813 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-08 22:34:50,849 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-08 22:34:50,884 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-08 22:34:50,918 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-08 22:34:50,953 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-08 22:34:50,989 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-08 22:34:51,026 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-08 22:34:51,100 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:51,168 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:51,168 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:51,169 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316512 effective words/s
2016-10-08 22:34:51,169 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:51,169 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:51,170 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-08 22:34:51,171 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-08 22:34:51,171 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-08 22:34:51,172 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-08 22:34:51,207 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-08 22:34:51,241 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-08 22:34:51,275 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-08 22:34:51,310 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-08 22:34:51,346 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-08 22:34:51,382 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-08 22:34:51,418 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-08 22:34:51,454 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-08 22:34:51,491 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-08 22:34:51,527 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-08 22:34:51,562 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-08 22:34:51,596 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-08 22:34:51,631 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-08 22:34:51,666 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-08 22:34:51,701 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-08 22:34:51,739 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-08 22:34:51,775 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-08 22:34:51,811 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-08 22:34:51,848 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-08 22:34:51,883 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-08 22:34:51,917 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-08 22:34:51,952 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-08 22:34:51,987 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-08 22:34:52,022 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-08 22:34:52,057 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-08 22:34:52,094 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-08 22:34:52,130 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-08 22:34:52,167 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-08 22:34:52,202 : INFO : PROGRESS: at 60.59% examples, 320376 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:52,203 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-08 22:34:52,239 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-08 22:34:52,274 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-08 22:34:52,308 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-08 22:34:52,343 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-08 22:34:52,379 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-08 22:34:52,416 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-08 22:34:52,452 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-08 22:34:52,495 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-08 22:34:52,539 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-08 22:34:52,574 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-08 22:34:52,608 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-08 22:34:52,642 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-08 22:34:52,677 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-08 22:34:52,712 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-08 22:34:52,748 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-08 22:34:52,819 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:52,891 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:52,891 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:52,892 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 317131 effective words/s
2016-10-08 22:34:52,892 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:52,892 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:52,893 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-08 22:34:52,894 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-08 22:34:52,894 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-08 22:34:52,895 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-08 22:34:52,931 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-08 22:34:52,965 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-08 22:34:53,000 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-08 22:34:53,035 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-08 22:34:53,070 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-08 22:34:53,109 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-08 22:34:53,146 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-08 22:34:53,182 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-08 22:34:53,219 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-08 22:34:53,255 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-08 22:34:53,290 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-08 22:34:53,324 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-08 22:34:53,359 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-08 22:34:53,398 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-08 22:34:53,434 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-08 22:34:53,471 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-08 22:34:53,506 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-08 22:34:53,543 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-08 22:34:53,580 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-08 22:34:53,615 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-08 22:34:53,650 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-08 22:34:53,684 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-08 22:34:53,719 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-08 22:34:53,754 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-08 22:34:53,790 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-08 22:34:53,827 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-08 22:34:53,862 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-08 22:34:53,900 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-08 22:34:53,900 : INFO : PROGRESS: at 58.68% examples, 316930 words/s, in_qsize 2, out_qsize 0
2016-10-08 22:34:53,936 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-08 22:34:53,971 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-08 22:34:54,005 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-08 22:34:54,040 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-08 22:34:54,075 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-08 22:34:54,111 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-08 22:34:54,148 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-08 22:34:54,184 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-08 22:34:54,220 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-08 22:34:54,257 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-08 22:34:54,293 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-08 22:34:54,327 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-08 22:34:54,361 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-08 22:34:54,397 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-08 22:34:54,432 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-08 22:34:54,468 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-08 22:34:54,539 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:54,606 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:54,607 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:54,607 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 318631 effective words/s
2016-10-08 22:34:54,607 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:54,607 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:54,608 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-08 22:34:54,609 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-08 22:34:54,609 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-08 22:34:54,610 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-08 22:34:54,646 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-08 22:34:54,681 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-08 22:34:54,718 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-08 22:34:54,754 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-08 22:34:54,790 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-08 22:34:54,827 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-08 22:34:54,865 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-08 22:34:54,905 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-08 22:34:54,942 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-08 22:34:54,980 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-08 22:34:55,016 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-08 22:34:55,050 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-08 22:34:55,086 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-08 22:34:55,125 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-08 22:34:55,161 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-08 22:34:55,199 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-08 22:34:55,236 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-08 22:34:55,273 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-08 22:34:55,311 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-08 22:34:55,349 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-08 22:34:55,385 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-08 22:34:55,420 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-08 22:34:55,456 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-08 22:34:55,492 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-08 22:34:55,529 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-08 22:34:55,567 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-08 22:34:55,603 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-08 22:34:55,640 : INFO : PROGRESS: at 58.68% examples, 309108 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:55,641 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-08 22:34:55,679 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-08 22:34:55,715 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-08 22:34:55,750 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-08 22:34:55,785 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-08 22:34:55,821 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-08 22:34:55,856 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-08 22:34:55,898 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-08 22:34:55,934 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-08 22:34:55,971 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-08 22:34:56,009 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-08 22:34:56,045 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-08 22:34:56,080 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-08 22:34:56,114 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-08 22:34:56,150 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-08 22:34:56,186 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-08 22:34:56,222 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-08 22:34:56,294 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:56,365 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:56,365 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:56,365 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310704 effective words/s
2016-10-08 22:34:56,365 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:56,366 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:56,367 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-08 22:34:56,368 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-08 22:34:56,368 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-08 22:34:56,369 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-08 22:34:56,405 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-08 22:34:56,439 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-08 22:34:56,474 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-08 22:34:56,509 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-08 22:34:56,545 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-08 22:34:56,581 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-08 22:34:56,617 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-08 22:34:56,654 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-08 22:34:56,694 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-08 22:34:56,730 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-08 22:34:56,766 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-08 22:34:56,800 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-08 22:34:56,835 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-08 22:34:56,870 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-08 22:34:56,905 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-08 22:34:56,942 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-08 22:34:56,978 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-08 22:34:57,014 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-08 22:34:57,052 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-08 22:34:57,087 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-08 22:34:57,122 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-08 22:34:57,156 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-08 22:34:57,191 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-08 22:34:57,227 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-08 22:34:57,263 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-08 22:34:57,299 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-08 22:34:57,335 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-08 22:34:57,371 : INFO : PROGRESS: at 58.68% examples, 317720 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:57,372 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-08 22:34:57,408 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-08 22:34:57,444 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-08 22:34:57,478 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-08 22:34:57,513 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-08 22:34:57,548 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-08 22:34:57,583 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-08 22:34:57,623 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-08 22:34:57,660 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-08 22:34:57,696 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-08 22:34:57,732 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-08 22:34:57,768 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-08 22:34:57,803 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-08 22:34:57,837 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-08 22:34:57,872 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-08 22:34:57,911 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-08 22:34:57,947 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-08 22:34:58,027 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:58,094 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:58,094 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:58,094 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316152 effective words/s
2016-10-08 22:34:58,094 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:58,094 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:58,095 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-08 22:34:58,096 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-08 22:34:58,097 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-08 22:34:58,098 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-08 22:34:58,133 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-08 22:34:58,168 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-08 22:34:58,203 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-08 22:34:58,238 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-08 22:34:58,274 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-08 22:34:58,311 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-08 22:34:58,348 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-08 22:34:58,385 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-08 22:34:58,422 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-08 22:34:58,459 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-08 22:34:58,494 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-08 22:34:58,529 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-08 22:34:58,564 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-08 22:34:58,600 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-08 22:34:58,636 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-08 22:34:58,673 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-08 22:34:58,711 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-08 22:34:58,749 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-08 22:34:58,786 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-08 22:34:58,823 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-08 22:34:58,858 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-08 22:34:58,892 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-08 22:34:58,928 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-08 22:34:58,964 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-08 22:34:59,001 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-08 22:34:59,038 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-08 22:34:59,075 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-08 22:34:59,112 : INFO : PROGRESS: at 58.68% examples, 314010 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:34:59,113 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-08 22:34:59,149 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-08 22:34:59,185 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-08 22:34:59,220 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-08 22:34:59,256 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-08 22:34:59,293 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-08 22:34:59,330 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-08 22:34:59,369 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-08 22:34:59,408 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-08 22:34:59,444 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-08 22:34:59,482 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-08 22:34:59,518 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-08 22:34:59,553 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-08 22:34:59,590 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-08 22:34:59,625 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-08 22:34:59,661 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-08 22:34:59,698 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-08 22:34:59,774 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:34:59,843 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:34:59,843 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:34:59,843 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312321 effective words/s
2016-10-08 22:34:59,844 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:34:59,844 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:34:59,845 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-08 22:34:59,846 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-08 22:34:59,846 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-08 22:34:59,847 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-08 22:34:59,882 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-08 22:34:59,917 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-08 22:34:59,951 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-08 22:34:59,986 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-08 22:35:00,022 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-08 22:35:00,059 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-08 22:35:00,095 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-08 22:35:00,131 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-08 22:35:00,168 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-08 22:35:00,204 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-08 22:35:00,239 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-08 22:35:00,273 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-08 22:35:00,308 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-08 22:35:00,343 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-08 22:35:00,378 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-08 22:35:00,415 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-08 22:35:00,454 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-08 22:35:00,490 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-08 22:35:00,528 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-08 22:35:00,563 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-08 22:35:00,597 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-08 22:35:00,632 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-08 22:35:00,667 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-08 22:35:00,702 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-08 22:35:00,742 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-08 22:35:00,778 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-08 22:35:00,814 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-08 22:35:00,850 : INFO : PROGRESS: at 58.68% examples, 317587 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:35:00,851 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-08 22:35:00,886 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-08 22:35:00,922 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-08 22:35:00,957 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-08 22:35:00,992 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-08 22:35:01,028 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-08 22:35:01,063 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-08 22:35:01,100 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-08 22:35:01,135 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-08 22:35:01,172 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-08 22:35:01,208 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-08 22:35:01,244 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-08 22:35:01,278 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-08 22:35:01,315 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-08 22:35:01,350 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-08 22:35:01,386 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-08 22:35:01,421 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-08 22:35:01,493 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:35:01,561 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:35:01,561 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:35:01,561 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 318131 effective words/s
2016-10-08 22:35:01,561 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-08 22:35:01,561 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-08 22:35:01,563 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-08 22:35:01,563 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-08 22:35:01,564 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-08 22:35:01,565 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-08 22:35:01,600 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-08 22:35:01,635 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-08 22:35:01,672 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-08 22:35:01,707 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-08 22:35:01,746 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-08 22:35:01,782 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-08 22:35:01,818 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-08 22:35:01,857 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-08 22:35:01,894 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-08 22:35:01,930 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-08 22:35:01,965 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-08 22:35:01,998 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-08 22:35:02,033 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-08 22:35:02,069 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-08 22:35:02,107 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-08 22:35:02,144 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-08 22:35:02,180 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-08 22:35:02,217 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-08 22:35:02,254 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-08 22:35:02,290 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-08 22:35:02,323 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-08 22:35:02,358 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-08 22:35:02,393 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-08 22:35:02,429 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-08 22:35:02,465 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-08 22:35:02,502 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-08 22:35:02,537 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-08 22:35:02,574 : INFO : PROGRESS: at 58.68% examples, 315709 words/s, in_qsize 1, out_qsize 0
2016-10-08 22:35:02,575 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-08 22:35:02,614 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-08 22:35:02,649 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-08 22:35:02,683 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-08 22:35:02,718 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-08 22:35:02,755 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-08 22:35:02,790 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-08 22:35:02,827 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-08 22:35:02,863 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-08 22:35:02,899 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-08 22:35:02,936 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-08 22:35:02,971 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-08 22:35:03,006 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-08 22:35:03,043 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-08 22:35:03,078 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-08 22:35:03,113 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-08 22:35:03,149 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-08 22:35:03,220 : DEBUG : job loop exiting, total 48 jobs
2016-10-08 22:35:03,287 : DEBUG : worker exiting, processed 48 jobs
2016-10-08 22:35:03,288 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-08 22:35:03,288 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316518 effective words/s
2016-10-08 22:35:03,288 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-08 22:35:03,288 : INFO : not storing attribute cum_table
2016-10-08 22:35:03,288 : INFO : not storing attribute syn0norm
2016-10-09 11:10:15,017 : INFO : collecting all words and their counts
2016-10-09 11:10:15,018 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 11:10:15,105 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-09 11:10:15,116 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-09 11:10:15,116 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-09 11:10:15,121 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-09 11:10:15,121 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 11:10:15,121 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-09 11:10:15,121 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-09 11:10:15,123 : INFO : constructing a huffman tree from 2637 words
2016-10-09 11:10:15,183 : INFO : built huffman tree with maximum node depth 14
2016-10-09 11:10:15,184 : INFO : resetting layer weights
2016-10-09 11:10:15,222 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:15,222 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:15,224 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 11:10:15,224 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 11:10:15,225 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 11:10:15,226 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 11:10:15,264 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 11:10:15,299 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-09 11:10:15,337 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-09 11:10:15,373 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-09 11:10:15,409 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-09 11:10:15,446 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-09 11:10:15,486 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-09 11:10:15,523 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-09 11:10:15,560 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-09 11:10:15,597 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-09 11:10:15,633 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-09 11:10:15,668 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-09 11:10:15,703 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-09 11:10:15,740 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-09 11:10:15,775 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-09 11:10:15,813 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-09 11:10:15,850 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-09 11:10:15,887 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-09 11:10:15,925 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-09 11:10:15,961 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-09 11:10:15,996 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-09 11:10:16,031 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-09 11:10:16,067 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-09 11:10:16,103 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-09 11:10:16,143 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-09 11:10:16,180 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-09 11:10:16,218 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-09 11:10:16,255 : INFO : PROGRESS: at 58.68% examples, 309550 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:16,256 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-09 11:10:16,293 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-09 11:10:16,329 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-09 11:10:16,364 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-09 11:10:16,399 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-09 11:10:16,435 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-09 11:10:16,471 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-09 11:10:16,509 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-09 11:10:16,546 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-09 11:10:16,582 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-09 11:10:16,621 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-09 11:10:16,657 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-09 11:10:16,693 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-09 11:10:16,729 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-09 11:10:16,764 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-09 11:10:16,801 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-09 11:10:16,837 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-09 11:10:16,910 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:16,979 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:16,979 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:16,979 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 311042 effective words/s
2016-10-09 11:10:16,979 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:16,979 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:16,980 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 11:10:16,981 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 11:10:16,982 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 11:10:16,983 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 11:10:17,019 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 11:10:17,054 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-09 11:10:17,089 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-09 11:10:17,125 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-09 11:10:17,161 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-09 11:10:17,199 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-09 11:10:17,236 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-09 11:10:17,273 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-09 11:10:17,312 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-09 11:10:17,349 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-09 11:10:17,385 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-09 11:10:17,420 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-09 11:10:17,456 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-09 11:10:17,492 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-09 11:10:17,529 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-09 11:10:17,567 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-09 11:10:17,604 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-09 11:10:17,641 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-09 11:10:17,680 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-09 11:10:17,716 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-09 11:10:17,752 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-09 11:10:17,791 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-09 11:10:17,827 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-09 11:10:17,863 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-09 11:10:17,900 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-09 11:10:17,938 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-09 11:10:17,975 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-09 11:10:18,012 : INFO : PROGRESS: at 58.68% examples, 309302 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:18,013 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-09 11:10:18,050 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-09 11:10:18,086 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-09 11:10:18,122 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-09 11:10:18,157 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-09 11:10:18,194 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-09 11:10:18,233 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-09 11:10:18,271 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-09 11:10:18,310 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-09 11:10:18,347 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-09 11:10:18,385 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-09 11:10:18,421 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-09 11:10:18,456 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-09 11:10:18,492 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-09 11:10:18,528 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-09 11:10:18,565 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-09 11:10:18,604 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-09 11:10:18,678 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:18,747 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:18,748 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:18,748 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308962 effective words/s
2016-10-09 11:10:18,748 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:18,748 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:18,749 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 11:10:18,750 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 11:10:18,751 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 11:10:18,751 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 11:10:18,791 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 11:10:18,826 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-09 11:10:18,861 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-09 11:10:18,897 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-09 11:10:18,933 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-09 11:10:18,970 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-09 11:10:19,007 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-09 11:10:19,044 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-09 11:10:19,082 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-09 11:10:19,118 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-09 11:10:19,154 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-09 11:10:19,189 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-09 11:10:19,225 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-09 11:10:19,261 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-09 11:10:19,298 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-09 11:10:19,336 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-09 11:10:19,372 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-09 11:10:19,409 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-09 11:10:19,447 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-09 11:10:19,487 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-09 11:10:19,524 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-09 11:10:19,560 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-09 11:10:19,596 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-09 11:10:19,633 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-09 11:10:19,670 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-09 11:10:19,707 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-09 11:10:19,744 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-09 11:10:19,781 : INFO : PROGRESS: at 58.68% examples, 309172 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:19,782 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-09 11:10:19,819 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-09 11:10:19,855 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-09 11:10:19,890 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-09 11:10:19,925 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-09 11:10:19,961 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-09 11:10:19,997 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-09 11:10:20,035 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-09 11:10:20,073 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-09 11:10:20,112 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-09 11:10:20,150 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-09 11:10:20,187 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-09 11:10:20,223 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-09 11:10:20,259 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-09 11:10:20,297 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-09 11:10:20,336 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-09 11:10:20,373 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-09 11:10:20,445 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:20,514 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:20,514 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:20,514 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309311 effective words/s
2016-10-09 11:10:20,514 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:20,515 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:20,516 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 11:10:20,516 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 11:10:20,517 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 11:10:20,518 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 11:10:20,555 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 11:10:20,590 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-09 11:10:20,627 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-09 11:10:20,663 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-09 11:10:20,700 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-09 11:10:20,738 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-09 11:10:20,776 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-09 11:10:20,814 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-09 11:10:20,852 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-09 11:10:20,889 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-09 11:10:20,926 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-09 11:10:20,961 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-09 11:10:21,000 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-09 11:10:21,037 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-09 11:10:21,074 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-09 11:10:21,113 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-09 11:10:21,150 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-09 11:10:21,188 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-09 11:10:21,227 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-09 11:10:21,264 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-09 11:10:21,300 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-09 11:10:21,335 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-09 11:10:21,371 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-09 11:10:21,412 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-09 11:10:21,449 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-09 11:10:21,488 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-09 11:10:21,525 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-09 11:10:21,526 : INFO : PROGRESS: at 56.90% examples, 304273 words/s, in_qsize 2, out_qsize 0
2016-10-09 11:10:21,564 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-09 11:10:21,603 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-09 11:10:21,641 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-09 11:10:21,677 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-09 11:10:21,713 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-09 11:10:21,750 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-09 11:10:21,786 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-09 11:10:21,825 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-09 11:10:21,863 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-09 11:10:21,900 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-09 11:10:21,939 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-09 11:10:21,976 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-09 11:10:22,012 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-09 11:10:22,047 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-09 11:10:22,083 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-09 11:10:22,123 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-09 11:10:22,161 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-09 11:10:22,235 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:22,306 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:22,306 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:22,306 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 304911 effective words/s
2016-10-09 11:10:22,307 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:22,307 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:22,308 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 11:10:22,309 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 11:10:22,309 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 11:10:22,310 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 11:10:22,347 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 11:10:22,382 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-09 11:10:22,420 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-09 11:10:22,456 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-09 11:10:22,492 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-09 11:10:22,529 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-09 11:10:22,567 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-09 11:10:22,604 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-09 11:10:22,642 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-09 11:10:22,679 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-09 11:10:22,715 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-09 11:10:22,750 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-09 11:10:22,786 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-09 11:10:22,822 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-09 11:10:22,858 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-09 11:10:22,896 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-09 11:10:22,933 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-09 11:10:22,970 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-09 11:10:23,008 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-09 11:10:23,044 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-09 11:10:23,079 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-09 11:10:23,115 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-09 11:10:23,153 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-09 11:10:23,189 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-09 11:10:23,226 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-09 11:10:23,263 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-09 11:10:23,304 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-09 11:10:23,341 : INFO : PROGRESS: at 58.68% examples, 308963 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:23,342 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-09 11:10:23,379 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-09 11:10:23,415 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-09 11:10:23,449 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-09 11:10:23,485 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-09 11:10:23,523 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-09 11:10:23,559 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-09 11:10:23,601 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-09 11:10:23,638 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-09 11:10:23,675 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-09 11:10:23,713 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-09 11:10:23,756 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-09 11:10:23,791 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-09 11:10:23,826 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-09 11:10:23,862 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-09 11:10:23,898 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-09 11:10:23,935 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-09 11:10:24,008 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:24,079 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:24,080 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:24,080 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308131 effective words/s
2016-10-09 11:10:24,080 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:24,080 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:24,082 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 11:10:24,083 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 11:10:24,083 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 11:10:24,084 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 11:10:24,125 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 11:10:24,162 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-09 11:10:24,197 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-09 11:10:24,234 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-09 11:10:24,273 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-09 11:10:24,311 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-09 11:10:24,348 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-09 11:10:24,385 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-09 11:10:24,422 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-09 11:10:24,459 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-09 11:10:24,495 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-09 11:10:24,530 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-09 11:10:24,566 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-09 11:10:24,603 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-09 11:10:24,639 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-09 11:10:24,678 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-09 11:10:24,714 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-09 11:10:24,751 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-09 11:10:24,790 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-09 11:10:24,826 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-09 11:10:24,861 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-09 11:10:24,897 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-09 11:10:24,932 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-09 11:10:24,969 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-09 11:10:25,006 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-09 11:10:25,043 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-09 11:10:25,080 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-09 11:10:25,117 : INFO : PROGRESS: at 58.68% examples, 308487 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:25,118 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-09 11:10:25,155 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-09 11:10:25,194 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-09 11:10:25,229 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-09 11:10:25,265 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-09 11:10:25,301 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-09 11:10:25,338 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-09 11:10:25,375 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-09 11:10:25,412 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-09 11:10:25,449 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-09 11:10:25,487 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-09 11:10:25,527 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-09 11:10:25,562 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-09 11:10:25,597 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-09 11:10:25,633 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-09 11:10:25,669 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-09 11:10:25,706 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-09 11:10:25,779 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:25,853 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:25,854 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:25,854 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308229 effective words/s
2016-10-09 11:10:25,854 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:25,854 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:25,855 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 11:10:25,856 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 11:10:25,857 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 11:10:25,858 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 11:10:25,895 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 11:10:25,930 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-09 11:10:25,965 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-09 11:10:26,001 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-09 11:10:26,037 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-09 11:10:26,074 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-09 11:10:26,111 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-09 11:10:26,149 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-09 11:10:26,186 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-09 11:10:26,223 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-09 11:10:26,259 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-09 11:10:26,294 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-09 11:10:26,330 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-09 11:10:26,366 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-09 11:10:26,402 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-09 11:10:26,440 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-09 11:10:26,477 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-09 11:10:26,514 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-09 11:10:26,552 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-09 11:10:26,588 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-09 11:10:26,626 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-09 11:10:26,661 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-09 11:10:26,697 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-09 11:10:26,734 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-09 11:10:26,771 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-09 11:10:26,808 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-09 11:10:26,844 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-09 11:10:26,881 : INFO : PROGRESS: at 58.68% examples, 311237 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:26,882 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-09 11:10:26,919 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-09 11:10:26,955 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-09 11:10:26,990 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-09 11:10:27,026 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-09 11:10:27,063 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-09 11:10:27,099 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-09 11:10:27,138 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-09 11:10:27,174 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-09 11:10:27,213 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-09 11:10:27,253 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-09 11:10:27,290 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-09 11:10:27,327 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-09 11:10:27,362 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-09 11:10:27,398 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-09 11:10:27,435 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-09 11:10:27,471 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-09 11:10:27,544 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:27,614 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:27,614 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:27,614 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310507 effective words/s
2016-10-09 11:10:27,614 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:27,614 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:27,616 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 11:10:27,616 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 11:10:27,617 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 11:10:27,618 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 11:10:27,654 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 11:10:27,689 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-09 11:10:27,724 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-09 11:10:27,760 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-09 11:10:27,797 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-09 11:10:27,835 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-09 11:10:27,874 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-09 11:10:27,910 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-09 11:10:27,948 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-09 11:10:27,984 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-09 11:10:28,020 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-09 11:10:28,055 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-09 11:10:28,091 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-09 11:10:28,128 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-09 11:10:28,164 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-09 11:10:28,202 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-09 11:10:28,240 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-09 11:10:28,277 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-09 11:10:28,315 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-09 11:10:28,352 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-09 11:10:28,387 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-09 11:10:28,422 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-09 11:10:28,458 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-09 11:10:28,496 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-09 11:10:28,537 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-09 11:10:28,574 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-09 11:10:28,612 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-09 11:10:28,649 : INFO : PROGRESS: at 58.68% examples, 308794 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:28,650 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-09 11:10:28,690 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-09 11:10:28,726 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-09 11:10:28,761 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-09 11:10:28,797 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-09 11:10:28,833 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-09 11:10:28,869 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-09 11:10:28,907 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-09 11:10:28,944 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-09 11:10:28,980 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-09 11:10:29,018 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-09 11:10:29,055 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-09 11:10:29,093 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-09 11:10:29,128 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-09 11:10:29,164 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-09 11:10:29,200 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-09 11:10:29,237 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-09 11:10:29,310 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:29,379 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:29,379 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:29,379 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309643 effective words/s
2016-10-09 11:10:29,379 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:29,379 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:29,380 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 11:10:29,381 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 11:10:29,382 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 11:10:29,383 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 11:10:29,420 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 11:10:29,455 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-09 11:10:29,491 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-09 11:10:29,527 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-09 11:10:29,564 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-09 11:10:29,602 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-09 11:10:29,641 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-09 11:10:29,678 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-09 11:10:29,717 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-09 11:10:29,754 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-09 11:10:29,790 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-09 11:10:29,826 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-09 11:10:29,862 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-09 11:10:29,898 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-09 11:10:29,935 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-09 11:10:29,974 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-09 11:10:30,011 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-09 11:10:30,049 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-09 11:10:30,087 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-09 11:10:30,125 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-09 11:10:30,160 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-09 11:10:30,196 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-09 11:10:30,233 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-09 11:10:30,269 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-09 11:10:30,308 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-09 11:10:30,346 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-09 11:10:30,382 : INFO : PROGRESS: at 56.90% examples, 306555 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:30,383 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-09 11:10:30,422 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-09 11:10:30,459 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-09 11:10:30,496 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-09 11:10:30,531 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-09 11:10:30,567 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-09 11:10:30,605 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-09 11:10:30,643 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-09 11:10:30,682 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-09 11:10:30,719 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-09 11:10:30,757 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-09 11:10:30,796 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-09 11:10:30,833 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-09 11:10:30,868 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-09 11:10:30,904 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-09 11:10:30,940 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-09 11:10:30,977 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-09 11:10:31,014 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-09 11:10:31,087 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:31,158 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:31,158 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:31,158 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307064 effective words/s
2016-10-09 11:10:31,158 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:10:31,158 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:10:31,159 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 11:10:31,160 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 11:10:31,161 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 11:10:31,162 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 11:10:31,198 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 11:10:31,234 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-09 11:10:31,269 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-09 11:10:31,306 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-09 11:10:31,342 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-09 11:10:31,380 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-09 11:10:31,417 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-09 11:10:31,454 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-09 11:10:31,492 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-09 11:10:31,529 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-09 11:10:31,565 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-09 11:10:31,601 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-09 11:10:31,637 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-09 11:10:31,674 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-09 11:10:31,711 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-09 11:10:31,749 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-09 11:10:31,786 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-09 11:10:31,824 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-09 11:10:31,863 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-09 11:10:31,900 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-09 11:10:31,935 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-09 11:10:31,970 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-09 11:10:32,006 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-09 11:10:32,043 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-09 11:10:32,080 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-09 11:10:32,118 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-09 11:10:32,155 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-09 11:10:32,192 : INFO : PROGRESS: at 58.68% examples, 308971 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:10:32,193 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-09 11:10:32,231 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-09 11:10:32,267 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-09 11:10:32,302 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-09 11:10:32,342 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-09 11:10:32,378 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-09 11:10:32,415 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-09 11:10:32,453 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-09 11:10:32,490 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-09 11:10:32,527 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-09 11:10:32,565 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-09 11:10:32,603 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-09 11:10:32,640 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-09 11:10:32,675 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-09 11:10:32,711 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-09 11:10:32,748 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-09 11:10:32,784 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-09 11:10:32,866 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:10:32,935 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:10:32,936 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:10:32,936 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 307405 effective words/s
2016-10-09 11:10:32,936 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 11:10:32,936 : INFO : not storing attribute cum_table
2016-10-09 11:10:32,936 : INFO : not storing attribute syn0norm
2016-10-09 11:20:56,003 : INFO : collecting all words and their counts
2016-10-09 11:20:56,004 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 11:20:56,095 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-09 11:20:56,106 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-09 11:20:56,106 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-09 11:20:56,110 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-09 11:20:56,111 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 11:20:56,111 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-09 11:20:56,111 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-09 11:20:56,113 : INFO : constructing a huffman tree from 2637 words
2016-10-09 11:20:56,173 : INFO : built huffman tree with maximum node depth 14
2016-10-09 11:20:56,174 : INFO : resetting layer weights
2016-10-09 11:20:56,209 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:20:56,209 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:20:56,211 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 11:20:56,211 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 11:20:56,212 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 11:20:56,213 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 11:20:56,254 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 11:20:56,289 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-09 11:20:56,328 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-09 11:20:56,365 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-09 11:20:56,401 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-09 11:20:56,439 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-09 11:20:56,481 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-09 11:20:56,519 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-09 11:20:56,557 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-09 11:20:56,599 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-09 11:20:56,636 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-09 11:20:56,671 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-09 11:20:56,706 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-09 11:20:56,742 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-09 11:20:56,782 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-09 11:20:56,823 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-09 11:20:56,860 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-09 11:20:56,898 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-09 11:20:56,939 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-09 11:20:56,975 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-09 11:20:57,010 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-09 11:20:57,048 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-09 11:20:57,086 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-09 11:20:57,123 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-09 11:20:57,160 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-09 11:20:57,197 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-09 11:20:57,233 : INFO : PROGRESS: at 56.90% examples, 300648 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:20:57,234 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-09 11:20:57,274 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-09 11:20:57,312 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-09 11:20:57,351 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-09 11:20:57,385 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-09 11:20:57,421 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-09 11:20:57,457 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-09 11:20:57,493 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-09 11:20:57,530 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-09 11:20:57,567 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-09 11:20:57,606 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-09 11:20:57,643 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-09 11:20:57,679 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-09 11:20:57,714 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-09 11:20:57,749 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-09 11:20:57,784 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-09 11:20:57,820 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-09 11:20:57,860 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-09 11:20:57,940 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:20:58,009 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:20:58,009 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:20:58,009 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 303582 effective words/s
2016-10-09 11:20:58,009 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:20:58,009 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:20:58,011 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 11:20:58,011 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 11:20:58,012 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 11:20:58,013 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 11:20:58,048 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 11:20:58,082 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-09 11:20:58,118 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-09 11:20:58,153 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-09 11:20:58,189 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-09 11:20:58,225 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-09 11:20:58,262 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-09 11:20:58,298 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-09 11:20:58,335 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-09 11:20:58,371 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-09 11:20:58,410 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-09 11:20:58,444 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-09 11:20:58,479 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-09 11:20:58,514 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-09 11:20:58,549 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-09 11:20:58,586 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-09 11:20:58,622 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-09 11:20:58,658 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-09 11:20:58,695 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-09 11:20:58,731 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-09 11:20:58,765 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-09 11:20:58,799 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-09 11:20:58,834 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-09 11:20:58,870 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-09 11:20:58,906 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-09 11:20:58,942 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-09 11:20:58,978 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-09 11:20:59,014 : INFO : PROGRESS: at 58.68% examples, 318046 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:20:59,015 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-09 11:20:59,051 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-09 11:20:59,087 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-09 11:20:59,120 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-09 11:20:59,155 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-09 11:20:59,190 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-09 11:20:59,226 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-09 11:20:59,263 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-09 11:20:59,299 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-09 11:20:59,335 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-09 11:20:59,372 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-09 11:20:59,409 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-09 11:20:59,445 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-09 11:20:59,482 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-09 11:20:59,517 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-09 11:20:59,554 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-09 11:20:59,597 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-09 11:20:59,668 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:20:59,735 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:20:59,736 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:20:59,736 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316521 effective words/s
2016-10-09 11:20:59,736 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:20:59,736 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:20:59,737 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 11:20:59,738 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 11:20:59,738 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 11:20:59,739 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 11:20:59,775 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 11:20:59,809 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-09 11:20:59,843 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-09 11:20:59,878 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-09 11:20:59,914 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-09 11:20:59,951 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-09 11:20:59,988 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-09 11:21:00,024 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-09 11:21:00,061 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-09 11:21:00,097 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-09 11:21:00,132 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-09 11:21:00,166 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-09 11:21:00,201 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-09 11:21:00,236 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-09 11:21:00,275 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-09 11:21:00,312 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-09 11:21:00,348 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-09 11:21:00,385 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-09 11:21:00,422 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-09 11:21:00,459 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-09 11:21:00,494 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-09 11:21:00,528 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-09 11:21:00,564 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-09 11:21:00,600 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-09 11:21:00,638 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-09 11:21:00,674 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-09 11:21:00,711 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-09 11:21:00,747 : INFO : PROGRESS: at 58.68% examples, 316076 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:00,748 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-09 11:21:00,784 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-09 11:21:00,819 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-09 11:21:00,852 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-09 11:21:00,887 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-09 11:21:00,922 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-09 11:21:00,958 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-09 11:21:00,995 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-09 11:21:01,032 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-09 11:21:01,068 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-09 11:21:01,105 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-09 11:21:01,141 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-09 11:21:01,177 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-09 11:21:01,212 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-09 11:21:01,247 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-09 11:21:01,283 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-09 11:21:01,319 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-09 11:21:01,390 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:01,458 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:01,458 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:01,458 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 317229 effective words/s
2016-10-09 11:21:01,458 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:01,458 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:01,460 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 11:21:01,460 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 11:21:01,461 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 11:21:01,463 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 11:21:01,499 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 11:21:01,533 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-09 11:21:01,568 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-09 11:21:01,607 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-09 11:21:01,644 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-09 11:21:01,680 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-09 11:21:01,716 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-09 11:21:01,752 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-09 11:21:01,789 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-09 11:21:01,825 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-09 11:21:01,863 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-09 11:21:01,898 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-09 11:21:01,933 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-09 11:21:01,968 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-09 11:21:02,005 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-09 11:21:02,042 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-09 11:21:02,078 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-09 11:21:02,114 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-09 11:21:02,151 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-09 11:21:02,190 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-09 11:21:02,225 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-09 11:21:02,259 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-09 11:21:02,295 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-09 11:21:02,330 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-09 11:21:02,366 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-09 11:21:02,403 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-09 11:21:02,439 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-09 11:21:02,475 : INFO : PROGRESS: at 58.68% examples, 314426 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:02,476 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-09 11:21:02,513 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-09 11:21:02,548 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-09 11:21:02,585 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-09 11:21:02,620 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-09 11:21:02,655 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-09 11:21:02,691 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-09 11:21:02,730 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-09 11:21:02,769 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-09 11:21:02,806 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-09 11:21:02,843 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-09 11:21:02,879 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-09 11:21:02,914 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-09 11:21:02,950 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-09 11:21:02,985 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-09 11:21:03,020 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-09 11:21:03,056 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-09 11:21:03,127 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:03,195 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:03,195 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:03,195 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 314734 effective words/s
2016-10-09 11:21:03,195 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:03,195 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:03,196 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 11:21:03,197 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 11:21:03,198 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 11:21:03,199 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 11:21:03,234 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 11:21:03,271 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-09 11:21:03,306 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-09 11:21:03,341 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-09 11:21:03,377 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-09 11:21:03,413 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-09 11:21:03,449 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-09 11:21:03,485 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-09 11:21:03,523 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-09 11:21:03,559 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-09 11:21:03,596 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-09 11:21:03,630 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-09 11:21:03,665 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-09 11:21:03,700 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-09 11:21:03,736 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-09 11:21:03,773 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-09 11:21:03,809 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-09 11:21:03,845 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-09 11:21:03,882 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-09 11:21:03,918 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-09 11:21:03,952 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-09 11:21:03,986 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-09 11:21:04,021 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-09 11:21:04,057 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-09 11:21:04,093 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-09 11:21:04,130 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-09 11:21:04,166 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-09 11:21:04,202 : INFO : PROGRESS: at 58.68% examples, 317396 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:04,203 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-09 11:21:04,239 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-09 11:21:04,275 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-09 11:21:04,309 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-09 11:21:04,343 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-09 11:21:04,379 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-09 11:21:04,417 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-09 11:21:04,454 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-09 11:21:04,490 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-09 11:21:04,527 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-09 11:21:04,567 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-09 11:21:04,607 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-09 11:21:04,641 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-09 11:21:04,675 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-09 11:21:04,710 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-09 11:21:04,746 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-09 11:21:04,782 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-09 11:21:04,853 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:04,920 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:04,921 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:04,921 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316658 effective words/s
2016-10-09 11:21:04,921 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:04,921 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:04,922 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 11:21:04,923 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 11:21:04,923 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 11:21:04,924 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 11:21:04,960 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 11:21:04,994 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-09 11:21:05,028 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-09 11:21:05,063 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-09 11:21:05,099 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-09 11:21:05,135 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-09 11:21:05,171 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-09 11:21:05,207 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-09 11:21:05,244 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-09 11:21:05,280 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-09 11:21:05,315 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-09 11:21:05,349 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-09 11:21:05,384 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-09 11:21:05,419 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-09 11:21:05,454 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-09 11:21:05,492 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-09 11:21:05,527 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-09 11:21:05,564 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-09 11:21:05,601 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-09 11:21:05,636 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-09 11:21:05,671 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-09 11:21:05,705 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-09 11:21:05,740 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-09 11:21:05,775 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-09 11:21:05,811 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-09 11:21:05,847 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-09 11:21:05,884 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-09 11:21:05,920 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-09 11:21:05,957 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-09 11:21:05,957 : INFO : PROGRESS: at 60.59% examples, 319504 words/s, in_qsize 2, out_qsize 0
2016-10-09 11:21:05,993 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-09 11:21:06,027 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-09 11:21:06,061 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-09 11:21:06,097 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-09 11:21:06,133 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-09 11:21:06,170 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-09 11:21:06,206 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-09 11:21:06,241 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-09 11:21:06,279 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-09 11:21:06,314 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-09 11:21:06,348 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-09 11:21:06,383 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-09 11:21:06,418 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-09 11:21:06,453 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-09 11:21:06,489 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-09 11:21:06,560 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:06,627 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:06,627 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:06,628 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 320157 effective words/s
2016-10-09 11:21:06,628 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:06,628 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:06,629 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 11:21:06,630 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 11:21:06,630 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 11:21:06,631 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 11:21:06,667 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 11:21:06,701 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-09 11:21:06,735 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-09 11:21:06,770 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-09 11:21:06,806 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-09 11:21:06,842 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-09 11:21:06,882 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-09 11:21:06,918 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-09 11:21:06,954 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-09 11:21:06,990 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-09 11:21:07,025 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-09 11:21:07,059 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-09 11:21:07,094 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-09 11:21:07,129 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-09 11:21:07,164 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-09 11:21:07,201 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-09 11:21:07,237 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-09 11:21:07,277 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-09 11:21:07,314 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-09 11:21:07,350 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-09 11:21:07,384 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-09 11:21:07,418 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-09 11:21:07,453 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-09 11:21:07,489 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-09 11:21:07,525 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-09 11:21:07,562 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-09 11:21:07,601 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-09 11:21:07,637 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-09 11:21:07,637 : INFO : PROGRESS: at 58.68% examples, 316450 words/s, in_qsize 2, out_qsize 0
2016-10-09 11:21:07,674 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-09 11:21:07,709 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-09 11:21:07,743 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-09 11:21:07,777 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-09 11:21:07,812 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-09 11:21:07,848 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-09 11:21:07,885 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-09 11:21:07,920 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-09 11:21:07,957 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-09 11:21:07,994 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-09 11:21:08,029 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-09 11:21:08,063 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-09 11:21:08,098 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-09 11:21:08,133 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-09 11:21:08,168 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-09 11:21:08,204 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-09 11:21:08,274 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:08,341 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:08,341 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:08,341 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 318843 effective words/s
2016-10-09 11:21:08,342 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:08,342 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:08,343 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 11:21:08,343 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 11:21:08,344 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 11:21:08,345 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 11:21:08,380 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 11:21:08,414 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-09 11:21:08,449 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-09 11:21:08,483 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-09 11:21:08,519 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-09 11:21:08,555 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-09 11:21:08,592 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-09 11:21:08,628 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-09 11:21:08,664 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-09 11:21:08,700 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-09 11:21:08,735 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-09 11:21:08,769 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-09 11:21:08,804 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-09 11:21:08,839 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-09 11:21:08,874 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-09 11:21:08,910 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-09 11:21:08,946 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-09 11:21:08,982 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-09 11:21:09,019 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-09 11:21:09,055 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-09 11:21:09,089 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-09 11:21:09,124 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-09 11:21:09,160 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-09 11:21:09,197 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-09 11:21:09,233 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-09 11:21:09,272 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-09 11:21:09,309 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-09 11:21:09,347 : INFO : PROGRESS: at 58.68% examples, 317726 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:09,348 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-09 11:21:09,384 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-09 11:21:09,419 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-09 11:21:09,453 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-09 11:21:09,488 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-09 11:21:09,523 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-09 11:21:09,558 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-09 11:21:09,596 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-09 11:21:09,632 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-09 11:21:09,668 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-09 11:21:09,705 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-09 11:21:09,740 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-09 11:21:09,774 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-09 11:21:09,808 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-09 11:21:09,843 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-09 11:21:09,878 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-09 11:21:09,914 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-09 11:21:09,984 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:10,051 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:10,052 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:10,052 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 319522 effective words/s
2016-10-09 11:21:10,052 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:10,052 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:10,053 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 11:21:10,054 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 11:21:10,054 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 11:21:10,055 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 11:21:10,092 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 11:21:10,126 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-09 11:21:10,161 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-09 11:21:10,196 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-09 11:21:10,232 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-09 11:21:10,269 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-09 11:21:10,305 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-09 11:21:10,341 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-09 11:21:10,378 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-09 11:21:10,415 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-09 11:21:10,450 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-09 11:21:10,484 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-09 11:21:10,519 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-09 11:21:10,555 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-09 11:21:10,591 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-09 11:21:10,628 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-09 11:21:10,665 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-09 11:21:10,701 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-09 11:21:10,739 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-09 11:21:10,775 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-09 11:21:10,811 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-09 11:21:10,846 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-09 11:21:10,881 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-09 11:21:10,916 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-09 11:21:10,953 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-09 11:21:10,989 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-09 11:21:11,026 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-09 11:21:11,062 : INFO : PROGRESS: at 58.68% examples, 316294 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:11,063 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-09 11:21:11,099 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-09 11:21:11,135 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-09 11:21:11,169 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-09 11:21:11,203 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-09 11:21:11,239 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-09 11:21:11,275 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-09 11:21:11,314 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-09 11:21:11,353 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-09 11:21:11,390 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-09 11:21:11,427 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-09 11:21:11,463 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-09 11:21:11,498 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-09 11:21:11,532 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-09 11:21:11,568 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-09 11:21:11,606 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-09 11:21:11,642 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-09 11:21:11,714 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:11,782 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:11,783 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:11,783 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315687 effective words/s
2016-10-09 11:21:11,783 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:21:11,783 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:21:11,784 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 11:21:11,785 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 11:21:11,785 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 11:21:11,786 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 11:21:11,822 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 11:21:11,855 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-09 11:21:11,890 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-09 11:21:11,925 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-09 11:21:11,960 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-09 11:21:11,997 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-09 11:21:12,033 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-09 11:21:12,069 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-09 11:21:12,107 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-09 11:21:12,144 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-09 11:21:12,179 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-09 11:21:12,214 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-09 11:21:12,249 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-09 11:21:12,284 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-09 11:21:12,319 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-09 11:21:12,356 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-09 11:21:12,393 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-09 11:21:12,430 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-09 11:21:12,467 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-09 11:21:12,503 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-09 11:21:12,541 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-09 11:21:12,576 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-09 11:21:12,615 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-09 11:21:12,650 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-09 11:21:12,686 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-09 11:21:12,722 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-09 11:21:12,758 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-09 11:21:12,795 : INFO : PROGRESS: at 58.68% examples, 315695 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:21:12,796 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-09 11:21:12,832 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-09 11:21:12,871 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-09 11:21:12,905 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-09 11:21:12,939 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-09 11:21:12,975 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-09 11:21:13,011 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-09 11:21:13,048 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-09 11:21:13,084 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-09 11:21:13,120 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-09 11:21:13,157 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-09 11:21:13,193 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-09 11:21:13,227 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-09 11:21:13,264 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-09 11:21:13,300 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-09 11:21:13,336 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-09 11:21:13,371 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-09 11:21:13,443 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:21:13,510 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:21:13,511 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:21:13,511 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316221 effective words/s
2016-10-09 11:21:13,511 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 11:21:13,511 : INFO : not storing attribute syn0norm
2016-10-09 11:21:13,511 : INFO : not storing attribute cum_table
2016-10-09 11:24:22,208 : INFO : collecting all words and their counts
2016-10-09 11:24:22,208 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 11:24:22,294 : INFO : collected 11802 word types and 13 unique tags from a corpus of 4880 examples and 95616 words
2016-10-09 11:24:22,305 : INFO : min_count=5 retains 2637 unique words (drops 9165)
2016-10-09 11:24:22,305 : INFO : min_count leaves 81620 word corpus (85% of original 95616)
2016-10-09 11:24:22,309 : INFO : deleting the raw counts dictionary of 11802 items
2016-10-09 11:24:22,310 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 11:24:22,310 : INFO : downsampling leaves estimated 81620 word corpus (100.0% of prior 81620)
2016-10-09 11:24:22,310 : INFO : estimated required memory for 2637 words and 300 dimensions: 8192900 bytes
2016-10-09 11:24:22,312 : INFO : constructing a huffman tree from 2637 words
2016-10-09 11:24:22,376 : INFO : built huffman tree with maximum node depth 14
2016-10-09 11:24:22,377 : INFO : resetting layer weights
2016-10-09 11:24:22,419 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:22,419 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:22,420 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 11:24:22,421 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 11:24:22,422 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 11:24:22,422 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 11:24:22,460 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 11:24:22,495 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02500
2016-10-09 11:24:22,532 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02500
2016-10-09 11:24:22,567 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02500
2016-10-09 11:24:22,607 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02500
2016-10-09 11:24:22,644 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02500
2016-10-09 11:24:22,681 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02500
2016-10-09 11:24:22,718 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02500
2016-10-09 11:24:22,755 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02500
2016-10-09 11:24:22,792 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02500
2016-10-09 11:24:22,827 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02500
2016-10-09 11:24:22,862 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02500
2016-10-09 11:24:22,898 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02500
2016-10-09 11:24:22,933 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02500
2016-10-09 11:24:22,970 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02500
2016-10-09 11:24:23,008 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02500
2016-10-09 11:24:23,045 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02500
2016-10-09 11:24:23,086 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02500
2016-10-09 11:24:23,124 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02500
2016-10-09 11:24:23,163 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02500
2016-10-09 11:24:23,198 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02500
2016-10-09 11:24:23,234 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02500
2016-10-09 11:24:23,272 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02500
2016-10-09 11:24:23,309 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02500
2016-10-09 11:24:23,345 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02500
2016-10-09 11:24:23,383 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02500
2016-10-09 11:24:23,419 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02500
2016-10-09 11:24:23,456 : INFO : PROGRESS: at 58.68% examples, 308154 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:23,457 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02500
2016-10-09 11:24:23,497 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02500
2016-10-09 11:24:23,533 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02500
2016-10-09 11:24:23,567 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02500
2016-10-09 11:24:23,603 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02500
2016-10-09 11:24:23,643 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02500
2016-10-09 11:24:23,679 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02500
2016-10-09 11:24:23,717 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02500
2016-10-09 11:24:23,754 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02500
2016-10-09 11:24:23,791 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02500
2016-10-09 11:24:23,834 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02500
2016-10-09 11:24:23,871 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02500
2016-10-09 11:24:23,907 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02500
2016-10-09 11:24:23,941 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02500
2016-10-09 11:24:23,977 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02500
2016-10-09 11:24:24,013 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02500
2016-10-09 11:24:24,050 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02500
2016-10-09 11:24:24,123 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:24,192 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:24,192 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:24,192 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308175 effective words/s
2016-10-09 11:24:24,192 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:24,192 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:24,193 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 11:24:24,194 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 11:24:24,195 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 11:24:24,196 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 11:24:24,232 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 11:24:24,267 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02300
2016-10-09 11:24:24,302 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02300
2016-10-09 11:24:24,339 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02300
2016-10-09 11:24:24,375 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02300
2016-10-09 11:24:24,413 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02300
2016-10-09 11:24:24,450 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02300
2016-10-09 11:24:24,487 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02300
2016-10-09 11:24:24,525 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02300
2016-10-09 11:24:24,561 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02300
2016-10-09 11:24:24,601 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02300
2016-10-09 11:24:24,639 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02300
2016-10-09 11:24:24,675 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02300
2016-10-09 11:24:24,715 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02300
2016-10-09 11:24:24,751 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02300
2016-10-09 11:24:24,789 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02300
2016-10-09 11:24:24,826 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02300
2016-10-09 11:24:24,866 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02300
2016-10-09 11:24:24,904 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02300
2016-10-09 11:24:24,940 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02300
2016-10-09 11:24:24,975 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02300
2016-10-09 11:24:25,011 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02300
2016-10-09 11:24:25,046 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02300
2016-10-09 11:24:25,082 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02300
2016-10-09 11:24:25,119 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02300
2016-10-09 11:24:25,157 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02300
2016-10-09 11:24:25,193 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02300
2016-10-09 11:24:25,230 : INFO : PROGRESS: at 58.68% examples, 307904 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:25,231 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02300
2016-10-09 11:24:25,268 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02300
2016-10-09 11:24:25,306 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02300
2016-10-09 11:24:25,340 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02300
2016-10-09 11:24:25,376 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02300
2016-10-09 11:24:25,411 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02300
2016-10-09 11:24:25,447 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02300
2016-10-09 11:24:25,485 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02300
2016-10-09 11:24:25,522 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02300
2016-10-09 11:24:25,559 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02300
2016-10-09 11:24:25,598 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02300
2016-10-09 11:24:25,634 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02300
2016-10-09 11:24:25,669 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02300
2016-10-09 11:24:25,704 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02300
2016-10-09 11:24:25,740 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02300
2016-10-09 11:24:25,779 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02300
2016-10-09 11:24:25,816 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02300
2016-10-09 11:24:25,892 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:25,961 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:25,961 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:25,961 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308889 effective words/s
2016-10-09 11:24:25,961 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:25,961 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:25,962 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 11:24:25,963 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 11:24:25,964 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 11:24:25,965 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 11:24:26,000 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 11:24:26,035 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.02100
2016-10-09 11:24:26,070 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.02100
2016-10-09 11:24:26,106 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.02100
2016-10-09 11:24:26,142 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.02100
2016-10-09 11:24:26,179 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.02100
2016-10-09 11:24:26,219 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.02100
2016-10-09 11:24:26,257 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.02100
2016-10-09 11:24:26,294 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.02100
2016-10-09 11:24:26,331 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.02100
2016-10-09 11:24:26,370 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.02100
2016-10-09 11:24:26,404 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.02100
2016-10-09 11:24:26,439 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.02100
2016-10-09 11:24:26,476 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.02100
2016-10-09 11:24:26,512 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.02100
2016-10-09 11:24:26,549 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.02100
2016-10-09 11:24:26,587 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.02100
2016-10-09 11:24:26,623 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.02100
2016-10-09 11:24:26,661 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.02100
2016-10-09 11:24:26,698 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.02100
2016-10-09 11:24:26,732 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.02100
2016-10-09 11:24:26,770 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.02100
2016-10-09 11:24:26,806 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.02100
2016-10-09 11:24:26,842 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.02100
2016-10-09 11:24:26,879 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.02100
2016-10-09 11:24:26,917 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.02100
2016-10-09 11:24:26,953 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.02100
2016-10-09 11:24:26,990 : INFO : PROGRESS: at 58.68% examples, 310495 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:26,991 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.02100
2016-10-09 11:24:27,028 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.02100
2016-10-09 11:24:27,064 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.02100
2016-10-09 11:24:27,098 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.02100
2016-10-09 11:24:27,134 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.02100
2016-10-09 11:24:27,171 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.02100
2016-10-09 11:24:27,207 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.02100
2016-10-09 11:24:27,244 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.02100
2016-10-09 11:24:27,281 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.02100
2016-10-09 11:24:27,318 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.02100
2016-10-09 11:24:27,356 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.02100
2016-10-09 11:24:27,392 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.02100
2016-10-09 11:24:27,428 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.02100
2016-10-09 11:24:27,462 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.02100
2016-10-09 11:24:27,500 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.02100
2016-10-09 11:24:27,536 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.02100
2016-10-09 11:24:27,573 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.02100
2016-10-09 11:24:27,645 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:27,718 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:27,718 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:27,718 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310982 effective words/s
2016-10-09 11:24:27,718 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:27,718 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:27,719 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 11:24:27,720 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 11:24:27,721 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 11:24:27,722 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 11:24:27,758 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 11:24:27,792 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01900
2016-10-09 11:24:27,827 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01900
2016-10-09 11:24:27,862 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01900
2016-10-09 11:24:27,898 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01900
2016-10-09 11:24:27,935 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01900
2016-10-09 11:24:27,972 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01900
2016-10-09 11:24:28,009 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01900
2016-10-09 11:24:28,046 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01900
2016-10-09 11:24:28,082 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01900
2016-10-09 11:24:28,118 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01900
2016-10-09 11:24:28,152 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01900
2016-10-09 11:24:28,188 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01900
2016-10-09 11:24:28,223 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01900
2016-10-09 11:24:28,259 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01900
2016-10-09 11:24:28,297 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01900
2016-10-09 11:24:28,333 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01900
2016-10-09 11:24:28,370 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01900
2016-10-09 11:24:28,408 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01900
2016-10-09 11:24:28,444 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01900
2016-10-09 11:24:28,478 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01900
2016-10-09 11:24:28,513 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01900
2016-10-09 11:24:28,548 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01900
2016-10-09 11:24:28,587 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01900
2016-10-09 11:24:28,626 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01900
2016-10-09 11:24:28,664 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01900
2016-10-09 11:24:28,701 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01900
2016-10-09 11:24:28,740 : INFO : PROGRESS: at 58.68% examples, 312277 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:28,741 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01900
2016-10-09 11:24:28,780 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01900
2016-10-09 11:24:28,816 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01900
2016-10-09 11:24:28,850 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01900
2016-10-09 11:24:28,887 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01900
2016-10-09 11:24:28,923 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01900
2016-10-09 11:24:28,962 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01900
2016-10-09 11:24:28,999 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01900
2016-10-09 11:24:29,036 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01900
2016-10-09 11:24:29,072 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01900
2016-10-09 11:24:29,115 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01900
2016-10-09 11:24:29,151 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01900
2016-10-09 11:24:29,185 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01900
2016-10-09 11:24:29,220 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01900
2016-10-09 11:24:29,255 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01900
2016-10-09 11:24:29,291 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01900
2016-10-09 11:24:29,327 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01900
2016-10-09 11:24:29,399 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:29,469 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:29,469 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:29,469 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 311832 effective words/s
2016-10-09 11:24:29,469 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:29,469 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:29,470 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 11:24:29,471 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 11:24:29,472 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 11:24:29,473 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 11:24:29,509 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 11:24:29,544 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01700
2016-10-09 11:24:29,583 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01700
2016-10-09 11:24:29,622 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01700
2016-10-09 11:24:29,658 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01700
2016-10-09 11:24:29,695 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01700
2016-10-09 11:24:29,732 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01700
2016-10-09 11:24:29,768 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01700
2016-10-09 11:24:29,807 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01700
2016-10-09 11:24:29,843 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01700
2016-10-09 11:24:29,880 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01700
2016-10-09 11:24:29,916 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01700
2016-10-09 11:24:29,951 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01700
2016-10-09 11:24:29,987 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01700
2016-10-09 11:24:30,023 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01700
2016-10-09 11:24:30,061 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01700
2016-10-09 11:24:30,098 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01700
2016-10-09 11:24:30,134 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01700
2016-10-09 11:24:30,176 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01700
2016-10-09 11:24:30,212 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01700
2016-10-09 11:24:30,246 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01700
2016-10-09 11:24:30,282 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01700
2016-10-09 11:24:30,317 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01700
2016-10-09 11:24:30,353 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01700
2016-10-09 11:24:30,390 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01700
2016-10-09 11:24:30,427 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01700
2016-10-09 11:24:30,464 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01700
2016-10-09 11:24:30,501 : INFO : PROGRESS: at 58.68% examples, 309616 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:30,502 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01700
2016-10-09 11:24:30,539 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01700
2016-10-09 11:24:30,575 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01700
2016-10-09 11:24:30,610 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01700
2016-10-09 11:24:30,645 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01700
2016-10-09 11:24:30,681 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01700
2016-10-09 11:24:30,716 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01700
2016-10-09 11:24:30,754 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01700
2016-10-09 11:24:30,791 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01700
2016-10-09 11:24:30,828 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01700
2016-10-09 11:24:30,866 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01700
2016-10-09 11:24:30,902 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01700
2016-10-09 11:24:30,937 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01700
2016-10-09 11:24:30,972 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01700
2016-10-09 11:24:31,008 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01700
2016-10-09 11:24:31,044 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01700
2016-10-09 11:24:31,080 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01700
2016-10-09 11:24:31,163 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:31,232 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:31,232 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:31,232 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 309969 effective words/s
2016-10-09 11:24:31,232 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:31,232 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:31,233 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 11:24:31,234 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 11:24:31,235 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 11:24:31,236 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 11:24:31,272 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 11:24:31,309 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01500
2016-10-09 11:24:31,344 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01500
2016-10-09 11:24:31,380 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01500
2016-10-09 11:24:31,416 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01500
2016-10-09 11:24:31,456 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01500
2016-10-09 11:24:31,492 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01500
2016-10-09 11:24:31,528 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01500
2016-10-09 11:24:31,565 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01500
2016-10-09 11:24:31,606 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01500
2016-10-09 11:24:31,643 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01500
2016-10-09 11:24:31,678 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01500
2016-10-09 11:24:31,713 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01500
2016-10-09 11:24:31,749 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01500
2016-10-09 11:24:31,786 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01500
2016-10-09 11:24:31,826 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01500
2016-10-09 11:24:31,865 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01500
2016-10-09 11:24:31,902 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01500
2016-10-09 11:24:31,940 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01500
2016-10-09 11:24:31,976 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01500
2016-10-09 11:24:32,011 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01500
2016-10-09 11:24:32,045 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01500
2016-10-09 11:24:32,081 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01500
2016-10-09 11:24:32,117 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01500
2016-10-09 11:24:32,153 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01500
2016-10-09 11:24:32,190 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01500
2016-10-09 11:24:32,226 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01500
2016-10-09 11:24:32,263 : INFO : PROGRESS: at 58.68% examples, 310063 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:32,264 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01500
2016-10-09 11:24:32,300 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01500
2016-10-09 11:24:32,336 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01500
2016-10-09 11:24:32,370 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01500
2016-10-09 11:24:32,405 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01500
2016-10-09 11:24:32,440 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01500
2016-10-09 11:24:32,476 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01500
2016-10-09 11:24:32,513 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01500
2016-10-09 11:24:32,549 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01500
2016-10-09 11:24:32,589 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01500
2016-10-09 11:24:32,626 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01500
2016-10-09 11:24:32,662 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01500
2016-10-09 11:24:32,697 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01500
2016-10-09 11:24:32,731 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01500
2016-10-09 11:24:32,766 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01500
2016-10-09 11:24:32,802 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01500
2016-10-09 11:24:32,838 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01500
2016-10-09 11:24:32,910 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:32,978 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:32,978 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:32,978 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 312876 effective words/s
2016-10-09 11:24:32,979 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:32,979 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:32,980 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 11:24:32,981 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 11:24:32,981 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 11:24:32,982 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 11:24:33,019 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 11:24:33,053 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01300
2016-10-09 11:24:33,089 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01300
2016-10-09 11:24:33,124 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01300
2016-10-09 11:24:33,160 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01300
2016-10-09 11:24:33,197 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01300
2016-10-09 11:24:33,234 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01300
2016-10-09 11:24:33,271 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01300
2016-10-09 11:24:33,312 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01300
2016-10-09 11:24:33,349 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01300
2016-10-09 11:24:33,385 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01300
2016-10-09 11:24:33,419 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01300
2016-10-09 11:24:33,455 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01300
2016-10-09 11:24:33,494 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01300
2016-10-09 11:24:33,530 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01300
2016-10-09 11:24:33,568 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01300
2016-10-09 11:24:33,611 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01300
2016-10-09 11:24:33,648 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01300
2016-10-09 11:24:33,686 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01300
2016-10-09 11:24:33,723 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01300
2016-10-09 11:24:33,757 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01300
2016-10-09 11:24:33,793 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01300
2016-10-09 11:24:33,828 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01300
2016-10-09 11:24:33,865 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01300
2016-10-09 11:24:33,903 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01300
2016-10-09 11:24:33,941 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01300
2016-10-09 11:24:33,977 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01300
2016-10-09 11:24:34,014 : INFO : PROGRESS: at 58.68% examples, 308511 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:34,015 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01300
2016-10-09 11:24:34,052 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01300
2016-10-09 11:24:34,089 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01300
2016-10-09 11:24:34,124 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01300
2016-10-09 11:24:34,159 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01300
2016-10-09 11:24:34,196 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01300
2016-10-09 11:24:34,231 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01300
2016-10-09 11:24:34,270 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01300
2016-10-09 11:24:34,306 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01300
2016-10-09 11:24:34,343 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01300
2016-10-09 11:24:34,381 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01300
2016-10-09 11:24:34,417 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01300
2016-10-09 11:24:34,452 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01300
2016-10-09 11:24:34,487 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01300
2016-10-09 11:24:34,522 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01300
2016-10-09 11:24:34,558 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01300
2016-10-09 11:24:34,598 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01300
2016-10-09 11:24:34,670 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:34,739 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:34,739 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:34,739 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 310424 effective words/s
2016-10-09 11:24:34,739 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:34,739 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:34,740 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 11:24:34,741 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 11:24:34,742 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 11:24:34,743 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 11:24:34,778 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 11:24:34,812 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.01100
2016-10-09 11:24:34,847 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.01100
2016-10-09 11:24:34,883 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.01100
2016-10-09 11:24:34,918 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.01100
2016-10-09 11:24:34,955 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.01100
2016-10-09 11:24:34,992 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.01100
2016-10-09 11:24:35,028 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.01100
2016-10-09 11:24:35,066 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.01100
2016-10-09 11:24:35,102 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.01100
2016-10-09 11:24:35,137 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.01100
2016-10-09 11:24:35,171 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.01100
2016-10-09 11:24:35,206 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.01100
2016-10-09 11:24:35,242 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.01100
2016-10-09 11:24:35,278 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.01100
2016-10-09 11:24:35,315 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.01100
2016-10-09 11:24:35,351 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.01100
2016-10-09 11:24:35,388 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.01100
2016-10-09 11:24:35,425 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.01100
2016-10-09 11:24:35,461 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.01100
2016-10-09 11:24:35,495 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.01100
2016-10-09 11:24:35,529 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.01100
2016-10-09 11:24:35,565 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.01100
2016-10-09 11:24:35,601 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.01100
2016-10-09 11:24:35,637 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.01100
2016-10-09 11:24:35,674 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.01100
2016-10-09 11:24:35,710 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.01100
2016-10-09 11:24:35,746 : INFO : PROGRESS: at 58.68% examples, 317202 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:35,747 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.01100
2016-10-09 11:24:35,784 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.01100
2016-10-09 11:24:35,819 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.01100
2016-10-09 11:24:35,853 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.01100
2016-10-09 11:24:35,888 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.01100
2016-10-09 11:24:35,924 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.01100
2016-10-09 11:24:35,959 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.01100
2016-10-09 11:24:35,997 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.01100
2016-10-09 11:24:36,033 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.01100
2016-10-09 11:24:36,070 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.01100
2016-10-09 11:24:36,108 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.01100
2016-10-09 11:24:36,143 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.01100
2016-10-09 11:24:36,178 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.01100
2016-10-09 11:24:36,213 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.01100
2016-10-09 11:24:36,248 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.01100
2016-10-09 11:24:36,284 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.01100
2016-10-09 11:24:36,320 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.01100
2016-10-09 11:24:36,402 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:36,470 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:36,470 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:36,471 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 315567 effective words/s
2016-10-09 11:24:36,471 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:36,471 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:36,472 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 11:24:36,473 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 11:24:36,473 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 11:24:36,474 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 11:24:36,510 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 11:24:36,545 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00900
2016-10-09 11:24:36,580 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00900
2016-10-09 11:24:36,616 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00900
2016-10-09 11:24:36,652 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00900
2016-10-09 11:24:36,689 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00900
2016-10-09 11:24:36,726 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00900
2016-10-09 11:24:36,763 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00900
2016-10-09 11:24:36,800 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00900
2016-10-09 11:24:36,837 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00900
2016-10-09 11:24:36,873 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00900
2016-10-09 11:24:36,907 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00900
2016-10-09 11:24:36,943 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00900
2016-10-09 11:24:36,979 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00900
2016-10-09 11:24:37,015 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00900
2016-10-09 11:24:37,052 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00900
2016-10-09 11:24:37,089 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00900
2016-10-09 11:24:37,126 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00900
2016-10-09 11:24:37,164 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00900
2016-10-09 11:24:37,201 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00900
2016-10-09 11:24:37,235 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00900
2016-10-09 11:24:37,278 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00900
2016-10-09 11:24:37,317 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00900
2016-10-09 11:24:37,355 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00900
2016-10-09 11:24:37,393 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00900
2016-10-09 11:24:37,430 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00900
2016-10-09 11:24:37,467 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00900
2016-10-09 11:24:37,504 : INFO : PROGRESS: at 58.68% examples, 309137 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:37,505 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00900
2016-10-09 11:24:37,542 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00900
2016-10-09 11:24:37,578 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00900
2016-10-09 11:24:37,613 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00900
2016-10-09 11:24:37,647 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00900
2016-10-09 11:24:37,684 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00900
2016-10-09 11:24:37,720 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00900
2016-10-09 11:24:37,758 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00900
2016-10-09 11:24:37,794 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00900
2016-10-09 11:24:37,831 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00900
2016-10-09 11:24:37,868 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00900
2016-10-09 11:24:37,908 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00900
2016-10-09 11:24:37,945 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00900
2016-10-09 11:24:37,980 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00900
2016-10-09 11:24:38,016 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00900
2016-10-09 11:24:38,052 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00900
2016-10-09 11:24:38,089 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00900
2016-10-09 11:24:38,171 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:38,240 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:38,240 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:38,240 : INFO : training on 478080 raw words (545575 effective words) took 1.8s, 308820 effective words/s
2016-10-09 11:24:38,240 : INFO : training model with 1 workers on 2637 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 11:24:38,240 : INFO : expecting 4880 sentences, matching count from corpus used for vocabulary survey
2016-10-09 11:24:38,241 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 11:24:38,242 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 11:24:38,243 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 11:24:38,244 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 11:24:38,280 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 11:24:38,314 : DEBUG : queueing job #5 (9992 words, 501 sentences) at alpha 0.00700
2016-10-09 11:24:38,348 : DEBUG : queueing job #6 (9964 words, 447 sentences) at alpha 0.00700
2016-10-09 11:24:38,384 : DEBUG : queueing job #7 (9952 words, 428 sentences) at alpha 0.00700
2016-10-09 11:24:38,420 : DEBUG : queueing job #8 (9966 words, 433 sentences) at alpha 0.00700
2016-10-09 11:24:38,456 : DEBUG : queueing job #9 (9990 words, 491 sentences) at alpha 0.00700
2016-10-09 11:24:38,492 : DEBUG : queueing job #10 (9993 words, 566 sentences) at alpha 0.00700
2016-10-09 11:24:38,529 : DEBUG : queueing job #11 (9991 words, 561 sentences) at alpha 0.00700
2016-10-09 11:24:38,566 : DEBUG : queueing job #12 (9987 words, 560 sentences) at alpha 0.00700
2016-10-09 11:24:38,605 : DEBUG : queueing job #13 (9967 words, 547 sentences) at alpha 0.00700
2016-10-09 11:24:38,641 : DEBUG : queueing job #14 (9987 words, 578 sentences) at alpha 0.00700
2016-10-09 11:24:38,675 : DEBUG : queueing job #15 (9989 words, 465 sentences) at alpha 0.00700
2016-10-09 11:24:38,710 : DEBUG : queueing job #16 (9993 words, 431 sentences) at alpha 0.00700
2016-10-09 11:24:38,745 : DEBUG : queueing job #17 (9986 words, 420 sentences) at alpha 0.00700
2016-10-09 11:24:38,781 : DEBUG : queueing job #18 (9996 words, 453 sentences) at alpha 0.00700
2016-10-09 11:24:38,818 : DEBUG : queueing job #19 (9986 words, 538 sentences) at alpha 0.00700
2016-10-09 11:24:38,854 : DEBUG : queueing job #20 (9994 words, 557 sentences) at alpha 0.00700
2016-10-09 11:24:38,891 : DEBUG : queueing job #21 (9997 words, 576 sentences) at alpha 0.00700
2016-10-09 11:24:38,928 : DEBUG : queueing job #22 (9980 words, 542 sentences) at alpha 0.00700
2016-10-09 11:24:38,964 : DEBUG : queueing job #23 (9990 words, 572 sentences) at alpha 0.00700
2016-10-09 11:24:38,998 : DEBUG : queueing job #24 (9985 words, 528 sentences) at alpha 0.00700
2016-10-09 11:24:39,032 : DEBUG : queueing job #25 (9968 words, 453 sentences) at alpha 0.00700
2016-10-09 11:24:39,068 : DEBUG : queueing job #26 (9994 words, 424 sentences) at alpha 0.00700
2016-10-09 11:24:39,104 : DEBUG : queueing job #27 (9973 words, 435 sentences) at alpha 0.00700
2016-10-09 11:24:39,140 : DEBUG : queueing job #28 (9993 words, 465 sentences) at alpha 0.00700
2016-10-09 11:24:39,177 : DEBUG : queueing job #29 (9980 words, 572 sentences) at alpha 0.00700
2016-10-09 11:24:39,213 : DEBUG : queueing job #30 (9985 words, 557 sentences) at alpha 0.00700
2016-10-09 11:24:39,249 : INFO : PROGRESS: at 58.68% examples, 316786 words/s, in_qsize 1, out_qsize 0
2016-10-09 11:24:39,250 : DEBUG : queueing job #31 (9986 words, 562 sentences) at alpha 0.00700
2016-10-09 11:24:39,286 : DEBUG : queueing job #32 (9998 words, 550 sentences) at alpha 0.00700
2016-10-09 11:24:39,322 : DEBUG : queueing job #33 (9999 words, 579 sentences) at alpha 0.00700
2016-10-09 11:24:39,355 : DEBUG : queueing job #34 (9996 words, 479 sentences) at alpha 0.00700
2016-10-09 11:24:39,390 : DEBUG : queueing job #35 (9990 words, 433 sentences) at alpha 0.00700
2016-10-09 11:24:39,426 : DEBUG : queueing job #36 (9989 words, 421 sentences) at alpha 0.00700
2016-10-09 11:24:39,461 : DEBUG : queueing job #37 (9999 words, 457 sentences) at alpha 0.00700
2016-10-09 11:24:39,499 : DEBUG : queueing job #38 (9966 words, 512 sentences) at alpha 0.00700
2016-10-09 11:24:39,535 : DEBUG : queueing job #39 (9984 words, 570 sentences) at alpha 0.00700
2016-10-09 11:24:39,575 : DEBUG : queueing job #40 (9977 words, 562 sentences) at alpha 0.00700
2016-10-09 11:24:39,612 : DEBUG : queueing job #41 (9997 words, 552 sentences) at alpha 0.00700
2016-10-09 11:24:39,648 : DEBUG : queueing job #42 (9997 words, 557 sentences) at alpha 0.00700
2016-10-09 11:24:39,683 : DEBUG : queueing job #43 (9991 words, 551 sentences) at alpha 0.00700
2016-10-09 11:24:39,717 : DEBUG : queueing job #44 (9978 words, 460 sentences) at alpha 0.00700
2016-10-09 11:24:39,752 : DEBUG : queueing job #45 (9997 words, 423 sentences) at alpha 0.00700
2016-10-09 11:24:39,789 : DEBUG : queueing job #46 (9976 words, 432 sentences) at alpha 0.00700
2016-10-09 11:24:39,825 : DEBUG : queueing job #47 (8756 words, 388 sentences) at alpha 0.00700
2016-10-09 11:24:39,897 : DEBUG : job loop exiting, total 48 jobs
2016-10-09 11:24:39,965 : DEBUG : worker exiting, processed 48 jobs
2016-10-09 11:24:39,965 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 11:24:39,965 : INFO : training on 478080 raw words (545575 effective words) took 1.7s, 316811 effective words/s
2016-10-09 11:24:39,965 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 11:24:39,965 : INFO : not storing attribute cum_table
2016-10-09 11:24:39,965 : INFO : not storing attribute syn0norm
2016-10-09 13:10:39,963 : INFO : collecting all words and their counts
2016-10-09 13:10:39,964 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 13:10:40,019 : INFO : collected 8594 word types and 11 unique tags from a corpus of 3090 examples and 54879 words
2016-10-09 13:10:40,024 : INFO : min_count=5 retains 1815 unique words (drops 6779)
2016-10-09 13:10:40,025 : INFO : min_count leaves 44534 word corpus (81% of original 54879)
2016-10-09 13:10:40,027 : INFO : deleting the raw counts dictionary of 8594 items
2016-10-09 13:10:40,028 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 13:10:40,028 : INFO : downsampling leaves estimated 44534 word corpus (100.0% of prior 44534)
2016-10-09 13:10:40,028 : INFO : estimated required memory for 1815 words and 300 dimensions: 5641900 bytes
2016-10-09 13:10:40,029 : INFO : constructing a huffman tree from 1815 words
2016-10-09 13:10:40,068 : INFO : built huffman tree with maximum node depth 13
2016-10-09 13:10:40,069 : INFO : resetting layer weights
2016-10-09 13:10:40,094 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:40,094 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:40,095 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 13:10:40,096 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 13:10:40,096 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 13:10:40,097 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 13:10:40,133 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 13:10:40,175 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02500
2016-10-09 13:10:40,211 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02500
2016-10-09 13:10:40,251 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:10:40,286 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02500
2016-10-09 13:10:40,323 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02500
2016-10-09 13:10:40,364 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02500
2016-10-09 13:10:40,397 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02500
2016-10-09 13:10:40,431 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:10:40,472 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02500
2016-10-09 13:10:40,515 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02500
2016-10-09 13:10:40,549 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02500
2016-10-09 13:10:40,581 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02500
2016-10-09 13:10:40,619 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02500
2016-10-09 13:10:40,656 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02500
2016-10-09 13:10:40,695 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02500
2016-10-09 13:10:40,729 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02500
2016-10-09 13:10:40,762 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02500
2016-10-09 13:10:40,797 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02500
2016-10-09 13:10:40,831 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02500
2016-10-09 13:10:40,870 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02500
2016-10-09 13:10:40,904 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02500
2016-10-09 13:10:40,942 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02500
2016-10-09 13:10:40,977 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02500
2016-10-09 13:10:41,042 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:41,090 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:41,091 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:41,091 : INFO : training on 274395 raw words (294385 effective words) took 1.0s, 296094 effective words/s
2016-10-09 13:10:41,091 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:41,091 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:41,092 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 13:10:41,093 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 13:10:41,093 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 13:10:41,094 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 13:10:41,128 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 13:10:41,159 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02300
2016-10-09 13:10:41,191 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02300
2016-10-09 13:10:41,224 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:10:41,257 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02300
2016-10-09 13:10:41,290 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02300
2016-10-09 13:10:41,323 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02300
2016-10-09 13:10:41,355 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02300
2016-10-09 13:10:41,387 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:10:41,421 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02300
2016-10-09 13:10:41,453 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02300
2016-10-09 13:10:41,486 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02300
2016-10-09 13:10:41,518 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02300
2016-10-09 13:10:41,550 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02300
2016-10-09 13:10:41,583 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02300
2016-10-09 13:10:41,617 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02300
2016-10-09 13:10:41,650 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02300
2016-10-09 13:10:41,682 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02300
2016-10-09 13:10:41,714 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02300
2016-10-09 13:10:41,746 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02300
2016-10-09 13:10:41,780 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02300
2016-10-09 13:10:41,813 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02300
2016-10-09 13:10:41,846 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02300
2016-10-09 13:10:41,878 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02300
2016-10-09 13:10:41,948 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:41,995 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:41,996 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:41,996 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 326322 effective words/s
2016-10-09 13:10:41,996 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:41,996 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:41,997 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 13:10:41,998 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 13:10:41,999 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 13:10:41,999 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 13:10:42,032 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 13:10:42,066 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02100
2016-10-09 13:10:42,100 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02100
2016-10-09 13:10:42,132 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:10:42,166 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02100
2016-10-09 13:10:42,199 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02100
2016-10-09 13:10:42,232 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02100
2016-10-09 13:10:42,264 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02100
2016-10-09 13:10:42,303 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:10:42,340 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02100
2016-10-09 13:10:42,376 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02100
2016-10-09 13:10:42,410 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02100
2016-10-09 13:10:42,442 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02100
2016-10-09 13:10:42,479 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02100
2016-10-09 13:10:42,512 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02100
2016-10-09 13:10:42,546 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02100
2016-10-09 13:10:42,581 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02100
2016-10-09 13:10:42,614 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02100
2016-10-09 13:10:42,646 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02100
2016-10-09 13:10:42,678 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02100
2016-10-09 13:10:42,711 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02100
2016-10-09 13:10:42,748 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02100
2016-10-09 13:10:42,781 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02100
2016-10-09 13:10:42,813 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02100
2016-10-09 13:10:42,884 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:42,933 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:42,933 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:42,933 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 314763 effective words/s
2016-10-09 13:10:42,933 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:42,933 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:42,935 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 13:10:42,936 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 13:10:42,937 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 13:10:42,938 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 13:10:42,971 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 13:10:43,003 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01900
2016-10-09 13:10:43,035 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01900
2016-10-09 13:10:43,068 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:10:43,102 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01900
2016-10-09 13:10:43,135 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01900
2016-10-09 13:10:43,167 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01900
2016-10-09 13:10:43,199 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01900
2016-10-09 13:10:43,232 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:10:43,268 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01900
2016-10-09 13:10:43,302 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01900
2016-10-09 13:10:43,335 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01900
2016-10-09 13:10:43,367 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01900
2016-10-09 13:10:43,403 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01900
2016-10-09 13:10:43,435 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01900
2016-10-09 13:10:43,469 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01900
2016-10-09 13:10:43,502 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01900
2016-10-09 13:10:43,534 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01900
2016-10-09 13:10:43,566 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01900
2016-10-09 13:10:43,601 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01900
2016-10-09 13:10:43,636 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01900
2016-10-09 13:10:43,669 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01900
2016-10-09 13:10:43,702 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01900
2016-10-09 13:10:43,734 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01900
2016-10-09 13:10:43,797 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:43,845 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:43,845 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:43,845 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 323946 effective words/s
2016-10-09 13:10:43,846 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:43,846 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:43,847 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 13:10:43,848 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 13:10:43,848 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 13:10:43,849 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 13:10:43,887 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 13:10:43,921 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01700
2016-10-09 13:10:43,954 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01700
2016-10-09 13:10:43,987 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:10:44,021 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01700
2016-10-09 13:10:44,054 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01700
2016-10-09 13:10:44,088 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01700
2016-10-09 13:10:44,120 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01700
2016-10-09 13:10:44,154 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:10:44,188 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01700
2016-10-09 13:10:44,222 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01700
2016-10-09 13:10:44,259 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01700
2016-10-09 13:10:44,291 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01700
2016-10-09 13:10:44,324 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01700
2016-10-09 13:10:44,357 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01700
2016-10-09 13:10:44,394 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01700
2016-10-09 13:10:44,428 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01700
2016-10-09 13:10:44,464 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01700
2016-10-09 13:10:44,504 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01700
2016-10-09 13:10:44,538 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01700
2016-10-09 13:10:44,574 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01700
2016-10-09 13:10:44,609 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01700
2016-10-09 13:10:44,642 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01700
2016-10-09 13:10:44,674 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01700
2016-10-09 13:10:44,739 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:44,789 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:44,790 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:44,790 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 312708 effective words/s
2016-10-09 13:10:44,790 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:44,790 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:44,791 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 13:10:44,792 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 13:10:44,792 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 13:10:44,793 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 13:10:44,826 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 13:10:44,858 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01500
2016-10-09 13:10:44,890 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01500
2016-10-09 13:10:44,923 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:10:44,963 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01500
2016-10-09 13:10:44,996 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01500
2016-10-09 13:10:45,029 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01500
2016-10-09 13:10:45,060 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01500
2016-10-09 13:10:45,093 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:10:45,130 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01500
2016-10-09 13:10:45,164 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01500
2016-10-09 13:10:45,197 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01500
2016-10-09 13:10:45,229 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01500
2016-10-09 13:10:45,261 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01500
2016-10-09 13:10:45,294 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01500
2016-10-09 13:10:45,328 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01500
2016-10-09 13:10:45,361 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01500
2016-10-09 13:10:45,395 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01500
2016-10-09 13:10:45,431 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01500
2016-10-09 13:10:45,463 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01500
2016-10-09 13:10:45,496 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01500
2016-10-09 13:10:45,529 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01500
2016-10-09 13:10:45,563 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01500
2016-10-09 13:10:45,594 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01500
2016-10-09 13:10:45,661 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:45,708 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:45,709 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:45,709 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 321367 effective words/s
2016-10-09 13:10:45,709 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:45,709 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:45,710 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 13:10:45,711 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 13:10:45,711 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 13:10:45,712 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 13:10:45,745 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 13:10:45,776 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01300
2016-10-09 13:10:45,808 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01300
2016-10-09 13:10:45,841 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:10:45,874 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01300
2016-10-09 13:10:45,908 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01300
2016-10-09 13:10:45,940 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01300
2016-10-09 13:10:45,971 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01300
2016-10-09 13:10:46,004 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:10:46,037 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01300
2016-10-09 13:10:46,070 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01300
2016-10-09 13:10:46,103 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01300
2016-10-09 13:10:46,134 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01300
2016-10-09 13:10:46,169 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01300
2016-10-09 13:10:46,202 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01300
2016-10-09 13:10:46,236 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01300
2016-10-09 13:10:46,269 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01300
2016-10-09 13:10:46,305 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01300
2016-10-09 13:10:46,341 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01300
2016-10-09 13:10:46,373 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01300
2016-10-09 13:10:46,408 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01300
2016-10-09 13:10:46,441 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01300
2016-10-09 13:10:46,474 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01300
2016-10-09 13:10:46,505 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01300
2016-10-09 13:10:46,568 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:46,616 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:46,616 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:46,616 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 325332 effective words/s
2016-10-09 13:10:46,616 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:46,616 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:46,618 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 13:10:46,618 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 13:10:46,619 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 13:10:46,620 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 13:10:46,653 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 13:10:46,684 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01100
2016-10-09 13:10:46,717 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01100
2016-10-09 13:10:46,749 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:10:46,782 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01100
2016-10-09 13:10:46,816 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01100
2016-10-09 13:10:46,848 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01100
2016-10-09 13:10:46,881 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01100
2016-10-09 13:10:46,918 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:10:46,955 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01100
2016-10-09 13:10:46,993 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01100
2016-10-09 13:10:47,032 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01100
2016-10-09 13:10:47,068 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01100
2016-10-09 13:10:47,101 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01100
2016-10-09 13:10:47,135 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01100
2016-10-09 13:10:47,171 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01100
2016-10-09 13:10:47,206 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01100
2016-10-09 13:10:47,239 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01100
2016-10-09 13:10:47,274 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01100
2016-10-09 13:10:47,309 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01100
2016-10-09 13:10:47,342 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01100
2016-10-09 13:10:47,379 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01100
2016-10-09 13:10:47,415 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01100
2016-10-09 13:10:47,447 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01100
2016-10-09 13:10:47,512 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:47,577 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:47,577 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:47,577 : INFO : training on 274395 raw words (294385 effective words) took 1.0s, 306940 effective words/s
2016-10-09 13:10:47,578 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:47,578 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:47,579 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 13:10:47,580 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 13:10:47,580 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 13:10:47,581 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 13:10:47,615 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 13:10:47,648 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00900
2016-10-09 13:10:47,682 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00900
2016-10-09 13:10:47,718 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:10:47,753 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00900
2016-10-09 13:10:47,790 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00900
2016-10-09 13:10:47,824 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00900
2016-10-09 13:10:47,857 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00900
2016-10-09 13:10:47,890 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:10:47,924 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00900
2016-10-09 13:10:47,958 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00900
2016-10-09 13:10:47,993 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00900
2016-10-09 13:10:48,029 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00900
2016-10-09 13:10:48,062 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00900
2016-10-09 13:10:48,096 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00900
2016-10-09 13:10:48,130 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00900
2016-10-09 13:10:48,164 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00900
2016-10-09 13:10:48,197 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00900
2016-10-09 13:10:48,229 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00900
2016-10-09 13:10:48,261 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00900
2016-10-09 13:10:48,294 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00900
2016-10-09 13:10:48,327 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00900
2016-10-09 13:10:48,361 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00900
2016-10-09 13:10:48,392 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00900
2016-10-09 13:10:48,455 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:48,515 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:48,516 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:48,516 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 314725 effective words/s
2016-10-09 13:10:48,516 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:10:48,516 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:10:48,517 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 13:10:48,518 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 13:10:48,519 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 13:10:48,520 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 13:10:48,555 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 13:10:48,587 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00700
2016-10-09 13:10:48,620 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00700
2016-10-09 13:10:48,654 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:10:48,692 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00700
2016-10-09 13:10:48,726 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00700
2016-10-09 13:10:48,759 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00700
2016-10-09 13:10:48,791 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00700
2016-10-09 13:10:48,823 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:10:48,860 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00700
2016-10-09 13:10:48,894 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00700
2016-10-09 13:10:48,945 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00700
2016-10-09 13:10:48,979 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00700
2016-10-09 13:10:49,014 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00700
2016-10-09 13:10:49,049 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00700
2016-10-09 13:10:49,086 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00700
2016-10-09 13:10:49,131 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00700
2016-10-09 13:10:49,166 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00700
2016-10-09 13:10:49,198 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00700
2016-10-09 13:10:49,235 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00700
2016-10-09 13:10:49,270 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00700
2016-10-09 13:10:49,306 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00700
2016-10-09 13:10:49,342 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00700
2016-10-09 13:10:49,375 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00700
2016-10-09 13:10:49,442 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:10:49,491 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:10:49,491 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:10:49,492 : INFO : training on 274395 raw words (294385 effective words) took 1.0s, 302997 effective words/s
2016-10-09 13:10:49,492 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 13:10:49,492 : INFO : not storing attribute syn0norm
2016-10-09 13:10:49,492 : INFO : not storing attribute cum_table
2016-10-09 13:15:03,241 : INFO : collecting all words and their counts
2016-10-09 13:15:03,241 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 13:15:03,287 : INFO : collected 8594 word types and 11 unique tags from a corpus of 3090 examples and 54879 words
2016-10-09 13:15:03,293 : INFO : min_count=5 retains 1815 unique words (drops 6779)
2016-10-09 13:15:03,293 : INFO : min_count leaves 44534 word corpus (81% of original 54879)
2016-10-09 13:15:03,296 : INFO : deleting the raw counts dictionary of 8594 items
2016-10-09 13:15:03,296 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 13:15:03,296 : INFO : downsampling leaves estimated 44534 word corpus (100.0% of prior 44534)
2016-10-09 13:15:03,296 : INFO : estimated required memory for 1815 words and 300 dimensions: 5641900 bytes
2016-10-09 13:15:03,297 : INFO : constructing a huffman tree from 1815 words
2016-10-09 13:15:03,334 : INFO : built huffman tree with maximum node depth 13
2016-10-09 13:15:03,335 : INFO : resetting layer weights
2016-10-09 13:15:03,357 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:03,358 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:03,359 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 13:15:03,360 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 13:15:03,360 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 13:15:03,361 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 13:15:03,398 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 13:15:03,430 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02500
2016-10-09 13:15:03,462 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02500
2016-10-09 13:15:03,495 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:15:03,528 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02500
2016-10-09 13:15:03,560 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02500
2016-10-09 13:15:03,593 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02500
2016-10-09 13:15:03,628 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02500
2016-10-09 13:15:03,661 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:15:03,695 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02500
2016-10-09 13:15:03,728 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02500
2016-10-09 13:15:03,761 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02500
2016-10-09 13:15:03,793 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02500
2016-10-09 13:15:03,825 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02500
2016-10-09 13:15:03,858 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02500
2016-10-09 13:15:03,891 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02500
2016-10-09 13:15:03,927 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02500
2016-10-09 13:15:03,960 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02500
2016-10-09 13:15:03,995 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02500
2016-10-09 13:15:04,027 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02500
2016-10-09 13:15:04,064 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02500
2016-10-09 13:15:04,097 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02500
2016-10-09 13:15:04,130 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02500
2016-10-09 13:15:04,162 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02500
2016-10-09 13:15:04,226 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:04,274 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:04,274 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:04,274 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 322225 effective words/s
2016-10-09 13:15:04,274 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:04,274 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:04,275 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 13:15:04,276 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 13:15:04,277 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 13:15:04,278 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 13:15:04,311 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 13:15:04,343 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02300
2016-10-09 13:15:04,376 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02300
2016-10-09 13:15:04,409 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:15:04,443 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02300
2016-10-09 13:15:04,476 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02300
2016-10-09 13:15:04,510 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02300
2016-10-09 13:15:04,541 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02300
2016-10-09 13:15:04,574 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:15:04,608 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02300
2016-10-09 13:15:04,641 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02300
2016-10-09 13:15:04,674 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02300
2016-10-09 13:15:04,709 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02300
2016-10-09 13:15:04,741 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02300
2016-10-09 13:15:04,775 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02300
2016-10-09 13:15:04,808 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02300
2016-10-09 13:15:04,841 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02300
2016-10-09 13:15:04,874 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02300
2016-10-09 13:15:04,906 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02300
2016-10-09 13:15:04,939 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02300
2016-10-09 13:15:04,973 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02300
2016-10-09 13:15:05,006 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02300
2016-10-09 13:15:05,040 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02300
2016-10-09 13:15:05,071 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02300
2016-10-09 13:15:05,137 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:05,185 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:05,185 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:05,185 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 324118 effective words/s
2016-10-09 13:15:05,185 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:05,185 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:05,186 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 13:15:05,187 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 13:15:05,188 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 13:15:05,189 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 13:15:05,222 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 13:15:05,253 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02100
2016-10-09 13:15:05,285 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02100
2016-10-09 13:15:05,318 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:15:05,352 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02100
2016-10-09 13:15:05,389 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02100
2016-10-09 13:15:05,424 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02100
2016-10-09 13:15:05,455 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02100
2016-10-09 13:15:05,489 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:15:05,522 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02100
2016-10-09 13:15:05,555 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02100
2016-10-09 13:15:05,588 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02100
2016-10-09 13:15:05,620 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02100
2016-10-09 13:15:05,652 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02100
2016-10-09 13:15:05,686 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02100
2016-10-09 13:15:05,721 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02100
2016-10-09 13:15:05,754 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02100
2016-10-09 13:15:05,787 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02100
2016-10-09 13:15:05,818 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02100
2016-10-09 13:15:05,851 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02100
2016-10-09 13:15:05,885 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02100
2016-10-09 13:15:05,919 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02100
2016-10-09 13:15:05,952 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02100
2016-10-09 13:15:05,984 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02100
2016-10-09 13:15:06,047 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:06,096 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:06,096 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:06,096 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 323954 effective words/s
2016-10-09 13:15:06,097 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:06,097 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:06,098 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 13:15:06,099 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 13:15:06,099 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 13:15:06,100 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 13:15:06,133 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 13:15:06,165 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01900
2016-10-09 13:15:06,197 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01900
2016-10-09 13:15:06,229 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:15:06,266 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01900
2016-10-09 13:15:06,298 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01900
2016-10-09 13:15:06,331 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01900
2016-10-09 13:15:06,362 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01900
2016-10-09 13:15:06,397 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:15:06,430 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01900
2016-10-09 13:15:06,463 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01900
2016-10-09 13:15:06,495 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01900
2016-10-09 13:15:06,527 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01900
2016-10-09 13:15:06,562 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01900
2016-10-09 13:15:06,596 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01900
2016-10-09 13:15:06,629 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01900
2016-10-09 13:15:06,663 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01900
2016-10-09 13:15:06,695 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01900
2016-10-09 13:15:06,727 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01900
2016-10-09 13:15:06,759 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01900
2016-10-09 13:15:06,792 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01900
2016-10-09 13:15:06,825 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01900
2016-10-09 13:15:06,858 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01900
2016-10-09 13:15:06,889 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01900
2016-10-09 13:15:06,956 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:07,004 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:07,004 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:07,004 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 325233 effective words/s
2016-10-09 13:15:07,005 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:07,005 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:07,006 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 13:15:07,007 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 13:15:07,007 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 13:15:07,008 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 13:15:07,042 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 13:15:07,079 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01700
2016-10-09 13:15:07,112 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01700
2016-10-09 13:15:07,145 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:15:07,179 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01700
2016-10-09 13:15:07,212 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01700
2016-10-09 13:15:07,245 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01700
2016-10-09 13:15:07,277 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01700
2016-10-09 13:15:07,310 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:15:07,343 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01700
2016-10-09 13:15:07,377 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01700
2016-10-09 13:15:07,411 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01700
2016-10-09 13:15:07,443 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01700
2016-10-09 13:15:07,476 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01700
2016-10-09 13:15:07,509 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01700
2016-10-09 13:15:07,543 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01700
2016-10-09 13:15:07,576 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01700
2016-10-09 13:15:07,609 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01700
2016-10-09 13:15:07,641 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01700
2016-10-09 13:15:07,677 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01700
2016-10-09 13:15:07,712 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01700
2016-10-09 13:15:07,748 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01700
2016-10-09 13:15:07,781 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01700
2016-10-09 13:15:07,813 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01700
2016-10-09 13:15:07,878 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:07,928 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:07,928 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:07,928 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 319710 effective words/s
2016-10-09 13:15:07,928 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:07,928 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:07,929 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 13:15:07,930 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 13:15:07,931 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 13:15:07,932 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 13:15:07,965 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 13:15:08,000 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01500
2016-10-09 13:15:08,034 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01500
2016-10-09 13:15:08,067 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:15:08,101 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01500
2016-10-09 13:15:08,134 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01500
2016-10-09 13:15:08,169 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01500
2016-10-09 13:15:08,204 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01500
2016-10-09 13:15:08,238 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:15:08,273 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01500
2016-10-09 13:15:08,307 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01500
2016-10-09 13:15:08,340 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01500
2016-10-09 13:15:08,372 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01500
2016-10-09 13:15:08,406 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01500
2016-10-09 13:15:08,439 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01500
2016-10-09 13:15:08,472 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01500
2016-10-09 13:15:08,507 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01500
2016-10-09 13:15:08,542 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01500
2016-10-09 13:15:08,574 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01500
2016-10-09 13:15:08,607 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01500
2016-10-09 13:15:08,640 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01500
2016-10-09 13:15:08,674 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01500
2016-10-09 13:15:08,707 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01500
2016-10-09 13:15:08,739 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01500
2016-10-09 13:15:08,803 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:08,851 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:08,851 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:08,852 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 319755 effective words/s
2016-10-09 13:15:08,852 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:08,852 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:08,853 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 13:15:08,854 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 13:15:08,854 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 13:15:08,855 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 13:15:08,888 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 13:15:08,920 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01300
2016-10-09 13:15:08,952 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01300
2016-10-09 13:15:08,985 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:15:09,018 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01300
2016-10-09 13:15:09,051 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01300
2016-10-09 13:15:09,084 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01300
2016-10-09 13:15:09,116 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01300
2016-10-09 13:15:09,148 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:15:09,182 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01300
2016-10-09 13:15:09,215 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01300
2016-10-09 13:15:09,248 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01300
2016-10-09 13:15:09,280 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01300
2016-10-09 13:15:09,312 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01300
2016-10-09 13:15:09,345 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01300
2016-10-09 13:15:09,379 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01300
2016-10-09 13:15:09,413 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01300
2016-10-09 13:15:09,449 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01300
2016-10-09 13:15:09,483 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01300
2016-10-09 13:15:09,516 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01300
2016-10-09 13:15:09,550 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01300
2016-10-09 13:15:09,586 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01300
2016-10-09 13:15:09,619 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01300
2016-10-09 13:15:09,650 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01300
2016-10-09 13:15:09,717 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:09,767 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:09,767 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:09,768 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 322360 effective words/s
2016-10-09 13:15:09,768 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:09,768 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:09,769 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 13:15:09,770 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 13:15:09,770 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 13:15:09,771 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 13:15:09,804 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 13:15:09,836 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01100
2016-10-09 13:15:09,868 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01100
2016-10-09 13:15:09,902 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:15:09,935 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01100
2016-10-09 13:15:09,968 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01100
2016-10-09 13:15:10,000 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01100
2016-10-09 13:15:10,032 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01100
2016-10-09 13:15:10,065 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:15:10,099 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01100
2016-10-09 13:15:10,132 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01100
2016-10-09 13:15:10,166 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01100
2016-10-09 13:15:10,197 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01100
2016-10-09 13:15:10,230 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01100
2016-10-09 13:15:10,262 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01100
2016-10-09 13:15:10,296 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01100
2016-10-09 13:15:10,329 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01100
2016-10-09 13:15:10,361 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01100
2016-10-09 13:15:10,394 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01100
2016-10-09 13:15:10,426 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01100
2016-10-09 13:15:10,459 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01100
2016-10-09 13:15:10,492 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01100
2016-10-09 13:15:10,526 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01100
2016-10-09 13:15:10,558 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01100
2016-10-09 13:15:10,621 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:10,669 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:10,669 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:10,669 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 327385 effective words/s
2016-10-09 13:15:10,670 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:10,670 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:10,671 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 13:15:10,672 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 13:15:10,672 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 13:15:10,673 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 13:15:10,706 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 13:15:10,738 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00900
2016-10-09 13:15:10,769 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00900
2016-10-09 13:15:10,802 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:15:10,835 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00900
2016-10-09 13:15:10,868 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00900
2016-10-09 13:15:10,901 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00900
2016-10-09 13:15:10,933 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00900
2016-10-09 13:15:10,965 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:15:10,998 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00900
2016-10-09 13:15:11,031 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00900
2016-10-09 13:15:11,064 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00900
2016-10-09 13:15:11,096 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00900
2016-10-09 13:15:11,128 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00900
2016-10-09 13:15:11,161 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00900
2016-10-09 13:15:11,195 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00900
2016-10-09 13:15:11,227 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00900
2016-10-09 13:15:11,259 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00900
2016-10-09 13:15:11,291 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00900
2016-10-09 13:15:11,323 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00900
2016-10-09 13:15:11,356 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00900
2016-10-09 13:15:11,391 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00900
2016-10-09 13:15:11,424 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00900
2016-10-09 13:15:11,455 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00900
2016-10-09 13:15:11,519 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:11,567 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:11,567 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:11,567 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 328947 effective words/s
2016-10-09 13:15:11,567 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:15:11,567 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:15:11,569 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 13:15:11,569 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 13:15:11,570 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 13:15:11,571 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 13:15:11,605 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 13:15:11,636 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00700
2016-10-09 13:15:11,669 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00700
2016-10-09 13:15:11,704 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:15:11,737 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00700
2016-10-09 13:15:11,770 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00700
2016-10-09 13:15:11,804 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00700
2016-10-09 13:15:11,836 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00700
2016-10-09 13:15:11,868 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:15:11,903 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00700
2016-10-09 13:15:11,937 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00700
2016-10-09 13:15:11,970 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00700
2016-10-09 13:15:12,002 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00700
2016-10-09 13:15:12,035 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00700
2016-10-09 13:15:12,069 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00700
2016-10-09 13:15:12,102 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00700
2016-10-09 13:15:12,136 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00700
2016-10-09 13:15:12,169 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00700
2016-10-09 13:15:12,201 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00700
2016-10-09 13:15:12,237 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00700
2016-10-09 13:15:12,271 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00700
2016-10-09 13:15:12,304 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00700
2016-10-09 13:15:12,338 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00700
2016-10-09 13:15:12,370 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00700
2016-10-09 13:15:12,436 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:15:12,484 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:15:12,485 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:15:12,485 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 321859 effective words/s
2016-10-09 13:15:12,485 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 13:15:12,485 : INFO : not storing attribute syn0norm
2016-10-09 13:15:12,485 : INFO : not storing attribute cum_table
2016-10-09 13:25:46,550 : INFO : collecting all words and their counts
2016-10-09 13:25:46,550 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags
2016-10-09 13:25:46,596 : INFO : collected 8594 word types and 11 unique tags from a corpus of 3090 examples and 54879 words
2016-10-09 13:25:46,602 : INFO : min_count=5 retains 1815 unique words (drops 6779)
2016-10-09 13:25:46,602 : INFO : min_count leaves 44534 word corpus (81% of original 54879)
2016-10-09 13:25:46,605 : INFO : deleting the raw counts dictionary of 8594 items
2016-10-09 13:25:46,605 : INFO : sample=0 downsamples 0 most-common words
2016-10-09 13:25:46,606 : INFO : downsampling leaves estimated 44534 word corpus (100.0% of prior 44534)
2016-10-09 13:25:46,606 : INFO : estimated required memory for 1815 words and 300 dimensions: 5641900 bytes
2016-10-09 13:25:46,607 : INFO : constructing a huffman tree from 1815 words
2016-10-09 13:25:46,644 : INFO : built huffman tree with maximum node depth 13
2016-10-09 13:25:46,645 : INFO : resetting layer weights
2016-10-09 13:25:46,668 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:46,668 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:46,669 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02500
2016-10-09 13:25:46,670 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02500
2016-10-09 13:25:46,671 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02500
2016-10-09 13:25:46,672 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02500
2016-10-09 13:25:46,706 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02500
2016-10-09 13:25:46,738 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02500
2016-10-09 13:25:46,771 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02500
2016-10-09 13:25:46,804 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:25:46,837 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02500
2016-10-09 13:25:46,870 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02500
2016-10-09 13:25:46,903 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02500
2016-10-09 13:25:46,935 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02500
2016-10-09 13:25:46,968 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02500
2016-10-09 13:25:47,001 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02500
2016-10-09 13:25:47,035 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02500
2016-10-09 13:25:47,069 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02500
2016-10-09 13:25:47,100 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02500
2016-10-09 13:25:47,133 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02500
2016-10-09 13:25:47,168 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02500
2016-10-09 13:25:47,201 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02500
2016-10-09 13:25:47,235 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02500
2016-10-09 13:25:47,269 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02500
2016-10-09 13:25:47,301 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02500
2016-10-09 13:25:47,334 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02500
2016-10-09 13:25:47,370 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02500
2016-10-09 13:25:47,404 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02500
2016-10-09 13:25:47,437 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02500
2016-10-09 13:25:47,468 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02500
2016-10-09 13:25:47,533 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:47,581 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:47,581 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:47,581 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 322744 effective words/s
2016-10-09 13:25:47,582 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:47,582 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:47,583 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02300
2016-10-09 13:25:47,584 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02300
2016-10-09 13:25:47,584 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02300
2016-10-09 13:25:47,585 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02300
2016-10-09 13:25:47,619 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02300
2016-10-09 13:25:47,650 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02300
2016-10-09 13:25:47,683 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02300
2016-10-09 13:25:47,716 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:25:47,750 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02300
2016-10-09 13:25:47,783 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02300
2016-10-09 13:25:47,816 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02300
2016-10-09 13:25:47,847 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02300
2016-10-09 13:25:47,881 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02300
2016-10-09 13:25:47,914 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02300
2016-10-09 13:25:47,947 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02300
2016-10-09 13:25:47,980 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02300
2016-10-09 13:25:48,012 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02300
2016-10-09 13:25:48,048 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02300
2016-10-09 13:25:48,081 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02300
2016-10-09 13:25:48,115 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02300
2016-10-09 13:25:48,147 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02300
2016-10-09 13:25:48,180 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02300
2016-10-09 13:25:48,212 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02300
2016-10-09 13:25:48,245 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02300
2016-10-09 13:25:48,278 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02300
2016-10-09 13:25:48,311 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02300
2016-10-09 13:25:48,344 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02300
2016-10-09 13:25:48,379 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02300
2016-10-09 13:25:48,442 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:48,491 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:48,491 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:48,491 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 324657 effective words/s
2016-10-09 13:25:48,491 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:48,491 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:48,492 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.02100
2016-10-09 13:25:48,493 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.02100
2016-10-09 13:25:48,494 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.02100
2016-10-09 13:25:48,495 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.02100
2016-10-09 13:25:48,528 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.02100
2016-10-09 13:25:48,559 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.02100
2016-10-09 13:25:48,592 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.02100
2016-10-09 13:25:48,625 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:25:48,658 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.02100
2016-10-09 13:25:48,691 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.02100
2016-10-09 13:25:48,724 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.02100
2016-10-09 13:25:48,756 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.02100
2016-10-09 13:25:48,789 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.02100
2016-10-09 13:25:48,822 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.02100
2016-10-09 13:25:48,855 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.02100
2016-10-09 13:25:48,888 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.02100
2016-10-09 13:25:48,928 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.02100
2016-10-09 13:25:48,969 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.02100
2016-10-09 13:25:49,004 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.02100
2016-10-09 13:25:49,038 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.02100
2016-10-09 13:25:49,072 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.02100
2016-10-09 13:25:49,116 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.02100
2016-10-09 13:25:49,149 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.02100
2016-10-09 13:25:49,185 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.02100
2016-10-09 13:25:49,218 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.02100
2016-10-09 13:25:49,255 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.02100
2016-10-09 13:25:49,288 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.02100
2016-10-09 13:25:49,319 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.02100
2016-10-09 13:25:49,384 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:49,432 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:49,432 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:49,433 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 313628 effective words/s
2016-10-09 13:25:49,433 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:49,433 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:49,434 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01900
2016-10-09 13:25:49,435 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01900
2016-10-09 13:25:49,435 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01900
2016-10-09 13:25:49,436 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01900
2016-10-09 13:25:49,470 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01900
2016-10-09 13:25:49,503 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01900
2016-10-09 13:25:49,535 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01900
2016-10-09 13:25:49,568 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:25:49,601 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01900
2016-10-09 13:25:49,634 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01900
2016-10-09 13:25:49,667 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01900
2016-10-09 13:25:49,699 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01900
2016-10-09 13:25:49,734 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01900
2016-10-09 13:25:49,767 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01900
2016-10-09 13:25:49,800 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01900
2016-10-09 13:25:49,833 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01900
2016-10-09 13:25:49,865 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01900
2016-10-09 13:25:49,898 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01900
2016-10-09 13:25:49,931 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01900
2016-10-09 13:25:49,965 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01900
2016-10-09 13:25:50,001 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01900
2016-10-09 13:25:50,035 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01900
2016-10-09 13:25:50,074 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01900
2016-10-09 13:25:50,107 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01900
2016-10-09 13:25:50,140 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01900
2016-10-09 13:25:50,174 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01900
2016-10-09 13:25:50,207 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01900
2016-10-09 13:25:50,238 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01900
2016-10-09 13:25:50,302 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:50,349 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:50,350 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:50,350 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 321974 effective words/s
2016-10-09 13:25:50,350 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:50,350 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:50,351 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01700
2016-10-09 13:25:50,352 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01700
2016-10-09 13:25:50,352 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01700
2016-10-09 13:25:50,353 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01700
2016-10-09 13:25:50,387 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01700
2016-10-09 13:25:50,419 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01700
2016-10-09 13:25:50,451 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01700
2016-10-09 13:25:50,485 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:25:50,518 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01700
2016-10-09 13:25:50,551 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01700
2016-10-09 13:25:50,584 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01700
2016-10-09 13:25:50,616 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01700
2016-10-09 13:25:50,649 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01700
2016-10-09 13:25:50,682 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01700
2016-10-09 13:25:50,716 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01700
2016-10-09 13:25:50,750 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01700
2016-10-09 13:25:50,781 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01700
2016-10-09 13:25:50,814 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01700
2016-10-09 13:25:50,847 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01700
2016-10-09 13:25:50,880 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01700
2016-10-09 13:25:50,913 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01700
2016-10-09 13:25:50,947 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01700
2016-10-09 13:25:50,979 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01700
2016-10-09 13:25:51,012 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01700
2016-10-09 13:25:51,045 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01700
2016-10-09 13:25:51,080 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01700
2016-10-09 13:25:51,114 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01700
2016-10-09 13:25:51,145 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01700
2016-10-09 13:25:51,210 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:51,258 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:51,258 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:51,258 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 325075 effective words/s
2016-10-09 13:25:51,258 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:51,258 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:51,259 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01500
2016-10-09 13:25:51,260 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01500
2016-10-09 13:25:51,261 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01500
2016-10-09 13:25:51,262 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01500
2016-10-09 13:25:51,295 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01500
2016-10-09 13:25:51,327 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01500
2016-10-09 13:25:51,361 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01500
2016-10-09 13:25:51,394 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:25:51,428 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01500
2016-10-09 13:25:51,461 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01500
2016-10-09 13:25:51,494 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01500
2016-10-09 13:25:51,526 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01500
2016-10-09 13:25:51,560 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01500
2016-10-09 13:25:51,593 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01500
2016-10-09 13:25:51,626 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01500
2016-10-09 13:25:51,660 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01500
2016-10-09 13:25:51,692 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01500
2016-10-09 13:25:51,724 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01500
2016-10-09 13:25:51,758 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01500
2016-10-09 13:25:51,792 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01500
2016-10-09 13:25:51,825 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01500
2016-10-09 13:25:51,858 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01500
2016-10-09 13:25:51,890 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01500
2016-10-09 13:25:51,923 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01500
2016-10-09 13:25:51,957 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01500
2016-10-09 13:25:51,990 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01500
2016-10-09 13:25:52,024 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01500
2016-10-09 13:25:52,055 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01500
2016-10-09 13:25:52,120 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:52,168 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:52,169 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:52,169 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 323792 effective words/s
2016-10-09 13:25:52,169 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:52,169 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:52,170 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01300
2016-10-09 13:25:52,171 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01300
2016-10-09 13:25:52,171 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01300
2016-10-09 13:25:52,172 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01300
2016-10-09 13:25:52,205 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01300
2016-10-09 13:25:52,237 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01300
2016-10-09 13:25:52,269 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01300
2016-10-09 13:25:52,302 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:25:52,335 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01300
2016-10-09 13:25:52,369 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01300
2016-10-09 13:25:52,402 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01300
2016-10-09 13:25:52,435 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01300
2016-10-09 13:25:52,469 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01300
2016-10-09 13:25:52,502 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01300
2016-10-09 13:25:52,535 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01300
2016-10-09 13:25:52,568 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01300
2016-10-09 13:25:52,600 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01300
2016-10-09 13:25:52,632 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01300
2016-10-09 13:25:52,665 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01300
2016-10-09 13:25:52,698 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01300
2016-10-09 13:25:52,731 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01300
2016-10-09 13:25:52,764 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01300
2016-10-09 13:25:52,796 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01300
2016-10-09 13:25:52,828 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01300
2016-10-09 13:25:52,864 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01300
2016-10-09 13:25:52,897 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01300
2016-10-09 13:25:52,930 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01300
2016-10-09 13:25:52,961 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01300
2016-10-09 13:25:53,025 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:53,074 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:53,074 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:53,074 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 326137 effective words/s
2016-10-09 13:25:53,074 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:53,074 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:53,075 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.01100
2016-10-09 13:25:53,076 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.01100
2016-10-09 13:25:53,077 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.01100
2016-10-09 13:25:53,078 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.01100
2016-10-09 13:25:53,111 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.01100
2016-10-09 13:25:53,142 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.01100
2016-10-09 13:25:53,174 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.01100
2016-10-09 13:25:53,207 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:25:53,240 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.01100
2016-10-09 13:25:53,273 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.01100
2016-10-09 13:25:53,306 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.01100
2016-10-09 13:25:53,337 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.01100
2016-10-09 13:25:53,371 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.01100
2016-10-09 13:25:53,404 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.01100
2016-10-09 13:25:53,437 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.01100
2016-10-09 13:25:53,470 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.01100
2016-10-09 13:25:53,501 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.01100
2016-10-09 13:25:53,534 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.01100
2016-10-09 13:25:53,567 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.01100
2016-10-09 13:25:53,600 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.01100
2016-10-09 13:25:53,632 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.01100
2016-10-09 13:25:53,665 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.01100
2016-10-09 13:25:53,697 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.01100
2016-10-09 13:25:53,729 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.01100
2016-10-09 13:25:53,762 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.01100
2016-10-09 13:25:53,796 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.01100
2016-10-09 13:25:53,828 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.01100
2016-10-09 13:25:53,863 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.01100
2016-10-09 13:25:53,927 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:53,976 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:53,976 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:53,976 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 327454 effective words/s
2016-10-09 13:25:53,976 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:53,976 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:53,977 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00900
2016-10-09 13:25:53,978 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00900
2016-10-09 13:25:53,979 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00900
2016-10-09 13:25:53,980 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00900
2016-10-09 13:25:54,013 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00900
2016-10-09 13:25:54,049 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00900
2016-10-09 13:25:54,081 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00900
2016-10-09 13:25:54,114 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:25:54,148 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00900
2016-10-09 13:25:54,182 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00900
2016-10-09 13:25:54,215 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00900
2016-10-09 13:25:54,247 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00900
2016-10-09 13:25:54,280 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00900
2016-10-09 13:25:54,313 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00900
2016-10-09 13:25:54,346 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00900
2016-10-09 13:25:54,383 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00900
2016-10-09 13:25:54,415 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00900
2016-10-09 13:25:54,447 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00900
2016-10-09 13:25:54,481 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00900
2016-10-09 13:25:54,514 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00900
2016-10-09 13:25:54,548 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00900
2016-10-09 13:25:54,581 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00900
2016-10-09 13:25:54,612 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00900
2016-10-09 13:25:54,645 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00900
2016-10-09 13:25:54,679 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00900
2016-10-09 13:25:54,712 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00900
2016-10-09 13:25:54,746 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00900
2016-10-09 13:25:54,778 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00900
2016-10-09 13:25:54,845 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:54,894 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:54,894 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:54,894 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 321656 effective words/s
2016-10-09 13:25:54,894 : INFO : training model with 1 workers on 1815 vocabulary and 300 features, using sg=0 hs=1 sample=0 negative=0
2016-10-09 13:25:54,894 : INFO : expecting 3090 sentences, matching count from corpus used for vocabulary survey
2016-10-09 13:25:54,895 : DEBUG : queueing job #0 (9993 words, 558 sentences) at alpha 0.00700
2016-10-09 13:25:54,896 : DEBUG : queueing job #1 (9982 words, 562 sentences) at alpha 0.00700
2016-10-09 13:25:54,897 : DEBUG : queueing job #2 (9977 words, 564 sentences) at alpha 0.00700
2016-10-09 13:25:54,898 : DEBUG : queueing job #3 (9991 words, 547 sentences) at alpha 0.00700
2016-10-09 13:25:54,931 : DEBUG : queueing job #4 (9983 words, 581 sentences) at alpha 0.00700
2016-10-09 13:25:54,963 : DEBUG : queueing job #5 (9998 words, 561 sentences) at alpha 0.00700
2016-10-09 13:25:54,995 : DEBUG : queueing job #6 (10000 words, 568 sentences) at alpha 0.00700
2016-10-09 13:25:55,028 : DEBUG : queueing job #7 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:25:55,062 : DEBUG : queueing job #8 (9990 words, 553 sentences) at alpha 0.00700
2016-10-09 13:25:55,095 : DEBUG : queueing job #9 (9971 words, 545 sentences) at alpha 0.00700
2016-10-09 13:25:55,128 : DEBUG : queueing job #10 (9978 words, 583 sentences) at alpha 0.00700
2016-10-09 13:25:55,160 : DEBUG : queueing job #11 (9981 words, 559 sentences) at alpha 0.00700
2016-10-09 13:25:55,193 : DEBUG : queueing job #12 (9994 words, 562 sentences) at alpha 0.00700
2016-10-09 13:25:55,226 : DEBUG : queueing job #13 (9997 words, 566 sentences) at alpha 0.00700
2016-10-09 13:25:55,260 : DEBUG : queueing job #14 (9981 words, 547 sentences) at alpha 0.00700
2016-10-09 13:25:55,294 : DEBUG : queueing job #15 (9985 words, 579 sentences) at alpha 0.00700
2016-10-09 13:25:55,325 : DEBUG : queueing job #16 (9985 words, 560 sentences) at alpha 0.00700
2016-10-09 13:25:55,359 : DEBUG : queueing job #17 (9968 words, 569 sentences) at alpha 0.00700
2016-10-09 13:25:55,392 : DEBUG : queueing job #18 (9999 words, 561 sentences) at alpha 0.00700
2016-10-09 13:25:55,426 : DEBUG : queueing job #19 (9974 words, 555 sentences) at alpha 0.00700
2016-10-09 13:25:55,459 : DEBUG : queueing job #20 (9985 words, 541 sentences) at alpha 0.00700
2016-10-09 13:25:55,491 : DEBUG : queueing job #21 (9972 words, 584 sentences) at alpha 0.00700
2016-10-09 13:25:55,523 : DEBUG : queueing job #22 (10000 words, 560 sentences) at alpha 0.00700
2016-10-09 13:25:55,556 : DEBUG : queueing job #23 (9992 words, 563 sentences) at alpha 0.00700
2016-10-09 13:25:55,591 : DEBUG : queueing job #24 (9994 words, 565 sentences) at alpha 0.00700
2016-10-09 13:25:55,624 : DEBUG : queueing job #25 (9984 words, 547 sentences) at alpha 0.00700
2016-10-09 13:25:55,657 : DEBUG : queueing job #26 (9974 words, 578 sentences) at alpha 0.00700
2016-10-09 13:25:55,689 : DEBUG : queueing job #27 (4773 words, 270 sentences) at alpha 0.00700
2016-10-09 13:25:55,756 : DEBUG : job loop exiting, total 28 jobs
2016-10-09 13:25:55,805 : DEBUG : worker exiting, processed 28 jobs
2016-10-09 13:25:55,805 : INFO : worker thread finished; awaiting finish of 0 more threads
2016-10-09 13:25:55,805 : INFO : training on 274395 raw words (294385 effective words) took 0.9s, 324161 effective words/s
2016-10-09 13:25:55,805 : INFO : saving Doc2Vec object under ./tmp/RareModel, separately None
2016-10-09 13:25:55,805 : INFO : not storing attribute syn0norm
2016-10-09 13:25:55,805 : INFO : not storing attribute cum_table
2016-10-09 20:19:27,261 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 20:19:27,500 : INFO : built Dictionary(11949 unique tokens: ['leashes', 'iopd', 'rlly', 'expanding', 'obgyn']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 20:19:27,504 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 20:19:27,507 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 20:19:27,509 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 20:19:27,510 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:19:27,511 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:19:27,511 : INFO : PROGRESS: saving document #0
2016-10-09 20:19:27,567 : INFO : PROGRESS: saving document #1000
2016-10-09 20:19:27,619 : INFO : PROGRESS: saving document #2000
2016-10-09 20:19:27,671 : INFO : PROGRESS: saving document #3000
2016-10-09 20:19:27,734 : INFO : PROGRESS: saving document #4000
2016-10-09 20:19:27,791 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-09 20:19:27,791 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:19:27,794 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:19:27,794 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 20:19:27,797 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 20:19:27,797 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:19:27,797 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-09 20:19:27,797 : INFO : collecting document frequencies
2016-10-09 20:19:27,797 : INFO : PROGRESS: processing document #0
2016-10-09 20:19:27,960 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 20:19:27,963 : INFO : using serial LSI version on this node
2016-10-09 20:19:27,963 : INFO : updating model with new documents
2016-10-09 20:19:28,236 : INFO : preparing a new chunk of documents
2016-10-09 20:19:28,237 : DEBUG : converting corpus to csc format
2016-10-09 20:19:28,272 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 20:19:28,272 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 20:19:28,360 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 20:19:28,375 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:19:28,447 : DEBUG : running 2 power iterations
2016-10-09 20:19:28,508 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:19:28,601 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:19:28,665 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-09 20:19:28,756 : INFO : computing the final decomposition
2016-10-09 20:19:28,756 : INFO : keeping 200 factors (discarding 18.873% of energy spectrum)
2016-10-09 20:19:28,770 : INFO : processed documents up to #4880
2016-10-09 20:19:28,772 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-09 20:19:28,773 : INFO : topic #1(5.571): -0.612*"visa" + -0.343*"visit" + -0.210*"family" + 0.166*"buy" + 0.164*"doha" + 0.146*"good" + 0.138*"anyone" + 0.132*"know" + -0.129*"wife" + 0.117*"find"
2016-10-09 20:19:28,773 : INFO : topic #2(4.311): -0.275*"doha" + 0.258*"driving" + 0.254*"car" + -0.247*"visa" + 0.228*"company" + 0.205*"qatar" + -0.203*"visit" + 0.198*"license" + -0.195*"anyone" + -0.194*"buy"
2016-10-09 20:19:28,773 : INFO : topic #3(4.144): -0.552*"car" + -0.441*"buy" + 0.204*"school" + -0.164*"one" + 0.154*"would" + -0.128*"driving" + 0.126*"like" + -0.114*"license" + 0.108*"job" + -0.100*"need"
2016-10-09 20:19:28,773 : INFO : topic #4(4.124): 0.584*"driving" + 0.403*"school" + 0.396*"license" + -0.210*"company" + 0.117*"international" + 0.116*"test" + -0.098*"buy" + -0.094*"bank" + -0.091*"job" + 0.090*"visit"
2016-10-09 20:19:28,778 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 20:19:29,274 : INFO : creating matrix with 4880 documents and 200 features
2016-10-09 20:19:29,298 : DEBUG : PROGRESS: at document #0/4880
2016-10-09 20:19:29,429 : DEBUG : PROGRESS: at document #1000/4880
2016-10-09 20:19:29,582 : DEBUG : PROGRESS: at document #2000/4880
2016-10-09 20:19:29,735 : DEBUG : PROGRESS: at document #3000/4880
2016-10-09 20:19:29,904 : DEBUG : PROGRESS: at document #4000/4880
2016-10-09 20:20:50,603 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 20:20:50,841 : INFO : built Dictionary(11949 unique tokens: ['spanco', 'lvova', 'going', 'jm', 'visper']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 20:20:50,846 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 20:20:50,849 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 20:20:50,851 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 20:20:50,852 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:20:50,852 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:20:50,852 : INFO : PROGRESS: saving document #0
2016-10-09 20:20:50,904 : INFO : PROGRESS: saving document #1000
2016-10-09 20:20:50,956 : INFO : PROGRESS: saving document #2000
2016-10-09 20:20:51,008 : INFO : PROGRESS: saving document #3000
2016-10-09 20:20:51,070 : INFO : PROGRESS: saving document #4000
2016-10-09 20:20:51,127 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-09 20:20:51,127 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:20:51,130 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:20:51,130 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 20:20:51,132 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 20:20:51,132 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 20:20:51,132 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-09 20:20:51,133 : INFO : collecting document frequencies
2016-10-09 20:20:51,133 : INFO : PROGRESS: processing document #0
2016-10-09 20:20:51,291 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 20:20:51,294 : INFO : using serial LSI version on this node
2016-10-09 20:20:51,294 : INFO : updating model with new documents
2016-10-09 20:20:51,566 : INFO : preparing a new chunk of documents
2016-10-09 20:20:51,567 : DEBUG : converting corpus to csc format
2016-10-09 20:20:51,599 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 20:20:51,600 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 20:20:51,685 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 20:20:51,699 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:20:51,746 : DEBUG : running 2 power iterations
2016-10-09 20:20:51,808 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:20:51,900 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 20:20:51,965 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-09 20:20:52,044 : INFO : computing the final decomposition
2016-10-09 20:20:52,044 : INFO : keeping 200 factors (discarding 18.884% of energy spectrum)
2016-10-09 20:20:52,057 : INFO : processed documents up to #4880
2016-10-09 20:20:52,058 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-09 20:20:52,059 : INFO : topic #1(5.571): 0.612*"visa" + 0.342*"visit" + 0.210*"family" + -0.166*"buy" + -0.165*"doha" + -0.146*"good" + -0.138*"anyone" + -0.132*"know" + 0.129*"wife" + -0.117*"find"
2016-10-09 20:20:52,059 : INFO : topic #2(4.311): 0.274*"doha" + -0.258*"driving" + -0.253*"car" + 0.246*"visa" + -0.227*"company" + -0.204*"qatar" + 0.204*"visit" + -0.196*"license" + 0.194*"anyone" + 0.194*"buy"
2016-10-09 20:20:52,059 : INFO : topic #3(4.144): -0.552*"car" + -0.441*"buy" + 0.206*"school" + -0.165*"one" + 0.154*"would" + 0.126*"like" + -0.123*"driving" + -0.111*"license" + 0.107*"job" + -0.099*"need"
2016-10-09 20:20:52,059 : INFO : topic #4(4.124): -0.583*"driving" + -0.401*"school" + -0.398*"license" + 0.210*"company" + -0.118*"test" + -0.116*"international" + 0.094*"buy" + 0.094*"bank" + 0.092*"job" + -0.091*"visit"
2016-10-09 20:20:52,064 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 20:20:52,577 : INFO : creating matrix with 4880 documents and 200 features
2016-10-09 20:20:52,600 : DEBUG : PROGRESS: at document #0/4880
2016-10-09 20:20:52,732 : DEBUG : PROGRESS: at document #1000/4880
2016-10-09 20:20:52,887 : DEBUG : PROGRESS: at document #2000/4880
2016-10-09 20:20:53,042 : DEBUG : PROGRESS: at document #3000/4880
2016-10-09 20:20:53,214 : DEBUG : PROGRESS: at document #4000/4880
2016-10-09 21:13:29,835 : INFO : collecting document frequencies
2016-10-09 21:13:29,835 : INFO : PROGRESS: processing document #0
2016-10-09 21:13:30,004 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 21:21:53,501 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:21:53,746 : INFO : built Dictionary(11949 unique tokens: ['greately', 'dth', 'too', 'less', 'grinder']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:21:53,751 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:21:53,754 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:21:53,756 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:21:53,757 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:21:53,758 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:21:53,758 : INFO : PROGRESS: saving document #0
2016-10-09 21:21:53,810 : INFO : PROGRESS: saving document #1000
2016-10-09 21:21:53,862 : INFO : PROGRESS: saving document #2000
2016-10-09 21:21:53,914 : INFO : PROGRESS: saving document #3000
2016-10-09 21:21:53,980 : INFO : PROGRESS: saving document #4000
2016-10-09 21:21:54,037 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-09 21:21:54,037 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:21:54,037 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:21:54,037 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:21:54,040 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:21:54,040 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:21:54,040 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-09 21:21:54,040 : INFO : collecting document frequencies
2016-10-09 21:21:54,040 : INFO : PROGRESS: processing document #0
2016-10-09 21:21:54,201 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 21:21:54,204 : INFO : using serial LSI version on this node
2016-10-09 21:21:54,204 : INFO : updating model with new documents
2016-10-09 21:21:54,477 : INFO : preparing a new chunk of documents
2016-10-09 21:21:54,478 : DEBUG : converting corpus to csc format
2016-10-09 21:21:54,510 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:21:54,510 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:21:54,599 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:21:54,613 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:21:54,661 : DEBUG : running 2 power iterations
2016-10-09 21:21:54,722 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:21:54,819 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:21:54,884 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-09 21:21:54,966 : INFO : computing the final decomposition
2016-10-09 21:21:54,966 : INFO : keeping 200 factors (discarding 18.884% of energy spectrum)
2016-10-09 21:21:54,978 : INFO : processed documents up to #4880
2016-10-09 21:21:54,980 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-09 21:21:54,980 : INFO : topic #1(5.571): 0.612*"visa" + 0.342*"visit" + 0.210*"family" + -0.166*"buy" + -0.164*"doha" + -0.146*"good" + -0.138*"anyone" + -0.132*"know" + 0.129*"wife" + -0.117*"find"
2016-10-09 21:21:54,980 : INFO : topic #2(4.311): 0.276*"doha" + -0.257*"driving" + -0.253*"car" + 0.247*"visa" + -0.227*"company" + -0.205*"qatar" + 0.204*"visit" + -0.197*"license" + 0.194*"anyone" + 0.194*"buy"
2016-10-09 21:21:54,981 : INFO : topic #3(4.144): 0.552*"car" + 0.441*"buy" + -0.205*"school" + 0.164*"one" + -0.156*"would" + 0.127*"driving" + -0.125*"like" + 0.112*"license" + -0.108*"job" + 0.100*"need"
2016-10-09 21:21:54,981 : INFO : topic #4(4.124): 0.584*"driving" + 0.403*"school" + 0.396*"license" + -0.211*"company" + 0.118*"test" + 0.116*"international" + -0.097*"buy" + -0.093*"bank" + -0.092*"job" + 0.091*"visit"
2016-10-09 21:21:54,986 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:21:55,503 : INFO : creating matrix with 4880 documents and 200 features
2016-10-09 21:21:55,526 : DEBUG : PROGRESS: at document #0/4880
2016-10-09 21:21:55,663 : DEBUG : PROGRESS: at document #1000/4880
2016-10-09 21:21:55,814 : DEBUG : PROGRESS: at document #2000/4880
2016-10-09 21:21:55,966 : DEBUG : PROGRESS: at document #3000/4880
2016-10-09 21:21:56,137 : DEBUG : PROGRESS: at document #4000/4880
2016-10-09 21:23:22,597 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:23:22,833 : INFO : built Dictionary(11949 unique tokens: ['avid', 'nightly', 'results', 'qr23', 'suzuki']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:23:22,838 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:23:22,840 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:23:22,842 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:23:22,844 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:23:22,844 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:23:22,844 : INFO : PROGRESS: saving document #0
2016-10-09 21:23:22,899 : INFO : PROGRESS: saving document #1000
2016-10-09 21:23:22,951 : INFO : PROGRESS: saving document #2000
2016-10-09 21:23:23,003 : INFO : PROGRESS: saving document #3000
2016-10-09 21:23:23,066 : INFO : PROGRESS: saving document #4000
2016-10-09 21:23:23,123 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-09 21:23:23,123 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:23:23,127 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:23:23,127 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:23:23,129 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:23:23,129 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:23:23,130 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-09 21:23:23,130 : INFO : collecting document frequencies
2016-10-09 21:23:23,130 : INFO : PROGRESS: processing document #0
2016-10-09 21:23:23,298 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 21:23:23,301 : INFO : using serial LSI version on this node
2016-10-09 21:23:23,301 : INFO : updating model with new documents
2016-10-09 21:23:23,576 : INFO : preparing a new chunk of documents
2016-10-09 21:23:23,577 : DEBUG : converting corpus to csc format
2016-10-09 21:23:23,611 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:23:23,611 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:23:23,699 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:23:23,713 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:23:23,761 : DEBUG : running 2 power iterations
2016-10-09 21:23:23,823 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:23:23,919 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:23:23,984 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-09 21:23:24,065 : INFO : computing the final decomposition
2016-10-09 21:23:24,065 : INFO : keeping 200 factors (discarding 18.878% of energy spectrum)
2016-10-09 21:23:24,078 : INFO : processed documents up to #4880
2016-10-09 21:23:24,079 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-09 21:23:24,080 : INFO : topic #1(5.571): -0.612*"visa" + -0.343*"visit" + -0.210*"family" + 0.166*"buy" + 0.164*"doha" + 0.146*"good" + 0.138*"anyone" + 0.132*"know" + -0.130*"wife" + 0.117*"find"
2016-10-09 21:23:24,080 : INFO : topic #2(4.311): 0.275*"doha" + -0.258*"driving" + -0.253*"car" + 0.246*"visa" + -0.227*"company" + -0.204*"qatar" + 0.203*"visit" + -0.198*"license" + 0.194*"anyone" + 0.194*"buy"
2016-10-09 21:23:24,080 : INFO : topic #3(4.144): 0.552*"car" + 0.441*"buy" + -0.203*"school" + 0.163*"one" + -0.156*"would" + 0.129*"driving" + -0.126*"like" + 0.114*"license" + -0.107*"job" + 0.099*"need"
2016-10-09 21:23:24,080 : INFO : topic #4(4.124): -0.583*"driving" + -0.404*"school" + -0.395*"license" + 0.210*"company" + -0.118*"international" + -0.117*"test" + 0.098*"buy" + 0.095*"bank" + 0.091*"job" + -0.091*"visit"
2016-10-09 21:23:24,087 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:23:24,605 : INFO : creating matrix with 4880 documents and 200 features
2016-10-09 21:23:24,628 : DEBUG : PROGRESS: at document #0/4880
2016-10-09 21:23:24,761 : DEBUG : PROGRESS: at document #1000/4880
2016-10-09 21:23:24,916 : DEBUG : PROGRESS: at document #2000/4880
2016-10-09 21:23:25,078 : DEBUG : PROGRESS: at document #3000/4880
2016-10-09 21:23:25,252 : DEBUG : PROGRESS: at document #4000/4880
2016-10-09 21:24:55,258 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:24:55,495 : INFO : built Dictionary(11949 unique tokens: ['overhauling', 'medical', 'mage', 'goodevening', 'learner']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:24:55,500 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:24:55,502 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:24:55,504 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:24:55,506 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:24:55,506 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:24:55,506 : INFO : PROGRESS: saving document #0
2016-10-09 21:24:55,562 : INFO : PROGRESS: saving document #1000
2016-10-09 21:24:55,614 : INFO : PROGRESS: saving document #2000
2016-10-09 21:24:55,669 : INFO : PROGRESS: saving document #3000
2016-10-09 21:24:55,731 : INFO : PROGRESS: saving document #4000
2016-10-09 21:24:55,788 : INFO : saved 4880x5337 matrix, density=0.308% (80289/26044560)
2016-10-09 21:24:55,789 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:24:55,792 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:24:55,792 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:24:55,794 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:24:55,794 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:24:55,795 : INFO : accepted corpus with 4880 documents, 5337 features, 80289 non-zero entries
2016-10-09 21:24:55,795 : INFO : collecting document frequencies
2016-10-09 21:24:55,795 : INFO : PROGRESS: processing document #0
2016-10-09 21:24:55,960 : INFO : calculating IDF weights for 4880 documents and 5336 features (80289 matrix non-zeros)
2016-10-09 21:24:55,963 : INFO : using serial LSI version on this node
2016-10-09 21:24:55,964 : INFO : updating model with new documents
2016-10-09 21:24:56,236 : INFO : preparing a new chunk of documents
2016-10-09 21:24:56,237 : DEBUG : converting corpus to csc format
2016-10-09 21:24:56,270 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:24:56,270 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:24:56,355 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:24:56,370 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:24:56,420 : DEBUG : running 2 power iterations
2016-10-09 21:24:56,482 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:24:56,579 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:24:56,644 : INFO : 2nd phase: running dense svd on (300, 4880) matrix
2016-10-09 21:24:56,725 : INFO : computing the final decomposition
2016-10-09 21:24:56,725 : INFO : keeping 200 factors (discarding 18.894% of energy spectrum)
2016-10-09 21:24:56,738 : INFO : processed documents up to #4880
2016-10-09 21:24:56,740 : INFO : topic #0(8.383): 0.259*"visa" + 0.206*"qatar" + 0.177*"know" + 0.177*"doha" + 0.166*"thanks" + 0.159*"please" + 0.159*"anyone" + 0.148*"hi" + 0.145*"get" + 0.140*"one"
2016-10-09 21:24:56,740 : INFO : topic #1(5.571): -0.612*"visa" + -0.342*"visit" + -0.210*"family" + 0.166*"buy" + 0.164*"doha" + 0.146*"good" + 0.138*"anyone" + 0.132*"know" + -0.130*"wife" + 0.117*"find"
2016-10-09 21:24:56,740 : INFO : topic #2(4.311): 0.275*"doha" + -0.258*"driving" + -0.254*"car" + 0.247*"visa" + -0.227*"company" + -0.204*"qatar" + 0.203*"visit" + -0.198*"license" + 0.194*"anyone" + 0.193*"buy"
2016-10-09 21:24:56,740 : INFO : topic #3(4.144): 0.552*"car" + 0.441*"buy" + -0.205*"school" + 0.164*"one" + -0.156*"would" + -0.126*"like" + 0.126*"driving" + 0.113*"license" + -0.108*"job" + 0.099*"need"
2016-10-09 21:24:56,740 : INFO : topic #4(4.124): 0.584*"driving" + 0.402*"school" + 0.396*"license" + -0.210*"company" + 0.118*"test" + 0.116*"international" + -0.097*"buy" + -0.094*"bank" + -0.092*"job" + 0.090*"visit"
2016-10-09 21:24:56,746 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:24:57,260 : INFO : creating matrix with 4880 documents and 200 features
2016-10-09 21:24:57,283 : DEBUG : PROGRESS: at document #0/4880
2016-10-09 21:24:57,414 : DEBUG : PROGRESS: at document #1000/4880
2016-10-09 21:24:57,575 : DEBUG : PROGRESS: at document #2000/4880
2016-10-09 21:24:57,733 : DEBUG : PROGRESS: at document #3000/4880
2016-10-09 21:24:57,900 : DEBUG : PROGRESS: at document #4000/4880
2016-10-09 21:34:54,448 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:34:54,689 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:34:54,694 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:34:54,697 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:34:54,699 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:35:10,074 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:35:10,319 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:35:10,323 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:35:10,326 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:35:10,328 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:35:31,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:35:31,396 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:35:31,403 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:35:31,407 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:35:31,410 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:35:31,473 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:35:31,473 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:35:31,473 : INFO : PROGRESS: saving document #0
2016-10-09 21:35:31,474 : INFO : saved 10x5283 matrix, density=0.305% (161/52830)
2016-10-09 21:35:31,474 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:35:31,474 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:35:31,474 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:35:31,474 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:35:31,474 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:35:31,474 : INFO : accepted corpus with 10 documents, 5283 features, 161 non-zero entries
2016-10-09 21:35:31,475 : INFO : collecting document frequencies
2016-10-09 21:35:31,475 : INFO : PROGRESS: processing document #0
2016-10-09 21:35:31,475 : INFO : calculating IDF weights for 10 documents and 5282 features (161 matrix non-zeros)
2016-10-09 21:35:31,476 : INFO : using serial LSI version on this node
2016-10-09 21:35:31,476 : INFO : updating model with new documents
2016-10-09 21:35:31,477 : INFO : preparing a new chunk of documents
2016-10-09 21:35:31,477 : DEBUG : converting corpus to csc format
2016-10-09 21:35:31,477 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:35:31,477 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:35:31,478 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:35:31,496 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:35:31,544 : DEBUG : running 2 power iterations
2016-10-09 21:35:31,566 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:35:31,629 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:35:31,676 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:35:31,683 : INFO : computing the final decomposition
2016-10-09 21:35:31,684 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:35:31,685 : INFO : processed documents up to #10
2016-10-09 21:35:31,687 : INFO : topic #0(1.187): 0.284*"open" + 0.283*"best" + 0.281*"savings" + 0.244*"account" + 0.188*"doha" + 0.175*"hi" + 0.168*"everybody" + 0.163*"using" + 0.156*"deal" + 0.156*"soon"
2016-10-09 21:35:31,687 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"ql" + -0.155*"home" + -0.133*"recommend"
2016-10-09 21:35:31,687 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"ql" + 0.267*"home" + -0.246*"islamic" + -0.246*"services" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"idea"
2016-10-09 21:35:31,688 : INFO : topic #3(1.002): 0.271*"services" + 0.271*"islamic" + -0.269*"accept" + -0.179*"transfer" + -0.159*"paid" + -0.159*"funds" + -0.159*"recommendations" + -0.159*"overseas" + -0.159*"use" + -0.159*"used"
2016-10-09 21:35:31,688 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"opening" + 0.146*"want" + 0.146*"nice" + 0.146*"weekend" + 0.146*"someone" + 0.146*"greetings" + 0.146*"help"
2016-10-09 21:35:31,688 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:35:31,689 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:35:31,690 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:03,174 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:36:03,415 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:36:03,419 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:03,422 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:03,424 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:36:03,514 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:03,514 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:03,514 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:03,515 : INFO : saved 10x5283 matrix, density=0.305% (161/52830)
2016-10-09 21:36:03,515 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:03,515 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:03,515 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:03,516 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:03,516 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:03,516 : INFO : accepted corpus with 10 documents, 5283 features, 161 non-zero entries
2016-10-09 21:36:03,516 : INFO : collecting document frequencies
2016-10-09 21:36:03,516 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:03,517 : INFO : calculating IDF weights for 10 documents and 5282 features (161 matrix non-zeros)
2016-10-09 21:36:03,517 : INFO : using serial LSI version on this node
2016-10-09 21:36:03,517 : INFO : updating model with new documents
2016-10-09 21:36:03,518 : INFO : preparing a new chunk of documents
2016-10-09 21:36:03,518 : DEBUG : converting corpus to csc format
2016-10-09 21:36:03,518 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:03,521 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:03,521 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:03,534 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:03,576 : DEBUG : running 2 power iterations
2016-10-09 21:36:03,594 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:03,653 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:03,701 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:03,705 : INFO : computing the final decomposition
2016-10-09 21:36:03,705 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:03,707 : INFO : processed documents up to #10
2016-10-09 21:36:03,709 : INFO : topic #0(1.187): -0.284*"open" + -0.283*"best" + -0.281*"savings" + -0.244*"account" + -0.188*"doha" + -0.175*"hi" + -0.168*"everybody" + -0.163*"using" + -0.156*"deal" + -0.156*"soon"
2016-10-09 21:36:03,709 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"ql" + -0.155*"home" + -0.133*"recommend"
2016-10-09 21:36:03,709 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"ql" + 0.267*"home" + -0.246*"islamic" + -0.246*"services" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"idea"
2016-10-09 21:36:03,709 : INFO : topic #3(1.002): 0.271*"islamic" + 0.271*"services" + -0.269*"accept" + -0.179*"transfer" + -0.159*"overseas" + -0.159*"use" + -0.159*"paid" + -0.159*"recommendations" + -0.159*"used" + -0.159*"funds"
2016-10-09 21:36:03,709 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"everyone" + 0.146*"weekend" + 0.146*"greetings" + 0.146*"know" + 0.146*"someone" + 0.146*"want" + 0.146*"help"
2016-10-09 21:36:03,710 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:03,711 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:03,711 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:32,535 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:36:32,782 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:36:32,786 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:32,789 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:32,791 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:36:32,853 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:32,853 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:32,853 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:32,854 : INFO : saved 10x5283 matrix, density=0.305% (161/52830)
2016-10-09 21:36:32,854 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:32,854 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:32,854 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:32,855 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:32,855 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:32,855 : INFO : accepted corpus with 10 documents, 5283 features, 161 non-zero entries
2016-10-09 21:36:32,855 : INFO : collecting document frequencies
2016-10-09 21:36:32,855 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:32,856 : INFO : calculating IDF weights for 10 documents and 5282 features (161 matrix non-zeros)
2016-10-09 21:36:32,857 : INFO : using serial LSI version on this node
2016-10-09 21:36:32,857 : INFO : updating model with new documents
2016-10-09 21:36:32,858 : INFO : preparing a new chunk of documents
2016-10-09 21:36:32,858 : DEBUG : converting corpus to csc format
2016-10-09 21:36:32,859 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:32,862 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:32,862 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:32,876 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:32,917 : DEBUG : running 2 power iterations
2016-10-09 21:36:32,935 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:32,994 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:33,042 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:33,047 : INFO : computing the final decomposition
2016-10-09 21:36:33,047 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:33,049 : INFO : processed documents up to #10
2016-10-09 21:36:33,050 : INFO : topic #0(1.187): 0.284*"open" + 0.283*"best" + 0.281*"savings" + 0.244*"account" + 0.188*"doha" + 0.175*"hi" + 0.168*"everybody" + 0.163*"using" + 0.156*"deal" + 0.156*"soon"
2016-10-09 21:36:33,050 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"ql" + -0.155*"home" + -0.133*"recommend"
2016-10-09 21:36:33,050 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"ql" + 0.267*"home" + -0.246*"islamic" + -0.246*"services" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"idea"
2016-10-09 21:36:33,051 : INFO : topic #3(1.002): 0.271*"islamic" + 0.271*"services" + -0.269*"accept" + -0.179*"transfer" + -0.159*"overseas" + -0.159*"use" + -0.159*"paid" + -0.159*"recommendations" + -0.159*"used" + -0.159*"funds"
2016-10-09 21:36:33,051 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"want" + 0.146*"nice" + 0.146*"weekend" + 0.146*"someone" + 0.146*"see" + 0.146*"greetings" + 0.146*"know"
2016-10-09 21:36:33,051 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:33,052 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:33,053 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:47,216 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 21:36:47,456 : INFO : built Dictionary(11949 unique tokens: ['distant', 'series', 'unfit', 'destinations', 'reducing']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 21:36:47,461 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:47,464 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 21:36:47,466 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 21:36:47,559 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,559 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,559 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:47,560 : INFO : saved 10x5283 matrix, density=0.305% (161/52830)
2016-10-09 21:36:47,560 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,560 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,560 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,561 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,561 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,561 : INFO : accepted corpus with 10 documents, 5283 features, 161 non-zero entries
2016-10-09 21:36:47,561 : INFO : collecting document frequencies
2016-10-09 21:36:47,561 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:47,562 : INFO : calculating IDF weights for 10 documents and 5282 features (161 matrix non-zeros)
2016-10-09 21:36:47,563 : INFO : using serial LSI version on this node
2016-10-09 21:36:47,563 : INFO : updating model with new documents
2016-10-09 21:36:47,564 : INFO : preparing a new chunk of documents
2016-10-09 21:36:47,564 : DEBUG : converting corpus to csc format
2016-10-09 21:36:47,565 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:47,565 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:47,566 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:47,590 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,634 : DEBUG : running 2 power iterations
2016-10-09 21:36:47,653 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,711 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,757 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:47,761 : INFO : computing the final decomposition
2016-10-09 21:36:47,761 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:47,763 : INFO : processed documents up to #10
2016-10-09 21:36:47,765 : INFO : topic #0(1.187): 0.284*"open" + 0.283*"best" + 0.281*"savings" + 0.244*"account" + 0.188*"doha" + 0.175*"hi" + 0.168*"everybody" + 0.163*"using" + 0.156*"soon" + 0.156*"advise"
2016-10-09 21:36:47,765 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"ql" + -0.155*"home" + -0.133*"recommend"
2016-10-09 21:36:47,765 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"ql" + 0.267*"home" + -0.246*"islamic" + -0.246*"services" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"idea"
2016-10-09 21:36:47,765 : INFO : topic #3(1.002): 0.271*"islamic" + 0.271*"services" + -0.269*"accept" + -0.179*"transfer" + -0.159*"overseas" + -0.159*"use" + -0.159*"paid" + -0.159*"recommendations" + -0.159*"used" + -0.159*"funds"
2016-10-09 21:36:47,765 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"help" + 0.146*"want" + 0.146*"nice" + 0.146*"weekend" + 0.146*"someone" + 0.146*"greetings" + 0.146*"see"
2016-10-09 21:36:47,765 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:47,767 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:47,767 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:47,768 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,768 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,768 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:47,769 : INFO : saved 10x5176 matrix, density=0.284% (147/51760)
2016-10-09 21:36:47,769 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,769 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,769 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,770 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,770 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,770 : INFO : accepted corpus with 10 documents, 5176 features, 147 non-zero entries
2016-10-09 21:36:47,770 : INFO : collecting document frequencies
2016-10-09 21:36:47,770 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:47,771 : INFO : calculating IDF weights for 10 documents and 5175 features (147 matrix non-zeros)
2016-10-09 21:36:47,771 : INFO : using serial LSI version on this node
2016-10-09 21:36:47,771 : INFO : updating model with new documents
2016-10-09 21:36:47,772 : INFO : preparing a new chunk of documents
2016-10-09 21:36:47,772 : DEBUG : converting corpus to csc format
2016-10-09 21:36:47,772 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:47,774 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:47,774 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:47,785 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,824 : DEBUG : running 2 power iterations
2016-10-09 21:36:47,842 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,900 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:47,946 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:47,950 : INFO : computing the final decomposition
2016-10-09 21:36:47,951 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:47,952 : INFO : processed documents up to #10
2016-10-09 21:36:47,953 : INFO : topic #0(1.125): 0.314*"go" + 0.268*"qatar" + 0.258*"catch" + 0.255*"friday" + 0.255*"next" + 0.227*"planning" + 0.213*"know" + 0.163*"place" + 0.149*"beach" + 0.149*"like"
2016-10-09 21:36:47,953 : INFO : topic #1(1.046): 0.257*"shisha" + 0.218*"hi" + 0.202*"family" + -0.193*"planning" + -0.183*"go" + 0.166*"quiet" + 0.166*"someone" + 0.166*"north" + 0.166*"swimming" + 0.166*"say"
2016-10-09 21:36:47,953 : INFO : topic #2(1.018): 0.432*"card" + 0.215*"would" + 0.173*"gives" + 0.173*"using" + 0.154*"spend" + 0.134*"please" + 0.134*"mind" + 0.134*"tell" + 0.134*"plz" + 0.134*"1000qr"
2016-10-09 21:36:47,953 : INFO : topic #3(1.000): -0.382*"reliable" + -0.191*"industrial" + -0.191*"low" + -0.191*"also" + -0.191*"garage" + -0.191*"experience" + -0.191*"qatarliving" + -0.191*"hard" + -0.191*"members" + -0.191*"around"
2016-10-09 21:36:47,953 : INFO : topic #4(1.000): -0.408*"nice" + -0.408*"plus" + -0.408*"well" + -0.408*"coffee" + -0.408*"view" + -0.408*"cup" + -0.000*"reliable" + -0.000*"qatarliving" + -0.000*"industrial" + -0.000*"hard"
2016-10-09 21:36:47,954 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:47,955 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:47,955 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:47,956 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,956 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,956 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:47,957 : INFO : saved 10x5207 matrix, density=0.232% (121/52070)
2016-10-09 21:36:47,957 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,957 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,957 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,958 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:47,958 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:47,958 : INFO : accepted corpus with 10 documents, 5207 features, 121 non-zero entries
2016-10-09 21:36:47,958 : INFO : collecting document frequencies
2016-10-09 21:36:47,958 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:47,958 : INFO : calculating IDF weights for 10 documents and 5206 features (121 matrix non-zeros)
2016-10-09 21:36:47,959 : INFO : using serial LSI version on this node
2016-10-09 21:36:47,959 : INFO : updating model with new documents
2016-10-09 21:36:47,959 : INFO : preparing a new chunk of documents
2016-10-09 21:36:47,959 : DEBUG : converting corpus to csc format
2016-10-09 21:36:47,960 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:47,962 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:47,962 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:47,973 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,012 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,030 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,087 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,134 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:48,138 : INFO : computing the final decomposition
2016-10-09 21:36:48,138 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:48,140 : INFO : processed documents up to #10
2016-10-09 21:36:48,140 : INFO : topic #0(1.162): -0.309*"go" + -0.246*"best" + -0.220*"friday" + -0.220*"next" + -0.207*"know" + -0.195*"place" + -0.194*"beach" + -0.185*"18" + -0.185*"years" + -0.182*"planning"
2016-10-09 21:36:48,141 : INFO : topic #1(1.081): 0.329*"tourists" + 0.312*"18" + 0.312*"years" + 0.256*"places" + 0.245*"visit" + -0.193*"best" + -0.166*"catch" + -0.161*"go" + -0.159*"place" + -0.154*"friday"
2016-10-09 21:36:48,141 : INFO : topic #2(1.014): -0.360*"island" + -0.254*"park" + -0.185*"corniche" + -0.185*"5" + -0.180*"anyone" + -0.180*"2013" + -0.180*"banana" + -0.180*"resort" + -0.180*"near" + -0.180*"end"
2016-10-09 21:36:48,141 : INFO : topic #3(1.001): -0.387*"spend" + -0.387*"time" + -0.387*"quality" + -0.387*"good" + -0.276*"friends" + 0.202*"suggestions" + -0.200*"place" + 0.153*"maybe" + 0.153*"silent" + 0.153*"romantic"
2016-10-09 21:36:48,141 : INFO : topic #4(1.000): -0.577*"destinations" + -0.577*"experience" + -0.577*"holiday" + 0.000*"suggestions" + 0.000*"new" + 0.000*"something" + 0.000*"happenings" + 0.000*"quality" + 0.000*"good" + 0.000*"time"
2016-10-09 21:36:48,141 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:48,142 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:48,143 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:48,144 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,144 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,144 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:48,145 : INFO : saved 10x5296 matrix, density=0.406% (215/52960)
2016-10-09 21:36:48,145 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,145 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,145 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,145 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,146 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,146 : INFO : accepted corpus with 10 documents, 5296 features, 215 non-zero entries
2016-10-09 21:36:48,146 : INFO : collecting document frequencies
2016-10-09 21:36:48,146 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:48,146 : INFO : calculating IDF weights for 10 documents and 5295 features (215 matrix non-zeros)
2016-10-09 21:36:48,147 : INFO : using serial LSI version on this node
2016-10-09 21:36:48,147 : INFO : updating model with new documents
2016-10-09 21:36:48,148 : INFO : preparing a new chunk of documents
2016-10-09 21:36:48,148 : DEBUG : converting corpus to csc format
2016-10-09 21:36:48,148 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:48,150 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:48,150 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:48,161 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,200 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,218 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,275 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,322 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:48,327 : INFO : computing the final decomposition
2016-10-09 21:36:48,327 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:48,329 : INFO : processed documents up to #10
2016-10-09 21:36:48,329 : INFO : topic #0(1.111): 0.250*"qatar" + 0.196*"good" + 0.177*"also" + 0.159*"know" + 0.153*"doha" + 0.140*"wanted" + 0.128*"housing" + 0.127*"transportation" + 0.127*"single" + 0.127*"salary"
2016-10-09 21:36:48,329 : INFO : topic #1(1.059): -0.364*"month" + -0.265*"per" + -0.256*"mate" + -0.176*"offered" + -0.176*"qar" + -0.151*"day" + -0.151*"left" + -0.128*"lost" + -0.128*"direct" + -0.128*"contact"
2016-10-09 21:36:48,330 : INFO : topic #2(1.021): 0.246*"possible" + 0.246*"violation" + -0.188*"home" + 0.185*"anyone" + 0.142*"threads" + 0.142*"cheapest" + 0.142*"sorry" + 0.142*"absolutely" + 0.142*"times" + 0.142*"reputable"
2016-10-09 21:36:48,330 : INFO : topic #3(1.004): 0.308*"possible" + 0.308*"violation" + 0.241*"home" + 0.161*"designer" + 0.161*"people" + 0.154*"willing" + 0.154*"accept" + 0.154*"transfer" + 0.154*"owner" + 0.154*"new"
2016-10-09 21:36:48,330 : INFO : topic #4(1.001): 0.387*"good" + 0.194*"deal" + 0.194*"provide" + 0.194*"12" + 0.194*"allowance" + 0.194*"person" + -0.157*"possible" + -0.157*"violation" + 0.154*"company" + -0.149*"trying"
2016-10-09 21:36:48,330 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:48,331 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:48,332 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:48,333 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,333 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,333 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:48,334 : INFO : saved 10x5301 matrix, density=0.547% (290/53010)
2016-10-09 21:36:48,334 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,334 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,334 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,335 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,335 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,335 : INFO : accepted corpus with 10 documents, 5301 features, 290 non-zero entries
2016-10-09 21:36:48,335 : INFO : collecting document frequencies
2016-10-09 21:36:48,335 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:48,336 : INFO : calculating IDF weights for 10 documents and 5300 features (290 matrix non-zeros)
2016-10-09 21:36:48,336 : INFO : using serial LSI version on this node
2016-10-09 21:36:48,336 : INFO : updating model with new documents
2016-10-09 21:36:48,337 : INFO : preparing a new chunk of documents
2016-10-09 21:36:48,337 : DEBUG : converting corpus to csc format
2016-10-09 21:36:48,338 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:48,340 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:48,340 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:48,351 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,390 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,408 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,465 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,511 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:48,516 : INFO : computing the final decomposition
2016-10-09 21:36:48,516 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:48,518 : INFO : processed documents up to #10
2016-10-09 21:36:48,518 : INFO : topic #0(1.159): 0.212*"qatar" + 0.212*"petroleum" + 0.181*"000" + 0.142*"interview" + 0.134*"2" + 0.131*"one" + 0.131*"visit" + 0.114*"14" + 0.110*"thank" + 0.109*"yearly"
2016-10-09 21:36:48,518 : INFO : topic #1(1.100): 0.252*"qatar" + 0.252*"petroleum" + -0.230*"000" + 0.164*"visit" + 0.164*"one" + 0.157*"interview" + -0.152*"experience" + -0.148*"14" + -0.138*"2" + 0.122*"process"
2016-10-09 21:36:48,518 : INFO : topic #2(1.026): 0.229*"month" + 0.229*"per" + -0.163*"yearly" + 0.153*"enough" + 0.153*"10" + -0.138*"years" + -0.128*"national" + 0.127*"000" + 0.125*"also" + -0.119*"final"
2016-10-09 21:36:48,518 : INFO : topic #3(1.012): 0.232*"help" + 0.190*"like" + 0.157*"4000" + 0.157*"period" + 0.157*"mean" + 0.157*"terminated" + 0.157*"3500" + 0.157*"anytime" + 0.157*"state" + 0.157*"total"
2016-10-09 21:36:48,519 : INFO : topic #4(0.988): 0.253*"month" + 0.253*"per" + 0.168*"10" + 0.168*"enough" + 0.145*"info" + 0.145*"give" + 0.145*"cons" + 0.145*"40" + 0.145*"main" + 0.145*"uk"
2016-10-09 21:36:48,519 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:48,520 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:48,522 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:48,523 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,523 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,523 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:48,524 : INFO : saved 10x5248 matrix, density=0.343% (180/52480)
2016-10-09 21:36:48,524 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,524 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,524 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,524 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,525 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,525 : INFO : accepted corpus with 10 documents, 5248 features, 180 non-zero entries
2016-10-09 21:36:48,525 : INFO : collecting document frequencies
2016-10-09 21:36:48,525 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:48,526 : INFO : calculating IDF weights for 10 documents and 5247 features (180 matrix non-zeros)
2016-10-09 21:36:48,526 : INFO : using serial LSI version on this node
2016-10-09 21:36:48,526 : INFO : updating model with new documents
2016-10-09 21:36:48,527 : INFO : preparing a new chunk of documents
2016-10-09 21:36:48,527 : DEBUG : converting corpus to csc format
2016-10-09 21:36:48,528 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:48,530 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:48,530 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:48,541 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,582 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,600 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,657 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,703 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:48,708 : INFO : computing the final decomposition
2016-10-09 21:36:48,708 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:48,710 : INFO : processed documents up to #10
2016-10-09 21:36:48,710 : INFO : topic #0(1.169): 0.279*"doha" + 0.229*"baby" + 0.208*"get" + 0.195*"coming" + 0.188*"vaccination" + 0.181*"vaccinations" + 0.172*"much" + 0.171*"regular" + 0.169*"remaining" + 0.141*"u"
2016-10-09 21:36:48,710 : INFO : topic #1(1.040): -0.260*"would" + -0.188*"coming" + -0.184*"get" + 0.176*"clinic" + 0.176*"u" + 0.168*"regular" + 0.167*"communicate" + 0.167*"recommend" + 0.167*"good" + -0.163*"know"
2016-10-09 21:36:48,711 : INFO : topic #2(1.027): 0.287*"doha" + 0.254*"selection" + 0.254*"law" + 0.254*"buy" + -0.176*"remaining" + 0.173*"communicate" + 0.173*"recommend" + 0.173*"good" + -0.151*"know" + -0.144*"schools"
2016-10-09 21:36:48,711 : INFO : topic #3(1.003): -0.291*"made" + 0.214*"would" + 0.211*"job" + 0.211*"considering" + 0.150*"selection" + 0.150*"buy" + 0.150*"law" + -0.145*"spent" + -0.145*"ones" + -0.145*"lot"
2016-10-09 21:36:48,711 : INFO : topic #4(1.001): -0.334*"made" + 0.208*"know" + 0.185*"anyone" + 0.185*"schools" + -0.167*"wonder" + -0.167*"cure" + -0.167*"money" + -0.167*"lot" + -0.167*"think" + -0.167*"someone"
2016-10-09 21:36:48,711 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:48,712 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:48,713 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:48,714 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,714 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,714 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:48,715 : INFO : saved 10x5162 matrix, density=0.275% (142/51620)
2016-10-09 21:36:48,715 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,715 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,715 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,715 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,716 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,716 : INFO : accepted corpus with 10 documents, 5162 features, 142 non-zero entries
2016-10-09 21:36:48,716 : INFO : collecting document frequencies
2016-10-09 21:36:48,716 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:48,716 : INFO : calculating IDF weights for 10 documents and 5161 features (142 matrix non-zeros)
2016-10-09 21:36:48,717 : INFO : using serial LSI version on this node
2016-10-09 21:36:48,717 : INFO : updating model with new documents
2016-10-09 21:36:48,717 : INFO : preparing a new chunk of documents
2016-10-09 21:36:48,717 : DEBUG : converting corpus to csc format
2016-10-09 21:36:48,718 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:48,719 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:48,720 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:48,731 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,770 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,788 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,845 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,891 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:48,896 : INFO : computing the final decomposition
2016-10-09 21:36:48,896 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:48,897 : INFO : processed documents up to #10
2016-10-09 21:36:48,898 : INFO : topic #0(1.165): -0.317*"cold" + -0.302*"curious" + -0.240*"winter" + -0.228*"coming" + -0.204*"doha" + -0.190*"hi" + -0.171*"thank" + -0.163*"october" + -0.163*"november" + -0.163*"already"
2016-10-09 21:36:48,898 : INFO : topic #1(1.056): -0.248*"curious" + 0.208*"coming" + -0.194*"winter" + 0.189*"bring" + -0.175*"doha" + 0.174*"thank" + 0.148*"qatar" + 0.140*"cloths" + 0.140*"pls" + 0.140*"30"
2016-10-09 21:36:48,898 : INFO : topic #2(1.027): 0.288*"normal" + -0.278*"curious" + 0.179*"know" + 0.149*"thanks" + 0.144*"else" + 0.144*"would" + 0.144*"due" + 0.144*"recent" + 0.144*"dust" + 0.144*"dr"
2016-10-09 21:36:48,898 : INFO : topic #3(1.000): -0.314*"travel" + -0.314*"also" + -0.157*"vegetarian" + -0.157*"plan" + -0.157*"packages" + -0.157*"package" + -0.157*"required" + -0.157*"august" + -0.157*"india" + -0.157*"please"
2016-10-09 21:36:48,899 : INFO : topic #4(0.995): -0.269*"wear" + -0.269*"visiting" + -0.269*"clothes" + -0.269*"jeans" + -0.269*"woman" + -0.269*"western" + -0.202*"december" + -0.182*"bring" + -0.158*"pool" + -0.158*"suggest"
2016-10-09 21:36:48,899 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:48,900 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:48,900 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:48,901 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,901 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,901 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:48,902 : INFO : saved 10x5296 matrix, density=0.359% (190/52960)
2016-10-09 21:36:48,902 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,902 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,902 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,903 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:48,903 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:48,903 : INFO : accepted corpus with 10 documents, 5296 features, 190 non-zero entries
2016-10-09 21:36:48,903 : INFO : collecting document frequencies
2016-10-09 21:36:48,903 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:48,904 : INFO : calculating IDF weights for 10 documents and 5295 features (190 matrix non-zeros)
2016-10-09 21:36:48,904 : INFO : using serial LSI version on this node
2016-10-09 21:36:48,904 : INFO : updating model with new documents
2016-10-09 21:36:48,905 : INFO : preparing a new chunk of documents
2016-10-09 21:36:48,905 : DEBUG : converting corpus to csc format
2016-10-09 21:36:48,905 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:48,907 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:48,907 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:48,919 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:48,957 : DEBUG : running 2 power iterations
2016-10-09 21:36:48,975 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,032 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,078 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:49,083 : INFO : computing the final decomposition
2016-10-09 21:36:49,083 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:49,085 : INFO : processed documents up to #10
2016-10-09 21:36:49,085 : INFO : topic #0(1.178): 0.315*"puppy" + 0.298*"dog" + 0.298*"small" + 0.296*"would" + 0.261*"buy" + 0.259*"doha" + 0.178*"bring" + 0.170*"dogs" + 0.169*"food" + 0.139*"cat"
2016-10-09 21:36:49,085 : INFO : topic #1(1.046): -0.239*"cat" + 0.213*"puppy" + -0.193*"cost" + -0.193*"much" + 0.178*"small" + 0.178*"dog" + -0.174*"com" + -0.174*"qatarliving" + -0.174*"www" + -0.174*"http"
2016-10-09 21:36:49,085 : INFO : topic #2(1.008): 0.234*"much" + 0.234*"cost" + 0.190*"pup" + 0.190*"let" + 0.190*"know" + 0.148*"place" + 0.148*"qatar" + -0.136*"food" + 0.130*"1" + -0.128*"qatarliving"
2016-10-09 21:36:49,086 : INFO : topic #3(1.003): 0.197*"buying" + 0.197*"necessary" + 0.197*"store" + 0.197*"cats" + 0.197*"successful" + 0.197*"finding" + 0.197*"thanks" + 0.197*"stuff" + 0.197*"recommend" + 0.197*"somebody"
2016-10-09 21:36:49,086 : INFO : topic #4(1.000): -0.447*"jesus" + -0.447*"attachment" + -0.447*"christian" + -0.447*"see" + -0.447*"muslim" + 0.000*"somebody" + 0.000*"recommend" + 0.000*"store" + 0.000*"finding" + 0.000*"cats"
2016-10-09 21:36:49,086 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:49,087 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:49,088 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:49,089 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,089 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,089 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:49,090 : INFO : saved 10x5266 matrix, density=0.332% (175/52660)
2016-10-09 21:36:49,090 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,090 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,090 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,090 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,090 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,090 : INFO : accepted corpus with 10 documents, 5266 features, 175 non-zero entries
2016-10-09 21:36:49,091 : INFO : collecting document frequencies
2016-10-09 21:36:49,091 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:49,091 : INFO : calculating IDF weights for 10 documents and 5265 features (175 matrix non-zeros)
2016-10-09 21:36:49,091 : INFO : using serial LSI version on this node
2016-10-09 21:36:49,092 : INFO : updating model with new documents
2016-10-09 21:36:49,092 : INFO : preparing a new chunk of documents
2016-10-09 21:36:49,092 : DEBUG : converting corpus to csc format
2016-10-09 21:36:49,093 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:49,094 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:49,095 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:49,106 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,145 : DEBUG : running 2 power iterations
2016-10-09 21:36:49,163 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,220 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,266 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:49,271 : INFO : computing the final decomposition
2016-10-09 21:36:49,271 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:49,273 : INFO : processed documents up to #10
2016-10-09 21:36:49,273 : INFO : topic #0(1.127): -0.261*"much" + -0.227*"would" + -0.198*"also" + -0.162*"qatar" + -0.160*"pay" + -0.160*"loan" + -0.147*"know" + -0.125*"qr" + -0.124*"first" + -0.124*"thinking"
2016-10-09 21:36:49,274 : INFO : topic #1(1.074): -0.324*"anyone" + -0.324*"recommend" + -0.305*"applied" + -0.305*"window" + -0.223*"place" + 0.182*"selection" + 0.182*"law" + 0.181*"doha" + 0.166*"buy" + -0.159*"apartment"
2016-10-09 21:36:49,274 : INFO : topic #2(1.060): 0.294*"doha" + 0.287*"law" + 0.287*"selection" + 0.268*"buy" + 0.173*"recommend" + 0.173*"anyone" + 0.160*"applied" + 0.160*"window" + -0.126*"much" + -0.108*"would"
2016-10-09 21:36:49,274 : INFO : topic #3(1.014): -0.366*"qr" + -0.314*"wife" + -0.157*"allowance" + -0.157*"1500" + -0.157*"enginner" + -0.157*"8000" + -0.157*"house" + -0.157*"everyone" + -0.157*"hello" + -0.157*"relocate"
2016-10-09 21:36:49,274 : INFO : topic #4(0.994): 0.372*"months" + 0.372*"sell" + 0.189*"one" + 0.186*"weeks" + 0.186*"long" + 0.186*"want" + 0.186*"leaving" + 0.186*"two" + 0.186*"best" + 0.186*"prefer"
2016-10-09 21:36:49,274 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:49,275 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:49,276 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:49,277 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,277 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,277 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:49,278 : INFO : saved 10x5162 matrix, density=0.353% (182/51620)
2016-10-09 21:36:49,278 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,278 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,278 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,279 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,279 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,279 : INFO : accepted corpus with 10 documents, 5162 features, 182 non-zero entries
2016-10-09 21:36:49,279 : INFO : collecting document frequencies
2016-10-09 21:36:49,279 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:49,280 : INFO : calculating IDF weights for 10 documents and 5161 features (182 matrix non-zeros)
2016-10-09 21:36:49,280 : INFO : using serial LSI version on this node
2016-10-09 21:36:49,280 : INFO : updating model with new documents
2016-10-09 21:36:49,281 : INFO : preparing a new chunk of documents
2016-10-09 21:36:49,281 : DEBUG : converting corpus to csc format
2016-10-09 21:36:49,281 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:49,283 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:49,283 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:49,294 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,334 : DEBUG : running 2 power iterations
2016-10-09 21:36:49,352 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,409 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,455 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:49,460 : INFO : computing the final decomposition
2016-10-09 21:36:49,460 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:49,462 : INFO : processed documents up to #10
2016-10-09 21:36:49,462 : INFO : topic #0(1.125): -0.233*"child" + -0.180*"bus" + -0.171*"seat" + -0.168*"one" + -0.165*"front" + -0.154*"children" + -0.147*"vehicles" + -0.143*"would" + -0.142*"kids" + -0.140*"law"
2016-10-09 21:36:49,462 : INFO : topic #1(1.060): 0.275*"sure" + 0.248*"kids" + -0.216*"child" + 0.210*"would" + -0.201*"bus" + 0.153*"front" + 0.144*"bit" + 0.144*"treat" + 0.144*"airlines" + 0.144*"available"
2016-10-09 21:36:49,462 : INFO : topic #2(1.041): -0.349*"baby" + -0.269*"sign" + 0.236*"bus" + -0.230*"stores" + -0.230*"everything" + -0.179*"board" + 0.136*"child" + 0.136*"school" + -0.119*"doha" + 0.118*"found"
2016-10-09 21:36:49,462 : INFO : topic #3(1.029): 0.368*"buy" + 0.368*"selection" + 0.300*"law" + 0.212*"doha" + 0.206*"qatar" + -0.157*"one" + -0.150*"seat" + -0.140*"sign" + -0.130*"baby" + -0.127*"qatari"
2016-10-09 21:36:49,463 : INFO : topic #4(1.020): 0.245*"one" + 0.160*"seat" + 0.159*"buy" + 0.159*"selection" + -0.159*"sure" + 0.153*"law" + -0.153*"bus" + -0.153*"school" + -0.142*"month" + -0.142*"place"
2016-10-09 21:36:49,463 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:49,464 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:49,465 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:49,465 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,466 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,466 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:49,467 : INFO : saved 10x5282 matrix, density=0.362% (191/52820)
2016-10-09 21:36:49,467 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,467 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,467 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,467 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,467 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,467 : INFO : accepted corpus with 10 documents, 5282 features, 191 non-zero entries
2016-10-09 21:36:49,468 : INFO : collecting document frequencies
2016-10-09 21:36:49,468 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:49,468 : INFO : calculating IDF weights for 10 documents and 5281 features (191 matrix non-zeros)
2016-10-09 21:36:49,469 : INFO : using serial LSI version on this node
2016-10-09 21:36:49,469 : INFO : updating model with new documents
2016-10-09 21:36:49,469 : INFO : preparing a new chunk of documents
2016-10-09 21:36:49,469 : DEBUG : converting corpus to csc format
2016-10-09 21:36:49,470 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:49,471 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:49,472 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:49,483 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,522 : DEBUG : running 2 power iterations
2016-10-09 21:36:49,540 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,596 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,643 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:49,648 : INFO : computing the final decomposition
2016-10-09 21:36:49,648 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:49,650 : INFO : processed documents up to #10
2016-10-09 21:36:49,650 : INFO : topic #0(1.168): 0.194*"beaches" + 0.191*"take" + 0.188*"beach" + 0.164*"dunes" + 0.163*"would" + 0.159*"anyone" + 0.159*"umm" + 0.155*"could" + 0.155*"start" + 0.155*"clean"
2016-10-09 21:36:49,650 : INFO : topic #1(1.031): -0.234*"public" + -0.234*"ridiculous" + -0.211*"suggestions" + -0.181*"one" + 0.160*"would" + -0.157*"please" + -0.137*"camping" + -0.137*"license" + 0.135*"could" + 0.133*"beaches"
2016-10-09 21:36:49,650 : INFO : topic #2(1.008): -0.368*"public" + -0.368*"ridiculous" + 0.353*"suggestions" + -0.199*"gulf" + -0.199*"speed" + -0.199*"times" + 0.177*"holidays" + 0.177*"new" + 0.177*"happenings" + 0.177*"something"
2016-10-09 21:36:49,651 : INFO : topic #3(1.005): 0.327*"suggestions" + 0.235*"private" + 0.235*"booze" + 0.235*"let" + 0.235*"party" + -0.169*"okay" + -0.169*"tell" + -0.168*"camping" + -0.168*"license" + 0.164*"something"
2016-10-09 21:36:49,651 : INFO : topic #4(0.995): -0.325*"ridiculous" + -0.325*"public" + 0.263*"times" + 0.263*"gulf" + 0.263*"speed" + -0.159*"beach" + -0.153*"tell" + -0.153*"okay" + 0.132*"1" + 0.132*"item_no"
2016-10-09 21:36:49,651 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:49,652 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:49,653 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:49,654 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,654 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,654 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:49,655 : INFO : saved 10x5332 matrix, density=0.392% (209/53320)
2016-10-09 21:36:49,655 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,655 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,655 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,655 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,656 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,656 : INFO : accepted corpus with 10 documents, 5332 features, 209 non-zero entries
2016-10-09 21:36:49,656 : INFO : collecting document frequencies
2016-10-09 21:36:49,656 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:49,656 : INFO : calculating IDF weights for 10 documents and 5331 features (209 matrix non-zeros)
2016-10-09 21:36:49,657 : INFO : using serial LSI version on this node
2016-10-09 21:36:49,657 : INFO : updating model with new documents
2016-10-09 21:36:49,658 : INFO : preparing a new chunk of documents
2016-10-09 21:36:49,658 : DEBUG : converting corpus to csc format
2016-10-09 21:36:49,658 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:49,660 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:49,660 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:49,671 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,710 : DEBUG : running 2 power iterations
2016-10-09 21:36:49,728 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,785 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,832 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:49,836 : INFO : computing the final decomposition
2016-10-09 21:36:49,836 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:49,838 : INFO : processed documents up to #10
2016-10-09 21:36:49,839 : INFO : topic #0(1.116): 0.255*"doha" + 0.252*"cars" + 0.177*"would" + 0.168*"much" + 0.154*"best" + 0.146*"toyota" + 0.146*"price" + 0.136*"reliable" + 0.133*"renault" + 0.121*"nissan"
2016-10-09 21:36:49,839 : INFO : topic #1(1.045): -0.257*"much" + 0.252*"doha" + 0.210*"cars" + -0.204*"would" + 0.159*"best" + -0.139*"pay" + -0.136*"thanks" + -0.133*"thinking" + -0.133*"per" + -0.133*"qlers"
2016-10-09 21:36:49,839 : INFO : topic #2(1.023): 0.219*"would" + 0.163*"much" + -0.150*"anyone" + -0.142*"reliable" + -0.141*"years" + 0.140*"toyota" + 0.140*"price" + -0.112*"renting" + -0.112*"thousand" + -0.112*"threads"
2016-10-09 21:36:49,839 : INFO : topic #3(1.010): 0.259*"maintenance" + 0.259*"using" + 0.259*"mean" + 0.259*"share" + 0.259*"yes" + 0.259*"anybody" + 0.259*"performance" + 0.221*"please" + 0.196*"experience" + 0.195*"renault"
2016-10-09 21:36:49,839 : INFO : topic #4(1.005): -0.147*"reliable" + 0.144*"shown" + 0.144*"come" + 0.144*"east" + 0.144*"thank" + 0.144*"light" + 0.144*"happens" + 0.144*"covering" + 0.144*"photo" + 0.144*"middle"
2016-10-09 21:36:49,839 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:49,840 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:49,841 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:49,842 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,842 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,842 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:49,843 : INFO : saved 10x5313 matrix, density=0.296% (157/53130)
2016-10-09 21:36:49,843 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,843 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,843 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,844 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:49,844 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:49,844 : INFO : accepted corpus with 10 documents, 5313 features, 157 non-zero entries
2016-10-09 21:36:49,844 : INFO : collecting document frequencies
2016-10-09 21:36:49,844 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:49,845 : INFO : calculating IDF weights for 10 documents and 5312 features (157 matrix non-zeros)
2016-10-09 21:36:49,845 : INFO : using serial LSI version on this node
2016-10-09 21:36:49,845 : INFO : updating model with new documents
2016-10-09 21:36:49,846 : INFO : preparing a new chunk of documents
2016-10-09 21:36:49,846 : DEBUG : converting corpus to csc format
2016-10-09 21:36:49,846 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:49,848 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:49,848 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:49,859 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,898 : DEBUG : running 2 power iterations
2016-10-09 21:36:49,916 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:49,973 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,019 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,024 : INFO : computing the final decomposition
2016-10-09 21:36:50,024 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,026 : INFO : processed documents up to #10
2016-10-09 21:36:50,026 : INFO : topic #0(1.209): -0.696*"water" + -0.270*"drinking" + -0.224*"filter" + -0.224*"using" + -0.206*"tap" + -0.183*"bottled" + -0.112*"safe" + -0.112*"something" + -0.112*"need" + -0.112*"anybody"
2016-10-09 21:36:50,026 : INFO : topic #1(1.128): 0.276*"plants" + 0.224*"know" + 0.217*"nurseries" + 0.205*"doha" + 0.200*"anyone" + -0.186*"water" + 0.166*"buy" + 0.166*"indoor" + 0.166*"photography" + 0.166*"supermarket"
2016-10-09 21:36:50,027 : INFO : topic #2(1.024): 0.315*"business" + 0.241*"wanted" + 0.187*"places" + 0.178*"answer" + 0.178*"numbers" + 0.178*"contact" + 0.178*"phone" + 0.178*"getting" + 0.178*"couple" + 0.148*"tried"
2016-10-09 21:36:50,027 : INFO : topic #3(1.011): -0.250*"happening" + -0.212*"tried" + 0.205*"told" + 0.205*"bcz" + 0.205*"explain" + 0.205*"doctor" + 0.205*"low" + 0.194*"business" + -0.179*"answer" + -0.179*"contact"
2016-10-09 21:36:50,027 : INFO : topic #4(1.001): 0.248*"treatment" + 0.238*"explain" + 0.238*"bcz" + 0.238*"low" + 0.238*"doctor" + 0.238*"told" + 0.202*"couple" + 0.202*"answer" + 0.202*"getting" + 0.202*"phone"
2016-10-09 21:36:50,027 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,028 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,029 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,030 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,030 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,030 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,031 : INFO : saved 10x5329 matrix, density=0.332% (177/53290)
2016-10-09 21:36:50,031 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,031 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,031 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,032 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,032 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,032 : INFO : accepted corpus with 10 documents, 5329 features, 177 non-zero entries
2016-10-09 21:36:50,032 : INFO : collecting document frequencies
2016-10-09 21:36:50,032 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,032 : INFO : calculating IDF weights for 10 documents and 5328 features (177 matrix non-zeros)
2016-10-09 21:36:50,033 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,033 : INFO : updating model with new documents
2016-10-09 21:36:50,034 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,034 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,034 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,036 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,036 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,047 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,086 : DEBUG : running 2 power iterations
2016-10-09 21:36:50,104 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,161 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,207 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,212 : INFO : computing the final decomposition
2016-10-09 21:36:50,212 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,214 : INFO : processed documents up to #10
2016-10-09 21:36:50,214 : INFO : topic #0(1.070): 0.460*"one" + 0.334*"places" + 0.334*"boring" + 0.334*"ever" + 0.323*"public" + 0.323*"beach" + 0.323*"ridiculous" + 0.221*"doha" + 0.075*"laffan" + 0.075*"ras"
2016-10-09 21:36:50,214 : INFO : topic #1(1.069): -0.244*"party" + -0.222*"restaurant" + -0.210*"anyone" + -0.182*"given" + -0.182*"place" + -0.182*"food" + -0.182*"venues" + -0.182*"rent" + -0.182*"kfc" + -0.182*"already"
2016-10-09 21:36:50,214 : INFO : topic #2(1.020): -0.231*"hmc" + -0.205*"laffan" + -0.205*"ras" + -0.154*"training" + -0.154*"salary" + -0.137*"live" + -0.133*"2" + -0.133*"baby" + -0.133*"son" + -0.133*"speech"
2016-10-09 21:36:50,214 : INFO : topic #3(1.016): 0.168*"party" + -0.166*"ras" + -0.166*"laffan" + -0.157*"airline" + -0.157*"gulf" + -0.157*"said" + -0.157*"gave" + -0.157*"crew" + -0.157*"experience" + -0.157*"air"
2016-10-09 21:36:50,215 : INFO : topic #4(1.001): -0.375*"result" + -0.375*"grade" + -0.187*"straight" + -0.187*"student" + -0.187*"university" + -0.187*"rejected" + -0.187*"sat" + -0.187*"criteria" + -0.187*"12" + -0.187*"anybody"
2016-10-09 21:36:50,215 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,216 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,217 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,218 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,218 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,218 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,219 : INFO : saved 10x5296 matrix, density=0.425% (225/52960)
2016-10-09 21:36:50,219 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,219 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,219 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,219 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,220 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,220 : INFO : accepted corpus with 10 documents, 5296 features, 225 non-zero entries
2016-10-09 21:36:50,220 : INFO : collecting document frequencies
2016-10-09 21:36:50,220 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,220 : INFO : calculating IDF weights for 10 documents and 5295 features (225 matrix non-zeros)
2016-10-09 21:36:50,221 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,221 : INFO : updating model with new documents
2016-10-09 21:36:50,222 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,222 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,222 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,224 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,224 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,235 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,274 : DEBUG : running 2 power iterations
2016-10-09 21:36:50,292 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,350 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,396 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,401 : INFO : computing the final decomposition
2016-10-09 21:36:50,401 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,403 : INFO : processed documents up to #10
2016-10-09 21:36:50,403 : INFO : topic #0(1.131): 0.168*"back" + 0.166*"american" + 0.162*"schools" + 0.162*"uk" + 0.158*"many" + 0.157*"private" + 0.157*"groups" + 0.135*"home" + 0.133*"qatar" + 0.127*"appreciated"
2016-10-09 21:36:50,403 : INFO : topic #1(1.037): -0.270*"child" + -0.268*"bus" + -0.185*"like" + -0.185*"next" + -0.185*"house" + -0.185*"park" + -0.185*"son" + -0.185*"7yrs" + -0.185*"month" + 0.161*"small"
2016-10-09 21:36:50,403 : INFO : topic #2(1.026): 0.285*"bus" + 0.227*"use" + 0.227*"books" + 0.227*"start" + 0.218*"3" + 0.178*"child" + 0.170*"small" + 0.143*"found" + -0.136*"groups" + -0.136*"private"
2016-10-09 21:36:50,403 : INFO : topic #3(1.002): 0.257*"much" + 0.178*"start" + 0.178*"books" + 0.178*"use" + 0.153*"home" + 0.152*"daughter" + -0.146*"bus" + 0.128*"toddler" + 0.128*"summer" + 0.128*"leave"
2016-10-09 21:36:50,404 : INFO : topic #4(0.990): -0.202*"much" + -0.200*"british" + -0.200*"thinking" + -0.200*"international" + -0.200*"family" + -0.200*"hello" + -0.200*"anything" + 0.168*"uk" + 0.146*"back" + 0.135*"small"
2016-10-09 21:36:50,404 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,405 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,406 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,407 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,407 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,407 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,408 : INFO : saved 10x5296 matrix, density=0.370% (196/52960)
2016-10-09 21:36:50,408 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,408 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,408 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,409 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,409 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,409 : INFO : accepted corpus with 10 documents, 5296 features, 196 non-zero entries
2016-10-09 21:36:50,409 : INFO : collecting document frequencies
2016-10-09 21:36:50,409 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,409 : INFO : calculating IDF weights for 10 documents and 5295 features (196 matrix non-zeros)
2016-10-09 21:36:50,410 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,410 : INFO : updating model with new documents
2016-10-09 21:36:50,411 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,411 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,411 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,413 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,413 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,424 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,467 : DEBUG : running 2 power iterations
2016-10-09 21:36:50,485 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,542 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,588 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,593 : INFO : computing the final decomposition
2016-10-09 21:36:50,593 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,595 : INFO : processed documents up to #10
2016-10-09 21:36:50,595 : INFO : topic #0(1.141): 0.265*"gratuity" + 0.224*"end" + 0.224*"service" + 0.205*"7" + 0.205*"confirm" + 0.205*"period" + 0.205*"benefits" + 0.205*"years" + 0.194*"working" + 0.182*"qatar"
2016-10-09 21:36:50,595 : INFO : topic #1(1.046): 0.224*"someone" + 0.220*"table" + 0.220*"dinner" + 0.220*"want" + 0.220*"share" + 0.220*"ask" + 0.210*"get" + 0.204*"please" + 0.183*"many" + 0.160*"anybody"
2016-10-09 21:36:50,595 : INFO : topic #2(1.008): -0.294*"good" + -0.252*"also" + -0.252*"months" + -0.252*"deposit" + -0.182*"doha" + -0.147*"allowance" + -0.147*"deal" + -0.147*"transportation" + -0.147*"housing" + -0.147*"provide"
2016-10-09 21:36:50,596 : INFO : topic #3(1.002): 0.407*"respect" + 0.271*"people" + 0.271*"think" + 0.271*"culture" + -0.155*"anybody" + 0.136*"feel" + 0.136*"local" + 0.136*"try" + 0.136*"take" + 0.136*"come"
2016-10-09 21:36:50,596 : INFO : topic #4(1.000): -0.457*"crime" + -0.305*"considered" + -0.305*"west" + -0.305*"wife" + -0.305*"polygamy" + -0.152*"even" + -0.152*"islamic" + -0.152*"girlfriend" + -0.152*"equally" + -0.152*"prostitution"
2016-10-09 21:36:50,596 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,597 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,598 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,599 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,599 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,599 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,600 : INFO : saved 10x5296 matrix, density=0.279% (148/52960)
2016-10-09 21:36:50,600 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,600 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,600 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,600 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,601 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,601 : INFO : accepted corpus with 10 documents, 5296 features, 148 non-zero entries
2016-10-09 21:36:50,601 : INFO : collecting document frequencies
2016-10-09 21:36:50,601 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,601 : INFO : calculating IDF weights for 10 documents and 5295 features (148 matrix non-zeros)
2016-10-09 21:36:50,602 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,602 : INFO : updating model with new documents
2016-10-09 21:36:50,602 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,602 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,603 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,604 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,605 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,616 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,655 : DEBUG : running 2 power iterations
2016-10-09 21:36:50,674 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,730 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,776 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,781 : INFO : computing the final decomposition
2016-10-09 21:36:50,781 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,783 : INFO : processed documents up to #10
2016-10-09 21:36:50,783 : INFO : topic #0(1.059): -0.241*"qatar" + -0.231*"moon" + -0.215*"islam" + -0.195*"hi" + -0.174*"18th" + -0.174*"national" + -0.174*"december" + -0.174*"thanks" + -0.174*"wanted" + -0.174*"confirm"
2016-10-09 21:36:50,783 : INFO : topic #1(1.043): 0.316*"moon" + 0.236*"islam" + 0.183*"right" + -0.172*"hi" + 0.156*"dirty" + 0.156*"world" + 0.156*"idiots" + 0.156*"fool" + 0.156*"live" + -0.156*"18th"
2016-10-09 21:36:50,783 : INFO : topic #2(1.032): -0.362*"one" + -0.323*"ones" + -0.323*"still" + -0.323*"waiting" + -0.323*"getting" + -0.194*"value" + -0.194*"u" + -0.194*"two" + -0.194*"cost" + -0.194*"comfort"
2016-10-09 21:36:50,784 : INFO : topic #3(1.007): -0.356*"wearing" + -0.190*"need" + -0.188*"teachers" + -0.178*"packed" + -0.178*"simply" + -0.178*"long" + -0.178*"stay" + -0.178*"family" + -0.178*"conservatively" + -0.178*"dressed"
2016-10-09 21:36:50,784 : INFO : topic #4(1.000): -0.447*"affordable" + -0.447*"month" + -0.447*"gym" + -0.447*"guy" + -0.447*"earning" + -0.000*"wearing" + -0.000*"packed" + -0.000*"new" + -0.000*"women" + -0.000*"conservatively"
2016-10-09 21:36:50,784 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,785 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,786 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,786 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,786 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,787 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,787 : INFO : saved 10x5305 matrix, density=0.385% (204/53050)
2016-10-09 21:36:50,788 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,788 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,788 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,788 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,788 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,788 : INFO : accepted corpus with 10 documents, 5305 features, 204 non-zero entries
2016-10-09 21:36:50,789 : INFO : collecting document frequencies
2016-10-09 21:36:50,789 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,789 : INFO : calculating IDF weights for 10 documents and 5304 features (204 matrix non-zeros)
2016-10-09 21:36:50,790 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,790 : INFO : updating model with new documents
2016-10-09 21:36:50,790 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,790 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,791 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,792 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,793 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,804 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,843 : DEBUG : running 2 power iterations
2016-10-09 21:36:50,861 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,918 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:50,964 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:50,969 : INFO : computing the final decomposition
2016-10-09 21:36:50,969 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:50,971 : INFO : processed documents up to #10
2016-10-09 21:36:50,971 : INFO : topic #0(1.108): 0.192*"decent" + 0.186*"get" + 0.175*"need" + 0.170*"advance" + 0.165*"directions" + 0.155*"embassy" + 0.155*"appointment" + 0.155*"help" + 0.155*"driving" + 0.155*"set"
2016-10-09 21:36:50,971 : INFO : topic #1(1.041): 0.236*"qatar" + 0.207*"wanted" + 0.207*"garmin" + 0.207*"gps" + 0.183*"books" + 0.183*"" + 0.183*"english" + 0.170*"us" + 0.152*"appointment" + 0.152*"help"
2016-10-09 21:36:50,971 : INFO : topic #2(1.020): -0.333*"thai" + -0.222*"food" + 0.177*"taxis" + 0.177*"karwa" + 0.177*"al" + 0.155*"repaire" + -0.152*"shops" + 0.138*"new" + 0.137*"anyone" + 0.115*"lulu"
2016-10-09 21:36:50,972 : INFO : topic #3(1.008): -0.238*"decent" + 0.221*"thai" + -0.158*"ones" + -0.158*"fresh" + -0.158*"bad" + -0.158*"carrefour" + -0.158*"really" + -0.158*"fruits" + -0.158*"bread" + -0.158*"vegetables"
2016-10-09 21:36:50,972 : INFO : topic #4(0.995): -0.177*"maps" + -0.177*"couple" + -0.177*"first" + 0.150*"thai" + -0.142*"decent" + 0.140*"need" + 0.135*"taxis" + 0.135*"al" + 0.135*"karwa" + -0.132*"lulu"
2016-10-09 21:36:50,972 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:50,973 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:50,974 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:50,975 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,975 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,975 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:50,976 : INFO : saved 10x5282 matrix, density=0.388% (205/52820)
2016-10-09 21:36:50,976 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,976 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,976 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,976 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:50,977 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:50,977 : INFO : accepted corpus with 10 documents, 5282 features, 205 non-zero entries
2016-10-09 21:36:50,977 : INFO : collecting document frequencies
2016-10-09 21:36:50,977 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:50,977 : INFO : calculating IDF weights for 10 documents and 5281 features (205 matrix non-zeros)
2016-10-09 21:36:50,978 : INFO : using serial LSI version on this node
2016-10-09 21:36:50,978 : INFO : updating model with new documents
2016-10-09 21:36:50,979 : INFO : preparing a new chunk of documents
2016-10-09 21:36:50,979 : DEBUG : converting corpus to csc format
2016-10-09 21:36:50,979 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:50,981 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:50,981 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:50,992 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,032 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,050 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,107 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,154 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:51,159 : INFO : computing the final decomposition
2016-10-09 21:36:51,159 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:51,160 : INFO : processed documents up to #10
2016-10-09 21:36:51,161 : INFO : topic #0(1.177): 0.283*"sponsorship" + 0.177*"visit" + 0.170*"visa" + 0.165*"work" + 0.157*"family" + 0.157*"sponsor" + 0.154*"qatar" + 0.150*"help" + 0.150*"months" + 0.141*"please"
2016-10-09 21:36:51,161 : INFO : topic #1(1.078): -0.402*"sponsorship" + -0.253*"work" + 0.204*"months" + -0.191*"sponsor" + 0.166*"visit" + 0.164*"maximum" + 0.164*"extend" + 0.164*"anybody" + 0.164*"currently" + 0.164*"whether"
2016-10-09 21:36:51,161 : INFO : topic #2(1.029): -0.231*"keep" + -0.231*"meet" + -0.215*"exam" + -0.186*"everyone" + -0.156*"besides" + -0.156*"days" + -0.135*"weeks" + 0.128*"visit" + -0.118*"medical" + -0.115*"getting"
2016-10-09 21:36:51,161 : INFO : topic #3(1.022): -0.235*"qatar" + -0.190*"medical" + 0.184*"sponsorship" + -0.169*"bring" + -0.169*"noc" + -0.169*"airways" + -0.169*"legally" + -0.169*"married" + -0.153*"10000" + -0.153*"govt"
2016-10-09 21:36:51,162 : INFO : topic #4(1.002): -0.283*"found" + -0.283*"expecting" + -0.283*"recommendations" + -0.283*"best" + -0.283*"year" + -0.283*"baby" + -0.283*"later" + -0.283*"doctors" + -0.283*"deliver" + -0.283*"place"
2016-10-09 21:36:51,162 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:51,163 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:51,164 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:51,164 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,165 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,165 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:51,165 : INFO : saved 10x5296 matrix, density=0.221% (117/52960)
2016-10-09 21:36:51,165 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,165 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,166 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,166 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,166 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,166 : INFO : accepted corpus with 10 documents, 5296 features, 117 non-zero entries
2016-10-09 21:36:51,166 : INFO : collecting document frequencies
2016-10-09 21:36:51,166 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:51,167 : INFO : calculating IDF weights for 10 documents and 5295 features (117 matrix non-zeros)
2016-10-09 21:36:51,167 : INFO : using serial LSI version on this node
2016-10-09 21:36:51,167 : INFO : updating model with new documents
2016-10-09 21:36:51,168 : INFO : preparing a new chunk of documents
2016-10-09 21:36:51,168 : DEBUG : converting corpus to csc format
2016-10-09 21:36:51,168 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:51,170 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:51,170 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:51,181 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,221 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,239 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,296 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,342 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:51,347 : INFO : computing the final decomposition
2016-10-09 21:36:51,347 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:51,349 : INFO : processed documents up to #10
2016-10-09 21:36:51,349 : INFO : topic #0(1.193): 0.366*"family" + 0.326*"best" + 0.324*"beach" + 0.320*"qatar" + 0.278*"go" + 0.222*"next" + 0.212*"romantic" + 0.212*"maybe" + 0.212*"silent" + 0.211*"planning"
2016-10-09 21:36:51,349 : INFO : topic #1(1.043): 0.293*"next" + 0.251*"visited" + 0.251*"countries" + 0.251*"plan" + 0.235*"experience" + 0.233*"holiday" + 0.233*"destinations" + -0.209*"beach" + 0.207*"summer" + 0.207*"vacation"
2016-10-09 21:36:51,350 : INFO : topic #2(1.030): -0.344*"destinations" + -0.344*"holiday" + -0.316*"experience" + 0.275*"countries" + 0.275*"visited" + 0.275*"plan" + 0.271*"next" + -0.217*"vacation" + -0.217*"summer" + -0.217*"places"
2016-10-09 21:36:51,350 : INFO : topic #3(1.016): -0.257*"lets" + -0.256*"away" + -0.256*"country" + -0.256*"long" + -0.256*"17" + -0.256*"start" + -0.256*"years" + -0.223*"beaches" + 0.150*"family" + -0.130*"holiday"
2016-10-09 21:36:51,350 : INFO : topic #4(0.999): 0.189*"involved" + 0.189*"pro" + 0.189*"decent" + 0.189*"clues" + 0.189*"etc" + 0.189*"september" + 0.189*"us" + 0.189*"moving" + 0.189*"advice" + 0.189*"wife"
2016-10-09 21:36:51,350 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:51,351 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:51,352 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:51,352 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,353 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,353 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:51,353 : INFO : saved 10x5248 matrix, density=0.347% (182/52480)
2016-10-09 21:36:51,354 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,354 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,354 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,354 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,354 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,354 : INFO : accepted corpus with 10 documents, 5248 features, 182 non-zero entries
2016-10-09 21:36:51,354 : INFO : collecting document frequencies
2016-10-09 21:36:51,355 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:51,355 : INFO : calculating IDF weights for 10 documents and 5247 features (182 matrix non-zeros)
2016-10-09 21:36:51,355 : INFO : using serial LSI version on this node
2016-10-09 21:36:51,355 : INFO : updating model with new documents
2016-10-09 21:36:51,356 : INFO : preparing a new chunk of documents
2016-10-09 21:36:51,356 : DEBUG : converting corpus to csc format
2016-10-09 21:36:51,357 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:51,358 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:51,359 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:51,370 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,409 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,427 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,484 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,531 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:51,535 : INFO : computing the final decomposition
2016-10-09 21:36:51,535 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:51,537 : INFO : processed documents up to #10
2016-10-09 21:36:51,537 : INFO : topic #0(1.092): -0.203*"running" + -0.185*"would" + -0.180*"evening" + -0.178*"place" + -0.174*"night" + -0.164*"corniche" + -0.140*"safe" + -0.135*"hi" + -0.135*"good" + -0.134*"could"
2016-10-09 21:36:51,538 : INFO : topic #1(1.036): -0.303*"running" + -0.239*"com" + -0.239*"www" + 0.199*"evening" + 0.196*"see" + 0.196*"groups" + 0.196*"lot" + 0.196*"qlers" + -0.157*"usually" + -0.157*"done"
2016-10-09 21:36:51,538 : INFO : topic #2(1.026): -0.248*"could" + -0.245*"like" + -0.226*"im" + -0.166*"know" + -0.151*"would" + -0.135*"wear" + 0.131*"lot" + 0.131*"see" + 0.131*"qlers" + 0.131*"groups"
2016-10-09 21:36:51,538 : INFO : topic #3(1.006): -0.283*"move" + -0.283*"alone" + -0.283*"ladies" + 0.283*"today" + -0.231*"safe" + -0.141*"hello" + -0.141*"indian" + -0.141*"used" + -0.141*"public" + -0.141*"comparable"
2016-10-09 21:36:51,538 : INFO : topic #4(1.003): -0.347*"wear" + -0.222*"see" + -0.222*"lot" + -0.222*"groups" + -0.222*"qlers" + -0.161*"evening" + -0.150*"www" + -0.150*"com" + 0.121*"night" + -0.119*"corniche"
2016-10-09 21:36:51,538 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:51,539 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:51,540 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:51,541 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,541 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,541 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:51,542 : INFO : saved 10x5329 matrix, density=0.364% (194/53290)
2016-10-09 21:36:51,542 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,542 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,542 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,543 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,543 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,543 : INFO : accepted corpus with 10 documents, 5329 features, 194 non-zero entries
2016-10-09 21:36:51,543 : INFO : collecting document frequencies
2016-10-09 21:36:51,543 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:51,544 : INFO : calculating IDF weights for 10 documents and 5328 features (194 matrix non-zeros)
2016-10-09 21:36:51,544 : INFO : using serial LSI version on this node
2016-10-09 21:36:51,544 : INFO : updating model with new documents
2016-10-09 21:36:51,545 : INFO : preparing a new chunk of documents
2016-10-09 21:36:51,545 : DEBUG : converting corpus to csc format
2016-10-09 21:36:51,545 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:51,547 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:51,547 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:51,559 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,597 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,615 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,672 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,719 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:51,724 : INFO : computing the final decomposition
2016-10-09 21:36:51,724 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:51,726 : INFO : processed documents up to #10
2016-10-09 21:36:51,726 : INFO : topic #0(1.153): -0.228*"much" + -0.208*"club" + -0.184*"people" + -0.169*"need" + -0.169*"member" + -0.158*"bars" + -0.157*"enjoy" + -0.157*"ways" + -0.157*"dubai" + -0.157*"doha"
2016-10-09 21:36:51,727 : INFO : topic #1(1.055): -0.198*"think" + -0.184*"night" + 0.176*"bars" + -0.169*"get" + 0.169*"anything" + 0.169*"knows" + 0.169*"anybody" + 0.160*"people" + 0.150*"qatar" + 0.150*"friends"
2016-10-09 21:36:51,727 : INFO : topic #2(1.041): 0.249*"people" + 0.191*"dance" + 0.189*"ways" + 0.189*"dubai" + 0.189*"enjoy" + -0.189*"anybody" + -0.189*"anything" + -0.189*"knows" + -0.182*"friends" + -0.182*"qatar"
2016-10-09 21:36:51,727 : INFO : topic #3(1.011): 0.245*"time" + 0.245*"opens" + 0.179*"friday" + -0.157*"getting" + -0.157*"world" + -0.157*"w" + -0.157*"decent" + -0.157*"hang" + -0.157*"find" + -0.157*"days"
2016-10-09 21:36:51,727 : INFO : topic #4(0.998): 0.198*"opens" + 0.198*"time" + -0.172*"bars" + 0.162*"friday" + -0.156*"nt" + -0.156*"bar" + -0.156*"give" + -0.156*"5" + -0.156*"criteria" + -0.156*"ambiance"
2016-10-09 21:36:51,727 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:51,728 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:51,729 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:51,730 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,730 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,730 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:51,731 : INFO : saved 10x5315 matrix, density=0.233% (124/53150)
2016-10-09 21:36:51,731 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,731 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,731 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,732 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,732 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,732 : INFO : accepted corpus with 10 documents, 5315 features, 124 non-zero entries
2016-10-09 21:36:51,732 : INFO : collecting document frequencies
2016-10-09 21:36:51,732 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:51,732 : INFO : calculating IDF weights for 10 documents and 5314 features (124 matrix non-zeros)
2016-10-09 21:36:51,733 : INFO : using serial LSI version on this node
2016-10-09 21:36:51,733 : INFO : updating model with new documents
2016-10-09 21:36:51,733 : INFO : preparing a new chunk of documents
2016-10-09 21:36:51,733 : DEBUG : converting corpus to csc format
2016-10-09 21:36:51,734 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:51,736 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:51,736 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:51,747 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,786 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,804 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,860 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,907 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:51,911 : INFO : computing the final decomposition
2016-10-09 21:36:51,912 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:51,913 : INFO : processed documents up to #10
2016-10-09 21:36:51,914 : INFO : topic #0(1.092): -0.314*"think" + -0.293*"qlers" + -0.233*"moment" + -0.233*"take" + -0.233*"let" + -0.233*"hear" + -0.226*"ql" + -0.211*"say" + -0.186*"active" + -0.186*"fun"
2016-10-09 21:36:51,914 : INFO : topic #1(1.012): -0.362*"points" + 0.253*"something" + 0.233*"list" + 0.233*"hate" + -0.205*"open" + -0.205*"villagio" + 0.190*"joke" + -0.181*"earn" + -0.181*"tell" + -0.181*"anyone"
2016-10-09 21:36:51,914 : INFO : topic #2(1.009): 0.312*"points" + 0.280*"joke" + 0.257*"hate" + 0.257*"list" + 0.201*"villagio" + 0.201*"open" + 0.172*"streets" + 0.158*"women" + 0.156*"tell" + 0.156*"earn"
2016-10-09 21:36:51,914 : INFO : topic #3(1.003): 0.578*"something" + 0.289*"red" + 0.289*"noticed" + 0.289*"dont" + 0.220*"know" + 0.219*"open" + 0.219*"villagio" + 0.204*"points" + 0.164*"yet" + -0.110*"take"
2016-10-09 21:36:51,914 : INFO : topic #4(1.000): -0.448*"still" + -0.224*"always" + -0.224*"mean" + -0.224*"words" + -0.224*"sincere" + -0.224*"men" + -0.224*"mind" + -0.224*"guy" + -0.224*"true" + -0.224*"number"
2016-10-09 21:36:51,915 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:51,915 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:51,916 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:51,917 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,917 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,917 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:51,918 : INFO : saved 10x5291 matrix, density=0.370% (196/52910)
2016-10-09 21:36:51,918 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,918 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,918 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,919 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:51,919 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:51,919 : INFO : accepted corpus with 10 documents, 5291 features, 196 non-zero entries
2016-10-09 21:36:51,919 : INFO : collecting document frequencies
2016-10-09 21:36:51,919 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:51,920 : INFO : calculating IDF weights for 10 documents and 5290 features (196 matrix non-zeros)
2016-10-09 21:36:51,920 : INFO : using serial LSI version on this node
2016-10-09 21:36:51,920 : INFO : updating model with new documents
2016-10-09 21:36:51,921 : INFO : preparing a new chunk of documents
2016-10-09 21:36:51,921 : DEBUG : converting corpus to csc format
2016-10-09 21:36:51,921 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:51,923 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:51,923 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:51,935 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:51,975 : DEBUG : running 2 power iterations
2016-10-09 21:36:51,993 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,050 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,096 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:52,101 : INFO : computing the final decomposition
2016-10-09 21:36:52,101 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:52,102 : INFO : processed documents up to #10
2016-10-09 21:36:52,103 : INFO : topic #0(1.114): -0.212*"details" + -0.212*"nursery" + -0.212*"speaking" + -0.204*"french" + -0.192*"contact" + -0.192*"give" + -0.190*"anyone" + -0.189*"know" + -0.163*"lycee" + -0.151*"doha"
2016-10-09 21:36:52,103 : INFO : topic #1(1.042): 0.274*"lycee" + 0.246*"soon" + 0.215*"rumor" + 0.215*"bar" + 0.215*"mall" + 0.215*"heard" + 0.215*"say" + 0.196*"qatar" + 0.177*"get" + -0.150*"beach"
2016-10-09 21:36:52,103 : INFO : topic #2(1.035): -0.294*"give" + -0.182*"contact" + -0.151*"details" + -0.151*"nursery" + -0.151*"speaking" + -0.147*"baby" + -0.147*"website" + -0.147*"email" + -0.147*"names" + -0.147*"could"
2016-10-09 21:36:52,103 : INFO : topic #3(1.009): -0.152*"lycee" + -0.152*"moving" + -0.142*"forum" + -0.142*"al" + -0.142*"hello" + -0.142*"villa" + -0.142*"picture" + -0.142*"compound" + -0.142*"find" + -0.142*"looking"
2016-10-09 21:36:52,103 : INFO : topic #4(1.001): -0.214*"bought" + -0.190*"british" + -0.190*"buy" + -0.190*"flat" + 0.148*"details" + 0.148*"nursery" + 0.148*"speaking" + -0.148*"good" + -0.141*"would" + -0.130*"kindergarten"
2016-10-09 21:36:52,104 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:52,105 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:52,106 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:52,106 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,107 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,107 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:52,107 : INFO : saved 10x5266 matrix, density=0.330% (174/52660)
2016-10-09 21:36:52,107 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,108 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,108 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,108 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,108 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,108 : INFO : accepted corpus with 10 documents, 5266 features, 174 non-zero entries
2016-10-09 21:36:52,108 : INFO : collecting document frequencies
2016-10-09 21:36:52,109 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:52,109 : INFO : calculating IDF weights for 10 documents and 5265 features (174 matrix non-zeros)
2016-10-09 21:36:52,109 : INFO : using serial LSI version on this node
2016-10-09 21:36:52,109 : INFO : updating model with new documents
2016-10-09 21:36:52,110 : INFO : preparing a new chunk of documents
2016-10-09 21:36:52,110 : DEBUG : converting corpus to csc format
2016-10-09 21:36:52,110 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:52,112 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:52,113 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:52,124 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,163 : DEBUG : running 2 power iterations
2016-10-09 21:36:52,181 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,238 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,284 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:52,289 : INFO : computing the final decomposition
2016-10-09 21:36:52,289 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:52,291 : INFO : processed documents up to #10
2016-10-09 21:36:52,291 : INFO : topic #0(1.087): 0.234*"without" + 0.202*"driving" + 0.202*"buy" + 0.202*"possible" + 0.202*"license" + 0.202*"name" + 0.202*"folks" + 0.200*"hi" + 0.186*"doha" + 0.175*"car"
2016-10-09 21:36:52,291 : INFO : topic #1(1.037): 0.240*"bus" + 0.222*"company" + 0.222*"suggestions" + 0.178*"rent" + 0.174*"keep" + 0.174*"visit" + 0.174*"everytime" + 0.174*"seems" + 0.174*"call" + 0.174*"used"
2016-10-09 21:36:52,292 : INFO : topic #2(1.035): 0.364*"bus" + 0.186*"mate" + 0.166*"qatar" + 0.150*"one" + 0.150*"day" + 0.140*"month" + 0.137*"household" + 0.137*"required" + 0.133*"need" + 0.128*"nurse"
2016-10-09 21:36:52,292 : INFO : topic #3(1.017): 0.224*"even" + 0.224*"passport" + 0.224*"visa" + 0.224*"cancel" + 0.224*"sponsor" + 0.211*"guys" + 0.209*"thank" + 0.157*"nurse" + -0.148*"mate" + 0.120*"without"
2016-10-09 21:36:52,292 : INFO : topic #4(0.998): 0.233*"advance" + 0.233*"phone" + 0.233*"list" + 0.233*"skilled" + 0.233*"recruiting" + 0.233*"jobs" + 0.233*"numbers" + 0.233*"agencies" + 0.233*"construction" + 0.233*"workers"
2016-10-09 21:36:52,292 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:52,293 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:52,294 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:52,295 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,295 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,295 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:52,296 : INFO : saved 10x5241 matrix, density=0.246% (129/52410)
2016-10-09 21:36:52,296 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,296 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,296 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,297 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,297 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,297 : INFO : accepted corpus with 10 documents, 5241 features, 129 non-zero entries
2016-10-09 21:36:52,297 : INFO : collecting document frequencies
2016-10-09 21:36:52,297 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:52,297 : INFO : calculating IDF weights for 10 documents and 5240 features (129 matrix non-zeros)
2016-10-09 21:36:52,298 : INFO : using serial LSI version on this node
2016-10-09 21:36:52,298 : INFO : updating model with new documents
2016-10-09 21:36:52,299 : INFO : preparing a new chunk of documents
2016-10-09 21:36:52,299 : DEBUG : converting corpus to csc format
2016-10-09 21:36:52,299 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:52,301 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:52,301 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:52,312 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,351 : DEBUG : running 2 power iterations
2016-10-09 21:36:52,369 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,426 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,473 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:52,477 : INFO : computing the final decomposition
2016-10-09 21:36:52,477 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:52,479 : INFO : processed documents up to #10
2016-10-09 21:36:52,480 : INFO : topic #0(1.171): -0.464*"park" + -0.363*"know" + -0.329*"water" + -0.329*"theme" + -0.238*"qatar" + -0.223*"instead" + -0.223*"would" + -0.154*"making" + -0.154*"parks" + -0.112*"top"
2016-10-09 21:36:52,480 : INFO : topic #1(1.046): 0.357*"ur" + 0.219*"place" + 0.205*"family" + 0.205*"enjoy" + 0.178*"friends" + 0.178*"best" + 0.178*"visited" + 0.178*"hi" + -0.174*"park" + 0.168*"party"
2016-10-09 21:36:52,480 : INFO : topic #2(1.032): -0.225*"ur" + 0.216*"party" + 0.176*"given" + 0.176*"venues" + 0.176*"kfc" + 0.176*"restaurant" + 0.176*"rent" + 0.176*"already" + 0.176*"food" + -0.159*"enjoy"
2016-10-09 21:36:52,480 : INFO : topic #3(1.023): -0.296*"http" + -0.226*"trap" + -0.226*"read" + -0.226*"avoid" + -0.226*"co" + -0.226*"bored" + -0.226*"post" + -0.226*"im" + -0.197*"youtube" + -0.197*"video"
2016-10-09 21:36:52,480 : INFO : topic #4(1.010): -0.265*"got" + 0.203*"parks" + 0.203*"making" + -0.150*"doha" + -0.136*"2" + 0.133*"post" + 0.133*"bored" + 0.133*"trap" + 0.133*"co" + 0.133*"avoid"
2016-10-09 21:36:52,480 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:52,481 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:52,482 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:52,483 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,483 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,483 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:52,484 : INFO : saved 10x5253 matrix, density=0.411% (216/52530)
2016-10-09 21:36:52,484 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,484 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,484 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,485 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,485 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,485 : INFO : accepted corpus with 10 documents, 5253 features, 216 non-zero entries
2016-10-09 21:36:52,485 : INFO : collecting document frequencies
2016-10-09 21:36:52,485 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:52,486 : INFO : calculating IDF weights for 10 documents and 5252 features (216 matrix non-zeros)
2016-10-09 21:36:52,486 : INFO : using serial LSI version on this node
2016-10-09 21:36:52,486 : INFO : updating model with new documents
2016-10-09 21:36:52,487 : INFO : preparing a new chunk of documents
2016-10-09 21:36:52,487 : DEBUG : converting corpus to csc format
2016-10-09 21:36:52,487 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:52,489 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:52,489 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:52,501 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,540 : DEBUG : running 2 power iterations
2016-10-09 21:36:52,558 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,615 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,664 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:52,683 : INFO : computing the final decomposition
2016-10-09 21:36:52,683 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:52,687 : INFO : processed documents up to #10
2016-10-09 21:36:52,688 : INFO : topic #0(1.142): -0.198*"month" + -0.176*"maximum" + -0.176*"doha" + -0.176*"3" + -0.159*"currently" + -0.159*"extend" + -0.159*"whether" + -0.149*"months" + -0.138*"anybody" + -0.136*"salary"
2016-10-09 21:36:52,688 : INFO : topic #1(1.064): 0.363*"salary" + 0.231*"come" + 0.231*"option" + 0.210*"wife" + 0.172*"family" + 0.172*"transfer" + 0.172*"possible" + 0.172*"bringing" + 0.172*"appreciate" + 0.172*"regards"
2016-10-09 21:36:52,689 : INFO : topic #2(1.021): 0.214*"available" + 0.214*"pakistan" + 0.214*"someone" + 0.214*"pakistanis" + -0.207*"need" + -0.194*"know" + -0.174*"want" + -0.174*"3months" + -0.174*"sri" + -0.174*"apply"
2016-10-09 21:36:52,689 : INFO : topic #3(1.013): 0.250*"process" + 0.250*"change" + 0.146*"available" + 0.146*"pakistan" + 0.146*"someone" + 0.146*"pakistanis" + 0.146*"need" + 0.138*"visas" + 0.125*"regarding" + 0.125*"consuming"
2016-10-09 21:36:52,689 : INFO : topic #4(0.998): 0.272*"baby" + 0.272*"deliver" + 0.250*"month" + 0.136*"shud" + 0.136*"coming" + 0.136*"formalities" + 0.136*"hard" + 0.136*"highly" + 0.136*"back" + 0.136*"4"
2016-10-09 21:36:52,689 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:52,691 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:52,692 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:52,693 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,693 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,693 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:52,694 : INFO : saved 10x5329 matrix, density=0.233% (124/53290)
2016-10-09 21:36:52,694 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,694 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,694 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,695 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,695 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,695 : INFO : accepted corpus with 10 documents, 5329 features, 124 non-zero entries
2016-10-09 21:36:52,695 : INFO : collecting document frequencies
2016-10-09 21:36:52,695 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:52,695 : INFO : calculating IDF weights for 10 documents and 5328 features (124 matrix non-zeros)
2016-10-09 21:36:52,696 : INFO : using serial LSI version on this node
2016-10-09 21:36:52,696 : INFO : updating model with new documents
2016-10-09 21:36:52,697 : INFO : preparing a new chunk of documents
2016-10-09 21:36:52,697 : DEBUG : converting corpus to csc format
2016-10-09 21:36:52,697 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:52,699 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:52,699 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:52,713 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,762 : DEBUG : running 2 power iterations
2016-10-09 21:36:52,781 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,856 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,921 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:52,926 : INFO : computing the final decomposition
2016-10-09 21:36:52,926 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:52,928 : INFO : processed documents up to #10
2016-10-09 21:36:52,929 : INFO : topic #0(1.063): 0.343*"ql" + 0.327*"group" + 0.264*"thread" + 0.206*"obviously" + 0.206*"wives" + 0.206*"back" + 0.206*"honest" + 0.182*"please" + 0.172*"english" + 0.172*"main"
2016-10-09 21:36:52,929 : INFO : topic #1(1.037): -0.223*"question" + -0.216*"dish" + -0.207*"simple" + -0.207*"lol" + -0.207*"solution" + 0.195*"advice" + -0.182*"party" + -0.154*"rice" + -0.153*"invited" + -0.153*"wedding"
2016-10-09 21:36:52,929 : INFO : topic #2(1.034): 0.567*"advice" + 0.238*"christmas" + 0.238*"doha" + 0.199*"new" + 0.199*"possible" + 0.199*"holidays" + 0.199*"thanks" + 0.199*"need" + 0.199*"like" + 0.199*"year"
2016-10-09 21:36:52,929 : INFO : topic #3(1.018): 0.313*"lol" + 0.313*"solution" + 0.313*"simple" + 0.274*"question" + -0.223*"dish" + -0.178*"party" + -0.156*"go" + -0.143*"invited" + -0.143*"wedding" + -0.132*"dinner"
2016-10-09 21:36:52,929 : INFO : topic #4(1.011): 0.304*"go" + -0.226*"group" + 0.208*"wives" + 0.208*"honest" + 0.208*"back" + 0.208*"obviously" + -0.161*"reasons" + -0.161*"say" + -0.161*"valid" + -0.161*"x"
2016-10-09 21:36:52,929 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:52,930 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:52,931 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:52,932 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,932 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,932 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:52,933 : INFO : saved 10x5296 matrix, density=0.387% (205/52960)
2016-10-09 21:36:52,933 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,933 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,933 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,934 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:52,934 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:52,934 : INFO : accepted corpus with 10 documents, 5296 features, 205 non-zero entries
2016-10-09 21:36:52,934 : INFO : collecting document frequencies
2016-10-09 21:36:52,934 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:52,935 : INFO : calculating IDF weights for 10 documents and 5295 features (205 matrix non-zeros)
2016-10-09 21:36:52,935 : INFO : using serial LSI version on this node
2016-10-09 21:36:52,935 : INFO : updating model with new documents
2016-10-09 21:36:52,936 : INFO : preparing a new chunk of documents
2016-10-09 21:36:52,936 : DEBUG : converting corpus to csc format
2016-10-09 21:36:52,936 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:52,938 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:52,938 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:52,950 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:52,988 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,007 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,064 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,110 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:53,115 : INFO : computing the final decomposition
2016-10-09 21:36:53,115 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:53,117 : INFO : processed documents up to #10
2016-10-09 21:36:53,117 : INFO : topic #0(1.139): 0.303*"suggestions" + 0.210*"week" + 0.178*"new" + 0.178*"happenings" + 0.175*"please" + 0.170*"holidays" + 0.154*"something" + 0.147*"days" + 0.136*"wife" + 0.136*"doha"
2016-10-09 21:36:53,117 : INFO : topic #1(1.062): 0.253*"ramadan" + 0.214*"comes" + 0.192*"know" + -0.189*"wife" + -0.189*"doha" + 0.170*"would" + -0.158*"places" + -0.138*"holidays" + 0.131*"october" + 0.131*"whole"
2016-10-09 21:36:53,117 : INFO : topic #2(1.020): 0.205*"places" + -0.184*"home" + -0.177*"leave" + 0.169*"doha" + 0.169*"wife" + -0.168*"holiday" + 0.138*"ramadan" + -0.129*"fitr" + -0.127*"go" + -0.123*"sponsor"
2016-10-09 21:36:53,117 : INFO : topic #3(1.008): 0.284*"please" + 0.270*"suggestions" + 0.260*"new" + 0.260*"happenings" + 0.173*"something" + -0.165*"home" + -0.152*"places" + 0.147*"evening" + 0.147*"guys" + 0.147*"dont"
2016-10-09 21:36:53,118 : INFO : topic #4(0.997): -0.262*"home" + -0.212*"week" + -0.184*"want" + -0.176*"appreciated" + -0.175*"sponsor" + -0.175*"permit" + -0.175*"exit" + -0.167*"suggestions" + 0.144*"holiday" + -0.122*"advice"
2016-10-09 21:36:53,118 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:53,119 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:53,120 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:53,121 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,121 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,121 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:53,122 : INFO : saved 10x5296 matrix, density=0.310% (164/52960)
2016-10-09 21:36:53,122 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,122 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,122 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,122 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,122 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,123 : INFO : accepted corpus with 10 documents, 5296 features, 164 non-zero entries
2016-10-09 21:36:53,123 : INFO : collecting document frequencies
2016-10-09 21:36:53,123 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:53,123 : INFO : calculating IDF weights for 10 documents and 5295 features (164 matrix non-zeros)
2016-10-09 21:36:53,124 : INFO : using serial LSI version on this node
2016-10-09 21:36:53,124 : INFO : updating model with new documents
2016-10-09 21:36:53,124 : INFO : preparing a new chunk of documents
2016-10-09 21:36:53,124 : DEBUG : converting corpus to csc format
2016-10-09 21:36:53,125 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:53,126 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:53,127 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:53,138 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,177 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,195 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,252 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,323 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:53,328 : INFO : computing the final decomposition
2016-10-09 21:36:53,328 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:53,330 : INFO : processed documents up to #10
2016-10-09 21:36:53,330 : INFO : topic #0(1.055): 0.267*"driving" + 0.267*"license" + 0.182*"move" + 0.171*"ladies" + 0.171*"alone" + 0.171*"safe" + 0.145*"also" + 0.140*"tell" + 0.129*"hi" + 0.121*"country"
2016-10-09 21:36:53,331 : INFO : topic #1(1.020): 0.245*"win" + 0.245*"gonna" + 0.245*"guess" + 0.222*"tell" + 0.216*"driving" + 0.216*"license" + -0.198*"also" + -0.160*"accept" + -0.160*"bank" + -0.135*"required"
2016-10-09 21:36:53,331 : INFO : topic #2(1.016): -0.212*"alone" + -0.212*"ladies" + -0.212*"safe" + 0.208*"india" + -0.207*"required" + -0.207*"household" + 0.173*"accept" + 0.173*"bank" + -0.146*"hello" + -0.146*"thanks"
2016-10-09 21:36:53,331 : INFO : topic #3(1.005): 0.462*"available" + 0.462*"tata" + 0.263*"gps" + 0.263*"wanted" + 0.263*"garmin" + 0.132*"installed" + 0.132*"trip" + 0.132*"outside" + 0.132*"dealer" + 0.132*"genuine"
2016-10-09 21:36:53,331 : INFO : topic #4(0.999): -0.346*"guess" + -0.346*"gonna" + -0.346*"win" + -0.238*"tell" + -0.156*"gps" + -0.156*"garmin" + -0.156*"wanted" + -0.134*"household" + -0.134*"required" + 0.126*"things"
2016-10-09 21:36:53,332 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:53,333 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:53,334 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:53,335 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,335 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,335 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:53,336 : INFO : saved 10x5321 matrix, density=0.340% (181/53210)
2016-10-09 21:36:53,336 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,336 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,336 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,336 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,336 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,336 : INFO : accepted corpus with 10 documents, 5321 features, 181 non-zero entries
2016-10-09 21:36:53,336 : INFO : collecting document frequencies
2016-10-09 21:36:53,336 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:53,337 : INFO : calculating IDF weights for 10 documents and 5320 features (181 matrix non-zeros)
2016-10-09 21:36:53,337 : INFO : using serial LSI version on this node
2016-10-09 21:36:53,337 : INFO : updating model with new documents
2016-10-09 21:36:53,338 : INFO : preparing a new chunk of documents
2016-10-09 21:36:53,338 : DEBUG : converting corpus to csc format
2016-10-09 21:36:53,338 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:53,340 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:53,341 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:53,352 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,391 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,409 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,466 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,512 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:53,517 : INFO : computing the final decomposition
2016-10-09 21:36:53,517 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:53,519 : INFO : processed documents up to #10
2016-10-09 21:36:53,519 : INFO : topic #0(1.067): 0.258*"rules" + 0.234*"would" + 0.158*"like" + 0.148*"watch" + 0.148*"traffic" + 0.148*"doha" + 0.130*"male" + 0.124*"hi" + 0.117*"http" + 0.117*"www"
2016-10-09 21:36:53,519 : INFO : topic #1(1.015): 0.255*"hijab" + 0.203*"male" + 0.162*"hi" + -0.161*"rules" + 0.160*"share" + 0.131*"loss" + 0.131*"thank" + 0.131*"rates" + 0.131*"tried" + 0.131*"weight"
2016-10-09 21:36:53,520 : INFO : topic #2(1.011): 0.318*"hijab" + 0.183*"male" + 0.175*"share" + -0.175*"qatar" + 0.159*"making" + 0.159*"plz" + 0.159*"wear" + 0.159*"muslim" + 0.159*"womens" + 0.159*"women"
2016-10-09 21:36:53,520 : INFO : topic #3(1.003): 0.274*"rumor" + 0.274*"liquor" + 0.274*"heard" + 0.274*"store" + -0.217*"qatar" + 0.164*"nations" + 0.137*"near" + 0.137*"sell" + 0.137*"pork" + 0.137*"else"
2016-10-09 21:36:53,520 : INFO : topic #4(1.000): -0.333*"even" + -0.333*"moderators" + -0.333*"banned" + -0.333*"line" + -0.333*"forum" + -0.333*"threads" + -0.333*"still" + -0.333*"silly" + -0.333*"one" + 0.009*"reason"
2016-10-09 21:36:53,520 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:53,521 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:53,522 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:53,523 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,523 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,523 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:53,524 : INFO : saved 10x5227 matrix, density=0.256% (134/52270)
2016-10-09 21:36:53,524 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,524 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,524 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,524 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,524 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,524 : INFO : accepted corpus with 10 documents, 5227 features, 134 non-zero entries
2016-10-09 21:36:53,524 : INFO : collecting document frequencies
2016-10-09 21:36:53,524 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:53,525 : INFO : calculating IDF weights for 10 documents and 5226 features (134 matrix non-zeros)
2016-10-09 21:36:53,525 : INFO : using serial LSI version on this node
2016-10-09 21:36:53,525 : INFO : updating model with new documents
2016-10-09 21:36:53,526 : INFO : preparing a new chunk of documents
2016-10-09 21:36:53,526 : DEBUG : converting corpus to csc format
2016-10-09 21:36:53,526 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:53,528 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:53,528 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:53,540 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,578 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,597 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,654 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,700 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:53,705 : INFO : computing the final decomposition
2016-10-09 21:36:53,705 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:53,707 : INFO : processed documents up to #10
2016-10-09 21:36:53,707 : INFO : topic #0(1.081): -0.301*"qatar" + -0.228*"anyone" + -0.217*"bar" + -0.211*"thank" + -0.211*"find" + -0.211*"hello" + -0.211*"indian" + -0.211*"help" + -0.190*"friends" + -0.142*"one"
2016-10-09 21:36:53,707 : INFO : topic #1(1.037): 0.248*"qatar" + -0.231*"one" + 0.164*"anyone" + -0.158*"issue" + -0.158*"pass" + -0.158*"partner" + -0.158*"hall" + -0.151*"someone" + -0.151*"right" + -0.151*"stop"
2016-10-09 21:36:53,707 : INFO : topic #2(1.000): 1.000*"hmm" + -0.000*"49cc" + 0.000*"cream" + -0.000*"shine" + 0.000*"round" + -0.000*"describe" + 0.000*"10000" + -0.000*"ive" + 0.000*"however" + -0.000*"superb"
2016-10-09 21:36:53,708 : INFO : topic #3(1.000): -0.408*"think" + -0.408*"issues" + -0.408*"work" + -0.408*"guys" + -0.408*"without" + -0.408*"ever" + -0.000*"saturday" + 0.000*"thinking" + 0.000*"know" + 0.000*"stop"
2016-10-09 21:36:53,708 : INFO : topic #4(1.000): 0.577*"sweet" + 0.577*"broken" + 0.577*"heart" + -0.000*"saturday" + 0.000*"someone" + 0.000*"thinking" + 0.000*"right" + 0.000*"know" + 0.000*"stand" + 0.000*"stop"
2016-10-09 21:36:53,708 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:53,709 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:53,710 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:53,710 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,710 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,711 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:53,711 : INFO : saved 10x5291 matrix, density=0.393% (208/52910)
2016-10-09 21:36:53,712 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,712 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,712 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,712 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,712 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,712 : INFO : accepted corpus with 10 documents, 5291 features, 208 non-zero entries
2016-10-09 21:36:53,713 : INFO : collecting document frequencies
2016-10-09 21:36:53,713 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:53,713 : INFO : calculating IDF weights for 10 documents and 5290 features (208 matrix non-zeros)
2016-10-09 21:36:53,714 : INFO : using serial LSI version on this node
2016-10-09 21:36:53,714 : INFO : updating model with new documents
2016-10-09 21:36:53,715 : INFO : preparing a new chunk of documents
2016-10-09 21:36:53,715 : DEBUG : converting corpus to csc format
2016-10-09 21:36:53,715 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:53,717 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:53,717 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:53,728 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,767 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,785 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,842 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,889 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:53,894 : INFO : computing the final decomposition
2016-10-09 21:36:53,894 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:53,896 : INFO : processed documents up to #10
2016-10-09 21:36:53,896 : INFO : topic #0(1.118): 0.192*"change" + 0.174*"visa" + 0.152*"thanks" + 0.151*"medical" + 0.150*"exam" + 0.150*"get" + 0.146*"ql" + 0.140*"company" + 0.136*"work" + 0.132*"would"
2016-10-09 21:36:53,896 : INFO : topic #1(1.048): -0.245*"change" + 0.179*"get" + 0.174*"advise" + 0.173*"town" + 0.173*"haircut" + 0.173*"boys" + 0.173*"kindly" + 0.171*"best" + 0.150*"car" + 0.150*"seat"
2016-10-09 21:36:53,896 : INFO : topic #2(1.039): -0.297*"ql" + -0.230*"delete" + -0.230*"kid" + -0.230*"wanna" + -0.230*"week" + -0.230*"join" + -0.230*"one" + -0.208*"anyone" + -0.183*"work" + -0.133*"reliable"
2016-10-09 21:36:53,896 : INFO : topic #3(1.020): -0.248*"c" + -0.248*"b" + 0.218*"change" + -0.217*"medical" + -0.197*"exam" + 0.168*"manager" + 0.168*"technician" + 0.168*"profession" + 0.168*"masters" + -0.165*"tested"
2016-10-09 21:36:53,897 : INFO : topic #4(0.992): 0.240*"reliable" + -0.220*"visa" + 0.185*"seat" + 0.185*"car" + -0.159*"even" + -0.159*"saudi" + -0.159*"come" + -0.159*"want" + -0.159*"procedure" + -0.159*"entry"
2016-10-09 21:36:53,897 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:53,898 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:53,899 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:53,900 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,900 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,900 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:53,900 : INFO : saved 10x5275 matrix, density=0.224% (118/52750)
2016-10-09 21:36:53,900 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,901 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,901 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,901 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:53,901 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:53,901 : INFO : accepted corpus with 10 documents, 5275 features, 118 non-zero entries
2016-10-09 21:36:53,901 : INFO : collecting document frequencies
2016-10-09 21:36:53,901 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:53,902 : INFO : calculating IDF weights for 10 documents and 5274 features (118 matrix non-zeros)
2016-10-09 21:36:53,902 : INFO : using serial LSI version on this node
2016-10-09 21:36:53,902 : INFO : updating model with new documents
2016-10-09 21:36:53,903 : INFO : preparing a new chunk of documents
2016-10-09 21:36:53,903 : DEBUG : converting corpus to csc format
2016-10-09 21:36:53,903 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:53,905 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:53,905 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:53,916 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:53,957 : DEBUG : running 2 power iterations
2016-10-09 21:36:53,975 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,032 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,077 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:54,082 : INFO : computing the final decomposition
2016-10-09 21:36:54,082 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:54,084 : INFO : processed documents up to #10
2016-10-09 21:36:54,084 : INFO : topic #0(1.199): -0.417*"www" + -0.417*"com" + -0.417*"http" + -0.322*"article" + -0.310*"look" + -0.204*"c" + -0.204*"bin" + -0.204*"f" + -0.204*"28" + -0.204*"2010"
2016-10-09 21:36:54,084 : INFO : topic #1(1.082): 0.354*"church" + 0.329*"catholic" + 0.245*"qatar" + 0.239*"please" + 0.210*"make" + 0.177*"know" + 0.177*"thanks" + 0.177*"assigned" + 0.177*"bring" + 0.177*"work"
2016-10-09 21:36:54,085 : INFO : topic #2(1.050): 0.348*"first" + 0.287*"egg" + 0.287*"came" + 0.287*"chicken" + 0.218*"makes" + 0.211*"guess" + 0.211*"list" + 0.211*"use" + 0.211*"words" + 0.211*"dumb"
2016-10-09 21:36:54,085 : INFO : topic #3(1.001): -0.271*"even" + -0.271*"worst" + -0.271*"lesser" + -0.271*"good" + -0.271*"way" + -0.271*"avoid" + -0.271*"person" + -0.271*"talking" + 0.255*"came" + 0.255*"egg"
2016-10-09 21:36:54,085 : INFO : topic #4(1.000): 0.447*"still" + 0.447*"waiting" + 0.447*"ones" + 0.447*"one" + 0.447*"getting" + -0.000*"talking" + -0.000*"good" + -0.000*"way" + -0.000*"worst" + -0.000*"avoid"
2016-10-09 21:36:54,085 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:54,086 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:54,087 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:54,087 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,088 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,088 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:54,088 : INFO : saved 10x5296 matrix, density=0.308% (163/52960)
2016-10-09 21:36:54,088 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,089 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,089 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,089 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,089 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,089 : INFO : accepted corpus with 10 documents, 5296 features, 163 non-zero entries
2016-10-09 21:36:54,089 : INFO : collecting document frequencies
2016-10-09 21:36:54,090 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:54,090 : INFO : calculating IDF weights for 10 documents and 5295 features (163 matrix non-zeros)
2016-10-09 21:36:54,090 : INFO : using serial LSI version on this node
2016-10-09 21:36:54,090 : INFO : updating model with new documents
2016-10-09 21:36:54,091 : INFO : preparing a new chunk of documents
2016-10-09 21:36:54,091 : DEBUG : converting corpus to csc format
2016-10-09 21:36:54,091 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:54,093 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:54,093 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:54,105 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,144 : DEBUG : running 2 power iterations
2016-10-09 21:36:54,162 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,218 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,265 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:54,269 : INFO : computing the final decomposition
2016-10-09 21:36:54,269 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:54,271 : INFO : processed documents up to #10
2016-10-09 21:36:54,272 : INFO : topic #0(1.181): 0.255*"licence" + 0.245*"driving" + 0.195*"driver" + 0.194*"valid" + 0.162*"visa" + 0.159*"company" + 0.146*"visiting" + 0.138*"anybody" + 0.137*"get" + 0.136*"ur"
2016-10-09 21:36:54,272 : INFO : topic #1(1.060): 0.337*"use" + 0.332*"philippines" + 0.255*"im" + 0.255*"know" + 0.255*"want" + 0.255*"long" + 0.220*"phil" + -0.162*"driving" + -0.161*"valid" + 0.134*"planning"
2016-10-09 21:36:54,272 : INFO : topic #2(1.054): -0.325*"visiting" + -0.312*"egyptian" + -0.312*"work" + 0.176*"dl" + 0.174*"test" + 0.171*"anybody" + 0.154*"thanks" + 0.154*"trick" + 0.154*"parking" + 0.154*"advise"
2016-10-09 21:36:54,272 : INFO : topic #3(1.016): 0.283*"valid" + -0.246*"dl" + 0.232*"ur" + 0.232*"still" + -0.158*"visiting" + -0.133*"licence" + -0.125*"week" + -0.125*"using" + -0.125*"car" + -0.125*"legal"
2016-10-09 21:36:54,272 : INFO : topic #4(1.001): 0.375*"licence" + 0.242*"company" + -0.218*"dl" + -0.194*"work" + -0.194*"egyptian" + 0.174*"parking" + 0.174*"thanks" + 0.174*"advise" + 0.174*"trick" + 0.169*"driver"
2016-10-09 21:36:54,272 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:54,273 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:54,274 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:54,275 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,275 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,275 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:54,276 : INFO : saved 10x5328 matrix, density=0.238% (127/53280)
2016-10-09 21:36:54,276 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,276 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,276 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,277 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,277 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,277 : INFO : accepted corpus with 10 documents, 5328 features, 127 non-zero entries
2016-10-09 21:36:54,277 : INFO : collecting document frequencies
2016-10-09 21:36:54,277 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:54,277 : INFO : calculating IDF weights for 10 documents and 5327 features (127 matrix non-zeros)
2016-10-09 21:36:54,278 : INFO : using serial LSI version on this node
2016-10-09 21:36:54,278 : INFO : updating model with new documents
2016-10-09 21:36:54,278 : INFO : preparing a new chunk of documents
2016-10-09 21:36:54,278 : DEBUG : converting corpus to csc format
2016-10-09 21:36:54,279 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:54,280 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:54,281 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:54,292 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,332 : DEBUG : running 2 power iterations
2016-10-09 21:36:54,350 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,407 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,453 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:54,458 : INFO : computing the final decomposition
2016-10-09 21:36:54,458 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:54,460 : INFO : processed documents up to #10
2016-10-09 21:36:54,460 : INFO : topic #0(1.103): 0.244*"love" + 0.234*"share" + 0.232*"take" + 0.225*"pics" + 0.225*"dubai" + 0.225*"go" + 0.220*"want" + 0.206*"vacation" + 0.187*"eat" + 0.174*"one"
2016-10-09 21:36:54,460 : INFO : topic #1(1.059): 0.402*"animals" + 0.390*"buy" + 0.304*"want" + 0.304*"qatar" + 0.243*"find" + 0.195*"difficult" + 0.195*"things" + 0.152*"chance" + 0.152*"someone" + 0.152*"life"
2016-10-09 21:36:54,460 : INFO : topic #2(1.048): -0.218*"eat" + -0.210*"love" + 0.164*"sponsor" + 0.163*"know" + 0.161*"passport" + 0.161*"visa" + 0.161*"thank" + 0.161*"cancel" + 0.161*"without" + 0.159*"even"
2016-10-09 21:36:54,460 : INFO : topic #3(1.020): 0.240*"without" + 0.240*"visa" + 0.240*"cancel" + 0.240*"thank" + 0.240*"passport" + 0.216*"sponsor" + 0.188*"guys" + 0.188*"even" + -0.171*"hello" + 0.167*"eat"
2016-10-09 21:36:54,461 : INFO : topic #4(0.999): -0.186*"told" + -0.186*"introduce" + -0.186*"wage" + -0.186*"maids" + -0.186*"employee" + -0.186*"bank" + -0.186*"pay" + -0.186*"minimum" + -0.186*"month" + -0.186*"account"
2016-10-09 21:36:54,461 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:54,462 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:54,462 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:54,463 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,463 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,463 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:54,464 : INFO : saved 10x5296 matrix, density=0.381% (202/52960)
2016-10-09 21:36:54,464 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,464 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,464 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,465 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,465 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,465 : INFO : accepted corpus with 10 documents, 5296 features, 202 non-zero entries
2016-10-09 21:36:54,465 : INFO : collecting document frequencies
2016-10-09 21:36:54,465 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:54,466 : INFO : calculating IDF weights for 10 documents and 5295 features (202 matrix non-zeros)
2016-10-09 21:36:54,466 : INFO : using serial LSI version on this node
2016-10-09 21:36:54,466 : INFO : updating model with new documents
2016-10-09 21:36:54,467 : INFO : preparing a new chunk of documents
2016-10-09 21:36:54,467 : DEBUG : converting corpus to csc format
2016-10-09 21:36:54,467 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:54,469 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:54,470 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:54,481 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,520 : DEBUG : running 2 power iterations
2016-10-09 21:36:54,538 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,594 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,641 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:54,646 : INFO : computing the final decomposition
2016-10-09 21:36:54,646 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:54,648 : INFO : processed documents up to #10
2016-10-09 21:36:54,648 : INFO : topic #0(1.140): -0.316*"job" + -0.233*"good" + -0.214*"many" + -0.158*"american" + -0.158*"hard" + -0.158*"com" + -0.158*"website" + -0.158*"time" + -0.156*"get" + -0.154*"doha"
2016-10-09 21:36:54,648 : INFO : topic #1(1.069): 0.281*"library" + 0.276*"like" + 0.211*"work" + 0.208*"ask" + 0.208*"conditions" + 0.208*"u" + 0.208*"e" + 0.208*"may" + 0.208*"comparable" + 0.190*"would"
2016-10-09 21:36:54,648 : INFO : topic #2(1.023): 0.348*"petroleum" + -0.266*"library" + 0.228*"im" + 0.210*"co" + 0.210*"http" + 0.210*"trap" + 0.210*"read" + 0.210*"avoid" + 0.210*"bored" + -0.157*"like"
2016-10-09 21:36:54,649 : INFO : topic #3(1.005): -0.261*"library" + -0.229*"bank" + -0.229*"accept" + 0.219*"safe" + 0.219*"expat" + -0.123*"like" + 0.116*"want" + -0.115*"problem" + -0.115*"us" + -0.115*"currently"
2016-10-09 21:36:54,649 : INFO : topic #4(0.999): 0.236*"library" + -0.203*"consultant" + -0.203*"guide" + 0.198*"trap" + 0.198*"co" + 0.198*"read" + 0.198*"bored" + 0.198*"avoid" + 0.198*"http" + -0.168*"accept"
2016-10-09 21:36:54,649 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:54,650 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:54,651 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:54,652 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,652 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,652 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:54,653 : INFO : saved 10x5296 matrix, density=0.329% (174/52960)
2016-10-09 21:36:54,653 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,653 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,653 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,654 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,654 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,654 : INFO : accepted corpus with 10 documents, 5296 features, 174 non-zero entries
2016-10-09 21:36:54,654 : INFO : collecting document frequencies
2016-10-09 21:36:54,654 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:54,654 : INFO : calculating IDF weights for 10 documents and 5295 features (174 matrix non-zeros)
2016-10-09 21:36:54,655 : INFO : using serial LSI version on this node
2016-10-09 21:36:54,655 : INFO : updating model with new documents
2016-10-09 21:36:54,656 : INFO : preparing a new chunk of documents
2016-10-09 21:36:54,656 : DEBUG : converting corpus to csc format
2016-10-09 21:36:54,656 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:54,658 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:54,658 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:54,669 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,708 : DEBUG : running 2 power iterations
2016-10-09 21:36:54,726 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,783 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,829 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:54,834 : INFO : computing the final decomposition
2016-10-09 21:36:54,834 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:54,836 : INFO : processed documents up to #10
2016-10-09 21:36:54,836 : INFO : topic #0(1.067): -0.278*"society" + -0.278*"jpg" + -0.278*"dr" + -0.278*"qatarliving" + -0.265*"www" + -0.265*"com" + -0.265*"http" + -0.179*"nations" + -0.168*"happen" + -0.168*"extend"
2016-10-09 21:36:54,837 : INFO : topic #1(1.029): 0.286*"hijab" + 0.231*"others" + 0.189*"islam" + 0.188*"pm" + 0.188*"process" + 0.188*"question" + 0.188*"person" + 0.188*"basically" + 0.188*"involved" + 0.188*"intrested"
2016-10-09 21:36:54,837 : INFO : topic #2(1.015): -0.260*"hijab" + 0.205*"people" + 0.198*"qatari" + 0.198*"drink" + 0.198*"must" + 0.198*"think" + 0.198*"important" + 0.198*"us" + 0.198*"tell" + 0.190*"done"
2016-10-09 21:36:54,837 : INFO : topic #3(1.002): -0.343*"crime" + 0.252*"gold" + -0.228*"west" + -0.228*"polygamy" + -0.228*"wife" + -0.228*"considered" + 0.189*"golden" + 0.189*"wearing" + -0.132*"nations" + 0.126*"indian"
2016-10-09 21:36:54,837 : INFO : topic #4(1.000): 0.336*"truth" + 0.336*"jesus" + 0.168*"came" + 0.168*"posts" + 0.168*"enemies" + 0.168*"earth" + 0.168*"spread" + 0.168*"message" + 0.168*"discussion" + 0.168*"explain"
2016-10-09 21:36:54,837 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:54,838 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:54,839 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:54,840 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,840 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,840 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:54,841 : INFO : saved 10x5321 matrix, density=0.391% (208/53210)
2016-10-09 21:36:54,841 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,841 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,841 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,842 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:54,842 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:54,842 : INFO : accepted corpus with 10 documents, 5321 features, 208 non-zero entries
2016-10-09 21:36:54,842 : INFO : collecting document frequencies
2016-10-09 21:36:54,842 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:54,843 : INFO : calculating IDF weights for 10 documents and 5320 features (208 matrix non-zeros)
2016-10-09 21:36:54,843 : INFO : using serial LSI version on this node
2016-10-09 21:36:54,843 : INFO : updating model with new documents
2016-10-09 21:36:54,844 : INFO : preparing a new chunk of documents
2016-10-09 21:36:54,844 : DEBUG : converting corpus to csc format
2016-10-09 21:36:54,844 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:54,846 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:54,847 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:54,858 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,897 : DEBUG : running 2 power iterations
2016-10-09 21:36:54,915 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:54,972 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,019 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:55,023 : INFO : computing the final decomposition
2016-10-09 21:36:55,023 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:55,025 : INFO : processed documents up to #10
2016-10-09 21:36:55,025 : INFO : topic #0(1.190): -0.268*"exam" + -0.257*"salary" + -0.222*"evaluation" + -0.213*"training" + -0.194*"need" + -0.149*"hmc" + -0.144*"pass" + -0.134*"nurses" + -0.132*"well" + -0.129*"experience"
2016-10-09 21:36:55,026 : INFO : topic #1(1.087): 0.367*"exam" + -0.267*"salary" + 0.202*"evaluation" + 0.188*"pass" + -0.179*"hmc" + 0.175*"prometric" + 0.175*"sit" + 0.156*"requirement" + 0.156*"regarding" + 0.156*"information"
2016-10-09 21:36:55,026 : INFO : topic #2(1.030): 0.357*"training" + 0.201*"license" + 0.201*"4" + 0.201*"get" + 0.187*"need" + -0.172*"qatar" + 0.169*"evaluation" + 0.162*"hmc" + 0.150*"sch" + -0.131*"exam"
2016-10-09 21:36:55,026 : INFO : topic #3(1.000): 0.816*"stage" + 0.408*"right" + 0.408*"verification" + 0.000*"take" + -0.000*"hmc" + -0.000*"medical" + 0.000*"even" + 0.000*"experience" + 0.000*"work" + 0.000*"company"
2016-10-09 21:36:55,026 : INFO : topic #4(0.998): -0.297*"take" + 0.218*"medical" + 0.180*"salary" + 0.150*"hmc" + -0.149*"work" + -0.149*"required" + -0.149*"construction" + -0.149*"currently" + -0.149*"hello" + -0.149*"almost"
2016-10-09 21:36:55,026 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:55,027 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:55,028 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:55,029 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,029 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,029 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:55,030 : INFO : saved 10x5282 matrix, density=0.443% (234/52820)
2016-10-09 21:36:55,030 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,031 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,031 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,031 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,031 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,031 : INFO : accepted corpus with 10 documents, 5282 features, 234 non-zero entries
2016-10-09 21:36:55,031 : INFO : collecting document frequencies
2016-10-09 21:36:55,032 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:55,032 : INFO : calculating IDF weights for 10 documents and 5281 features (234 matrix non-zeros)
2016-10-09 21:36:55,033 : INFO : using serial LSI version on this node
2016-10-09 21:36:55,033 : INFO : updating model with new documents
2016-10-09 21:36:55,034 : INFO : preparing a new chunk of documents
2016-10-09 21:36:55,034 : DEBUG : converting corpus to csc format
2016-10-09 21:36:55,034 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:55,036 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:55,036 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:55,047 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,086 : DEBUG : running 2 power iterations
2016-10-09 21:36:55,104 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,161 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,208 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:55,213 : INFO : computing the final decomposition
2016-10-09 21:36:55,213 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:55,215 : INFO : processed documents up to #10
2016-10-09 21:36:55,215 : INFO : topic #0(1.087): -0.204*"india" + -0.160*"indian" + -0.159*"sunny" + -0.142*"kerala" + -0.139*"asian" + -0.136*"part" + -0.134*"men" + -0.134*"women" + -0.134*"western" + -0.134*"2"
2016-10-09 21:36:55,215 : INFO : topic #1(1.044): 0.208*"indian" + 0.195*"keralites" + 0.195*"2" + 0.153*"india" + 0.151*"girls" + 0.151*"arab" + 0.151*"marry" + 0.151*"getting" + -0.147*"please" + -0.139*"hmc"
2016-10-09 21:36:55,215 : INFO : topic #2(1.025): 0.231*"p" + -0.216*"sunny" + -0.189*"asian" + -0.182*"women" + -0.182*"men" + -0.182*"western" + 0.154*"" + 0.154*"letter" + 0.149*"words" + -0.144*"sex"
2016-10-09 21:36:55,215 : INFO : topic #3(1.005): 0.246*"india" + -0.235*"hmc" + 0.215*"p" + -0.177*"jobs" + -0.177*"love" + -0.177*"really" + -0.177*"qbs" + -0.177*"wonder" + -0.177*"radio" + -0.177*"heard"
2016-10-09 21:36:55,216 : INFO : topic #4(1.000): 0.229*"getting" + 0.229*"marry" + 0.229*"girls" + 0.229*"arab" + -0.201*"special" + -0.201*"love" + -0.201*"consider" + -0.201*"jobs" + -0.201*"heard" + -0.201*"really"
2016-10-09 21:36:55,216 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:55,217 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:55,218 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:55,219 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,219 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,219 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:55,220 : INFO : saved 10x5315 matrix, density=0.314% (167/53150)
2016-10-09 21:36:55,220 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,220 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,220 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,220 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,220 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,221 : INFO : accepted corpus with 10 documents, 5315 features, 167 non-zero entries
2016-10-09 21:36:55,221 : INFO : collecting document frequencies
2016-10-09 21:36:55,221 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:55,221 : INFO : calculating IDF weights for 10 documents and 5314 features (167 matrix non-zeros)
2016-10-09 21:36:55,222 : INFO : using serial LSI version on this node
2016-10-09 21:36:55,222 : INFO : updating model with new documents
2016-10-09 21:36:55,222 : INFO : preparing a new chunk of documents
2016-10-09 21:36:55,222 : DEBUG : converting corpus to csc format
2016-10-09 21:36:55,223 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:55,225 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:55,225 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:55,236 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,275 : DEBUG : running 2 power iterations
2016-10-09 21:36:55,293 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,351 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,397 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:55,402 : INFO : computing the final decomposition
2016-10-09 21:36:55,402 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:55,404 : INFO : processed documents up to #10
2016-10-09 21:36:55,404 : INFO : topic #0(1.147): 0.384*"buy" + 0.268*"know" + 0.259*"please" + 0.259*"need" + 0.192*"knows" + 0.192*"called" + 0.192*"advance" + 0.192*"shop" + 0.192*"let" + 0.192*"purchase"
2016-10-09 21:36:55,404 : INFO : topic #1(1.080): 0.262*"hi" + 0.253*"get" + 0.232*"machine" + 0.232*"bread" + 0.215*"good" + 0.198*"much" + -0.177*"buy" + 0.175*"find" + 0.163*"thanks" + 0.152*"bicycle"
2016-10-09 21:36:55,405 : INFO : topic #2(1.011): -0.368*"cards" + -0.276*"bank" + 0.217*"dog" + 0.217*"filipino" + -0.184*"worked" + -0.184*"commercial" + -0.184*"qnb" + -0.155*"know" + -0.151*"yes" + 0.140*"buy"
2016-10-09 21:36:55,405 : INFO : topic #3(1.005): -0.215*"dog" + -0.215*"filipino" + -0.202*"qataris" + -0.202*"around" + -0.202*"anything" + -0.202*"like" + 0.176*"bread" + 0.176*"machine" + 0.163*"hi" + -0.153*"idea"
2016-10-09 21:36:55,405 : INFO : topic #4(1.001): -0.255*"cards" + 0.247*"qataris" + 0.247*"like" + 0.247*"around" + 0.247*"anything" + -0.191*"bank" + -0.127*"worked" + -0.127*"qnb" + -0.127*"commercial" + 0.127*"get"
2016-10-09 21:36:55,405 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:55,406 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:55,407 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:55,408 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,408 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,408 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:55,409 : INFO : saved 10x5321 matrix, density=0.368% (196/53210)
2016-10-09 21:36:55,409 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,409 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,409 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,410 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,410 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,410 : INFO : accepted corpus with 10 documents, 5321 features, 196 non-zero entries
2016-10-09 21:36:55,410 : INFO : collecting document frequencies
2016-10-09 21:36:55,410 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:55,410 : INFO : calculating IDF weights for 10 documents and 5320 features (196 matrix non-zeros)
2016-10-09 21:36:55,411 : INFO : using serial LSI version on this node
2016-10-09 21:36:55,411 : INFO : updating model with new documents
2016-10-09 21:36:55,412 : INFO : preparing a new chunk of documents
2016-10-09 21:36:55,412 : DEBUG : converting corpus to csc format
2016-10-09 21:36:55,412 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:55,414 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:55,414 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:55,425 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,464 : DEBUG : running 2 power iterations
2016-10-09 21:36:55,482 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,539 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,585 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:55,590 : INFO : computing the final decomposition
2016-10-09 21:36:55,590 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:55,592 : INFO : processed documents up to #10
2016-10-09 21:36:55,592 : INFO : topic #0(1.160): 0.231*"wife" + 0.203*"company" + 0.179*"even" + 0.179*"please" + 0.168*"sponsor" + 0.167*"know" + 0.164*"children" + 0.164*"government" + 0.161*"months" + 0.161*"three"
2016-10-09 21:36:55,592 : INFO : topic #1(1.042): 0.348*"know" + 0.203*"hi" + 0.171*"see" + 0.171*"meeting" + 0.171*"end" + 0.171*"friends" + 0.171*"today" + 0.171*"colleagues" + 0.171*"rejected" + 0.171*"managed"
2016-10-09 21:36:55,593 : INFO : topic #2(1.026): 0.353*"license" + 0.252*"need" + 0.219*"exit" + 0.219*"together" + 0.219*"away" + 0.219*"weekend" + 0.219*"long" + 0.219*"permit" + 0.219*"going" + 0.219*"go"
2016-10-09 21:36:55,593 : INFO : topic #3(1.010): 0.339*"license" + -0.309*"qatar" + -0.257*"family" + -0.171*"visa" + 0.167*"need" + -0.155*"policy" + -0.155*"gets" + -0.155*"hamad" + -0.155*"medical" + -0.155*"female"
2016-10-09 21:36:55,593 : INFO : topic #4(0.996): -0.206*"please" + -0.206*"even" + -0.196*"three" + -0.196*"months" + -0.196*"change" + 0.168*"sponsored" + 0.155*"job" + 0.137*"anyone" + 0.137*"would" + 0.137*"already"
2016-10-09 21:36:55,593 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:55,594 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:55,595 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:55,596 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,596 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,596 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:55,597 : INFO : saved 10x5315 matrix, density=0.346% (184/53150)
2016-10-09 21:36:55,597 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,597 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,597 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,654 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,654 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,654 : INFO : accepted corpus with 10 documents, 5315 features, 184 non-zero entries
2016-10-09 21:36:55,655 : INFO : collecting document frequencies
2016-10-09 21:36:55,655 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:55,655 : INFO : calculating IDF weights for 10 documents and 5314 features (184 matrix non-zeros)
2016-10-09 21:36:55,656 : INFO : using serial LSI version on this node
2016-10-09 21:36:55,656 : INFO : updating model with new documents
2016-10-09 21:36:55,656 : INFO : preparing a new chunk of documents
2016-10-09 21:36:55,657 : DEBUG : converting corpus to csc format
2016-10-09 21:36:55,657 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:55,659 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:55,659 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:55,672 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,711 : DEBUG : running 2 power iterations
2016-10-09 21:36:55,730 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,786 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,833 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:55,837 : INFO : computing the final decomposition
2016-10-09 21:36:55,837 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:55,839 : INFO : processed documents up to #10
2016-10-09 21:36:55,839 : INFO : topic #0(1.121): -0.309*"good" + -0.281*"budget" + -0.231*"maintenance" + -0.216*"performance" + -0.216*"shape" + -0.216*"45000" + -0.181*"best" + -0.128*"advice" + -0.127*"buying" + -0.116*"thank"
2016-10-09 21:36:55,840 : INFO : topic #1(1.055): 0.293*"buying" + -0.232*"good" + 0.225*"check" + 0.225*"advise" + 0.214*"please" + 0.193*"process" + 0.193*"costs" + 0.193*"porsche" + 0.193*"look" + 0.193*"servicing"
2016-10-09 21:36:55,840 : INFO : topic #2(1.024): 0.252*"dubai" + 0.239*"possible" + 0.216*"driving" + 0.216*"folks" + 0.216*"name" + 0.216*"without" + 0.216*"license" + 0.191*"cars" + 0.143*"doha" + 0.126*"local"
2016-10-09 21:36:55,840 : INFO : topic #3(1.009): -0.294*"cars" + -0.244*"would" + -0.221*"doha" + 0.191*"folks" + 0.191*"without" + 0.191*"name" + 0.191*"license" + 0.191*"driving" + 0.164*"possible" + -0.137*"prices"
2016-10-09 21:36:55,840 : INFO : topic #4(0.997): -0.345*"right" + 0.264*"cars" + 0.198*"doha" + -0.172*"prado" + -0.172*"available" + -0.172*"cost" + -0.172*"problems" + -0.172*"armada" + -0.172*"wants" + -0.172*"suggestions"
2016-10-09 21:36:55,840 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:55,841 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:55,842 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:55,843 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,843 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,843 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:55,844 : INFO : saved 10x5207 matrix, density=0.423% (220/52070)
2016-10-09 21:36:55,844 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,844 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,844 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,845 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:55,845 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:55,845 : INFO : accepted corpus with 10 documents, 5207 features, 220 non-zero entries
2016-10-09 21:36:55,845 : INFO : collecting document frequencies
2016-10-09 21:36:55,845 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:55,846 : INFO : calculating IDF weights for 10 documents and 5206 features (220 matrix non-zeros)
2016-10-09 21:36:55,846 : INFO : using serial LSI version on this node
2016-10-09 21:36:55,846 : INFO : updating model with new documents
2016-10-09 21:36:55,847 : INFO : preparing a new chunk of documents
2016-10-09 21:36:55,847 : DEBUG : converting corpus to csc format
2016-10-09 21:36:55,847 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:55,849 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:55,850 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:55,861 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,900 : DEBUG : running 2 power iterations
2016-10-09 21:36:55,918 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:55,975 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,021 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,025 : INFO : computing the final decomposition
2016-10-09 21:36:56,026 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,028 : INFO : processed documents up to #10
2016-10-09 21:36:56,028 : INFO : topic #0(1.158): 0.294*"best" + 0.290*"pakistani" + 0.218*"school" + 0.194*"thanks" + 0.168*"members" + 0.160*"3" + 0.157*"children" + 0.133*"qatar" + 0.128*"good" + 0.126*"education"
2016-10-09 21:36:56,028 : INFO : topic #1(1.045): 0.286*"schools" + 0.237*"british" + -0.187*"members" + 0.179*"many" + 0.158*"arabic" + 0.158*"know" + 0.158*"compulsory" + 0.158*"really" + 0.158*"solution" + -0.139*"dear"
2016-10-09 21:36:56,028 : INFO : topic #2(1.029): 0.207*"bus" + 0.194*"schools" + 0.185*"many" + -0.162*"3" + 0.152*"child" + -0.150*"international" + 0.147*"british" + -0.134*"location" + 0.132*"members" + -0.131*"education"
2016-10-09 21:36:56,028 : INFO : topic #3(1.002): 0.403*"bus" + -0.254*"pakistani" + 0.229*"child" + 0.201*"found" + -0.196*"best" + 0.185*"location" + 0.130*"international" + -0.122*"e" + -0.122*"terms" + -0.122*"managed"
2016-10-09 21:36:56,029 : INFO : topic #4(0.994): -0.306*"pakistani" + -0.273*"bus" + 0.194*"private" + 0.194*"tuition" + -0.168*"children" + -0.137*"found" + -0.126*"best" + 0.124*"members" + -0.113*"child" + -0.108*"thanks"
2016-10-09 21:36:56,029 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,030 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,031 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:56,032 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,032 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,032 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:56,033 : INFO : saved 10x5321 matrix, density=0.368% (196/53210)
2016-10-09 21:36:56,033 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,033 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,033 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,033 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,034 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,034 : INFO : accepted corpus with 10 documents, 5321 features, 196 non-zero entries
2016-10-09 21:36:56,034 : INFO : collecting document frequencies
2016-10-09 21:36:56,034 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:56,034 : INFO : calculating IDF weights for 10 documents and 5320 features (196 matrix non-zeros)
2016-10-09 21:36:56,035 : INFO : using serial LSI version on this node
2016-10-09 21:36:56,035 : INFO : updating model with new documents
2016-10-09 21:36:56,036 : INFO : preparing a new chunk of documents
2016-10-09 21:36:56,036 : DEBUG : converting corpus to csc format
2016-10-09 21:36:56,036 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:56,038 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:56,038 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:56,049 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,088 : DEBUG : running 2 power iterations
2016-10-09 21:36:56,106 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,163 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,209 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,214 : INFO : computing the final decomposition
2016-10-09 21:36:56,214 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,216 : INFO : processed documents up to #10
2016-10-09 21:36:56,216 : INFO : topic #0(1.139): -0.261*"qatar" + -0.223*"anybody" + -0.189*"please" + -0.174*"apply" + -0.171*"embassy" + -0.168*"know" + -0.162*"family" + -0.151*"itz" + -0.137*"tourist" + -0.137*"one"
2016-10-09 21:36:56,216 : INFO : topic #1(1.047): 0.256*"qatar" + -0.211*"family" + -0.190*"lebanese" + -0.179*"still" + -0.177*"exit" + -0.177*"country" + 0.143*"tourist" + 0.139*"embassy" + 0.135*"anybody" + -0.132*"itz"
2016-10-09 21:36:56,216 : INFO : topic #2(1.042): -0.318*"anybody" + 0.268*"qatar" + 0.199*"tourist" + -0.186*"please" + -0.167*"month" + -0.167*"3" + -0.167*"doha" + -0.167*"maximum" + -0.167*"whether" + -0.167*"currently"
2016-10-09 21:36:56,217 : INFO : topic #3(1.008): 0.207*"sad" + 0.207*"us" + 0.207*"salaam" + 0.207*"suggest" + 0.207*"road" + 0.207*"parents" + 0.207*"come" + 0.207*"air" + 0.207*"hear" + 0.207*"anything"
2016-10-09 21:36:56,217 : INFO : topic #4(1.003): 0.358*"extension" + 0.179*"comment" + 0.179*"printed" + 0.179*"4" + 0.179*"recently" + 0.179*"sponsor" + 0.179*"extended" + 0.179*"passport" + 0.179*"thing" + 0.179*"system"
2016-10-09 21:36:56,217 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,218 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,219 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:56,220 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,220 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,220 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:56,221 : INFO : saved 10x5248 matrix, density=0.263% (138/52480)
2016-10-09 21:36:56,221 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,221 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,221 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,222 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,222 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,222 : INFO : accepted corpus with 10 documents, 5248 features, 138 non-zero entries
2016-10-09 21:36:56,222 : INFO : collecting document frequencies
2016-10-09 21:36:56,222 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:56,222 : INFO : calculating IDF weights for 10 documents and 5247 features (138 matrix non-zeros)
2016-10-09 21:36:56,223 : INFO : using serial LSI version on this node
2016-10-09 21:36:56,223 : INFO : updating model with new documents
2016-10-09 21:36:56,223 : INFO : preparing a new chunk of documents
2016-10-09 21:36:56,223 : DEBUG : converting corpus to csc format
2016-10-09 21:36:56,224 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:56,225 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:56,226 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:56,237 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,276 : DEBUG : running 2 power iterations
2016-10-09 21:36:56,294 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,352 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,398 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,402 : INFO : computing the final decomposition
2016-10-09 21:36:56,402 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,404 : INFO : processed documents up to #10
2016-10-09 21:36:56,404 : INFO : topic #0(1.117): -0.281*"accommodation" + -0.277*"expensive" + -0.185*"decorations" + -0.185*"famous" + -0.185*"finishing" + -0.185*"standards" + -0.185*"quality" + -0.184*"qatar" + -0.183*"etc" + -0.166*"good"
2016-10-09 21:36:56,405 : INFO : topic #1(1.049): 0.358*"school" + 0.183*"th" + 0.183*"fees" + 0.183*"exam" + 0.183*"entry" + 0.183*"recommended" + 0.183*"passed" + 0.183*"asked" + 0.183*"son" + 0.182*"doha"
2016-10-09 21:36:56,405 : INFO : topic #2(1.033): -0.255*"thread" + -0.189*"milk" + -0.189*"else" + -0.189*"ps" + -0.189*"dedicated" + -0.189*"anywhere" + -0.175*"nice" + -0.175*"uk" + -0.175*"thinking" + -0.175*"higher"
2016-10-09 21:36:56,405 : INFO : topic #3(1.015): 0.171*"thanks" + -0.164*"really" + -0.164*"thinking" + -0.164*"uk" + -0.164*"nice" + -0.164*"higher" + -0.164*"soft" + -0.164*"buy" + 0.162*"u" + 0.162*"7"
2016-10-09 21:36:56,405 : INFO : topic #4(0.999): -0.258*"sort" + -0.258*"able" + -0.258*"concerned" + -0.258*"got" + -0.258*"years" + -0.258*"treatment" + -0.258*"insurance" + -0.258*"living" + -0.258*"health" + -0.258*"afford"
2016-10-09 21:36:56,405 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,406 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,407 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:56,408 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,408 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,408 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:56,409 : INFO : saved 10x5321 matrix, density=0.374% (199/53210)
2016-10-09 21:36:56,409 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,409 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,409 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,410 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,410 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,410 : INFO : accepted corpus with 10 documents, 5321 features, 199 non-zero entries
2016-10-09 21:36:56,410 : INFO : collecting document frequencies
2016-10-09 21:36:56,410 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:56,410 : INFO : calculating IDF weights for 10 documents and 5320 features (199 matrix non-zeros)
2016-10-09 21:36:56,411 : INFO : using serial LSI version on this node
2016-10-09 21:36:56,411 : INFO : updating model with new documents
2016-10-09 21:36:56,412 : INFO : preparing a new chunk of documents
2016-10-09 21:36:56,412 : DEBUG : converting corpus to csc format
2016-10-09 21:36:56,412 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:56,414 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:56,414 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:56,425 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,464 : DEBUG : running 2 power iterations
2016-10-09 21:36:56,482 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,539 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,586 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,590 : INFO : computing the final decomposition
2016-10-09 21:36:56,590 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,592 : INFO : processed documents up to #10
2016-10-09 21:36:56,592 : INFO : topic #0(1.091): 0.250*"ql" + 0.178*"work" + 0.161*"qatar" + 0.153*"never" + 0.151*"without" + 0.145*"lucky" + 0.139*"talk" + 0.139*"experiences" + 0.139*"wonder" + 0.139*"happened"
2016-10-09 21:36:56,593 : INFO : topic #1(1.048): 0.294*"qatar" + 0.206*"get" + 0.203*"diseases" + -0.200*"without" + 0.188*"thanks" + 0.180*"lucky" + -0.154*"watch" + -0.154*"look" + -0.154*"http" + -0.154*"com"
2016-10-09 21:36:56,593 : INFO : topic #2(1.031): -0.252*"diseases" + 0.232*"ql" + 0.207*"spend" + 0.207*"hour" + 0.207*"surfing" + 0.207*"everyone" + 0.207*"hours" + 0.180*"lucky" + -0.168*"noticed" + 0.152*"many"
2016-10-09 21:36:56,593 : INFO : topic #3(1.020): -0.219*"v" + -0.219*"www" + -0.219*"youtube" + -0.219*"com" + -0.219*"http" + -0.186*"look" + -0.186*"watch" + 0.185*"ql" + 0.172*"work" + -0.167*"qatar"
2016-10-09 21:36:56,593 : INFO : topic #4(1.000): 0.328*"diseases" + -0.251*"speed" + 0.219*"noticed" + -0.168*"qtel" + -0.168*"issue" + -0.168*"still" + -0.168*"help" + -0.138*"bye" + 0.117*"least" + -0.112*"like"
2016-10-09 21:36:56,593 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,594 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,595 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:56,596 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,596 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,596 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:56,597 : INFO : saved 10x5296 matrix, density=0.410% (217/52960)
2016-10-09 21:36:56,597 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,597 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,597 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,598 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,598 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,598 : INFO : accepted corpus with 10 documents, 5296 features, 217 non-zero entries
2016-10-09 21:36:56,598 : INFO : collecting document frequencies
2016-10-09 21:36:56,598 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:56,599 : INFO : calculating IDF weights for 10 documents and 5295 features (217 matrix non-zeros)
2016-10-09 21:36:56,599 : INFO : using serial LSI version on this node
2016-10-09 21:36:56,599 : INFO : updating model with new documents
2016-10-09 21:36:56,600 : INFO : preparing a new chunk of documents
2016-10-09 21:36:56,600 : DEBUG : converting corpus to csc format
2016-10-09 21:36:56,601 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:56,602 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:56,603 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:56,614 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,654 : DEBUG : running 2 power iterations
2016-10-09 21:36:56,672 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,729 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,775 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,780 : INFO : computing the final decomposition
2016-10-09 21:36:56,780 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,782 : INFO : processed documents up to #10
2016-10-09 21:36:56,782 : INFO : topic #0(1.059): 0.229*"license" + 0.215*"driving" + 0.210*"anyone" + 0.178*"al" + 0.178*"jazeera" + 0.158*"radio" + 0.158*"night" + 0.157*"please" + 0.155*"tell" + 0.145*"colour"
2016-10-09 21:36:56,783 : INFO : topic #1(1.019): -0.270*"true" + -0.217*"buy" + -0.188*"2" + -0.180*"places" + 0.146*"anyone" + -0.142*"qatar" + 0.131*"colour" + 0.131*"whether" + 0.131*"engineer" + 0.131*"blind"
2016-10-09 21:36:56,783 : INFO : topic #2(1.010): 0.376*"qar" + 0.240*"license" + -0.224*"al" + -0.224*"jazeera" + 0.188*"000" + 0.183*"driving" + -0.152*"buy" + -0.150*"accommodation" + -0.125*"anyone" + 0.125*"allowance"
2016-10-09 21:36:56,783 : INFO : topic #3(1.004): 0.371*"buy" + 0.185*"find" + 0.185*"things" + 0.185*"difficult" + 0.185*"sort" + 0.185*"special" + 0.185*"sin" + 0.185*"boxes" + 0.185*"two" + 0.185*"bought"
2016-10-09 21:36:56,783 : INFO : topic #4(1.001): 0.415*"2" + 0.207*"black" + 0.207*"lovely" + 0.207*"bits" + 0.207*"cups" + 0.207*"plz" + 0.207*"proper" + 0.207*"note" + 0.207*"meat" + -0.163*"items"
2016-10-09 21:36:56,783 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,784 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,785 : DEBUG : PROGRESS: at document #0/10
2016-10-09 21:36:56,786 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,786 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,786 : INFO : PROGRESS: saving document #0
2016-10-09 21:36:56,787 : INFO : saved 10x5207 matrix, density=0.186% (97/52070)
2016-10-09 21:36:56,787 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,787 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,787 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,788 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 21:36:56,788 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 21:36:56,788 : INFO : accepted corpus with 10 documents, 5207 features, 97 non-zero entries
2016-10-09 21:36:56,788 : INFO : collecting document frequencies
2016-10-09 21:36:56,788 : INFO : PROGRESS: processing document #0
2016-10-09 21:36:56,788 : INFO : calculating IDF weights for 10 documents and 5206 features (97 matrix non-zeros)
2016-10-09 21:36:56,789 : INFO : using serial LSI version on this node
2016-10-09 21:36:56,789 : INFO : updating model with new documents
2016-10-09 21:36:56,789 : INFO : preparing a new chunk of documents
2016-10-09 21:36:56,789 : DEBUG : converting corpus to csc format
2016-10-09 21:36:56,789 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 21:36:56,791 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 21:36:56,792 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 21:36:56,803 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,842 : DEBUG : running 2 power iterations
2016-10-09 21:36:56,860 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,917 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 21:36:56,963 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 21:36:56,968 : INFO : computing the final decomposition
2016-10-09 21:36:56,968 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 21:36:56,969 : INFO : processed documents up to #10
2016-10-09 21:36:56,970 : INFO : topic #0(1.112): 0.468*"see" + 0.353*"moon" + 0.325*"world" + 0.317*"didnt" + 0.200*"friend" + 0.176*"end" + 0.176*"lot" + 0.176*"round" + 0.158*"vacation" + 0.158*"comments"
2016-10-09 21:36:56,970 : INFO : topic #1(1.069): 0.517*"comment" + 0.449*"please" + 0.279*"missing" + 0.279*"qlers" + 0.279*"names" + 0.279*"authorized" + 0.240*"add" + 0.190*"topic" + 0.126*"every" + 0.063*"mon"
2016-10-09 21:36:56,970 : INFO : topic #2(1.034): 0.382*"many" + 0.366*"returns" + 0.366*"party" + 0.366*"happy" + 0.359*"boss" + 0.180*"com" + 0.180*"till" + 0.180*"jpg" + 0.180*"thinking" + 0.180*"infront"
2016-10-09 21:36:56,970 : INFO : topic #3(1.015): 0.282*"u" + -0.266*"data" + -0.266*"agree" + -0.266*"filipinos" + -0.266*"part" + -0.266*"men" + -0.266*"per" + -0.259*"world" + 0.177*"didnt" + 0.160*"ql"
2016-10-09 21:36:56,970 : INFO : topic #4(1.000): 1.000*"going" + 0.000*"happy" + 0.000*"returns" + 0.000*"party" + -0.000*"boss" + 0.000*"many" + -0.000*"u" + -0.000*"com" + -0.000*"thinking" + -0.000*"lol"
2016-10-09 21:36:56,971 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 21:36:56,971 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 21:36:56,972 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:03:06,967 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:03:07,203 : INFO : built Dictionary(11949 unique tokens: ['dim', 'disadvantage', 'tatasky', 'wink', 'telecom']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:03:07,209 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:03:07,211 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:03:07,214 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:03:39,559 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:03:39,801 : INFO : built Dictionary(11949 unique tokens: ['dim', 'disadvantage', 'tatasky', 'wink', 'telecom']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:03:39,805 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:03:39,808 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:03:39,810 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:03:39,901 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:03:39,901 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:05:52,426 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:06:09,019 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:06:09,265 : INFO : built Dictionary(11949 unique tokens: ['damaged', 'app_2344061033', 'prints', 'memorisation', 'qatar']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:06:09,270 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:06:09,273 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:06:09,275 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:06:09,331 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:06:09,332 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:09:47,247 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:10:04,654 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:10:04,890 : INFO : built Dictionary(11949 unique tokens: ['damaged', 'app_2344061033', 'prints', 'memorisation', 'qatar']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:10:04,895 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:10:04,898 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:10:04,900 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:10:04,983 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:10:04,983 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,191 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:12:36,432 : INFO : built Dictionary(11949 unique tokens: ['damaged', 'app_2344061033', 'prints', 'memorisation', 'qatar']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:12:36,436 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:12:36,439 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:12:36,441 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:12:36,501 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,501 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,501 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,501 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,501 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:12:36,502 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:12:36,502 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:12:36,503 : INFO : accepted corpus with 0 documents, 0 features, 0 non-zero entries
2016-10-09 22:12:36,503 : INFO : collecting document frequencies
2016-10-09 22:12:36,503 : INFO : calculating IDF weights for 0 documents and 0 features (0 matrix non-zeros)
2016-10-09 22:12:36,503 : INFO : using serial LSI version on this node
2016-10-09 22:12:36,503 : INFO : updating model with new documents
2016-10-09 22:12:36,504 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:15:39,161 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:15:39,395 : INFO : built Dictionary(11949 unique tokens: ['damaged', 'app_2344061033', 'prints', 'memorisation', 'qatar']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:15:39,400 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:15:39,403 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:15:39,405 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:16:17,721 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:16:17,963 : INFO : built Dictionary(11949 unique tokens: ['damaged', 'app_2344061033', 'prints', 'memorisation', 'qatar']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:16:17,967 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:16:17,970 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:16:17,972 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:16:18,031 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:16:18,031 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:16:18,031 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:16:18,031 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:16:18,031 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:16:18,032 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:16:18,032 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:16:18,032 : INFO : accepted corpus with 0 documents, 0 features, 0 non-zero entries
2016-10-09 22:16:18,032 : INFO : collecting document frequencies
2016-10-09 22:16:18,033 : INFO : calculating IDF weights for 0 documents and 0 features (0 matrix non-zeros)
2016-10-09 22:16:18,033 : INFO : using serial LSI version on this node
2016-10-09 22:16:18,033 : INFO : updating model with new documents
2016-10-09 22:24:53,977 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:24:54,212 : INFO : built Dictionary(11949 unique tokens: ['maraming', 'appropiate', 'involved', 'candian', 'absorbs']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:24:54,217 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:24:54,220 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:24:54,222 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:24:54,278 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:24:54,278 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:31:37,926 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:31:38,168 : INFO : built Dictionary(11949 unique tokens: ['maraming', 'appropiate', 'involved', 'candian', 'absorbs']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:31:38,173 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:31:38,175 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:31:38,177 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:31:38,265 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,185 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:32:05,427 : INFO : built Dictionary(11949 unique tokens: ['maraming', 'appropiate', 'involved', 'candian', 'absorbs']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:32:05,431 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:32:05,434 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:32:05,436 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:32:05,495 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,495 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,495 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:05,496 : INFO : saved 10x5235 matrix, density=0.308% (161/52350)
2016-10-09 22:32:05,496 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,496 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,496 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:05,496 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:05,497 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,497 : INFO : accepted corpus with 10 documents, 5235 features, 161 non-zero entries
2016-10-09 22:32:05,497 : INFO : collecting document frequencies
2016-10-09 22:32:05,497 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:05,497 : INFO : calculating IDF weights for 10 documents and 5234 features (161 matrix non-zeros)
2016-10-09 22:32:05,498 : INFO : using serial LSI version on this node
2016-10-09 22:32:05,498 : INFO : updating model with new documents
2016-10-09 22:32:05,499 : INFO : preparing a new chunk of documents
2016-10-09 22:32:05,499 : DEBUG : converting corpus to csc format
2016-10-09 22:32:05,499 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:05,499 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:05,501 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:05,542 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:05,657 : DEBUG : running 2 power iterations
2016-10-09 22:32:05,702 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:05,846 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:05,960 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:05,968 : INFO : computing the final decomposition
2016-10-09 22:32:05,968 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:05,971 : INFO : processed documents up to #10
2016-10-09 22:32:05,972 : INFO : topic #0(1.187): -0.284*"open" + -0.283*"best" + -0.281*"savings" + -0.244*"account" + -0.188*"doha" + -0.175*"hi" + -0.168*"everybody" + -0.163*"using" + -0.156*"deal" + -0.156*"please"
2016-10-09 22:32:05,972 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"home" + -0.155*"ql" + -0.133*"credit"
2016-10-09 22:32:05,973 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"home" + 0.267*"ql" + -0.246*"islamic" + -0.246*"services" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"commercial"
2016-10-09 22:32:05,973 : INFO : topic #3(1.002): 0.271*"services" + 0.271*"islamic" + -0.269*"accept" + -0.179*"transfer" + -0.159*"paid" + -0.159*"use" + -0.159*"overseas" + -0.159*"funds" + -0.159*"used" + -0.159*"recommendations"
2016-10-09 22:32:05,973 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"want" + 0.146*"nice" + 0.146*"opening" + 0.146*"see" + 0.146*"weekend" + 0.146*"everyone" + 0.146*"help"
2016-10-09 22:32:05,973 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:05,974 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:05,975 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:05,976 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,976 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,976 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:05,977 : INFO : saved 10x5301 matrix, density=0.277% (147/53010)
2016-10-09 22:32:05,977 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,977 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,977 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:05,977 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:05,977 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:05,978 : INFO : accepted corpus with 10 documents, 5301 features, 147 non-zero entries
2016-10-09 22:32:05,978 : INFO : collecting document frequencies
2016-10-09 22:32:05,978 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:05,978 : INFO : calculating IDF weights for 10 documents and 5300 features (147 matrix non-zeros)
2016-10-09 22:32:05,978 : INFO : using serial LSI version on this node
2016-10-09 22:32:05,978 : INFO : updating model with new documents
2016-10-09 22:32:05,979 : INFO : preparing a new chunk of documents
2016-10-09 22:32:05,979 : DEBUG : converting corpus to csc format
2016-10-09 22:32:05,979 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:05,982 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:05,982 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:06,009 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,111 : DEBUG : running 2 power iterations
2016-10-09 22:32:06,151 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,289 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,402 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:06,410 : INFO : computing the final decomposition
2016-10-09 22:32:06,410 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:06,413 : INFO : processed documents up to #10
2016-10-09 22:32:06,413 : INFO : topic #0(1.125): -0.314*"go" + -0.268*"qatar" + -0.258*"catch" + -0.255*"friday" + -0.255*"next" + -0.227*"planning" + -0.213*"know" + -0.163*"place" + -0.149*"beach" + -0.149*"like"
2016-10-09 22:32:06,413 : INFO : topic #1(1.046): -0.257*"shisha" + -0.218*"hi" + -0.202*"family" + 0.193*"planning" + 0.183*"go" + -0.166*"say" + -0.166*"quiet" + -0.166*"north" + -0.166*"front" + -0.166*"swimming"
2016-10-09 22:32:06,413 : INFO : topic #2(1.018): -0.432*"card" + -0.215*"would" + -0.173*"gives" + -0.173*"using" + -0.154*"spend" + -0.134*"want" + -0.134*"please" + -0.134*"guys" + -0.134*"1000qr" + -0.134*"plz"
2016-10-09 22:32:06,413 : INFO : topic #3(1.000): 0.382*"reliable" + 0.191*"anyone" + 0.191*"hard" + 0.191*"garage" + 0.191*"cruiser" + 0.191*"land" + 0.191*"members" + 0.191*"hear" + 0.191*"qatarliving" + 0.191*"experience"
2016-10-09 22:32:06,414 : INFO : topic #4(1.000): 0.408*"coffee" + 0.408*"plus" + 0.408*"nice" + 0.408*"well" + 0.408*"view" + 0.408*"cup" + 0.000*"reliable" + 0.000*"way" + 0.000*"priced" + 0.000*"qatarliving"
2016-10-09 22:32:06,414 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:06,415 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:06,415 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:06,416 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,417 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,417 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:06,417 : INFO : saved 10x5299 matrix, density=0.228% (121/52990)
2016-10-09 22:32:06,417 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,417 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,417 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:06,418 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:06,418 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,418 : INFO : accepted corpus with 10 documents, 5299 features, 121 non-zero entries
2016-10-09 22:32:06,418 : INFO : collecting document frequencies
2016-10-09 22:32:06,418 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:06,418 : INFO : calculating IDF weights for 10 documents and 5298 features (121 matrix non-zeros)
2016-10-09 22:32:06,419 : INFO : using serial LSI version on this node
2016-10-09 22:32:06,419 : INFO : updating model with new documents
2016-10-09 22:32:06,419 : INFO : preparing a new chunk of documents
2016-10-09 22:32:06,419 : DEBUG : converting corpus to csc format
2016-10-09 22:32:06,419 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:06,422 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:06,423 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:06,449 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,548 : DEBUG : running 2 power iterations
2016-10-09 22:32:06,587 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,726 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,839 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:06,847 : INFO : computing the final decomposition
2016-10-09 22:32:06,847 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:06,850 : INFO : processed documents up to #10
2016-10-09 22:32:06,850 : INFO : topic #0(1.162): -0.309*"go" + -0.246*"best" + -0.220*"friday" + -0.220*"next" + -0.207*"know" + -0.195*"place" + -0.194*"beach" + -0.185*"years" + -0.185*"18" + -0.182*"planning"
2016-10-09 22:32:06,850 : INFO : topic #1(1.081): 0.329*"tourists" + 0.312*"18" + 0.312*"years" + 0.256*"places" + 0.245*"visit" + -0.193*"best" + -0.166*"catch" + -0.161*"go" + -0.159*"place" + -0.154*"friday"
2016-10-09 22:32:06,850 : INFO : topic #2(1.014): -0.360*"island" + -0.254*"park" + -0.185*"corniche" + -0.185*"5" + -0.180*"transfered" + -0.180*"banana" + -0.180*"stars" + -0.180*"2013" + -0.180*"resort" + -0.180*"called"
2016-10-09 22:32:06,850 : INFO : topic #3(1.001): -0.387*"good" + -0.387*"time" + -0.387*"spend" + -0.387*"quality" + -0.276*"friends" + 0.202*"suggestions" + -0.200*"place" + 0.153*"romantic" + 0.153*"bay" + 0.153*"maybe"
2016-10-09 22:32:06,851 : INFO : topic #4(1.000): -0.577*"destinations" + -0.577*"holiday" + -0.577*"experience" + -0.000*"suggestions" + -0.000*"happenings" + -0.000*"new" + -0.000*"something" + -0.000*"holidays" + -0.000*"please" + 0.000*"tourists"
2016-10-09 22:32:06,851 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:06,852 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:06,852 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:06,854 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,854 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,854 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:06,854 : INFO : saved 10x5200 matrix, density=0.413% (215/52000)
2016-10-09 22:32:06,854 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,854 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,854 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:06,855 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:06,855 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:06,855 : INFO : accepted corpus with 10 documents, 5200 features, 215 non-zero entries
2016-10-09 22:32:06,855 : INFO : collecting document frequencies
2016-10-09 22:32:06,855 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:06,855 : INFO : calculating IDF weights for 10 documents and 5199 features (215 matrix non-zeros)
2016-10-09 22:32:06,856 : INFO : using serial LSI version on this node
2016-10-09 22:32:06,856 : INFO : updating model with new documents
2016-10-09 22:32:06,856 : INFO : preparing a new chunk of documents
2016-10-09 22:32:06,856 : DEBUG : converting corpus to csc format
2016-10-09 22:32:06,857 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:06,860 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:06,860 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:06,886 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:06,985 : DEBUG : running 2 power iterations
2016-10-09 22:32:07,024 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,162 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,275 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:07,282 : INFO : computing the final decomposition
2016-10-09 22:32:07,283 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:07,285 : INFO : processed documents up to #10
2016-10-09 22:32:07,286 : INFO : topic #0(1.111): 0.250*"qatar" + 0.196*"good" + 0.177*"also" + 0.159*"know" + 0.153*"doha" + 0.140*"wanted" + 0.128*"housing" + 0.127*"transportation" + 0.127*"salary" + 0.127*"single"
2016-10-09 22:32:07,286 : INFO : topic #1(1.059): -0.364*"month" + -0.265*"per" + -0.256*"mate" + -0.176*"qar" + -0.176*"offered" + -0.151*"left" + -0.151*"day" + -0.128*"hence" + -0.128*"contact" + -0.128*"unable"
2016-10-09 22:32:07,286 : INFO : topic #2(1.021): 0.246*"violation" + 0.246*"possible" + -0.188*"home" + 0.185*"anyone" + 0.142*"absolutely" + 0.142*"old" + 0.142*"available" + 0.142*"times" + 0.142*"thousand" + 0.142*"asked"
2016-10-09 22:32:07,286 : INFO : topic #3(1.004): 0.308*"violation" + 0.308*"possible" + 0.241*"home" + 0.161*"people" + 0.161*"designer" + 0.154*"willing" + 0.154*"transfer" + 0.154*"owner" + 0.154*"accept" + 0.154*"new"
2016-10-09 22:32:07,286 : INFO : topic #4(1.001): 0.387*"good" + 0.194*"allowance" + 0.194*"provide" + 0.194*"deal" + 0.194*"12" + 0.194*"person" + -0.157*"violation" + -0.157*"possible" + 0.154*"company" + -0.149*"since"
2016-10-09 22:32:07,286 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:07,288 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:07,289 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:07,290 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,290 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,290 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:07,291 : INFO : saved 10x5335 matrix, density=0.544% (290/53350)
2016-10-09 22:32:07,291 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,291 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,291 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:07,291 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:07,292 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,292 : INFO : accepted corpus with 10 documents, 5335 features, 290 non-zero entries
2016-10-09 22:32:07,292 : INFO : collecting document frequencies
2016-10-09 22:32:07,292 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:07,292 : INFO : calculating IDF weights for 10 documents and 5334 features (290 matrix non-zeros)
2016-10-09 22:32:07,292 : INFO : using serial LSI version on this node
2016-10-09 22:32:07,292 : INFO : updating model with new documents
2016-10-09 22:32:07,293 : INFO : preparing a new chunk of documents
2016-10-09 22:32:07,293 : DEBUG : converting corpus to csc format
2016-10-09 22:32:07,293 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:07,296 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:07,297 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:07,323 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,422 : DEBUG : running 2 power iterations
2016-10-09 22:32:07,461 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,599 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,712 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:07,719 : INFO : computing the final decomposition
2016-10-09 22:32:07,719 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:07,722 : INFO : processed documents up to #10
2016-10-09 22:32:07,723 : INFO : topic #0(1.159): 0.212*"qatar" + 0.212*"petroleum" + 0.181*"000" + 0.142*"interview" + 0.134*"2" + 0.131*"one" + 0.131*"visit" + 0.114*"14" + 0.110*"thank" + 0.109*"yearly"
2016-10-09 22:32:07,723 : INFO : topic #1(1.100): 0.252*"qatar" + 0.252*"petroleum" + -0.230*"000" + 0.164*"visit" + 0.164*"one" + 0.157*"interview" + -0.152*"experience" + -0.148*"14" + -0.138*"2" + 0.122*"process"
2016-10-09 22:32:07,723 : INFO : topic #2(1.026): 0.229*"month" + 0.229*"per" + -0.163*"yearly" + 0.153*"enough" + 0.153*"10" + -0.138*"years" + -0.128*"national" + 0.127*"000" + 0.125*"also" + -0.119*"final"
2016-10-09 22:32:07,723 : INFO : topic #3(1.012): 0.232*"help" + 0.190*"like" + 0.157*"4000" + 0.157*"total" + 0.157*"3500" + 0.157*"anytime" + 0.157*"mean" + 0.157*"terminated" + 0.157*"period" + 0.157*"state"
2016-10-09 22:32:07,723 : INFO : topic #4(0.988): 0.253*"month" + 0.253*"per" + 0.168*"10" + 0.168*"enough" + 0.145*"currently" + 0.145*"advice" + 0.145*"finance" + 0.145*"main" + 0.145*"background" + 0.145*"yet"
2016-10-09 22:32:07,723 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:07,725 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:07,726 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:07,727 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,727 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,727 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:07,728 : INFO : saved 10x5332 matrix, density=0.338% (180/53320)
2016-10-09 22:32:07,728 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,728 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,728 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:07,729 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:07,729 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:07,729 : INFO : accepted corpus with 10 documents, 5332 features, 180 non-zero entries
2016-10-09 22:32:07,729 : INFO : collecting document frequencies
2016-10-09 22:32:07,729 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:07,729 : INFO : calculating IDF weights for 10 documents and 5331 features (180 matrix non-zeros)
2016-10-09 22:32:07,730 : INFO : using serial LSI version on this node
2016-10-09 22:32:07,730 : INFO : updating model with new documents
2016-10-09 22:32:07,730 : INFO : preparing a new chunk of documents
2016-10-09 22:32:07,730 : DEBUG : converting corpus to csc format
2016-10-09 22:32:07,730 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:07,733 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:07,734 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:07,760 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:07,859 : DEBUG : running 2 power iterations
2016-10-09 22:32:07,898 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,036 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,149 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:08,157 : INFO : computing the final decomposition
2016-10-09 22:32:08,157 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:08,160 : INFO : processed documents up to #10
2016-10-09 22:32:08,160 : INFO : topic #0(1.169): 0.279*"doha" + 0.229*"baby" + 0.208*"get" + 0.195*"coming" + 0.188*"vaccination" + 0.181*"vaccinations" + 0.172*"much" + 0.171*"regular" + 0.169*"remaining" + 0.141*"clinic"
2016-10-09 22:32:08,160 : INFO : topic #1(1.040): -0.260*"would" + -0.188*"coming" + -0.184*"get" + 0.176*"clinic" + 0.176*"u" + 0.168*"regular" + 0.167*"communicate" + 0.167*"recommend" + 0.167*"good" + -0.163*"know"
2016-10-09 22:32:08,160 : INFO : topic #2(1.027): -0.287*"doha" + -0.254*"law" + -0.254*"selection" + -0.254*"buy" + 0.176*"remaining" + -0.173*"recommend" + -0.173*"communicate" + -0.173*"good" + 0.151*"know" + 0.144*"anyone"
2016-10-09 22:32:08,161 : INFO : topic #3(1.003): -0.291*"made" + 0.214*"would" + 0.211*"considering" + 0.211*"job" + 0.150*"buy" + 0.150*"selection" + 0.150*"law" + -0.145*"nothing" + -0.145*"money" + -0.145*"wonder"
2016-10-09 22:32:08,161 : INFO : topic #4(1.001): 0.334*"made" + -0.208*"know" + -0.185*"anyone" + -0.185*"schools" + 0.167*"think" + 0.167*"wonder" + 0.167*"ones" + 0.167*"someone" + 0.167*"nothing" + 0.167*"spent"
2016-10-09 22:32:08,161 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:08,162 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:08,163 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:08,164 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,164 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,164 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:08,164 : INFO : saved 10x5307 matrix, density=0.268% (142/53070)
2016-10-09 22:32:08,165 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,165 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,165 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:08,165 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:08,165 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,165 : INFO : accepted corpus with 10 documents, 5307 features, 142 non-zero entries
2016-10-09 22:32:08,166 : INFO : collecting document frequencies
2016-10-09 22:32:08,166 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:08,166 : INFO : calculating IDF weights for 10 documents and 5306 features (142 matrix non-zeros)
2016-10-09 22:32:08,166 : INFO : using serial LSI version on this node
2016-10-09 22:32:08,166 : INFO : updating model with new documents
2016-10-09 22:32:08,166 : INFO : preparing a new chunk of documents
2016-10-09 22:32:08,167 : DEBUG : converting corpus to csc format
2016-10-09 22:32:08,167 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:08,170 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:08,170 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:08,196 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,297 : DEBUG : running 2 power iterations
2016-10-09 22:32:08,336 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,476 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,589 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:08,597 : INFO : computing the final decomposition
2016-10-09 22:32:08,597 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:08,600 : INFO : processed documents up to #10
2016-10-09 22:32:08,600 : INFO : topic #0(1.165): -0.317*"cold" + -0.302*"curious" + -0.240*"winter" + -0.228*"coming" + -0.204*"doha" + -0.190*"hi" + -0.171*"thank" + -0.163*"already" + -0.163*"share" + -0.163*"october"
2016-10-09 22:32:08,600 : INFO : topic #1(1.056): -0.248*"curious" + 0.208*"coming" + -0.194*"winter" + 0.189*"bring" + -0.175*"doha" + 0.174*"thank" + 0.148*"qatar" + 0.140*"oct" + 0.140*"pack" + 0.140*"30"
2016-10-09 22:32:08,600 : INFO : topic #2(1.027): 0.288*"normal" + -0.278*"curious" + 0.179*"know" + 0.149*"thanks" + 0.144*"else" + 0.144*"dust" + 0.144*"changes" + 0.144*"pain" + 0.144*"due" + 0.144*"correct"
2016-10-09 22:32:08,601 : INFO : topic #3(1.000): -0.314*"also" + -0.314*"travel" + -0.157*"vegetarian" + -0.157*"august" + -0.157*"visas" + -0.157*"required" + -0.157*"please" + -0.157*"plan" + -0.157*"europe" + -0.157*"india"
2016-10-09 22:32:08,601 : INFO : topic #4(0.995): -0.269*"woman" + -0.269*"wear" + -0.269*"clothes" + -0.269*"jeans" + -0.269*"western" + -0.269*"visiting" + -0.202*"december" + -0.182*"bring" + -0.158*"around" + -0.158*"route"
2016-10-09 22:32:08,601 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:08,602 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:08,602 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:08,604 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,604 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,604 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:08,604 : INFO : saved 10x5309 matrix, density=0.358% (190/53090)
2016-10-09 22:32:08,605 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,605 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,605 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:08,605 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:08,605 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:08,605 : INFO : accepted corpus with 10 documents, 5309 features, 190 non-zero entries
2016-10-09 22:32:08,605 : INFO : collecting document frequencies
2016-10-09 22:32:08,606 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:08,606 : INFO : calculating IDF weights for 10 documents and 5308 features (190 matrix non-zeros)
2016-10-09 22:32:08,606 : INFO : using serial LSI version on this node
2016-10-09 22:32:08,606 : INFO : updating model with new documents
2016-10-09 22:32:08,606 : INFO : preparing a new chunk of documents
2016-10-09 22:32:08,607 : DEBUG : converting corpus to csc format
2016-10-09 22:32:08,607 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:08,610 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:08,610 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:08,636 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,736 : DEBUG : running 2 power iterations
2016-10-09 22:32:08,775 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:08,914 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,027 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:09,035 : INFO : computing the final decomposition
2016-10-09 22:32:09,035 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:09,038 : INFO : processed documents up to #10
2016-10-09 22:32:09,038 : INFO : topic #0(1.178): -0.315*"puppy" + -0.298*"dog" + -0.298*"small" + -0.296*"would" + -0.261*"buy" + -0.259*"doha" + -0.178*"bring" + -0.170*"dogs" + -0.169*"food" + -0.139*"cat"
2016-10-09 22:32:09,038 : INFO : topic #1(1.046): 0.239*"cat" + -0.213*"puppy" + 0.193*"cost" + 0.193*"much" + -0.178*"dog" + -0.178*"small" + 0.174*"http" + 0.174*"qatarliving" + 0.174*"com" + 0.174*"www"
2016-10-09 22:32:09,038 : INFO : topic #2(1.008): -0.234*"much" + -0.234*"cost" + -0.190*"know" + -0.190*"pup" + -0.190*"let" + -0.148*"place" + -0.148*"qatar" + 0.136*"food" + -0.130*"1" + 0.128*"qatarliving"
2016-10-09 22:32:09,039 : INFO : topic #3(1.003): -0.197*"store" + -0.197*"recommend" + -0.197*"successful" + -0.197*"necessary" + -0.197*"cats" + -0.197*"thanks" + -0.197*"stuff" + -0.197*"finding" + -0.197*"somebody" + -0.197*"buying"
2016-10-09 22:32:09,039 : INFO : topic #4(1.000): 0.447*"attachment" + 0.447*"christian" + 0.447*"jesus" + 0.447*"muslim" + 0.447*"see" + 0.000*"rats" + 0.000*"back" + 0.000*"house" + -0.000*"cost" + -0.000*"much"
2016-10-09 22:32:09,039 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:09,040 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:09,041 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:09,042 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,043 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,043 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:09,043 : INFO : saved 10x5324 matrix, density=0.329% (175/53240)
2016-10-09 22:32:09,043 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,043 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,043 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,044 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,044 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,044 : INFO : accepted corpus with 10 documents, 5324 features, 175 non-zero entries
2016-10-09 22:32:09,044 : INFO : collecting document frequencies
2016-10-09 22:32:09,044 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:09,044 : INFO : calculating IDF weights for 10 documents and 5323 features (175 matrix non-zeros)
2016-10-09 22:32:09,045 : INFO : using serial LSI version on this node
2016-10-09 22:32:09,045 : INFO : updating model with new documents
2016-10-09 22:32:09,045 : INFO : preparing a new chunk of documents
2016-10-09 22:32:09,045 : DEBUG : converting corpus to csc format
2016-10-09 22:32:09,045 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:09,048 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:09,049 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:09,075 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,174 : DEBUG : running 2 power iterations
2016-10-09 22:32:09,213 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,351 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,464 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:09,471 : INFO : computing the final decomposition
2016-10-09 22:32:09,471 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:09,474 : INFO : processed documents up to #10
2016-10-09 22:32:09,475 : INFO : topic #0(1.127): 0.261*"much" + 0.227*"would" + 0.198*"also" + 0.162*"qatar" + 0.160*"pay" + 0.160*"loan" + 0.147*"know" + 0.125*"qr" + 0.124*"today" + 0.124*"thanks"
2016-10-09 22:32:09,475 : INFO : topic #1(1.074): 0.324*"anyone" + 0.324*"recommend" + 0.305*"window" + 0.305*"applied" + 0.223*"place" + -0.182*"law" + -0.182*"selection" + -0.181*"doha" + -0.166*"buy" + 0.159*"apartment"
2016-10-09 22:32:09,475 : INFO : topic #2(1.060): -0.294*"doha" + -0.287*"law" + -0.287*"selection" + -0.268*"buy" + -0.173*"anyone" + -0.173*"recommend" + -0.160*"applied" + -0.160*"window" + 0.126*"much" + 0.108*"would"
2016-10-09 22:32:09,475 : INFO : topic #3(1.014): 0.366*"qr" + 0.314*"wife" + 0.157*"afford" + 0.157*"everyone" + 0.157*"plan" + 0.157*"allowance" + 0.157*"civil" + 0.157*"enginner" + 0.157*"8000" + 0.157*"work"
2016-10-09 22:32:09,475 : INFO : topic #4(0.994): -0.372*"sell" + -0.372*"months" + -0.189*"one" + -0.186*"leaving" + -0.186*"weeks" + -0.186*"long" + -0.186*"want" + -0.186*"comfort" + -0.186*"resale" + -0.186*"value"
2016-10-09 22:32:09,475 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:09,476 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:09,477 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:09,479 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,479 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,479 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:09,479 : INFO : saved 10x5265 matrix, density=0.346% (182/52650)
2016-10-09 22:32:09,479 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,479 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,479 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,480 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,480 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,480 : INFO : accepted corpus with 10 documents, 5265 features, 182 non-zero entries
2016-10-09 22:32:09,480 : INFO : collecting document frequencies
2016-10-09 22:32:09,480 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:09,480 : INFO : calculating IDF weights for 10 documents and 5264 features (182 matrix non-zeros)
2016-10-09 22:32:09,481 : INFO : using serial LSI version on this node
2016-10-09 22:32:09,481 : INFO : updating model with new documents
2016-10-09 22:32:09,481 : INFO : preparing a new chunk of documents
2016-10-09 22:32:09,481 : DEBUG : converting corpus to csc format
2016-10-09 22:32:09,481 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:09,484 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:09,485 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:09,511 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,611 : DEBUG : running 2 power iterations
2016-10-09 22:32:09,650 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,789 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:09,901 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:09,909 : INFO : computing the final decomposition
2016-10-09 22:32:09,909 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:09,912 : INFO : processed documents up to #10
2016-10-09 22:32:09,912 : INFO : topic #0(1.125): 0.233*"child" + 0.180*"bus" + 0.171*"seat" + 0.168*"one" + 0.165*"front" + 0.154*"children" + 0.147*"vehicles" + 0.143*"would" + 0.142*"kids" + 0.140*"law"
2016-10-09 22:32:09,912 : INFO : topic #1(1.060): -0.275*"sure" + -0.248*"kids" + 0.216*"child" + -0.210*"would" + 0.201*"bus" + -0.153*"front" + -0.144*"break" + -0.144*"worried" + -0.144*"airlines" + -0.144*"seats"
2016-10-09 22:32:09,912 : INFO : topic #2(1.041): -0.349*"baby" + -0.269*"sign" + 0.236*"bus" + -0.230*"everything" + -0.230*"stores" + -0.179*"board" + 0.136*"child" + 0.136*"school" + -0.119*"doha" + 0.118*"found"
2016-10-09 22:32:09,913 : INFO : topic #3(1.029): 0.368*"selection" + 0.368*"buy" + 0.300*"law" + 0.212*"doha" + 0.206*"qatar" + -0.157*"one" + -0.150*"seat" + -0.140*"sign" + -0.130*"baby" + -0.127*"babies"
2016-10-09 22:32:09,913 : INFO : topic #4(1.020): 0.245*"one" + 0.160*"seat" + 0.159*"buy" + 0.159*"selection" + -0.159*"sure" + 0.153*"law" + -0.153*"bus" + -0.153*"school" + -0.142*"house" + -0.142*"feedback"
2016-10-09 22:32:09,913 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:09,914 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:09,915 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:09,916 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,916 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,916 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:09,917 : INFO : saved 10x5287 matrix, density=0.361% (191/52870)
2016-10-09 22:32:09,917 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,917 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,917 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,917 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:09,917 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:09,918 : INFO : accepted corpus with 10 documents, 5287 features, 191 non-zero entries
2016-10-09 22:32:09,918 : INFO : collecting document frequencies
2016-10-09 22:32:09,918 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:09,918 : INFO : calculating IDF weights for 10 documents and 5286 features (191 matrix non-zeros)
2016-10-09 22:32:09,918 : INFO : using serial LSI version on this node
2016-10-09 22:32:09,918 : INFO : updating model with new documents
2016-10-09 22:32:09,919 : INFO : preparing a new chunk of documents
2016-10-09 22:32:09,919 : DEBUG : converting corpus to csc format
2016-10-09 22:32:09,919 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:09,922 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:09,922 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:09,949 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,047 : DEBUG : running 2 power iterations
2016-10-09 22:32:10,086 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,225 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,337 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:10,344 : INFO : computing the final decomposition
2016-10-09 22:32:10,344 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:10,347 : INFO : processed documents up to #10
2016-10-09 22:32:10,347 : INFO : topic #0(1.168): 0.194*"beaches" + 0.191*"take" + 0.188*"beach" + 0.164*"dunes" + 0.163*"would" + 0.159*"umm" + 0.159*"anyone" + 0.155*"could" + 0.155*"clean" + 0.155*"start"
2016-10-09 22:32:10,348 : INFO : topic #1(1.031): 0.234*"ridiculous" + 0.234*"public" + 0.211*"suggestions" + 0.181*"one" + -0.160*"would" + 0.157*"please" + 0.137*"camping" + 0.137*"license" + -0.135*"could" + -0.133*"beaches"
2016-10-09 22:32:10,348 : INFO : topic #2(1.008): -0.368*"ridiculous" + -0.368*"public" + 0.353*"suggestions" + -0.199*"times" + -0.199*"gulf" + -0.199*"speed" + 0.177*"something" + 0.177*"new" + 0.177*"happenings" + 0.177*"holidays"
2016-10-09 22:32:10,348 : INFO : topic #3(1.005): 0.327*"suggestions" + 0.235*"private" + 0.235*"party" + 0.235*"let" + 0.235*"booze" + -0.169*"tell" + -0.169*"okay" + -0.168*"license" + -0.168*"camping" + 0.164*"something"
2016-10-09 22:32:10,348 : INFO : topic #4(0.995): -0.325*"public" + -0.325*"ridiculous" + 0.263*"gulf" + 0.263*"times" + 0.263*"speed" + -0.159*"beach" + -0.153*"tell" + -0.153*"okay" + 0.132*"item_no" + 0.132*"read"
2016-10-09 22:32:10,348 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:10,349 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:10,350 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:10,351 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,352 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,352 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:10,352 : INFO : saved 10x5336 matrix, density=0.392% (209/53360)
2016-10-09 22:32:10,352 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,352 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,352 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:10,353 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:10,353 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,353 : INFO : accepted corpus with 10 documents, 5336 features, 209 non-zero entries
2016-10-09 22:32:10,353 : INFO : collecting document frequencies
2016-10-09 22:32:10,353 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:10,353 : INFO : calculating IDF weights for 10 documents and 5335 features (209 matrix non-zeros)
2016-10-09 22:32:10,354 : INFO : using serial LSI version on this node
2016-10-09 22:32:10,354 : INFO : updating model with new documents
2016-10-09 22:32:10,354 : INFO : preparing a new chunk of documents
2016-10-09 22:32:10,354 : DEBUG : converting corpus to csc format
2016-10-09 22:32:10,355 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:10,358 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:10,358 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:10,384 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,483 : DEBUG : running 2 power iterations
2016-10-09 22:32:10,522 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,660 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,773 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:10,780 : INFO : computing the final decomposition
2016-10-09 22:32:10,780 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:10,783 : INFO : processed documents up to #10
2016-10-09 22:32:10,783 : INFO : topic #0(1.116): 0.255*"doha" + 0.252*"cars" + 0.177*"would" + 0.168*"much" + 0.154*"best" + 0.146*"price" + 0.146*"toyota" + 0.136*"reliable" + 0.133*"renault" + 0.121*"nissan"
2016-10-09 22:32:10,784 : INFO : topic #1(1.045): -0.257*"much" + 0.252*"doha" + 0.210*"cars" + -0.204*"would" + 0.159*"best" + -0.139*"pay" + -0.136*"thanks" + -0.133*"month" + -0.133*"today" + -0.133*"bachelor"
2016-10-09 22:32:10,784 : INFO : topic #2(1.023): 0.219*"would" + 0.163*"much" + -0.150*"anyone" + -0.142*"reliable" + -0.141*"years" + 0.140*"price" + 0.140*"toyota" + -0.112*"cheapest" + -0.112*"threads" + -0.112*"thousand"
2016-10-09 22:32:10,784 : INFO : topic #3(1.010): 0.259*"mean" + 0.259*"performance" + 0.259*"yes" + 0.259*"anybody" + 0.259*"maintenance" + 0.259*"share" + 0.259*"using" + 0.221*"please" + 0.196*"experience" + 0.195*"renault"
2016-10-09 22:32:10,784 : INFO : topic #4(1.005): 0.147*"reliable" + -0.144*"dear" + -0.144*"thank" + -0.144*"happens" + -0.144*"light" + -0.144*"east" + -0.144*"inside" + -0.144*"shown" + -0.144*"material" + -0.144*"come"
2016-10-09 22:32:10,784 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:10,785 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:10,786 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:10,788 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,788 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,788 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:10,788 : INFO : saved 10x5150 matrix, density=0.305% (157/51500)
2016-10-09 22:32:10,788 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,788 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,788 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:10,789 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:10,789 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:10,789 : INFO : accepted corpus with 10 documents, 5150 features, 157 non-zero entries
2016-10-09 22:32:10,789 : INFO : collecting document frequencies
2016-10-09 22:32:10,789 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:10,789 : INFO : calculating IDF weights for 10 documents and 5149 features (157 matrix non-zeros)
2016-10-09 22:32:10,790 : INFO : using serial LSI version on this node
2016-10-09 22:32:10,790 : INFO : updating model with new documents
2016-10-09 22:32:10,790 : INFO : preparing a new chunk of documents
2016-10-09 22:32:10,790 : DEBUG : converting corpus to csc format
2016-10-09 22:32:10,790 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:10,793 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:10,794 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:10,820 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:10,918 : DEBUG : running 2 power iterations
2016-10-09 22:32:10,957 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,096 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,208 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:11,216 : INFO : computing the final decomposition
2016-10-09 22:32:11,216 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:11,219 : INFO : processed documents up to #10
2016-10-09 22:32:11,219 : INFO : topic #0(1.209): -0.696*"water" + -0.270*"drinking" + -0.224*"using" + -0.224*"filter" + -0.206*"tap" + -0.183*"bottled" + -0.112*"instead" + -0.112*"need" + -0.112*"buying" + -0.112*"anybody"
2016-10-09 22:32:11,219 : INFO : topic #1(1.128): 0.276*"plants" + 0.224*"know" + 0.217*"nurseries" + 0.205*"doha" + 0.200*"anyone" + -0.186*"water" + 0.166*"besides" + 0.166*"also" + 0.166*"photography" + 0.166*"buy"
2016-10-09 22:32:11,220 : INFO : topic #2(1.024): 0.315*"business" + 0.241*"wanted" + 0.187*"places" + 0.178*"getting" + 0.178*"phone" + 0.178*"couple" + 0.178*"answer" + 0.178*"numbers" + 0.178*"contact" + 0.148*"tried"
2016-10-09 22:32:11,220 : INFO : topic #3(1.011): 0.250*"happening" + 0.212*"tried" + -0.205*"bcz" + -0.205*"told" + -0.205*"explain" + -0.205*"doctor" + -0.205*"low" + -0.194*"business" + 0.179*"getting" + 0.179*"phone"
2016-10-09 22:32:11,220 : INFO : topic #4(1.001): 0.248*"treatment" + 0.238*"told" + 0.238*"low" + 0.238*"explain" + 0.238*"doctor" + 0.238*"bcz" + 0.202*"getting" + 0.202*"phone" + 0.202*"contact" + 0.202*"numbers"
2016-10-09 22:32:11,220 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:11,221 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:11,222 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:11,223 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,223 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,224 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:11,224 : INFO : saved 10x5311 matrix, density=0.333% (177/53110)
2016-10-09 22:32:11,224 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,224 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,224 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:11,225 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:11,225 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,225 : INFO : accepted corpus with 10 documents, 5311 features, 177 non-zero entries
2016-10-09 22:32:11,225 : INFO : collecting document frequencies
2016-10-09 22:32:11,225 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:11,225 : INFO : calculating IDF weights for 10 documents and 5310 features (177 matrix non-zeros)
2016-10-09 22:32:11,226 : INFO : using serial LSI version on this node
2016-10-09 22:32:11,226 : INFO : updating model with new documents
2016-10-09 22:32:11,226 : INFO : preparing a new chunk of documents
2016-10-09 22:32:11,226 : DEBUG : converting corpus to csc format
2016-10-09 22:32:11,226 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:11,229 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:11,230 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:11,256 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,354 : DEBUG : running 2 power iterations
2016-10-09 22:32:11,393 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,531 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,644 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:11,651 : INFO : computing the final decomposition
2016-10-09 22:32:11,652 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:11,654 : INFO : processed documents up to #10
2016-10-09 22:32:11,655 : INFO : topic #0(1.070): 0.460*"one" + 0.334*"boring" + 0.334*"places" + 0.334*"ever" + 0.323*"ridiculous" + 0.323*"beach" + 0.323*"public" + 0.221*"doha" + 0.075*"ras" + 0.075*"laffan"
2016-10-09 22:32:11,655 : INFO : topic #1(1.069): -0.244*"party" + -0.222*"restaurant" + -0.210*"anyone" + -0.182*"kfc" + -0.182*"food" + -0.182*"already" + -0.182*"venues" + -0.182*"rent" + -0.182*"given" + -0.182*"place"
2016-10-09 22:32:11,655 : INFO : topic #2(1.020): -0.231*"hmc" + -0.205*"ras" + -0.205*"laffan" + -0.154*"training" + -0.154*"salary" + -0.137*"live" + -0.133*"speech" + -0.133*"son" + -0.133*"2" + -0.133*"baby"
2016-10-09 22:32:11,655 : INFO : topic #3(1.016): 0.168*"party" + -0.166*"laffan" + -0.166*"ras" + -0.157*"air" + -0.157*"bad" + -0.157*"gave" + -0.157*"crew" + -0.157*"said" + -0.157*"gulf" + -0.157*"experience"
2016-10-09 22:32:11,655 : INFO : topic #4(1.001): -0.375*"result" + -0.375*"grade" + -0.187*"university" + -0.187*"criteria" + -0.187*"student" + -0.187*"texas" + -0.187*"straight" + -0.187*"anybody" + -0.187*"cause" + -0.187*"rejected"
2016-10-09 22:32:11,655 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:11,657 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:11,657 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:11,659 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,659 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,659 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:11,659 : INFO : saved 10x5334 matrix, density=0.422% (225/53340)
2016-10-09 22:32:11,659 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,660 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,660 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:11,660 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:11,660 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:11,660 : INFO : accepted corpus with 10 documents, 5334 features, 225 non-zero entries
2016-10-09 22:32:11,660 : INFO : collecting document frequencies
2016-10-09 22:32:11,660 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:11,661 : INFO : calculating IDF weights for 10 documents and 5333 features (225 matrix non-zeros)
2016-10-09 22:32:11,661 : INFO : using serial LSI version on this node
2016-10-09 22:32:11,661 : INFO : updating model with new documents
2016-10-09 22:32:11,661 : INFO : preparing a new chunk of documents
2016-10-09 22:32:11,661 : DEBUG : converting corpus to csc format
2016-10-09 22:32:11,662 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:11,665 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:11,665 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:11,691 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,792 : DEBUG : running 2 power iterations
2016-10-09 22:32:11,832 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:11,970 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,083 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:12,090 : INFO : computing the final decomposition
2016-10-09 22:32:12,091 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:12,093 : INFO : processed documents up to #10
2016-10-09 22:32:12,094 : INFO : topic #0(1.131): 0.168*"back" + 0.166*"american" + 0.162*"schools" + 0.162*"uk" + 0.158*"many" + 0.157*"groups" + 0.157*"private" + 0.135*"home" + 0.133*"qatar" + 0.127*"appreciated"
2016-10-09 22:32:12,094 : INFO : topic #1(1.037): -0.270*"child" + -0.268*"bus" + -0.185*"house" + -0.185*"like" + -0.185*"son" + -0.185*"next" + -0.185*"park" + -0.185*"month" + -0.185*"7yrs" + 0.161*"small"
2016-10-09 22:32:12,094 : INFO : topic #2(1.026): 0.285*"bus" + 0.227*"use" + 0.227*"start" + 0.227*"books" + 0.218*"3" + 0.178*"child" + 0.170*"small" + 0.143*"found" + -0.136*"groups" + -0.136*"private"
2016-10-09 22:32:12,094 : INFO : topic #3(1.002): 0.257*"much" + 0.178*"start" + 0.178*"use" + 0.178*"books" + 0.153*"home" + 0.152*"daughter" + -0.146*"bus" + 0.128*"summer" + 0.128*"likes" + 0.128*"april"
2016-10-09 22:32:12,094 : INFO : topic #4(0.990): 0.202*"much" + 0.200*"anything" + 0.200*"international" + 0.200*"family" + 0.200*"british" + 0.200*"hello" + 0.200*"thinking" + -0.168*"uk" + -0.146*"back" + -0.135*"small"
2016-10-09 22:32:12,094 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:12,096 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:12,097 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:12,098 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,098 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,098 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:12,099 : INFO : saved 10x5246 matrix, density=0.374% (196/52460)
2016-10-09 22:32:12,099 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,099 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,099 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,099 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,099 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,100 : INFO : accepted corpus with 10 documents, 5246 features, 196 non-zero entries
2016-10-09 22:32:12,100 : INFO : collecting document frequencies
2016-10-09 22:32:12,100 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:12,100 : INFO : calculating IDF weights for 10 documents and 5245 features (196 matrix non-zeros)
2016-10-09 22:32:12,100 : INFO : using serial LSI version on this node
2016-10-09 22:32:12,100 : INFO : updating model with new documents
2016-10-09 22:32:12,101 : INFO : preparing a new chunk of documents
2016-10-09 22:32:12,101 : DEBUG : converting corpus to csc format
2016-10-09 22:32:12,101 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:12,104 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:12,104 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:12,131 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,229 : DEBUG : running 2 power iterations
2016-10-09 22:32:12,268 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,406 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,518 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:12,527 : INFO : computing the final decomposition
2016-10-09 22:32:12,527 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:12,530 : INFO : processed documents up to #10
2016-10-09 22:32:12,530 : INFO : topic #0(1.141): 0.265*"gratuity" + 0.224*"end" + 0.224*"service" + 0.205*"period" + 0.205*"7" + 0.205*"confirm" + 0.205*"years" + 0.205*"benefits" + 0.194*"working" + 0.182*"qatar"
2016-10-09 22:32:12,530 : INFO : topic #1(1.046): 0.224*"someone" + 0.220*"share" + 0.220*"want" + 0.220*"table" + 0.220*"dinner" + 0.220*"ask" + 0.210*"get" + 0.204*"please" + 0.183*"many" + 0.160*"anybody"
2016-10-09 22:32:12,530 : INFO : topic #2(1.008): 0.294*"good" + 0.252*"also" + 0.252*"months" + 0.252*"deposit" + 0.182*"doha" + 0.147*"transportation" + 0.147*"live" + 0.147*"deal" + 0.147*"provide" + 0.147*"single"
2016-10-09 22:32:12,531 : INFO : topic #3(1.002): -0.407*"respect" + -0.271*"think" + -0.271*"people" + -0.271*"culture" + 0.155*"anybody" + -0.136*"religion" + -0.136*"worried" + -0.136*"land" + -0.136*"open" + -0.136*"noticed"
2016-10-09 22:32:12,531 : INFO : topic #4(1.000): -0.457*"crime" + -0.305*"west" + -0.305*"wife" + -0.305*"polygamy" + -0.305*"considered" + -0.152*"islamic" + -0.152*"agrees" + -0.152*"scared" + -0.152*"equally" + -0.152*"serious"
2016-10-09 22:32:12,531 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:12,532 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:12,533 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:12,534 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,534 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,534 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:12,535 : INFO : saved 10x5234 matrix, density=0.283% (148/52340)
2016-10-09 22:32:12,535 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,535 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,535 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,536 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,536 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,536 : INFO : accepted corpus with 10 documents, 5234 features, 148 non-zero entries
2016-10-09 22:32:12,536 : INFO : collecting document frequencies
2016-10-09 22:32:12,536 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:12,536 : INFO : calculating IDF weights for 10 documents and 5233 features (148 matrix non-zeros)
2016-10-09 22:32:12,536 : INFO : using serial LSI version on this node
2016-10-09 22:32:12,536 : INFO : updating model with new documents
2016-10-09 22:32:12,537 : INFO : preparing a new chunk of documents
2016-10-09 22:32:12,537 : DEBUG : converting corpus to csc format
2016-10-09 22:32:12,537 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:12,540 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:12,540 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:12,567 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,665 : DEBUG : running 2 power iterations
2016-10-09 22:32:12,704 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,842 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:12,958 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:12,966 : INFO : computing the final decomposition
2016-10-09 22:32:12,966 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:12,969 : INFO : processed documents up to #10
2016-10-09 22:32:12,969 : INFO : topic #0(1.059): 0.241*"qatar" + 0.231*"moon" + 0.215*"islam" + 0.195*"hi" + 0.174*"national" + 0.174*"wanted" + 0.174*"december" + 0.174*"18th" + 0.174*"thanks" + 0.174*"confirm"
2016-10-09 22:32:12,969 : INFO : topic #1(1.043): -0.316*"moon" + -0.236*"islam" + -0.183*"right" + 0.172*"hi" + -0.156*"live" + -0.156*"dirty" + -0.156*"idiots" + -0.156*"world" + -0.156*"fool" + 0.156*"18th"
2016-10-09 22:32:12,970 : INFO : topic #2(1.032): -0.362*"one" + -0.323*"waiting" + -0.323*"still" + -0.323*"ones" + -0.323*"getting" + -0.194*"best" + -0.194*"doha" + -0.194*"cost" + -0.194*"prefer" + -0.194*"two"
2016-10-09 22:32:12,970 : INFO : topic #3(1.007): 0.356*"wearing" + 0.190*"need" + 0.188*"teachers" + 0.178*"women" + 0.178*"respect" + 0.178*"new" + 0.178*"dressed" + 0.178*"family" + 0.178*"conservatively" + 0.178*"however"
2016-10-09 22:32:12,970 : INFO : topic #4(1.000): 0.447*"gym" + 0.447*"month" + 0.447*"earning" + 0.447*"affordable" + 0.447*"guy" + 0.000*"wearing" + 0.000*"pajero" + 0.000*"u" + 0.000*"prefer" + 0.000*"doha"
2016-10-09 22:32:12,970 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:12,971 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:12,972 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:12,973 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,973 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,973 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:12,974 : INFO : saved 10x5324 matrix, density=0.383% (204/53240)
2016-10-09 22:32:12,974 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,974 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,974 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,974 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:12,974 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:12,974 : INFO : accepted corpus with 10 documents, 5324 features, 204 non-zero entries
2016-10-09 22:32:12,975 : INFO : collecting document frequencies
2016-10-09 22:32:12,975 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:12,975 : INFO : calculating IDF weights for 10 documents and 5323 features (204 matrix non-zeros)
2016-10-09 22:32:12,975 : INFO : using serial LSI version on this node
2016-10-09 22:32:12,975 : INFO : updating model with new documents
2016-10-09 22:32:12,976 : INFO : preparing a new chunk of documents
2016-10-09 22:32:12,976 : DEBUG : converting corpus to csc format
2016-10-09 22:32:12,976 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:12,979 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:12,979 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:13,005 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,106 : DEBUG : running 2 power iterations
2016-10-09 22:32:13,145 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,284 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,398 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:13,406 : INFO : computing the final decomposition
2016-10-09 22:32:13,406 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:13,409 : INFO : processed documents up to #10
2016-10-09 22:32:13,409 : INFO : topic #0(1.108): 0.192*"decent" + 0.186*"get" + 0.175*"need" + 0.170*"advance" + 0.165*"directions" + 0.155*"embassy" + 0.155*"driving" + 0.155*"appointment" + 0.155*"set" + 0.155*"help"
2016-10-09 22:32:13,409 : INFO : topic #1(1.041): 0.236*"qatar" + 0.207*"gps" + 0.207*"wanted" + 0.207*"garmin" + 0.183*"" + 0.183*"books" + 0.183*"english" + 0.170*"us" + 0.152*"set" + 0.152*"help"
2016-10-09 22:32:13,409 : INFO : topic #2(1.020): -0.333*"thai" + -0.222*"food" + 0.177*"taxis" + 0.177*"al" + 0.177*"karwa" + 0.155*"repaire" + -0.152*"shops" + 0.138*"new" + 0.137*"anyone" + 0.115*"lulu"
2016-10-09 22:32:13,409 : INFO : topic #3(1.008): -0.238*"decent" + 0.221*"thai" + -0.158*"carrefour" + -0.158*"really" + -0.158*"fruits" + -0.158*"ones" + -0.158*"bread" + -0.158*"fresh" + -0.158*"vegetables" + -0.158*"bad"
2016-10-09 22:32:13,410 : INFO : topic #4(0.995): -0.177*"couple" + -0.177*"first" + -0.177*"maps" + 0.150*"thai" + -0.142*"decent" + 0.140*"need" + 0.135*"al" + 0.135*"karwa" + 0.135*"taxis" + -0.132*"lulu"
2016-10-09 22:32:13,410 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:13,411 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:13,412 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:13,413 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,413 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,413 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:13,414 : INFO : saved 10x5323 matrix, density=0.385% (205/53230)
2016-10-09 22:32:13,414 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,414 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,414 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:13,414 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:13,414 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,415 : INFO : accepted corpus with 10 documents, 5323 features, 205 non-zero entries
2016-10-09 22:32:13,415 : INFO : collecting document frequencies
2016-10-09 22:32:13,415 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:13,415 : INFO : calculating IDF weights for 10 documents and 5322 features (205 matrix non-zeros)
2016-10-09 22:32:13,415 : INFO : using serial LSI version on this node
2016-10-09 22:32:13,415 : INFO : updating model with new documents
2016-10-09 22:32:13,416 : INFO : preparing a new chunk of documents
2016-10-09 22:32:13,416 : DEBUG : converting corpus to csc format
2016-10-09 22:32:13,416 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:13,419 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:13,419 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:13,445 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,545 : DEBUG : running 2 power iterations
2016-10-09 22:32:13,584 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,723 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,836 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:13,844 : INFO : computing the final decomposition
2016-10-09 22:32:13,844 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:13,847 : INFO : processed documents up to #10
2016-10-09 22:32:13,847 : INFO : topic #0(1.177): -0.283*"sponsorship" + -0.177*"visit" + -0.170*"visa" + -0.165*"work" + -0.157*"family" + -0.157*"sponsor" + -0.154*"qatar" + -0.150*"help" + -0.150*"months" + -0.141*"please"
2016-10-09 22:32:13,847 : INFO : topic #1(1.078): 0.402*"sponsorship" + 0.253*"work" + -0.204*"months" + 0.191*"sponsor" + -0.166*"visit" + -0.164*"currently" + -0.164*"whether" + -0.164*"maximum" + -0.164*"extend" + -0.164*"anybody"
2016-10-09 22:32:13,847 : INFO : topic #2(1.029): 0.231*"meet" + 0.231*"keep" + 0.215*"exam" + 0.186*"everyone" + 0.156*"besides" + 0.156*"days" + 0.135*"weeks" + -0.128*"visit" + 0.118*"medical" + 0.115*"school"
2016-10-09 22:32:13,847 : INFO : topic #3(1.022): -0.235*"qatar" + -0.190*"medical" + 0.184*"sponsorship" + -0.169*"bring" + -0.169*"legally" + -0.169*"airways" + -0.169*"married" + -0.169*"noc" + -0.153*"females" + -0.153*"policy"
2016-10-09 22:32:13,848 : INFO : topic #4(1.002): -0.283*"found" + -0.283*"later" + -0.283*"recommendations" + -0.283*"year" + -0.283*"expecting" + -0.283*"deliver" + -0.283*"place" + -0.283*"baby" + -0.283*"best" + -0.283*"doctors"
2016-10-09 22:32:13,848 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:13,849 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:13,850 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:13,851 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,851 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,851 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:13,851 : INFO : saved 10x5334 matrix, density=0.219% (117/53340)
2016-10-09 22:32:13,851 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,852 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,852 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:13,852 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:13,852 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:13,852 : INFO : accepted corpus with 10 documents, 5334 features, 117 non-zero entries
2016-10-09 22:32:13,852 : INFO : collecting document frequencies
2016-10-09 22:32:13,853 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:13,853 : INFO : calculating IDF weights for 10 documents and 5333 features (117 matrix non-zeros)
2016-10-09 22:32:13,853 : INFO : using serial LSI version on this node
2016-10-09 22:32:13,853 : INFO : updating model with new documents
2016-10-09 22:32:13,853 : INFO : preparing a new chunk of documents
2016-10-09 22:32:13,853 : DEBUG : converting corpus to csc format
2016-10-09 22:32:13,854 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:13,857 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:13,857 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:13,883 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:13,987 : DEBUG : running 2 power iterations
2016-10-09 22:32:14,026 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,166 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,280 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:14,288 : INFO : computing the final decomposition
2016-10-09 22:32:14,288 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:14,291 : INFO : processed documents up to #10
2016-10-09 22:32:14,291 : INFO : topic #0(1.193): 0.366*"family" + 0.326*"best" + 0.324*"beach" + 0.320*"qatar" + 0.278*"go" + 0.222*"next" + 0.212*"maybe" + 0.212*"romantic" + 0.212*"silent" + 0.211*"friday"
2016-10-09 22:32:14,291 : INFO : topic #1(1.043): 0.293*"next" + 0.251*"visited" + 0.251*"plan" + 0.251*"countries" + 0.235*"experience" + 0.233*"destinations" + 0.233*"holiday" + -0.209*"beach" + 0.207*"summer" + 0.207*"places"
2016-10-09 22:32:14,291 : INFO : topic #2(1.030): -0.344*"holiday" + -0.344*"destinations" + -0.316*"experience" + 0.275*"countries" + 0.275*"plan" + 0.275*"visited" + 0.271*"next" + -0.217*"summer" + -0.217*"vacation" + -0.217*"places"
2016-10-09 22:32:14,291 : INFO : topic #3(1.016): -0.257*"lets" + -0.256*"country" + -0.256*"away" + -0.256*"17" + -0.256*"years" + -0.256*"start" + -0.256*"long" + -0.223*"beaches" + 0.150*"family" + -0.130*"destinations"
2016-10-09 22:32:14,292 : INFO : topic #4(0.999): 0.189*"advice" + 0.189*"september" + 0.189*"expect" + 0.189*"moving" + 0.189*"decent" + 0.189*"looking" + 0.189*"info" + 0.189*"standard" + 0.189*"give" + 0.189*"wife"
2016-10-09 22:32:14,292 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:14,293 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:14,293 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:14,294 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,295 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,295 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:14,295 : INFO : saved 10x5273 matrix, density=0.345% (182/52730)
2016-10-09 22:32:14,295 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,295 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,295 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:14,296 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:14,296 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,296 : INFO : accepted corpus with 10 documents, 5273 features, 182 non-zero entries
2016-10-09 22:32:14,296 : INFO : collecting document frequencies
2016-10-09 22:32:14,296 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:14,296 : INFO : calculating IDF weights for 10 documents and 5272 features (182 matrix non-zeros)
2016-10-09 22:32:14,297 : INFO : using serial LSI version on this node
2016-10-09 22:32:14,297 : INFO : updating model with new documents
2016-10-09 22:32:14,297 : INFO : preparing a new chunk of documents
2016-10-09 22:32:14,297 : DEBUG : converting corpus to csc format
2016-10-09 22:32:14,297 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:14,300 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:14,301 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:14,327 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,426 : DEBUG : running 2 power iterations
2016-10-09 22:32:14,465 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,603 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,716 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:14,724 : INFO : computing the final decomposition
2016-10-09 22:32:14,724 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:14,727 : INFO : processed documents up to #10
2016-10-09 22:32:14,727 : INFO : topic #0(1.092): -0.203*"running" + -0.185*"would" + -0.180*"evening" + -0.178*"place" + -0.174*"night" + -0.164*"corniche" + -0.140*"safe" + -0.135*"hi" + -0.135*"good" + -0.134*"could"
2016-10-09 22:32:14,727 : INFO : topic #1(1.036): -0.303*"running" + -0.239*"com" + -0.239*"www" + 0.199*"evening" + 0.196*"see" + 0.196*"groups" + 0.196*"qlers" + 0.196*"lot" + -0.157*"done" + -0.157*"also"
2016-10-09 22:32:14,727 : INFO : topic #2(1.026): -0.248*"could" + -0.245*"like" + -0.226*"im" + -0.166*"know" + -0.151*"would" + -0.135*"wear" + 0.131*"groups" + 0.131*"qlers" + 0.131*"see" + 0.131*"lot"
2016-10-09 22:32:14,728 : INFO : topic #3(1.006): -0.283*"ladies" + -0.283*"move" + -0.283*"alone" + 0.283*"today" + -0.231*"safe" + -0.141*"public" + -0.141*"uae" + -0.141*"indian" + -0.141*"transport" + -0.141*"used"
2016-10-09 22:32:14,728 : INFO : topic #4(1.003): -0.347*"wear" + -0.222*"lot" + -0.222*"qlers" + -0.222*"see" + -0.222*"groups" + -0.161*"evening" + -0.150*"com" + -0.150*"www" + 0.121*"night" + -0.119*"corniche"
2016-10-09 22:32:14,728 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:14,729 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:14,730 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:14,731 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,731 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,731 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:14,732 : INFO : saved 10x5301 matrix, density=0.366% (194/53010)
2016-10-09 22:32:14,732 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,732 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,732 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:14,732 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:14,732 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:14,733 : INFO : accepted corpus with 10 documents, 5301 features, 194 non-zero entries
2016-10-09 22:32:14,733 : INFO : collecting document frequencies
2016-10-09 22:32:14,733 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:14,733 : INFO : calculating IDF weights for 10 documents and 5300 features (194 matrix non-zeros)
2016-10-09 22:32:14,733 : INFO : using serial LSI version on this node
2016-10-09 22:32:14,733 : INFO : updating model with new documents
2016-10-09 22:32:14,734 : INFO : preparing a new chunk of documents
2016-10-09 22:32:14,734 : DEBUG : converting corpus to csc format
2016-10-09 22:32:14,734 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:14,737 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:14,737 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:14,763 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:14,863 : DEBUG : running 2 power iterations
2016-10-09 22:32:14,902 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,040 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,153 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:15,160 : INFO : computing the final decomposition
2016-10-09 22:32:15,161 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:15,163 : INFO : processed documents up to #10
2016-10-09 22:32:15,164 : INFO : topic #0(1.153): 0.228*"much" + 0.208*"club" + 0.184*"people" + 0.169*"member" + 0.169*"need" + 0.158*"bars" + 0.157*"enjoy" + 0.157*"dubai" + 0.157*"ways" + 0.157*"doha"
2016-10-09 22:32:15,164 : INFO : topic #1(1.055): 0.198*"think" + 0.184*"night" + -0.176*"bars" + 0.169*"get" + -0.169*"anything" + -0.169*"knows" + -0.169*"anybody" + -0.160*"people" + -0.150*"qatar" + -0.150*"friends"
2016-10-09 22:32:15,164 : INFO : topic #2(1.041): -0.249*"people" + -0.191*"dance" + -0.189*"enjoy" + -0.189*"dubai" + -0.189*"ways" + 0.189*"anything" + 0.189*"knows" + 0.189*"anybody" + 0.182*"friends" + 0.182*"qatar"
2016-10-09 22:32:15,164 : INFO : topic #3(1.011): -0.245*"time" + -0.245*"opens" + -0.179*"friday" + 0.157*"getting" + 0.157*"small" + 0.157*"place" + 0.157*"decent" + 0.157*"hang" + 0.157*"world" + 0.157*"find"
2016-10-09 22:32:15,164 : INFO : topic #4(0.998): -0.198*"time" + -0.198*"opens" + 0.172*"bars" + -0.162*"friday" + 0.156*"5" + 0.156*"drinks" + 0.156*"give" + 0.156*"weekend" + 0.156*"bar" + 0.156*"one"
2016-10-09 22:32:15,164 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:15,166 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:15,166 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:15,168 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,168 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,168 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:15,168 : INFO : saved 10x5305 matrix, density=0.234% (124/53050)
2016-10-09 22:32:15,168 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,168 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,168 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:15,169 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:15,169 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,169 : INFO : accepted corpus with 10 documents, 5305 features, 124 non-zero entries
2016-10-09 22:32:15,169 : INFO : collecting document frequencies
2016-10-09 22:32:15,169 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:15,169 : INFO : calculating IDF weights for 10 documents and 5304 features (124 matrix non-zeros)
2016-10-09 22:32:15,170 : INFO : using serial LSI version on this node
2016-10-09 22:32:15,170 : INFO : updating model with new documents
2016-10-09 22:32:15,170 : INFO : preparing a new chunk of documents
2016-10-09 22:32:15,170 : DEBUG : converting corpus to csc format
2016-10-09 22:32:15,170 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:15,173 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:15,174 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:15,200 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,298 : DEBUG : running 2 power iterations
2016-10-09 22:32:15,338 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,476 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,589 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:15,597 : INFO : computing the final decomposition
2016-10-09 22:32:15,597 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:15,600 : INFO : processed documents up to #10
2016-10-09 22:32:15,600 : INFO : topic #0(1.092): -0.314*"think" + -0.293*"qlers" + -0.233*"hear" + -0.233*"moment" + -0.233*"let" + -0.233*"take" + -0.226*"ql" + -0.211*"say" + -0.186*"better" + -0.186*"write"
2016-10-09 22:32:15,601 : INFO : topic #1(1.012): -0.362*"points" + 0.253*"something" + 0.233*"list" + 0.233*"hate" + -0.205*"open" + -0.205*"villagio" + 0.190*"joke" + -0.181*"tell" + -0.181*"earn" + -0.181*"anyone"
2016-10-09 22:32:15,601 : INFO : topic #2(1.009): 0.312*"points" + 0.280*"joke" + 0.257*"list" + 0.257*"hate" + 0.201*"open" + 0.201*"villagio" + 0.172*"streets" + 0.158*"women" + 0.156*"anyone" + 0.156*"earn"
2016-10-09 22:32:15,601 : INFO : topic #3(1.003): 0.578*"something" + 0.289*"dont" + 0.289*"red" + 0.289*"noticed" + 0.220*"know" + 0.219*"open" + 0.219*"villagio" + 0.204*"points" + 0.164*"yet" + -0.110*"let"
2016-10-09 22:32:15,601 : INFO : topic #4(1.000): 0.383*"come" + 0.307*"still" + 0.192*"foot" + 0.192*"pie" + 0.192*"little" + 0.192*"best" + 0.192*"canal" + 0.192*"wearing" + 0.192*"4" + 0.192*"turn"
2016-10-09 22:32:15,601 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:15,602 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:15,603 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:15,604 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,604 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,604 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:15,605 : INFO : saved 10x5304 matrix, density=0.370% (196/53040)
2016-10-09 22:32:15,605 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,605 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,605 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:15,605 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:15,605 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:15,605 : INFO : accepted corpus with 10 documents, 5304 features, 196 non-zero entries
2016-10-09 22:32:15,605 : INFO : collecting document frequencies
2016-10-09 22:32:15,605 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:15,606 : INFO : calculating IDF weights for 10 documents and 5303 features (196 matrix non-zeros)
2016-10-09 22:32:15,606 : INFO : using serial LSI version on this node
2016-10-09 22:32:15,606 : INFO : updating model with new documents
2016-10-09 22:32:15,606 : INFO : preparing a new chunk of documents
2016-10-09 22:32:15,606 : DEBUG : converting corpus to csc format
2016-10-09 22:32:15,607 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:15,610 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:15,610 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:15,637 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,736 : DEBUG : running 2 power iterations
2016-10-09 22:32:15,775 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:15,913 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,026 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:16,034 : INFO : computing the final decomposition
2016-10-09 22:32:16,034 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:16,037 : INFO : processed documents up to #10
2016-10-09 22:32:16,037 : INFO : topic #0(1.114): 0.212*"speaking" + 0.212*"nursery" + 0.212*"details" + 0.204*"french" + 0.192*"contact" + 0.192*"give" + 0.190*"anyone" + 0.189*"know" + 0.163*"lycee" + 0.151*"doha"
2016-10-09 22:32:16,037 : INFO : topic #1(1.042): -0.274*"lycee" + -0.246*"soon" + -0.215*"heard" + -0.215*"bar" + -0.215*"mall" + -0.215*"say" + -0.215*"rumor" + -0.196*"qatar" + -0.177*"get" + 0.150*"beach"
2016-10-09 22:32:16,037 : INFO : topic #2(1.035): 0.294*"give" + 0.182*"contact" + 0.151*"nursery" + 0.151*"speaking" + 0.151*"details" + 0.147*"email" + 0.147*"could" + 0.147*"names" + 0.147*"baby" + 0.147*"nurseries"
2016-10-09 22:32:16,038 : INFO : topic #3(1.009): 0.152*"lycee" + 0.152*"moving" + 0.142*"forum" + 0.142*"picture" + 0.142*"hello" + 0.142*"compound" + 0.142*"time" + 0.142*"looking" + 0.142*"al" + 0.142*"find"
2016-10-09 22:32:16,038 : INFO : topic #4(1.001): 0.214*"bought" + 0.190*"british" + 0.190*"buy" + 0.190*"flat" + -0.148*"nursery" + -0.148*"details" + -0.148*"speaking" + 0.148*"good" + 0.141*"would" + 0.130*"kindergarten"
2016-10-09 22:32:16,038 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:16,039 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:16,040 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:16,041 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,041 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,041 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:16,042 : INFO : saved 10x5327 matrix, density=0.327% (174/53270)
2016-10-09 22:32:16,042 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,042 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,042 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,042 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,042 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,043 : INFO : accepted corpus with 10 documents, 5327 features, 174 non-zero entries
2016-10-09 22:32:16,043 : INFO : collecting document frequencies
2016-10-09 22:32:16,043 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:16,043 : INFO : calculating IDF weights for 10 documents and 5326 features (174 matrix non-zeros)
2016-10-09 22:32:16,043 : INFO : using serial LSI version on this node
2016-10-09 22:32:16,043 : INFO : updating model with new documents
2016-10-09 22:32:16,044 : INFO : preparing a new chunk of documents
2016-10-09 22:32:16,044 : DEBUG : converting corpus to csc format
2016-10-09 22:32:16,044 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:16,047 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:16,047 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:16,073 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,172 : DEBUG : running 2 power iterations
2016-10-09 22:32:16,210 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,349 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,462 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:16,470 : INFO : computing the final decomposition
2016-10-09 22:32:16,470 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:16,472 : INFO : processed documents up to #10
2016-10-09 22:32:16,473 : INFO : topic #0(1.087): -0.234*"without" + -0.202*"driving" + -0.202*"buy" + -0.202*"license" + -0.202*"folks" + -0.202*"possible" + -0.202*"name" + -0.200*"hi" + -0.186*"doha" + -0.175*"car"
2016-10-09 22:32:16,473 : INFO : topic #1(1.037): -0.240*"bus" + -0.222*"company" + -0.222*"suggestions" + -0.178*"rent" + -0.174*"dont" + -0.174*"making" + -0.174*"everytime" + -0.174*"call" + -0.174*"office" + -0.174*"visit"
2016-10-09 22:32:16,473 : INFO : topic #2(1.035): -0.364*"bus" + -0.186*"mate" + -0.166*"qatar" + -0.150*"one" + -0.150*"day" + -0.140*"month" + -0.137*"required" + -0.137*"household" + -0.133*"need" + -0.128*"nurse"
2016-10-09 22:32:16,473 : INFO : topic #3(1.017): -0.224*"visa" + -0.224*"sponsor" + -0.224*"even" + -0.224*"passport" + -0.224*"cancel" + -0.211*"guys" + -0.209*"thank" + -0.157*"nurse" + 0.148*"mate" + -0.120*"without"
2016-10-09 22:32:16,474 : INFO : topic #4(0.998): -0.233*"numbers" + -0.233*"recruiting" + -0.233*"phone" + -0.233*"construction" + -0.233*"skilled" + -0.233*"jobs" + -0.233*"agencies" + -0.233*"workers" + -0.233*"list" + -0.233*"advance"
2016-10-09 22:32:16,474 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:16,475 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:16,476 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:16,477 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,477 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,477 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:16,477 : INFO : saved 10x5319 matrix, density=0.243% (129/53190)
2016-10-09 22:32:16,477 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,477 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,477 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,478 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,478 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,478 : INFO : accepted corpus with 10 documents, 5319 features, 129 non-zero entries
2016-10-09 22:32:16,478 : INFO : collecting document frequencies
2016-10-09 22:32:16,478 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:16,478 : INFO : calculating IDF weights for 10 documents and 5318 features (129 matrix non-zeros)
2016-10-09 22:32:16,479 : INFO : using serial LSI version on this node
2016-10-09 22:32:16,479 : INFO : updating model with new documents
2016-10-09 22:32:16,479 : INFO : preparing a new chunk of documents
2016-10-09 22:32:16,479 : DEBUG : converting corpus to csc format
2016-10-09 22:32:16,479 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:16,482 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:16,483 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:16,509 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,609 : DEBUG : running 2 power iterations
2016-10-09 22:32:16,648 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,786 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:16,899 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:16,906 : INFO : computing the final decomposition
2016-10-09 22:32:16,907 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:16,909 : INFO : processed documents up to #10
2016-10-09 22:32:16,910 : INFO : topic #0(1.171): 0.464*"park" + 0.363*"know" + 0.329*"water" + 0.329*"theme" + 0.238*"qatar" + 0.223*"would" + 0.223*"instead" + 0.154*"making" + 0.154*"parks" + 0.112*"another"
2016-10-09 22:32:16,910 : INFO : topic #1(1.046): 0.357*"ur" + 0.219*"place" + 0.205*"enjoy" + 0.205*"family" + 0.178*"visited" + 0.178*"friends" + 0.178*"hi" + 0.178*"best" + -0.174*"park" + 0.168*"party"
2016-10-09 22:32:16,910 : INFO : topic #2(1.032): -0.225*"ur" + 0.216*"party" + 0.176*"restaurant" + 0.176*"kfc" + 0.176*"rent" + 0.176*"already" + 0.176*"venues" + 0.176*"given" + 0.176*"food" + -0.159*"enjoy"
2016-10-09 22:32:16,910 : INFO : topic #3(1.023): -0.296*"http" + -0.226*"avoid" + -0.226*"bored" + -0.226*"post" + -0.226*"im" + -0.226*"co" + -0.226*"trap" + -0.226*"read" + -0.197*"still" + -0.197*"visit"
2016-10-09 22:32:16,910 : INFO : topic #4(1.010): -0.265*"got" + 0.203*"making" + 0.203*"parks" + -0.150*"doha" + -0.136*"2" + 0.133*"post" + 0.133*"avoid" + 0.133*"bored" + 0.133*"read" + 0.133*"im"
2016-10-09 22:32:16,911 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:16,911 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:16,912 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:16,914 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,914 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,914 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:16,914 : INFO : saved 10x5148 matrix, density=0.420% (216/51480)
2016-10-09 22:32:16,914 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,914 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,914 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,915 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:16,915 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:16,915 : INFO : accepted corpus with 10 documents, 5148 features, 216 non-zero entries
2016-10-09 22:32:16,915 : INFO : collecting document frequencies
2016-10-09 22:32:16,915 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:16,915 : INFO : calculating IDF weights for 10 documents and 5147 features (216 matrix non-zeros)
2016-10-09 22:32:16,916 : INFO : using serial LSI version on this node
2016-10-09 22:32:16,916 : INFO : updating model with new documents
2016-10-09 22:32:16,916 : INFO : preparing a new chunk of documents
2016-10-09 22:32:16,916 : DEBUG : converting corpus to csc format
2016-10-09 22:32:16,917 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:16,920 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:16,920 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:16,946 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,044 : DEBUG : running 2 power iterations
2016-10-09 22:32:17,083 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,221 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,332 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:17,340 : INFO : computing the final decomposition
2016-10-09 22:32:17,340 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:17,343 : INFO : processed documents up to #10
2016-10-09 22:32:17,343 : INFO : topic #0(1.142): -0.198*"month" + -0.176*"3" + -0.176*"maximum" + -0.176*"doha" + -0.159*"extend" + -0.159*"whether" + -0.159*"currently" + -0.149*"months" + -0.138*"anybody" + -0.136*"salary"
2016-10-09 22:32:17,344 : INFO : topic #1(1.064): 0.363*"salary" + 0.231*"option" + 0.231*"come" + 0.210*"wife" + 0.172*"possible" + 0.172*"staying" + 0.172*"bringing" + 0.172*"transfer" + 0.172*"appreciate" + 0.172*"family"
2016-10-09 22:32:17,344 : INFO : topic #2(1.021): 0.214*"available" + 0.214*"pakistanis" + 0.214*"someone" + 0.214*"pakistan" + -0.207*"need" + -0.194*"know" + -0.174*"im" + -0.174*"apply" + -0.174*"want" + -0.174*"3months"
2016-10-09 22:32:17,344 : INFO : topic #3(1.013): 0.250*"process" + 0.250*"change" + 0.146*"available" + 0.146*"someone" + 0.146*"pakistanis" + 0.146*"pakistan" + 0.146*"need" + 0.138*"visas" + 0.125*"regarding" + 0.125*"u"
2016-10-09 22:32:17,344 : INFO : topic #4(0.998): 0.272*"baby" + 0.272*"deliver" + 0.250*"month" + 0.136*"hard" + 0.136*"place" + 0.136*"friends" + 0.136*"back" + 0.136*"charge" + 0.136*"4" + 0.136*"pregnant"
2016-10-09 22:32:17,344 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:17,346 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:17,347 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:17,348 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,348 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,348 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:17,348 : INFO : saved 10x5336 matrix, density=0.232% (124/53360)
2016-10-09 22:32:17,348 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,348 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,348 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:17,349 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:17,349 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,349 : INFO : accepted corpus with 10 documents, 5336 features, 124 non-zero entries
2016-10-09 22:32:17,349 : INFO : collecting document frequencies
2016-10-09 22:32:17,349 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:17,349 : INFO : calculating IDF weights for 10 documents and 5335 features (124 matrix non-zeros)
2016-10-09 22:32:17,350 : INFO : using serial LSI version on this node
2016-10-09 22:32:17,350 : INFO : updating model with new documents
2016-10-09 22:32:17,350 : INFO : preparing a new chunk of documents
2016-10-09 22:32:17,350 : DEBUG : converting corpus to csc format
2016-10-09 22:32:17,350 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:17,353 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:17,354 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:17,380 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,479 : DEBUG : running 2 power iterations
2016-10-09 22:32:17,518 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,657 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,771 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:17,778 : INFO : computing the final decomposition
2016-10-09 22:32:17,778 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:17,781 : INFO : processed documents up to #10
2016-10-09 22:32:17,782 : INFO : topic #0(1.063): -0.343*"ql" + -0.327*"group" + -0.264*"thread" + -0.206*"back" + -0.206*"obviously" + -0.206*"wives" + -0.206*"honest" + -0.182*"please" + -0.172*"moderator" + -0.172*"cooperation"
2016-10-09 22:32:17,782 : INFO : topic #1(1.037): 0.223*"question" + 0.216*"dish" + 0.207*"solution" + 0.207*"simple" + 0.207*"lol" + -0.195*"advice" + 0.182*"party" + 0.154*"rice" + 0.153*"invited" + 0.153*"wedding"
2016-10-09 22:32:17,782 : INFO : topic #2(1.034): -0.567*"advice" + -0.238*"doha" + -0.238*"christmas" + -0.199*"holidays" + -0.199*"new" + -0.199*"thanks" + -0.199*"celebrate" + -0.199*"possible" + -0.199*"eve" + -0.199*"need"
2016-10-09 22:32:17,782 : INFO : topic #3(1.018): -0.313*"simple" + -0.313*"solution" + -0.313*"lol" + -0.274*"question" + 0.223*"dish" + 0.178*"party" + 0.156*"go" + 0.143*"invited" + 0.143*"wedding" + 0.132*"dinner"
2016-10-09 22:32:17,782 : INFO : topic #4(1.011): -0.304*"go" + 0.226*"group" + -0.208*"honest" + -0.208*"obviously" + -0.208*"wives" + -0.208*"back" + 0.161*"b" + 0.161*"x" + 0.161*"want" + 0.161*"say"
2016-10-09 22:32:17,782 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:17,783 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:17,784 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:17,785 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,785 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,786 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:17,786 : INFO : saved 10x5299 matrix, density=0.387% (205/52990)
2016-10-09 22:32:17,786 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,786 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,786 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:17,787 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:17,787 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:17,787 : INFO : accepted corpus with 10 documents, 5299 features, 205 non-zero entries
2016-10-09 22:32:17,787 : INFO : collecting document frequencies
2016-10-09 22:32:17,787 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:17,787 : INFO : calculating IDF weights for 10 documents and 5298 features (205 matrix non-zeros)
2016-10-09 22:32:17,788 : INFO : using serial LSI version on this node
2016-10-09 22:32:17,788 : INFO : updating model with new documents
2016-10-09 22:32:17,788 : INFO : preparing a new chunk of documents
2016-10-09 22:32:17,788 : DEBUG : converting corpus to csc format
2016-10-09 22:32:17,788 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:17,791 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:17,792 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:17,818 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:17,917 : DEBUG : running 2 power iterations
2016-10-09 22:32:17,956 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,094 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,207 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:18,215 : INFO : computing the final decomposition
2016-10-09 22:32:18,215 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:18,218 : INFO : processed documents up to #10
2016-10-09 22:32:18,218 : INFO : topic #0(1.139): 0.303*"suggestions" + 0.210*"week" + 0.178*"happenings" + 0.178*"new" + 0.175*"please" + 0.170*"holidays" + 0.154*"something" + 0.147*"days" + 0.136*"doha" + 0.136*"wife"
2016-10-09 22:32:18,219 : INFO : topic #1(1.062): 0.253*"ramadan" + 0.214*"comes" + 0.192*"know" + -0.189*"doha" + -0.189*"wife" + 0.170*"would" + -0.158*"places" + -0.138*"holidays" + 0.131*"muslims" + 0.131*"whole"
2016-10-09 22:32:18,219 : INFO : topic #2(1.020): 0.205*"places" + -0.184*"home" + -0.177*"leave" + 0.169*"doha" + 0.169*"wife" + -0.168*"holiday" + 0.138*"ramadan" + -0.129*"fitr" + -0.127*"go" + -0.123*"exit"
2016-10-09 22:32:18,219 : INFO : topic #3(1.008): -0.284*"please" + -0.270*"suggestions" + -0.260*"happenings" + -0.260*"new" + -0.173*"something" + 0.165*"home" + 0.152*"places" + -0.147*"share" + -0.147*"evening" + -0.147*"shops"
2016-10-09 22:32:18,219 : INFO : topic #4(0.997): 0.262*"home" + 0.212*"week" + 0.184*"want" + 0.176*"appreciated" + 0.175*"permit" + 0.175*"sponsor" + 0.175*"exit" + 0.167*"suggestions" + -0.144*"holiday" + 0.122*"advice"
2016-10-09 22:32:18,219 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:18,220 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:18,221 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:18,222 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,223 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,223 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:18,223 : INFO : saved 10x5319 matrix, density=0.308% (164/53190)
2016-10-09 22:32:18,223 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,223 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,223 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:18,224 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:18,224 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,224 : INFO : accepted corpus with 10 documents, 5319 features, 164 non-zero entries
2016-10-09 22:32:18,224 : INFO : collecting document frequencies
2016-10-09 22:32:18,224 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:18,224 : INFO : calculating IDF weights for 10 documents and 5318 features (164 matrix non-zeros)
2016-10-09 22:32:18,225 : INFO : using serial LSI version on this node
2016-10-09 22:32:18,225 : INFO : updating model with new documents
2016-10-09 22:32:18,225 : INFO : preparing a new chunk of documents
2016-10-09 22:32:18,225 : DEBUG : converting corpus to csc format
2016-10-09 22:32:18,225 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:18,228 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:18,229 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:18,255 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,354 : DEBUG : running 2 power iterations
2016-10-09 22:32:18,393 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,532 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,645 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:18,652 : INFO : computing the final decomposition
2016-10-09 22:32:18,653 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:18,655 : INFO : processed documents up to #10
2016-10-09 22:32:18,656 : INFO : topic #0(1.055): -0.267*"driving" + -0.267*"license" + -0.182*"move" + -0.171*"alone" + -0.171*"ladies" + -0.171*"safe" + -0.145*"also" + -0.140*"tell" + -0.129*"hi" + -0.121*"country"
2016-10-09 22:32:18,656 : INFO : topic #1(1.020): -0.245*"win" + -0.245*"guess" + -0.245*"gonna" + -0.222*"tell" + -0.216*"driving" + -0.216*"license" + 0.198*"also" + 0.160*"bank" + 0.160*"accept" + 0.135*"household"
2016-10-09 22:32:18,656 : INFO : topic #2(1.016): 0.212*"safe" + 0.212*"ladies" + 0.212*"alone" + -0.208*"india" + 0.207*"household" + 0.207*"required" + -0.173*"accept" + -0.173*"bank" + 0.146*"hello" + 0.146*"thanks"
2016-10-09 22:32:18,656 : INFO : topic #3(1.005): -0.462*"tata" + -0.462*"available" + -0.263*"gps" + -0.263*"wanted" + -0.263*"garmin" + -0.132*"go" + -0.132*"trip" + -0.132*"know" + -0.132*"outside" + -0.132*"genuine"
2016-10-09 22:32:18,656 : INFO : topic #4(0.999): 0.346*"guess" + 0.346*"win" + 0.346*"gonna" + 0.238*"tell" + 0.156*"garmin" + 0.156*"wanted" + 0.156*"gps" + 0.134*"household" + 0.134*"required" + -0.126*"urgent"
2016-10-09 22:32:18,657 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:18,658 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:18,658 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:18,660 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,660 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,660 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:18,660 : INFO : saved 10x5323 matrix, density=0.340% (181/53230)
2016-10-09 22:32:18,660 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,660 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,660 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:18,661 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:18,661 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:18,661 : INFO : accepted corpus with 10 documents, 5323 features, 181 non-zero entries
2016-10-09 22:32:18,661 : INFO : collecting document frequencies
2016-10-09 22:32:18,661 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:18,661 : INFO : calculating IDF weights for 10 documents and 5322 features (181 matrix non-zeros)
2016-10-09 22:32:18,662 : INFO : using serial LSI version on this node
2016-10-09 22:32:18,662 : INFO : updating model with new documents
2016-10-09 22:32:18,662 : INFO : preparing a new chunk of documents
2016-10-09 22:32:18,662 : DEBUG : converting corpus to csc format
2016-10-09 22:32:18,663 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:18,666 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:18,666 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:18,692 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,802 : DEBUG : running 2 power iterations
2016-10-09 22:32:18,841 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:18,979 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,092 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:19,100 : INFO : computing the final decomposition
2016-10-09 22:32:19,100 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:19,103 : INFO : processed documents up to #10
2016-10-09 22:32:19,103 : INFO : topic #0(1.067): -0.258*"rules" + -0.234*"would" + -0.158*"like" + -0.148*"watch" + -0.148*"doha" + -0.148*"traffic" + -0.130*"male" + -0.124*"hi" + -0.117*"www" + -0.117*"http"
2016-10-09 22:32:19,104 : INFO : topic #1(1.015): -0.255*"hijab" + -0.203*"male" + -0.162*"hi" + 0.161*"rules" + -0.160*"share" + -0.131*"thank" + -0.131*"tried" + -0.131*"center" + -0.131*"timings" + -0.131*"help"
2016-10-09 22:32:19,104 : INFO : topic #2(1.011): 0.318*"hijab" + 0.183*"male" + 0.175*"share" + -0.175*"qatar" + 0.159*"comments" + 0.159*"making" + 0.159*"womens" + 0.159*"others" + 0.159*"wear" + 0.159*"muslim"
2016-10-09 22:32:19,104 : INFO : topic #3(1.003): 0.274*"store" + 0.274*"rumor" + 0.274*"heard" + 0.274*"liquor" + -0.217*"qatar" + 0.164*"nations" + 0.137*"sell" + 0.137*"near" + 0.137*"products" + 0.137*"pork"
2016-10-09 22:32:19,104 : INFO : topic #4(1.000): -0.306*"still" + -0.306*"line" + -0.306*"threads" + -0.306*"silly" + -0.306*"one" + -0.306*"forum" + -0.306*"moderators" + -0.306*"banned" + -0.306*"even" + -0.230*"reason"
2016-10-09 22:32:19,104 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:19,105 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:19,106 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:19,107 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,107 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,108 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:19,108 : INFO : saved 10x5301 matrix, density=0.253% (134/53010)
2016-10-09 22:32:19,108 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,108 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,108 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,109 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,109 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,109 : INFO : accepted corpus with 10 documents, 5301 features, 134 non-zero entries
2016-10-09 22:32:19,109 : INFO : collecting document frequencies
2016-10-09 22:32:19,109 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:19,109 : INFO : calculating IDF weights for 10 documents and 5300 features (134 matrix non-zeros)
2016-10-09 22:32:19,109 : INFO : using serial LSI version on this node
2016-10-09 22:32:19,110 : INFO : updating model with new documents
2016-10-09 22:32:19,110 : INFO : preparing a new chunk of documents
2016-10-09 22:32:19,110 : DEBUG : converting corpus to csc format
2016-10-09 22:32:19,110 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:19,113 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:19,113 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:19,140 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,239 : DEBUG : running 2 power iterations
2016-10-09 22:32:19,278 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,417 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,530 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:19,538 : INFO : computing the final decomposition
2016-10-09 22:32:19,538 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:19,541 : INFO : processed documents up to #10
2016-10-09 22:32:19,541 : INFO : topic #0(1.081): -0.301*"qatar" + -0.228*"anyone" + -0.217*"bar" + -0.211*"indian" + -0.211*"hello" + -0.211*"help" + -0.211*"find" + -0.211*"thank" + -0.190*"friends" + -0.142*"one"
2016-10-09 22:32:19,542 : INFO : topic #1(1.037): 0.248*"qatar" + -0.231*"one" + 0.164*"anyone" + -0.158*"issue" + -0.158*"partner" + -0.158*"pass" + -0.158*"hall" + -0.151*"right" + -0.151*"thinking" + -0.151*"know"
2016-10-09 22:32:19,542 : INFO : topic #2(1.000): 0.408*"broken" + 0.408*"sweet" + 0.408*"heart" + -0.289*"issues" + -0.289*"think" + -0.289*"work" + -0.289*"guys" + -0.289*"without" + -0.289*"ever" + -0.000*"saturday"
2016-10-09 22:32:19,542 : INFO : topic #3(1.000): -1.000*"hmm" + -0.000*"film" + 0.000*"resigned" + -0.000*"f1" + 0.000*"feet" + -0.000*"instead" + 0.000*"extend" + 0.000*"polite" + -0.000*"hungry" + -0.000*"location"
2016-10-09 22:32:19,542 : INFO : topic #4(1.000): -0.408*"broken" + -0.408*"sweet" + -0.408*"heart" + -0.289*"without" + -0.289*"ever" + -0.289*"issues" + -0.289*"guys" + -0.289*"work" + -0.289*"think" + -0.000*"thread"
2016-10-09 22:32:19,542 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:19,543 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:19,544 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:19,545 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,545 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,545 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:19,546 : INFO : saved 10x5305 matrix, density=0.392% (208/53050)
2016-10-09 22:32:19,546 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,546 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,546 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,547 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,547 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,547 : INFO : accepted corpus with 10 documents, 5305 features, 208 non-zero entries
2016-10-09 22:32:19,547 : INFO : collecting document frequencies
2016-10-09 22:32:19,547 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:19,547 : INFO : calculating IDF weights for 10 documents and 5304 features (208 matrix non-zeros)
2016-10-09 22:32:19,547 : INFO : using serial LSI version on this node
2016-10-09 22:32:19,548 : INFO : updating model with new documents
2016-10-09 22:32:19,548 : INFO : preparing a new chunk of documents
2016-10-09 22:32:19,548 : DEBUG : converting corpus to csc format
2016-10-09 22:32:19,548 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:19,551 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:19,552 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:19,578 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,678 : DEBUG : running 2 power iterations
2016-10-09 22:32:19,717 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,856 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:19,969 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:19,976 : INFO : computing the final decomposition
2016-10-09 22:32:19,976 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:19,979 : INFO : processed documents up to #10
2016-10-09 22:32:19,980 : INFO : topic #0(1.118): -0.192*"change" + -0.174*"visa" + -0.152*"thanks" + -0.151*"medical" + -0.150*"exam" + -0.150*"get" + -0.146*"ql" + -0.140*"company" + -0.136*"work" + -0.132*"would"
2016-10-09 22:32:19,980 : INFO : topic #1(1.048): 0.245*"change" + -0.179*"get" + -0.174*"advise" + -0.173*"haircut" + -0.173*"town" + -0.173*"boys" + -0.173*"kindly" + -0.171*"best" + -0.150*"car" + -0.150*"seat"
2016-10-09 22:32:19,980 : INFO : topic #2(1.039): 0.297*"ql" + 0.230*"one" + 0.230*"delete" + 0.230*"join" + 0.230*"week" + 0.230*"kid" + 0.230*"wanna" + 0.208*"anyone" + 0.183*"work" + 0.133*"reliable"
2016-10-09 22:32:19,980 : INFO : topic #3(1.020): 0.248*"c" + 0.248*"b" + -0.218*"change" + 0.217*"medical" + 0.197*"exam" + -0.168*"profession" + -0.168*"technician" + -0.168*"masters" + -0.168*"manager" + 0.165*"tested"
2016-10-09 22:32:19,980 : INFO : topic #4(0.992): -0.240*"reliable" + 0.220*"visa" + -0.185*"car" + -0.185*"seat" + 0.159*"even" + 0.159*"saudi" + 0.159*"umrah" + 0.159*"procedure" + 0.159*"friends" + 0.159*"want"
2016-10-09 22:32:19,980 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:19,982 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:19,982 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:19,984 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,984 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,984 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:19,984 : INFO : saved 10x5324 matrix, density=0.222% (118/53240)
2016-10-09 22:32:19,984 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,984 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,984 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,985 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:19,985 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:19,985 : INFO : accepted corpus with 10 documents, 5324 features, 118 non-zero entries
2016-10-09 22:32:19,985 : INFO : collecting document frequencies
2016-10-09 22:32:19,985 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:19,985 : INFO : calculating IDF weights for 10 documents and 5323 features (118 matrix non-zeros)
2016-10-09 22:32:19,986 : INFO : using serial LSI version on this node
2016-10-09 22:32:19,986 : INFO : updating model with new documents
2016-10-09 22:32:19,986 : INFO : preparing a new chunk of documents
2016-10-09 22:32:19,986 : DEBUG : converting corpus to csc format
2016-10-09 22:32:19,986 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:19,989 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:19,990 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:20,016 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,132 : DEBUG : running 2 power iterations
2016-10-09 22:32:20,172 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,340 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,454 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:20,462 : INFO : computing the final decomposition
2016-10-09 22:32:20,462 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:20,465 : INFO : processed documents up to #10
2016-10-09 22:32:20,465 : INFO : topic #0(1.199): -0.417*"com" + -0.417*"http" + -0.417*"www" + -0.322*"article" + -0.310*"look" + -0.204*"08" + -0.204*"28" + -0.204*"c" + -0.204*"bin" + -0.204*"f"
2016-10-09 22:32:20,465 : INFO : topic #1(1.082): 0.354*"church" + 0.329*"catholic" + 0.245*"qatar" + 0.239*"please" + 0.210*"make" + 0.177*"bring" + 0.177*"group" + 0.177*"bible" + 0.177*"cell" + 0.177*"thanks"
2016-10-09 22:32:20,465 : INFO : topic #2(1.050): -0.348*"first" + -0.287*"came" + -0.287*"chicken" + -0.287*"egg" + -0.218*"makes" + -0.211*"guess" + -0.211*"dumb" + -0.211*"list" + -0.211*"use" + -0.211*"crazy"
2016-10-09 22:32:20,466 : INFO : topic #3(1.001): -0.271*"even" + -0.271*"lesser" + -0.271*"talking" + -0.271*"avoid" + -0.271*"person" + -0.271*"worst" + -0.271*"good" + -0.271*"way" + 0.255*"egg" + 0.255*"chicken"
2016-10-09 22:32:20,466 : INFO : topic #4(1.000): -0.447*"ones" + -0.447*"waiting" + -0.447*"still" + -0.447*"one" + -0.447*"getting" + -0.000*"chicken" + -0.000*"came" + -0.000*"egg" + 0.000*"way" + 0.000*"person"
2016-10-09 22:32:20,466 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:20,467 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:20,468 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:20,469 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,469 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,469 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:20,469 : INFO : saved 10x5319 matrix, density=0.306% (163/53190)
2016-10-09 22:32:20,469 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,469 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,470 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:20,470 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:20,470 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,470 : INFO : accepted corpus with 10 documents, 5319 features, 163 non-zero entries
2016-10-09 22:32:20,470 : INFO : collecting document frequencies
2016-10-09 22:32:20,470 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:20,470 : INFO : calculating IDF weights for 10 documents and 5318 features (163 matrix non-zeros)
2016-10-09 22:32:20,471 : INFO : using serial LSI version on this node
2016-10-09 22:32:20,471 : INFO : updating model with new documents
2016-10-09 22:32:20,471 : INFO : preparing a new chunk of documents
2016-10-09 22:32:20,471 : DEBUG : converting corpus to csc format
2016-10-09 22:32:20,472 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:20,475 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:20,475 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:20,501 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,602 : DEBUG : running 2 power iterations
2016-10-09 22:32:20,641 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,780 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:20,892 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:20,900 : INFO : computing the final decomposition
2016-10-09 22:32:20,900 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:20,903 : INFO : processed documents up to #10
2016-10-09 22:32:20,903 : INFO : topic #0(1.181): -0.255*"licence" + -0.245*"driving" + -0.195*"driver" + -0.194*"valid" + -0.162*"visa" + -0.159*"company" + -0.146*"visiting" + -0.138*"anybody" + -0.137*"get" + -0.136*"ur"
2016-10-09 22:32:20,903 : INFO : topic #1(1.060): -0.337*"use" + -0.332*"philippines" + -0.255*"long" + -0.255*"know" + -0.255*"want" + -0.255*"im" + -0.220*"phil" + 0.162*"driving" + 0.161*"valid" + -0.134*"planning"
2016-10-09 22:32:20,903 : INFO : topic #2(1.054): 0.325*"visiting" + 0.312*"egyptian" + 0.312*"work" + -0.176*"dl" + -0.174*"test" + -0.171*"anybody" + -0.154*"thanks" + -0.154*"parking" + -0.154*"trick" + -0.154*"advise"
2016-10-09 22:32:20,903 : INFO : topic #3(1.016): -0.283*"valid" + 0.246*"dl" + -0.232*"ur" + -0.232*"still" + 0.158*"visiting" + 0.133*"licence" + 0.125*"legal" + 0.125*"intend" + 0.125*"week" + 0.125*"car"
2016-10-09 22:32:20,904 : INFO : topic #4(1.001): -0.375*"licence" + -0.242*"company" + 0.218*"dl" + 0.194*"egyptian" + 0.194*"work" + -0.174*"thanks" + -0.174*"advise" + -0.174*"trick" + -0.174*"parking" + -0.169*"driver"
2016-10-09 22:32:20,904 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:20,905 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:20,905 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:20,907 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,907 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,907 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:20,907 : INFO : saved 10x5225 matrix, density=0.243% (127/52250)
2016-10-09 22:32:20,907 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,907 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,907 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:20,908 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:20,908 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:20,908 : INFO : accepted corpus with 10 documents, 5225 features, 127 non-zero entries
2016-10-09 22:32:20,908 : INFO : collecting document frequencies
2016-10-09 22:32:20,908 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:20,908 : INFO : calculating IDF weights for 10 documents and 5224 features (127 matrix non-zeros)
2016-10-09 22:32:20,909 : INFO : using serial LSI version on this node
2016-10-09 22:32:20,909 : INFO : updating model with new documents
2016-10-09 22:32:20,909 : INFO : preparing a new chunk of documents
2016-10-09 22:32:20,909 : DEBUG : converting corpus to csc format
2016-10-09 22:32:20,909 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:20,912 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:20,913 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:20,939 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,038 : DEBUG : running 2 power iterations
2016-10-09 22:32:21,077 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,215 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,327 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:21,335 : INFO : computing the final decomposition
2016-10-09 22:32:21,335 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:21,338 : INFO : processed documents up to #10
2016-10-09 22:32:21,338 : INFO : topic #0(1.103): 0.244*"love" + 0.234*"share" + 0.232*"take" + 0.225*"dubai" + 0.225*"go" + 0.225*"pics" + 0.220*"want" + 0.206*"vacation" + 0.187*"eat" + 0.174*"one"
2016-10-09 22:32:21,338 : INFO : topic #1(1.059): 0.402*"animals" + 0.390*"buy" + 0.304*"want" + 0.304*"qatar" + 0.243*"find" + 0.195*"things" + 0.195*"difficult" + 0.152*"someone" + 0.152*"life" + 0.152*"chance"
2016-10-09 22:32:21,339 : INFO : topic #2(1.048): -0.218*"eat" + -0.210*"love" + 0.164*"sponsor" + 0.163*"know" + 0.161*"cancel" + 0.161*"without" + 0.161*"thank" + 0.161*"passport" + 0.161*"visa" + 0.159*"guys"
2016-10-09 22:32:21,339 : INFO : topic #3(1.020): 0.240*"passport" + 0.240*"thank" + 0.240*"cancel" + 0.240*"visa" + 0.240*"without" + 0.216*"sponsor" + 0.188*"guys" + 0.188*"even" + -0.171*"hello" + 0.167*"eat"
2016-10-09 22:32:21,339 : INFO : topic #4(0.999): -0.186*"qatari" + -0.186*"employee" + -0.186*"directly" + -0.186*"introduce" + -0.186*"bank" + -0.186*"pay" + -0.186*"told" + -0.186*"house" + -0.186*"government" + -0.186*"maids"
2016-10-09 22:32:21,339 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:21,340 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:21,341 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:21,342 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,342 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,342 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:21,343 : INFO : saved 10x5216 matrix, density=0.387% (202/52160)
2016-10-09 22:32:21,343 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,343 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,343 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:21,343 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:21,344 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,344 : INFO : accepted corpus with 10 documents, 5216 features, 202 non-zero entries
2016-10-09 22:32:21,344 : INFO : collecting document frequencies
2016-10-09 22:32:21,344 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:21,344 : INFO : calculating IDF weights for 10 documents and 5215 features (202 matrix non-zeros)
2016-10-09 22:32:21,344 : INFO : using serial LSI version on this node
2016-10-09 22:32:21,344 : INFO : updating model with new documents
2016-10-09 22:32:21,345 : INFO : preparing a new chunk of documents
2016-10-09 22:32:21,345 : DEBUG : converting corpus to csc format
2016-10-09 22:32:21,345 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:21,348 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:21,348 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:21,375 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,472 : DEBUG : running 2 power iterations
2016-10-09 22:32:21,511 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,651 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,763 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:21,770 : INFO : computing the final decomposition
2016-10-09 22:32:21,770 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:21,773 : INFO : processed documents up to #10
2016-10-09 22:32:21,774 : INFO : topic #0(1.140): -0.316*"job" + -0.233*"good" + -0.214*"many" + -0.158*"website" + -0.158*"com" + -0.158*"hard" + -0.158*"american" + -0.158*"time" + -0.156*"get" + -0.154*"doha"
2016-10-09 22:32:21,774 : INFO : topic #1(1.069): 0.281*"library" + 0.276*"like" + 0.211*"work" + 0.208*"ask" + 0.208*"may" + 0.208*"comparable" + 0.208*"e" + 0.208*"conditions" + 0.208*"u" + 0.190*"would"
2016-10-09 22:32:21,774 : INFO : topic #2(1.023): 0.348*"petroleum" + -0.266*"library" + 0.228*"im" + 0.210*"http" + 0.210*"co" + 0.210*"read" + 0.210*"avoid" + 0.210*"trap" + 0.210*"bored" + -0.157*"like"
2016-10-09 22:32:21,774 : INFO : topic #3(1.005): 0.261*"library" + 0.229*"accept" + 0.229*"bank" + -0.219*"expat" + -0.219*"safe" + 0.123*"like" + -0.116*"want" + 0.115*"loan" + 0.115*"mean" + 0.115*"one"
2016-10-09 22:32:21,774 : INFO : topic #4(0.999): 0.236*"library" + -0.203*"consultant" + -0.203*"guide" + 0.198*"read" + 0.198*"co" + 0.198*"avoid" + 0.198*"bored" + 0.198*"http" + 0.198*"trap" + -0.168*"accept"
2016-10-09 22:32:21,774 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:21,776 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:21,776 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:21,778 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,778 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,778 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:21,778 : INFO : saved 10x5332 matrix, density=0.326% (174/53320)
2016-10-09 22:32:21,778 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,778 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,778 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:21,779 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:21,779 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:21,779 : INFO : accepted corpus with 10 documents, 5332 features, 174 non-zero entries
2016-10-09 22:32:21,779 : INFO : collecting document frequencies
2016-10-09 22:32:21,779 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:21,779 : INFO : calculating IDF weights for 10 documents and 5331 features (174 matrix non-zeros)
2016-10-09 22:32:21,780 : INFO : using serial LSI version on this node
2016-10-09 22:32:21,780 : INFO : updating model with new documents
2016-10-09 22:32:21,780 : INFO : preparing a new chunk of documents
2016-10-09 22:32:21,780 : DEBUG : converting corpus to csc format
2016-10-09 22:32:21,781 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:21,784 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:21,784 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:21,810 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:21,909 : DEBUG : running 2 power iterations
2016-10-09 22:32:21,949 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,086 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,199 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:22,207 : INFO : computing the final decomposition
2016-10-09 22:32:22,207 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:22,210 : INFO : processed documents up to #10
2016-10-09 22:32:22,210 : INFO : topic #0(1.067): -0.278*"society" + -0.278*"qatarliving" + -0.278*"jpg" + -0.278*"dr" + -0.265*"com" + -0.265*"www" + -0.265*"http" + -0.179*"nations" + -0.168*"another" + -0.168*"v"
2016-10-09 22:32:22,211 : INFO : topic #1(1.029): 0.286*"hijab" + 0.231*"others" + 0.189*"islam" + 0.188*"likes" + 0.188*"process" + 0.188*"intrested" + 0.188*"pm" + 0.188*"basically" + 0.188*"question" + 0.188*"involved"
2016-10-09 22:32:22,211 : INFO : topic #2(1.015): -0.260*"hijab" + 0.205*"people" + 0.198*"us" + 0.198*"think" + 0.198*"qatari" + 0.198*"drink" + 0.198*"must" + 0.198*"tell" + 0.198*"important" + 0.190*"done"
2016-10-09 22:32:22,211 : INFO : topic #3(1.002): -0.343*"crime" + 0.252*"gold" + -0.228*"wife" + -0.228*"polygamy" + -0.228*"considered" + -0.228*"west" + 0.189*"wearing" + 0.189*"golden" + -0.132*"nations" + 0.126*"indian"
2016-10-09 22:32:22,211 : INFO : topic #4(1.000): 0.362*"gold" + 0.272*"crime" + 0.272*"wearing" + 0.272*"golden" + 0.181*"wife" + 0.181*"considered" + 0.181*"west" + 0.181*"polygamy" + 0.181*"indian" + 0.181*"accessories"
2016-10-09 22:32:22,211 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:22,212 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:22,213 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:22,214 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,215 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,215 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:22,215 : INFO : saved 10x5292 matrix, density=0.393% (208/52920)
2016-10-09 22:32:22,215 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,215 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,215 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:22,216 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:22,216 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,216 : INFO : accepted corpus with 10 documents, 5292 features, 208 non-zero entries
2016-10-09 22:32:22,216 : INFO : collecting document frequencies
2016-10-09 22:32:22,216 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:22,216 : INFO : calculating IDF weights for 10 documents and 5291 features (208 matrix non-zeros)
2016-10-09 22:32:22,217 : INFO : using serial LSI version on this node
2016-10-09 22:32:22,217 : INFO : updating model with new documents
2016-10-09 22:32:22,217 : INFO : preparing a new chunk of documents
2016-10-09 22:32:22,217 : DEBUG : converting corpus to csc format
2016-10-09 22:32:22,217 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:22,220 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:22,221 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:22,247 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,346 : DEBUG : running 2 power iterations
2016-10-09 22:32:22,385 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,523 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,639 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:22,646 : INFO : computing the final decomposition
2016-10-09 22:32:22,647 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:22,649 : INFO : processed documents up to #10
2016-10-09 22:32:22,650 : INFO : topic #0(1.190): -0.268*"exam" + -0.257*"salary" + -0.222*"evaluation" + -0.213*"training" + -0.194*"need" + -0.149*"hmc" + -0.144*"pass" + -0.134*"nurses" + -0.132*"well" + -0.129*"experience"
2016-10-09 22:32:22,650 : INFO : topic #1(1.087): 0.367*"exam" + -0.267*"salary" + 0.202*"evaluation" + 0.188*"pass" + -0.179*"hmc" + 0.175*"prometric" + 0.175*"sit" + 0.156*"giving" + 0.156*"information" + 0.156*"regarding"
2016-10-09 22:32:22,650 : INFO : topic #2(1.030): 0.357*"training" + 0.201*"license" + 0.201*"4" + 0.201*"get" + 0.187*"need" + -0.172*"qatar" + 0.169*"evaluation" + 0.162*"hmc" + 0.150*"sch" + -0.131*"exam"
2016-10-09 22:32:22,650 : INFO : topic #3(1.000): -0.816*"stage" + -0.408*"verification" + -0.408*"right" + 0.000*"take" + -0.000*"medical" + -0.000*"salary" + 0.000*"evaluation" + 0.000*"currently" + 0.000*"experience" + 0.000*"dont"
2016-10-09 22:32:22,650 : INFO : topic #4(0.998): -0.297*"take" + 0.218*"medical" + 0.180*"salary" + 0.150*"hmc" + -0.149*"currently" + -0.149*"necessary" + -0.149*"company" + -0.149*"construction" + -0.149*"lot" + -0.149*"hello"
2016-10-09 22:32:22,651 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:22,652 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:22,653 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:22,654 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,654 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,654 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:22,655 : INFO : saved 10x5308 matrix, density=0.441% (234/53080)
2016-10-09 22:32:22,655 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,655 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,655 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:22,655 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:22,656 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:22,656 : INFO : accepted corpus with 10 documents, 5308 features, 234 non-zero entries
2016-10-09 22:32:22,656 : INFO : collecting document frequencies
2016-10-09 22:32:22,656 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:22,656 : INFO : calculating IDF weights for 10 documents and 5307 features (234 matrix non-zeros)
2016-10-09 22:32:22,656 : INFO : using serial LSI version on this node
2016-10-09 22:32:22,656 : INFO : updating model with new documents
2016-10-09 22:32:22,657 : INFO : preparing a new chunk of documents
2016-10-09 22:32:22,657 : DEBUG : converting corpus to csc format
2016-10-09 22:32:22,657 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:22,660 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:22,661 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:22,687 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,786 : DEBUG : running 2 power iterations
2016-10-09 22:32:22,825 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:22,963 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,076 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:23,083 : INFO : computing the final decomposition
2016-10-09 22:32:23,083 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:23,086 : INFO : processed documents up to #10
2016-10-09 22:32:23,087 : INFO : topic #0(1.087): -0.204*"india" + -0.160*"indian" + -0.159*"sunny" + -0.142*"kerala" + -0.139*"asian" + -0.136*"part" + -0.134*"women" + -0.134*"men" + -0.134*"western" + -0.134*"2"
2016-10-09 22:32:23,087 : INFO : topic #1(1.044): 0.208*"indian" + 0.195*"2" + 0.195*"keralites" + 0.153*"india" + 0.151*"getting" + 0.151*"marry" + 0.151*"girls" + 0.151*"arab" + -0.147*"please" + -0.139*"hmc"
2016-10-09 22:32:23,087 : INFO : topic #2(1.025): 0.231*"p" + -0.216*"sunny" + -0.189*"asian" + -0.182*"western" + -0.182*"women" + -0.182*"men" + 0.154*"letter" + 0.154*"" + 0.149*"words" + -0.144*"qatari"
2016-10-09 22:32:23,087 : INFO : topic #3(1.005): 0.246*"india" + -0.235*"hmc" + 0.215*"p" + -0.177*"qbs" + -0.177*"heard" + -0.177*"special" + -0.177*"really" + -0.177*"love" + -0.177*"wonder" + -0.177*"jobs"
2016-10-09 22:32:23,087 : INFO : topic #4(1.000): 0.229*"getting" + 0.229*"girls" + 0.229*"marry" + 0.229*"arab" + -0.201*"qbs" + -0.201*"love" + -0.201*"consider" + -0.201*"special" + -0.201*"wonder" + -0.201*"really"
2016-10-09 22:32:23,087 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:23,089 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:23,090 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:23,091 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,091 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,091 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:23,091 : INFO : saved 10x5324 matrix, density=0.314% (167/53240)
2016-10-09 22:32:23,091 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,091 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,092 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,092 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,092 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,092 : INFO : accepted corpus with 10 documents, 5324 features, 167 non-zero entries
2016-10-09 22:32:23,092 : INFO : collecting document frequencies
2016-10-09 22:32:23,092 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:23,093 : INFO : calculating IDF weights for 10 documents and 5323 features (167 matrix non-zeros)
2016-10-09 22:32:23,093 : INFO : using serial LSI version on this node
2016-10-09 22:32:23,093 : INFO : updating model with new documents
2016-10-09 22:32:23,093 : INFO : preparing a new chunk of documents
2016-10-09 22:32:23,093 : DEBUG : converting corpus to csc format
2016-10-09 22:32:23,094 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:23,097 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:23,097 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:23,123 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,238 : DEBUG : running 2 power iterations
2016-10-09 22:32:23,277 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,415 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,528 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:23,536 : INFO : computing the final decomposition
2016-10-09 22:32:23,536 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:23,539 : INFO : processed documents up to #10
2016-10-09 22:32:23,539 : INFO : topic #0(1.147): -0.384*"buy" + -0.268*"know" + -0.259*"please" + -0.259*"need" + -0.192*"called" + -0.192*"knows" + -0.192*"shop" + -0.192*"advance" + -0.192*"purchase" + -0.192*"let"
2016-10-09 22:32:23,539 : INFO : topic #1(1.080): -0.262*"hi" + -0.253*"get" + -0.232*"machine" + -0.232*"bread" + -0.215*"good" + -0.198*"much" + 0.177*"buy" + -0.175*"find" + -0.163*"thanks" + -0.152*"either"
2016-10-09 22:32:23,539 : INFO : topic #2(1.011): -0.368*"cards" + -0.276*"bank" + 0.217*"dog" + 0.217*"filipino" + -0.184*"qnb" + -0.184*"worked" + -0.184*"commercial" + -0.155*"know" + -0.151*"yes" + 0.140*"buy"
2016-10-09 22:32:23,539 : INFO : topic #3(1.005): -0.215*"dog" + -0.215*"filipino" + -0.202*"like" + -0.202*"anything" + -0.202*"qataris" + -0.202*"around" + 0.176*"machine" + 0.176*"bread" + 0.163*"hi" + -0.153*"idea"
2016-10-09 22:32:23,540 : INFO : topic #4(1.001): -0.255*"cards" + 0.247*"qataris" + 0.247*"like" + 0.247*"around" + 0.247*"anything" + -0.191*"bank" + -0.127*"commercial" + -0.127*"qnb" + -0.127*"worked" + 0.127*"get"
2016-10-09 22:32:23,540 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:23,541 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:23,542 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:23,543 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,544 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,544 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:23,544 : INFO : saved 10x5323 matrix, density=0.368% (196/53230)
2016-10-09 22:32:23,544 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,544 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,544 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,545 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,545 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,545 : INFO : accepted corpus with 10 documents, 5323 features, 196 non-zero entries
2016-10-09 22:32:23,545 : INFO : collecting document frequencies
2016-10-09 22:32:23,545 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:23,545 : INFO : calculating IDF weights for 10 documents and 5322 features (196 matrix non-zeros)
2016-10-09 22:32:23,546 : INFO : using serial LSI version on this node
2016-10-09 22:32:23,546 : INFO : updating model with new documents
2016-10-09 22:32:23,546 : INFO : preparing a new chunk of documents
2016-10-09 22:32:23,546 : DEBUG : converting corpus to csc format
2016-10-09 22:32:23,546 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:23,550 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:23,550 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:23,576 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,675 : DEBUG : running 2 power iterations
2016-10-09 22:32:23,714 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,852 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:23,965 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:23,973 : INFO : computing the final decomposition
2016-10-09 22:32:23,973 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:23,976 : INFO : processed documents up to #10
2016-10-09 22:32:23,976 : INFO : topic #0(1.160): 0.231*"wife" + 0.203*"company" + 0.179*"please" + 0.179*"even" + 0.168*"sponsor" + 0.167*"know" + 0.164*"children" + 0.164*"government" + 0.161*"change" + 0.161*"three"
2016-10-09 22:32:23,976 : INFO : topic #1(1.042): 0.348*"know" + 0.203*"hi" + 0.171*"application" + 0.171*"trying" + 0.171*"managed" + 0.171*"today" + 0.171*"end" + 0.171*"meeting" + 0.171*"rejected" + 0.171*"see"
2016-10-09 22:32:23,977 : INFO : topic #2(1.026): 0.353*"license" + 0.252*"need" + 0.219*"permit" + 0.219*"go" + 0.219*"weekend" + 0.219*"long" + 0.219*"exit" + 0.219*"going" + 0.219*"together" + 0.219*"away"
2016-10-09 22:32:23,977 : INFO : topic #3(1.010): -0.339*"license" + 0.309*"qatar" + 0.257*"family" + 0.171*"visa" + -0.167*"need" + 0.155*"kind" + 0.155*"govt" + 0.155*"allowed" + 0.155*"10000" + 0.155*"female"
2016-10-09 22:32:23,977 : INFO : topic #4(0.996): 0.206*"even" + 0.206*"please" + 0.196*"months" + 0.196*"change" + 0.196*"three" + -0.168*"sponsored" + -0.155*"job" + -0.137*"problem" + -0.137*"someone" + -0.137*"would"
2016-10-09 22:32:23,977 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:23,978 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:23,979 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:23,980 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,980 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,980 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:23,981 : INFO : saved 10x5208 matrix, density=0.353% (184/52080)
2016-10-09 22:32:23,981 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,981 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,981 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,982 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:23,982 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:23,982 : INFO : accepted corpus with 10 documents, 5208 features, 184 non-zero entries
2016-10-09 22:32:23,982 : INFO : collecting document frequencies
2016-10-09 22:32:23,982 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:23,982 : INFO : calculating IDF weights for 10 documents and 5207 features (184 matrix non-zeros)
2016-10-09 22:32:23,983 : INFO : using serial LSI version on this node
2016-10-09 22:32:23,983 : INFO : updating model with new documents
2016-10-09 22:32:23,983 : INFO : preparing a new chunk of documents
2016-10-09 22:32:23,983 : DEBUG : converting corpus to csc format
2016-10-09 22:32:23,983 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:23,986 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:23,987 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:24,013 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,112 : DEBUG : running 2 power iterations
2016-10-09 22:32:24,151 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,289 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,402 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:24,409 : INFO : computing the final decomposition
2016-10-09 22:32:24,410 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:24,412 : INFO : processed documents up to #10
2016-10-09 22:32:24,413 : INFO : topic #0(1.121): -0.309*"good" + -0.281*"budget" + -0.231*"maintenance" + -0.216*"45000" + -0.216*"shape" + -0.216*"performance" + -0.181*"best" + -0.128*"advice" + -0.127*"buying" + -0.116*"thank"
2016-10-09 22:32:24,413 : INFO : topic #1(1.055): 0.293*"buying" + -0.232*"good" + 0.225*"check" + 0.225*"advise" + 0.214*"please" + 0.193*"porsche" + 0.193*"servicing" + 0.193*"process" + 0.193*"offer" + 0.193*"u"
2016-10-09 22:32:24,413 : INFO : topic #2(1.024): 0.252*"dubai" + 0.239*"possible" + 0.216*"name" + 0.216*"folks" + 0.216*"without" + 0.216*"driving" + 0.216*"license" + 0.191*"cars" + 0.143*"doha" + 0.126*"seen"
2016-10-09 22:32:24,413 : INFO : topic #3(1.009): 0.294*"cars" + 0.244*"would" + 0.221*"doha" + -0.191*"driving" + -0.191*"name" + -0.191*"folks" + -0.191*"without" + -0.191*"license" + -0.164*"possible" + 0.137*"prices"
2016-10-09 22:32:24,413 : INFO : topic #4(0.997): 0.345*"right" + -0.264*"cars" + -0.198*"doha" + 0.172*"high" + 0.172*"problems" + 0.172*"prado" + 0.172*"cost" + 0.172*"available" + 0.172*"suggestions" + 0.172*"dad"
2016-10-09 22:32:24,413 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:24,415 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:24,415 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:24,417 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,417 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,417 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:24,417 : INFO : saved 10x5331 matrix, density=0.413% (220/53310)
2016-10-09 22:32:24,417 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,418 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,418 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:24,418 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:24,418 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,418 : INFO : accepted corpus with 10 documents, 5331 features, 220 non-zero entries
2016-10-09 22:32:24,418 : INFO : collecting document frequencies
2016-10-09 22:32:24,418 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:24,419 : INFO : calculating IDF weights for 10 documents and 5330 features (220 matrix non-zeros)
2016-10-09 22:32:24,419 : INFO : using serial LSI version on this node
2016-10-09 22:32:24,419 : INFO : updating model with new documents
2016-10-09 22:32:24,419 : INFO : preparing a new chunk of documents
2016-10-09 22:32:24,419 : DEBUG : converting corpus to csc format
2016-10-09 22:32:24,420 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:24,423 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:24,423 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:24,449 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,552 : DEBUG : running 2 power iterations
2016-10-09 22:32:24,591 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,729 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,842 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:24,850 : INFO : computing the final decomposition
2016-10-09 22:32:24,850 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:24,853 : INFO : processed documents up to #10
2016-10-09 22:32:24,853 : INFO : topic #0(1.158): -0.294*"best" + -0.290*"pakistani" + -0.218*"school" + -0.194*"thanks" + -0.168*"members" + -0.160*"3" + -0.157*"children" + -0.133*"qatar" + -0.128*"good" + -0.126*"planning"
2016-10-09 22:32:24,854 : INFO : topic #1(1.045): -0.286*"schools" + -0.237*"british" + 0.187*"members" + -0.179*"many" + -0.158*"arabic" + -0.158*"really" + -0.158*"solution" + -0.158*"know" + -0.158*"compulsory" + 0.139*"dear"
2016-10-09 22:32:24,854 : INFO : topic #2(1.029): -0.207*"bus" + -0.194*"schools" + -0.185*"many" + 0.162*"3" + -0.152*"child" + 0.150*"international" + -0.147*"british" + 0.134*"location" + -0.132*"members" + 0.131*"education"
2016-10-09 22:32:24,854 : INFO : topic #3(1.002): -0.403*"bus" + 0.254*"pakistani" + -0.229*"child" + -0.201*"found" + 0.196*"best" + -0.185*"location" + -0.130*"international" + 0.122*"b" + 0.122*"terms" + 0.122*"c"
2016-10-09 22:32:24,854 : INFO : topic #4(0.994): 0.306*"pakistani" + 0.273*"bus" + -0.194*"tuition" + -0.194*"private" + 0.168*"children" + 0.137*"found" + 0.126*"best" + -0.124*"members" + 0.113*"child" + 0.108*"thanks"
2016-10-09 22:32:24,854 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:24,855 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:24,856 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:24,857 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,858 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,858 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:24,858 : INFO : saved 10x5279 matrix, density=0.371% (196/52790)
2016-10-09 22:32:24,858 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,858 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,858 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:24,859 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:24,859 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:24,859 : INFO : accepted corpus with 10 documents, 5279 features, 196 non-zero entries
2016-10-09 22:32:24,859 : INFO : collecting document frequencies
2016-10-09 22:32:24,859 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:24,859 : INFO : calculating IDF weights for 10 documents and 5278 features (196 matrix non-zeros)
2016-10-09 22:32:24,860 : INFO : using serial LSI version on this node
2016-10-09 22:32:24,860 : INFO : updating model with new documents
2016-10-09 22:32:24,860 : INFO : preparing a new chunk of documents
2016-10-09 22:32:24,860 : DEBUG : converting corpus to csc format
2016-10-09 22:32:24,861 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:24,863 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:24,864 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:24,890 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:24,988 : DEBUG : running 2 power iterations
2016-10-09 22:32:25,028 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,167 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,279 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:25,286 : INFO : computing the final decomposition
2016-10-09 22:32:25,287 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:25,289 : INFO : processed documents up to #10
2016-10-09 22:32:25,290 : INFO : topic #0(1.139): -0.261*"qatar" + -0.223*"anybody" + -0.189*"please" + -0.174*"apply" + -0.171*"embassy" + -0.168*"know" + -0.162*"family" + -0.151*"itz" + -0.137*"tourist" + -0.137*"australian"
2016-10-09 22:32:25,290 : INFO : topic #1(1.047): 0.256*"qatar" + -0.211*"family" + -0.190*"lebanese" + -0.179*"still" + -0.177*"country" + -0.177*"exit" + 0.143*"tourist" + 0.139*"embassy" + 0.135*"anybody" + -0.132*"itz"
2016-10-09 22:32:25,290 : INFO : topic #2(1.042): -0.318*"anybody" + 0.268*"qatar" + 0.199*"tourist" + -0.186*"please" + -0.167*"extend" + -0.167*"month" + -0.167*"maximum" + -0.167*"doha" + -0.167*"whether" + -0.167*"3"
2016-10-09 22:32:25,290 : INFO : topic #3(1.008): 0.207*"us" + 0.207*"anything" + 0.207*"sad" + 0.207*"road" + 0.207*"suggest" + 0.207*"cant" + 0.207*"salaam" + 0.207*"parents" + 0.207*"air" + 0.207*"hear"
2016-10-09 22:32:25,290 : INFO : topic #4(1.003): 0.358*"extension" + 0.179*"system" + 0.179*"4" + 0.179*"passport" + 0.179*"sponsor" + 0.179*"something" + 0.179*"approved" + 0.179*"printed" + 0.179*"really" + 0.179*"form"
2016-10-09 22:32:25,290 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:25,292 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:25,292 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:25,294 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,294 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,294 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:25,294 : INFO : saved 10x5235 matrix, density=0.264% (138/52350)
2016-10-09 22:32:25,294 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,294 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,294 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:25,295 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:25,295 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,295 : INFO : accepted corpus with 10 documents, 5235 features, 138 non-zero entries
2016-10-09 22:32:25,295 : INFO : collecting document frequencies
2016-10-09 22:32:25,295 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:25,295 : INFO : calculating IDF weights for 10 documents and 5234 features (138 matrix non-zeros)
2016-10-09 22:32:25,296 : INFO : using serial LSI version on this node
2016-10-09 22:32:25,296 : INFO : updating model with new documents
2016-10-09 22:32:25,296 : INFO : preparing a new chunk of documents
2016-10-09 22:32:25,296 : DEBUG : converting corpus to csc format
2016-10-09 22:32:25,296 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:25,299 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:25,300 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:25,326 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,425 : DEBUG : running 2 power iterations
2016-10-09 22:32:25,464 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,602 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,714 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:25,722 : INFO : computing the final decomposition
2016-10-09 22:32:25,722 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:25,725 : INFO : processed documents up to #10
2016-10-09 22:32:25,725 : INFO : topic #0(1.117): -0.281*"accommodation" + -0.277*"expensive" + -0.185*"standards" + -0.185*"finishing" + -0.185*"quality" + -0.185*"decorations" + -0.185*"famous" + -0.184*"qatar" + -0.183*"etc" + -0.166*"good"
2016-10-09 22:32:25,725 : INFO : topic #1(1.049): 0.358*"school" + 0.183*"th" + 0.183*"asked" + 0.183*"recommended" + 0.183*"exam" + 0.183*"passed" + 0.183*"son" + 0.183*"entry" + 0.183*"fees" + 0.182*"doha"
2016-10-09 22:32:25,726 : INFO : topic #2(1.033): 0.255*"thread" + 0.189*"dedicated" + 0.189*"anywhere" + 0.189*"ps" + 0.189*"else" + 0.189*"milk" + 0.175*"really" + 0.175*"nice" + 0.175*"thinking" + 0.175*"uk"
2016-10-09 22:32:25,726 : INFO : topic #3(1.015): 0.171*"thanks" + -0.164*"soft" + -0.164*"higher" + -0.164*"really" + -0.164*"thinking" + -0.164*"buy" + -0.164*"uk" + -0.164*"nice" + 0.162*"would" + 0.162*"7"
2016-10-09 22:32:25,726 : INFO : topic #4(0.999): -0.258*"afford" + -0.258*"health" + -0.258*"living" + -0.258*"able" + -0.258*"years" + -0.258*"couple" + -0.258*"might" + -0.258*"got" + -0.258*"without" + -0.258*"treatment"
2016-10-09 22:32:25,726 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:25,727 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:25,728 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:25,729 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,729 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,729 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:25,730 : INFO : saved 10x5324 matrix, density=0.374% (199/53240)
2016-10-09 22:32:25,730 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,730 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,730 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:25,730 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:25,730 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:25,731 : INFO : accepted corpus with 10 documents, 5324 features, 199 non-zero entries
2016-10-09 22:32:25,731 : INFO : collecting document frequencies
2016-10-09 22:32:25,731 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:25,731 : INFO : calculating IDF weights for 10 documents and 5323 features (199 matrix non-zeros)
2016-10-09 22:32:25,731 : INFO : using serial LSI version on this node
2016-10-09 22:32:25,731 : INFO : updating model with new documents
2016-10-09 22:32:25,732 : INFO : preparing a new chunk of documents
2016-10-09 22:32:25,732 : DEBUG : converting corpus to csc format
2016-10-09 22:32:25,732 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:25,735 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:25,735 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:25,762 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:25,860 : DEBUG : running 2 power iterations
2016-10-09 22:32:25,900 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,040 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,153 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:26,160 : INFO : computing the final decomposition
2016-10-09 22:32:26,161 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:26,163 : INFO : processed documents up to #10
2016-10-09 22:32:26,164 : INFO : topic #0(1.091): -0.250*"ql" + -0.178*"work" + -0.161*"qatar" + -0.153*"never" + -0.151*"without" + -0.145*"lucky" + -0.139*"nobody" + -0.139*"xp" + -0.139*"talk" + -0.139*"wonder"
2016-10-09 22:32:26,164 : INFO : topic #1(1.048): 0.294*"qatar" + 0.206*"get" + 0.203*"diseases" + -0.200*"without" + 0.188*"thanks" + 0.180*"lucky" + -0.154*"look" + -0.154*"watch" + -0.154*"v" + -0.154*"www"
2016-10-09 22:32:26,164 : INFO : topic #2(1.031): -0.252*"diseases" + 0.232*"ql" + 0.207*"surfing" + 0.207*"everyone" + 0.207*"spend" + 0.207*"hour" + 0.207*"hours" + 0.180*"lucky" + -0.168*"noticed" + 0.152*"many"
2016-10-09 22:32:26,164 : INFO : topic #3(1.020): -0.219*"http" + -0.219*"v" + -0.219*"youtube" + -0.219*"www" + -0.219*"com" + -0.186*"look" + -0.186*"watch" + 0.185*"ql" + 0.172*"work" + -0.167*"qatar"
2016-10-09 22:32:26,164 : INFO : topic #4(1.000): 0.328*"diseases" + -0.251*"speed" + 0.219*"noticed" + -0.168*"still" + -0.168*"issue" + -0.168*"help" + -0.168*"qtel" + -0.138*"bye" + 0.117*"least" + -0.112*"like"
2016-10-09 22:32:26,164 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:26,166 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:26,166 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:26,168 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,168 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,168 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:26,168 : INFO : saved 10x5274 matrix, density=0.411% (217/52740)
2016-10-09 22:32:26,168 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,169 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,169 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:26,169 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:26,169 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,169 : INFO : accepted corpus with 10 documents, 5274 features, 217 non-zero entries
2016-10-09 22:32:26,169 : INFO : collecting document frequencies
2016-10-09 22:32:26,169 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:26,170 : INFO : calculating IDF weights for 10 documents and 5273 features (217 matrix non-zeros)
2016-10-09 22:32:26,170 : INFO : using serial LSI version on this node
2016-10-09 22:32:26,170 : INFO : updating model with new documents
2016-10-09 22:32:26,170 : INFO : preparing a new chunk of documents
2016-10-09 22:32:26,171 : DEBUG : converting corpus to csc format
2016-10-09 22:32:26,171 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:26,174 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:26,174 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:26,200 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,299 : DEBUG : running 2 power iterations
2016-10-09 22:32:26,338 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,476 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,589 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:26,596 : INFO : computing the final decomposition
2016-10-09 22:32:26,597 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:26,599 : INFO : processed documents up to #10
2016-10-09 22:32:26,600 : INFO : topic #0(1.059): 0.229*"license" + 0.215*"driving" + 0.210*"anyone" + 0.178*"jazeera" + 0.178*"al" + 0.158*"night" + 0.158*"radio" + 0.157*"please" + 0.155*"tell" + 0.145*"blind"
2016-10-09 22:32:26,600 : INFO : topic #1(1.019): -0.270*"true" + -0.217*"buy" + -0.188*"2" + -0.180*"places" + 0.146*"anyone" + -0.142*"qatar" + 0.131*"blind" + 0.131*"whether" + 0.131*"hey" + 0.131*"acceptable"
2016-10-09 22:32:26,600 : INFO : topic #2(1.010): 0.376*"qar" + 0.240*"license" + -0.224*"al" + -0.224*"jazeera" + 0.188*"000" + 0.183*"driving" + -0.152*"buy" + -0.150*"accommodation" + -0.125*"anyone" + 0.125*"basic"
2016-10-09 22:32:26,600 : INFO : topic #3(1.004): -0.371*"buy" + -0.185*"things" + -0.185*"sort" + -0.185*"find" + -0.185*"difficult" + -0.185*"worst" + -0.185*"two" + -0.185*"boxes" + -0.185*"done" + -0.185*"sin"
2016-10-09 22:32:26,601 : INFO : topic #4(1.001): 0.415*"2" + 0.207*"black" + 0.207*"plz" + 0.207*"cups" + 0.207*"meat" + 0.207*"note" + 0.207*"proper" + 0.207*"lovely" + 0.207*"bits" + -0.163*"ship"
2016-10-09 22:32:26,601 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:26,602 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:26,603 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:26,604 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,604 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,604 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:26,604 : INFO : saved 10x5319 matrix, density=0.182% (97/53190)
2016-10-09 22:32:26,604 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,604 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,605 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:26,605 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:26,605 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:26,605 : INFO : accepted corpus with 10 documents, 5319 features, 97 non-zero entries
2016-10-09 22:32:26,605 : INFO : collecting document frequencies
2016-10-09 22:32:26,605 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:26,606 : INFO : calculating IDF weights for 10 documents and 5318 features (97 matrix non-zeros)
2016-10-09 22:32:26,606 : INFO : using serial LSI version on this node
2016-10-09 22:32:26,606 : INFO : updating model with new documents
2016-10-09 22:32:26,606 : INFO : preparing a new chunk of documents
2016-10-09 22:32:26,606 : DEBUG : converting corpus to csc format
2016-10-09 22:32:26,607 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:26,610 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:26,610 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:26,636 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,735 : DEBUG : running 2 power iterations
2016-10-09 22:32:26,774 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:26,912 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,025 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:27,033 : INFO : computing the final decomposition
2016-10-09 22:32:27,033 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:27,036 : INFO : processed documents up to #10
2016-10-09 22:32:27,036 : INFO : topic #0(1.112): 0.468*"see" + 0.353*"moon" + 0.325*"world" + 0.317*"didnt" + 0.200*"friend" + 0.176*"end" + 0.176*"lot" + 0.176*"round" + 0.158*"comments" + 0.158*"also"
2016-10-09 22:32:27,036 : INFO : topic #1(1.069): 0.517*"comment" + 0.449*"please" + 0.279*"missing" + 0.279*"qlers" + 0.279*"names" + 0.279*"authorized" + 0.240*"add" + 0.190*"topic" + 0.126*"every" + 0.063*"getting"
2016-10-09 22:32:27,036 : INFO : topic #2(1.034): -0.382*"many" + -0.366*"party" + -0.366*"returns" + -0.366*"happy" + -0.359*"boss" + -0.180*"com" + -0.180*"till" + -0.180*"http" + -0.180*"missed" + -0.180*"infront"
2016-10-09 22:32:27,036 : INFO : topic #3(1.015): -0.282*"u" + 0.266*"filipinos" + 0.266*"agree" + 0.266*"per" + 0.266*"part" + 0.266*"men" + 0.266*"data" + 0.259*"world" + -0.177*"didnt" + -0.160*"ql"
2016-10-09 22:32:27,037 : INFO : topic #4(1.000): -1.000*"going" + -0.000*"party" + -0.000*"returns" + -0.000*"happy" + 0.000*"boss" + 0.000*"lol" + 0.000*"missed" + 0.000*"till" + 0.000*"com" + 0.000*"http"
2016-10-09 22:32:27,037 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:27,038 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:27,038 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:27,128 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,128 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,128 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:27,129 : INFO : saved 10x5235 matrix, density=0.308% (161/52350)
2016-10-09 22:32:27,129 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,129 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,129 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:27,129 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:27,129 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,129 : INFO : accepted corpus with 10 documents, 5235 features, 161 non-zero entries
2016-10-09 22:32:27,129 : INFO : collecting document frequencies
2016-10-09 22:32:27,129 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:27,130 : INFO : calculating IDF weights for 10 documents and 5234 features (161 matrix non-zeros)
2016-10-09 22:32:27,130 : INFO : using serial LSI version on this node
2016-10-09 22:32:27,130 : INFO : updating model with new documents
2016-10-09 22:32:27,130 : INFO : preparing a new chunk of documents
2016-10-09 22:32:27,130 : DEBUG : converting corpus to csc format
2016-10-09 22:32:27,131 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:27,134 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:27,135 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:27,163 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,267 : DEBUG : running 2 power iterations
2016-10-09 22:32:27,306 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,444 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,557 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:27,565 : INFO : computing the final decomposition
2016-10-09 22:32:27,565 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:27,568 : INFO : processed documents up to #10
2016-10-09 22:32:27,568 : INFO : topic #0(1.187): -0.284*"open" + -0.283*"best" + -0.281*"savings" + -0.244*"account" + -0.188*"doha" + -0.175*"hi" + -0.168*"everybody" + -0.163*"using" + -0.156*"soon" + -0.156*"possible"
2016-10-09 22:32:27,568 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"home" + -0.155*"ql" + -0.133*"sort"
2016-10-09 22:32:27,568 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"ql" + 0.267*"home" + -0.246*"services" + -0.246*"islamic" + 0.236*"regards" + -0.153*"good" + -0.153*"banks" + -0.127*"accept" + -0.123*"wise"
2016-10-09 22:32:27,569 : INFO : topic #3(1.002): 0.271*"islamic" + 0.271*"services" + -0.269*"accept" + -0.179*"transfer" + -0.159*"paid" + -0.159*"overseas" + -0.159*"used" + -0.159*"use" + -0.159*"recommendations" + -0.159*"funds"
2016-10-09 22:32:27,569 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"greetings" + 0.146*"know" + 0.146*"help" + 0.146*"everyone" + 0.146*"someone" + 0.146*"opening" + 0.146*"see"
2016-10-09 22:32:27,569 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:27,570 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:27,571 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:27,572 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,572 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,572 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:27,572 : INFO : saved 10x5301 matrix, density=0.277% (147/53010)
2016-10-09 22:32:27,572 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,573 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,573 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:27,573 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:27,573 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:27,573 : INFO : accepted corpus with 10 documents, 5301 features, 147 non-zero entries
2016-10-09 22:32:27,573 : INFO : collecting document frequencies
2016-10-09 22:32:27,573 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:27,573 : INFO : calculating IDF weights for 10 documents and 5300 features (147 matrix non-zeros)
2016-10-09 22:32:27,574 : INFO : using serial LSI version on this node
2016-10-09 22:32:27,574 : INFO : updating model with new documents
2016-10-09 22:32:27,574 : INFO : preparing a new chunk of documents
2016-10-09 22:32:27,574 : DEBUG : converting corpus to csc format
2016-10-09 22:32:27,575 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:27,578 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:27,578 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:27,604 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,703 : DEBUG : running 2 power iterations
2016-10-09 22:32:27,742 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,882 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:27,994 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:28,002 : INFO : computing the final decomposition
2016-10-09 22:32:28,002 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:28,005 : INFO : processed documents up to #10
2016-10-09 22:32:28,005 : INFO : topic #0(1.125): -0.314*"go" + -0.268*"qatar" + -0.258*"catch" + -0.255*"friday" + -0.255*"next" + -0.227*"planning" + -0.213*"know" + -0.163*"place" + -0.149*"beach" + -0.149*"like"
2016-10-09 22:32:28,006 : INFO : topic #1(1.046): -0.257*"shisha" + -0.218*"hi" + -0.202*"family" + 0.193*"planning" + 0.183*"go" + -0.166*"say" + -0.166*"quiet" + -0.166*"north" + -0.166*"front" + -0.166*"swimming"
2016-10-09 22:32:28,006 : INFO : topic #2(1.018): 0.432*"card" + 0.215*"would" + 0.173*"gives" + 0.173*"using" + 0.154*"spend" + 0.134*"answers" + 0.134*"please" + 0.134*"guys" + 0.134*"plz" + 0.134*"1000qr"
2016-10-09 22:32:28,006 : INFO : topic #3(1.000): -0.382*"reliable" + -0.191*"anyone" + -0.191*"hard" + -0.191*"garage" + -0.191*"cruiser" + -0.191*"land" + -0.191*"members" + -0.191*"hear" + -0.191*"qatarliving" + -0.191*"experience"
2016-10-09 22:32:28,006 : INFO : topic #4(1.000): -0.408*"well" + -0.408*"coffee" + -0.408*"cup" + -0.408*"nice" + -0.408*"plus" + -0.408*"view" + 0.000*"reliable" + 0.000*"way" + 0.000*"anyone" + 0.000*"experience"
2016-10-09 22:32:28,006 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:28,007 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:28,008 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:28,009 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,009 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,009 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:28,010 : INFO : saved 10x5299 matrix, density=0.228% (121/52990)
2016-10-09 22:32:28,010 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,010 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,010 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,010 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,010 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,011 : INFO : accepted corpus with 10 documents, 5299 features, 121 non-zero entries
2016-10-09 22:32:28,011 : INFO : collecting document frequencies
2016-10-09 22:32:28,011 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:28,011 : INFO : calculating IDF weights for 10 documents and 5298 features (121 matrix non-zeros)
2016-10-09 22:32:28,011 : INFO : using serial LSI version on this node
2016-10-09 22:32:28,011 : INFO : updating model with new documents
2016-10-09 22:32:28,012 : INFO : preparing a new chunk of documents
2016-10-09 22:32:28,012 : DEBUG : converting corpus to csc format
2016-10-09 22:32:28,012 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:28,015 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:28,015 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:28,041 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,140 : DEBUG : running 2 power iterations
2016-10-09 22:32:28,179 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,319 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,432 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:28,440 : INFO : computing the final decomposition
2016-10-09 22:32:28,440 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:28,443 : INFO : processed documents up to #10
2016-10-09 22:32:28,443 : INFO : topic #0(1.162): 0.309*"go" + 0.246*"best" + 0.220*"friday" + 0.220*"next" + 0.207*"know" + 0.195*"place" + 0.194*"beach" + 0.185*"years" + 0.185*"18" + 0.182*"planning"
2016-10-09 22:32:28,443 : INFO : topic #1(1.081): -0.329*"tourists" + -0.312*"18" + -0.312*"years" + -0.256*"places" + -0.245*"visit" + 0.193*"best" + 0.166*"catch" + 0.161*"go" + 0.159*"place" + 0.154*"friday"
2016-10-09 22:32:28,444 : INFO : topic #2(1.014): 0.360*"island" + 0.254*"park" + 0.185*"corniche" + 0.185*"5" + 0.180*"seen" + 0.180*"transfered" + 0.180*"stars" + 0.180*"2013" + 0.180*"banana" + 0.180*"called"
2016-10-09 22:32:28,444 : INFO : topic #3(1.001): 0.387*"good" + 0.387*"time" + 0.387*"spend" + 0.387*"quality" + 0.276*"friends" + -0.202*"suggestions" + 0.200*"place" + -0.153*"romantic" + -0.153*"bay" + -0.153*"maybe"
2016-10-09 22:32:28,444 : INFO : topic #4(1.000): 0.577*"holiday" + 0.577*"experience" + 0.577*"destinations" + -0.000*"time" + -0.000*"spend" + -0.000*"good" + -0.000*"quality" + -0.000*"friends" + 0.000*"suggestions" + -0.000*"place"
2016-10-09 22:32:28,444 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:28,445 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:28,446 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:28,447 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,447 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,447 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:28,448 : INFO : saved 10x5200 matrix, density=0.413% (215/52000)
2016-10-09 22:32:28,448 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,448 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,448 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,448 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,448 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,449 : INFO : accepted corpus with 10 documents, 5200 features, 215 non-zero entries
2016-10-09 22:32:28,449 : INFO : collecting document frequencies
2016-10-09 22:32:28,449 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:28,449 : INFO : calculating IDF weights for 10 documents and 5199 features (215 matrix non-zeros)
2016-10-09 22:32:28,449 : INFO : using serial LSI version on this node
2016-10-09 22:32:28,449 : INFO : updating model with new documents
2016-10-09 22:32:28,450 : INFO : preparing a new chunk of documents
2016-10-09 22:32:28,450 : DEBUG : converting corpus to csc format
2016-10-09 22:32:28,450 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:28,453 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:28,453 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:28,480 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,579 : DEBUG : running 2 power iterations
2016-10-09 22:32:28,618 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,756 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:28,868 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:28,876 : INFO : computing the final decomposition
2016-10-09 22:32:28,876 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:28,879 : INFO : processed documents up to #10
2016-10-09 22:32:28,879 : INFO : topic #0(1.111): 0.250*"qatar" + 0.196*"good" + 0.177*"also" + 0.159*"know" + 0.153*"doha" + 0.140*"wanted" + 0.128*"housing" + 0.127*"transportation" + 0.127*"salary" + 0.127*"single"
2016-10-09 22:32:28,879 : INFO : topic #1(1.059): -0.364*"month" + -0.265*"per" + -0.256*"mate" + -0.176*"qar" + -0.176*"offered" + -0.151*"left" + -0.151*"day" + -0.128*"hence" + -0.128*"contact" + -0.128*"unable"
2016-10-09 22:32:28,879 : INFO : topic #2(1.021): 0.246*"violation" + 0.246*"possible" + -0.188*"home" + 0.185*"anyone" + 0.142*"reputable" + 0.142*"absolutely" + 0.142*"interested" + 0.142*"old" + 0.142*"available" + 0.142*"times"
2016-10-09 22:32:28,879 : INFO : topic #3(1.004): 0.308*"violation" + 0.308*"possible" + 0.241*"home" + 0.161*"people" + 0.161*"designer" + 0.154*"willing" + 0.154*"transfer" + 0.154*"owner" + 0.154*"accept" + 0.154*"new"
2016-10-09 22:32:28,880 : INFO : topic #4(1.001): 0.387*"good" + 0.194*"provide" + 0.194*"person" + 0.194*"deal" + 0.194*"12" + 0.194*"allowance" + -0.157*"possible" + -0.157*"violation" + 0.154*"company" + -0.149*"weeks"
2016-10-09 22:32:28,880 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:28,881 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:28,882 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:28,883 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,883 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,883 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:28,884 : INFO : saved 10x5335 matrix, density=0.544% (290/53350)
2016-10-09 22:32:28,884 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,884 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,884 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,885 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:28,885 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:28,885 : INFO : accepted corpus with 10 documents, 5335 features, 290 non-zero entries
2016-10-09 22:32:28,885 : INFO : collecting document frequencies
2016-10-09 22:32:28,885 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:28,885 : INFO : calculating IDF weights for 10 documents and 5334 features (290 matrix non-zeros)
2016-10-09 22:32:28,886 : INFO : using serial LSI version on this node
2016-10-09 22:32:28,886 : INFO : updating model with new documents
2016-10-09 22:32:28,886 : INFO : preparing a new chunk of documents
2016-10-09 22:32:28,886 : DEBUG : converting corpus to csc format
2016-10-09 22:32:28,887 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:28,889 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:28,890 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:28,916 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,015 : DEBUG : running 2 power iterations
2016-10-09 22:32:29,055 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,193 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,307 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:29,315 : INFO : computing the final decomposition
2016-10-09 22:32:29,315 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:29,318 : INFO : processed documents up to #10
2016-10-09 22:32:29,318 : INFO : topic #0(1.159): -0.212*"petroleum" + -0.212*"qatar" + -0.181*"000" + -0.142*"interview" + -0.134*"2" + -0.131*"visit" + -0.131*"one" + -0.114*"14" + -0.110*"thank" + -0.109*"yearly"
2016-10-09 22:32:29,319 : INFO : topic #1(1.100): -0.252*"qatar" + -0.252*"petroleum" + 0.230*"000" + -0.164*"visit" + -0.164*"one" + -0.157*"interview" + 0.152*"experience" + 0.148*"14" + 0.138*"2" + -0.122*"process"
2016-10-09 22:32:29,319 : INFO : topic #2(1.026): -0.229*"month" + -0.229*"per" + 0.163*"yearly" + -0.153*"10" + -0.153*"enough" + 0.138*"years" + 0.128*"national" + -0.127*"000" + -0.125*"also" + 0.119*"final"
2016-10-09 22:32:29,319 : INFO : topic #3(1.012): -0.232*"help" + -0.190*"like" + -0.157*"total" + -0.157*"state" + -0.157*"terminated" + -0.157*"anytime" + -0.157*"mean" + -0.157*"4000" + -0.157*"3500" + -0.157*"period"
2016-10-09 22:32:29,319 : INFO : topic #4(0.988): -0.253*"month" + -0.253*"per" + -0.168*"10" + -0.168*"enough" + -0.145*"info" + -0.145*"cons" + -0.145*"uk" + -0.145*"main" + -0.145*"vs" + -0.145*"talks"
2016-10-09 22:32:29,319 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:29,321 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:29,322 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:29,323 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,323 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,323 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:29,324 : INFO : saved 10x5332 matrix, density=0.338% (180/53320)
2016-10-09 22:32:29,324 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,324 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,324 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:29,324 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:29,324 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,325 : INFO : accepted corpus with 10 documents, 5332 features, 180 non-zero entries
2016-10-09 22:32:29,325 : INFO : collecting document frequencies
2016-10-09 22:32:29,325 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:29,325 : INFO : calculating IDF weights for 10 documents and 5331 features (180 matrix non-zeros)
2016-10-09 22:32:29,325 : INFO : using serial LSI version on this node
2016-10-09 22:32:29,325 : INFO : updating model with new documents
2016-10-09 22:32:29,326 : INFO : preparing a new chunk of documents
2016-10-09 22:32:29,326 : DEBUG : converting corpus to csc format
2016-10-09 22:32:29,326 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:29,329 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:29,329 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:29,355 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,455 : DEBUG : running 2 power iterations
2016-10-09 22:32:29,494 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,633 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,746 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:29,754 : INFO : computing the final decomposition
2016-10-09 22:32:29,754 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:29,757 : INFO : processed documents up to #10
2016-10-09 22:32:29,757 : INFO : topic #0(1.169): 0.279*"doha" + 0.229*"baby" + 0.208*"get" + 0.195*"coming" + 0.188*"vaccination" + 0.181*"vaccinations" + 0.172*"much" + 0.171*"regular" + 0.169*"remaining" + 0.141*"clinic"
2016-10-09 22:32:29,757 : INFO : topic #1(1.040): 0.260*"would" + 0.188*"coming" + 0.184*"get" + -0.176*"clinic" + -0.176*"u" + -0.168*"regular" + -0.167*"recommend" + -0.167*"communicate" + -0.167*"good" + 0.163*"know"
2016-10-09 22:32:29,757 : INFO : topic #2(1.027): -0.287*"doha" + -0.254*"selection" + -0.254*"law" + -0.254*"buy" + 0.176*"remaining" + -0.173*"recommend" + -0.173*"good" + -0.173*"communicate" + 0.151*"know" + 0.144*"schools"
2016-10-09 22:32:29,757 : INFO : topic #3(1.003): -0.291*"made" + 0.214*"would" + 0.211*"considering" + 0.211*"job" + 0.150*"law" + 0.150*"buy" + 0.150*"selection" + -0.145*"someone" + -0.145*"spent" + -0.145*"nothing"
2016-10-09 22:32:29,758 : INFO : topic #4(1.001): -0.334*"made" + 0.208*"know" + 0.185*"anyone" + 0.185*"schools" + -0.167*"cure" + -0.167*"spent" + -0.167*"lot" + -0.167*"someone" + -0.167*"ones" + -0.167*"nothing"
2016-10-09 22:32:29,758 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:29,759 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:29,760 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:29,761 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,761 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,761 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:29,761 : INFO : saved 10x5307 matrix, density=0.268% (142/53070)
2016-10-09 22:32:29,761 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,762 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,762 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:29,762 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:29,762 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:29,762 : INFO : accepted corpus with 10 documents, 5307 features, 142 non-zero entries
2016-10-09 22:32:29,762 : INFO : collecting document frequencies
2016-10-09 22:32:29,763 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:29,763 : INFO : calculating IDF weights for 10 documents and 5306 features (142 matrix non-zeros)
2016-10-09 22:32:29,763 : INFO : using serial LSI version on this node
2016-10-09 22:32:29,763 : INFO : updating model with new documents
2016-10-09 22:32:29,763 : INFO : preparing a new chunk of documents
2016-10-09 22:32:29,763 : DEBUG : converting corpus to csc format
2016-10-09 22:32:29,764 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:29,767 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:29,767 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:29,793 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:29,893 : DEBUG : running 2 power iterations
2016-10-09 22:32:29,932 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,070 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,183 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:30,191 : INFO : computing the final decomposition
2016-10-09 22:32:30,191 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:30,194 : INFO : processed documents up to #10
2016-10-09 22:32:30,194 : INFO : topic #0(1.165): 0.317*"cold" + 0.302*"curious" + 0.240*"winter" + 0.228*"coming" + 0.204*"doha" + 0.190*"hi" + 0.171*"thank" + 0.163*"already" + 0.163*"november" + 0.163*"share"
2016-10-09 22:32:30,194 : INFO : topic #1(1.056): 0.248*"curious" + -0.208*"coming" + 0.194*"winter" + -0.189*"bring" + 0.175*"doha" + -0.174*"thank" + -0.148*"qatar" + -0.140*"oct" + -0.140*"pack" + -0.140*"30"
2016-10-09 22:32:30,194 : INFO : topic #2(1.027): -0.288*"normal" + 0.278*"curious" + -0.179*"know" + -0.149*"thanks" + -0.144*"else" + -0.144*"pain" + -0.144*"told" + -0.144*"correct" + -0.144*"recent" + -0.144*"rid"
2016-10-09 22:32:30,194 : INFO : topic #3(1.000): 0.314*"also" + 0.314*"travel" + 0.157*"vegetarian" + 0.157*"august" + 0.157*"visas" + 0.157*"required" + 0.157*"please" + 0.157*"plan" + 0.157*"europe" + 0.157*"india"
2016-10-09 22:32:30,195 : INFO : topic #4(0.995): -0.269*"western" + -0.269*"visiting" + -0.269*"wear" + -0.269*"clothes" + -0.269*"jeans" + -0.269*"woman" + -0.202*"december" + -0.182*"bring" + -0.158*"swimming" + -0.158*"route"
2016-10-09 22:32:30,195 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:30,196 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:30,196 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:30,198 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,198 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,198 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:30,198 : INFO : saved 10x5309 matrix, density=0.358% (190/53090)
2016-10-09 22:32:30,198 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,199 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,199 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:30,199 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:30,199 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,199 : INFO : accepted corpus with 10 documents, 5309 features, 190 non-zero entries
2016-10-09 22:32:30,199 : INFO : collecting document frequencies
2016-10-09 22:32:30,199 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:30,200 : INFO : calculating IDF weights for 10 documents and 5308 features (190 matrix non-zeros)
2016-10-09 22:32:30,200 : INFO : using serial LSI version on this node
2016-10-09 22:32:30,200 : INFO : updating model with new documents
2016-10-09 22:32:30,200 : INFO : preparing a new chunk of documents
2016-10-09 22:32:30,201 : DEBUG : converting corpus to csc format
2016-10-09 22:32:30,201 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:30,204 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:30,204 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:30,230 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,329 : DEBUG : running 2 power iterations
2016-10-09 22:32:30,368 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,507 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,620 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:30,628 : INFO : computing the final decomposition
2016-10-09 22:32:30,628 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:30,631 : INFO : processed documents up to #10
2016-10-09 22:32:30,631 : INFO : topic #0(1.178): 0.315*"puppy" + 0.298*"small" + 0.298*"dog" + 0.296*"would" + 0.261*"buy" + 0.259*"doha" + 0.178*"bring" + 0.170*"dogs" + 0.169*"food" + 0.139*"cat"
2016-10-09 22:32:30,631 : INFO : topic #1(1.046): -0.239*"cat" + 0.213*"puppy" + -0.193*"cost" + -0.193*"much" + 0.178*"dog" + 0.178*"small" + -0.174*"www" + -0.174*"http" + -0.174*"com" + -0.174*"qatarliving"
2016-10-09 22:32:30,631 : INFO : topic #2(1.008): 0.234*"cost" + 0.234*"much" + 0.190*"know" + 0.190*"let" + 0.190*"pup" + 0.148*"qatar" + 0.148*"place" + -0.136*"food" + 0.130*"1" + -0.128*"http"
2016-10-09 22:32:30,631 : INFO : topic #3(1.003): 0.197*"store" + 0.197*"somebody" + 0.197*"necessary" + 0.197*"successful" + 0.197*"recommend" + 0.197*"thanks" + 0.197*"buying" + 0.197*"cats" + 0.197*"stuff" + 0.197*"finding"
2016-10-09 22:32:30,632 : INFO : topic #4(1.000): 0.447*"christian" + 0.447*"muslim" + 0.447*"attachment" + 0.447*"jesus" + 0.447*"see" + -0.000*"rats" + -0.000*"house" + -0.000*"back" + 0.000*"could" + 0.000*"cats"
2016-10-09 22:32:30,632 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:30,633 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:30,634 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:30,635 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,635 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,635 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:30,635 : INFO : saved 10x5324 matrix, density=0.329% (175/53240)
2016-10-09 22:32:30,636 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,636 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,636 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:30,636 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:30,636 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:30,636 : INFO : accepted corpus with 10 documents, 5324 features, 175 non-zero entries
2016-10-09 22:32:30,636 : INFO : collecting document frequencies
2016-10-09 22:32:30,637 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:30,637 : INFO : calculating IDF weights for 10 documents and 5323 features (175 matrix non-zeros)
2016-10-09 22:32:30,637 : INFO : using serial LSI version on this node
2016-10-09 22:32:30,637 : INFO : updating model with new documents
2016-10-09 22:32:30,637 : INFO : preparing a new chunk of documents
2016-10-09 22:32:30,638 : DEBUG : converting corpus to csc format
2016-10-09 22:32:30,638 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:30,641 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:30,641 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:30,668 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,767 : DEBUG : running 2 power iterations
2016-10-09 22:32:30,806 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:30,944 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,058 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:31,065 : INFO : computing the final decomposition
2016-10-09 22:32:31,065 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:31,068 : INFO : processed documents up to #10
2016-10-09 22:32:31,069 : INFO : topic #0(1.127): -0.261*"much" + -0.227*"would" + -0.198*"also" + -0.162*"qatar" + -0.160*"pay" + -0.160*"loan" + -0.147*"know" + -0.125*"qr" + -0.124*"thanks" + -0.124*"buying"
2016-10-09 22:32:31,069 : INFO : topic #1(1.074): -0.324*"recommend" + -0.324*"anyone" + -0.305*"window" + -0.305*"applied" + -0.223*"place" + 0.182*"selection" + 0.182*"law" + 0.181*"doha" + 0.166*"buy" + -0.159*"apartment"
2016-10-09 22:32:31,069 : INFO : topic #2(1.060): 0.294*"doha" + 0.287*"law" + 0.287*"selection" + 0.268*"buy" + 0.173*"anyone" + 0.173*"recommend" + 0.160*"window" + 0.160*"applied" + -0.126*"much" + -0.108*"would"
2016-10-09 22:32:31,069 : INFO : topic #3(1.014): -0.366*"qr" + -0.314*"wife" + -0.157*"enginner" + -0.157*"relocate" + -0.157*"house" + -0.157*"living" + -0.157*"proceed" + -0.157*"1500" + -0.157*"civil" + -0.157*"14000"
2016-10-09 22:32:31,069 : INFO : topic #4(0.994): 0.372*"months" + 0.372*"sell" + 0.189*"one" + 0.186*"long" + 0.186*"weeks" + 0.186*"want" + 0.186*"leaving" + 0.186*"prado" + 0.186*"best" + 0.186*"resale"
2016-10-09 22:32:31,069 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:31,070 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:31,071 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:31,073 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,073 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,073 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:31,073 : INFO : saved 10x5265 matrix, density=0.346% (182/52650)
2016-10-09 22:32:31,073 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,073 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,073 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,074 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,074 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,074 : INFO : accepted corpus with 10 documents, 5265 features, 182 non-zero entries
2016-10-09 22:32:31,074 : INFO : collecting document frequencies
2016-10-09 22:32:31,074 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:31,074 : INFO : calculating IDF weights for 10 documents and 5264 features (182 matrix non-zeros)
2016-10-09 22:32:31,075 : INFO : using serial LSI version on this node
2016-10-09 22:32:31,075 : INFO : updating model with new documents
2016-10-09 22:32:31,075 : INFO : preparing a new chunk of documents
2016-10-09 22:32:31,075 : DEBUG : converting corpus to csc format
2016-10-09 22:32:31,076 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:31,079 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:31,079 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:31,105 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,205 : DEBUG : running 2 power iterations
2016-10-09 22:32:31,244 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,381 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,494 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:31,501 : INFO : computing the final decomposition
2016-10-09 22:32:31,502 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:31,504 : INFO : processed documents up to #10
2016-10-09 22:32:31,505 : INFO : topic #0(1.125): 0.233*"child" + 0.180*"bus" + 0.171*"seat" + 0.168*"one" + 0.165*"front" + 0.154*"children" + 0.147*"vehicles" + 0.143*"would" + 0.142*"kids" + 0.140*"law"
2016-10-09 22:32:31,505 : INFO : topic #1(1.060): -0.275*"sure" + -0.248*"kids" + 0.216*"child" + -0.210*"would" + 0.201*"bus" + -0.153*"front" + -0.144*"break" + -0.144*"worried" + -0.144*"airlines" + -0.144*"seats"
2016-10-09 22:32:31,505 : INFO : topic #2(1.041): -0.349*"baby" + -0.269*"sign" + 0.236*"bus" + -0.230*"everything" + -0.230*"stores" + -0.179*"board" + 0.136*"child" + 0.136*"school" + -0.119*"doha" + 0.118*"found"
2016-10-09 22:32:31,505 : INFO : topic #3(1.029): 0.368*"selection" + 0.368*"buy" + 0.300*"law" + 0.212*"doha" + 0.206*"qatar" + -0.157*"one" + -0.150*"seat" + -0.140*"sign" + -0.130*"baby" + -0.127*"babies"
2016-10-09 22:32:31,505 : INFO : topic #4(1.020): 0.245*"one" + 0.160*"seat" + 0.159*"buy" + 0.159*"selection" + -0.159*"sure" + 0.153*"law" + -0.153*"bus" + -0.153*"school" + -0.142*"house" + -0.142*"feedback"
2016-10-09 22:32:31,506 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:31,507 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:31,507 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:31,509 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,509 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,509 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:31,509 : INFO : saved 10x5287 matrix, density=0.361% (191/52870)
2016-10-09 22:32:31,509 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,510 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,510 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,510 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,510 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,510 : INFO : accepted corpus with 10 documents, 5287 features, 191 non-zero entries
2016-10-09 22:32:31,510 : INFO : collecting document frequencies
2016-10-09 22:32:31,510 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:31,511 : INFO : calculating IDF weights for 10 documents and 5286 features (191 matrix non-zeros)
2016-10-09 22:32:31,511 : INFO : using serial LSI version on this node
2016-10-09 22:32:31,511 : INFO : updating model with new documents
2016-10-09 22:32:31,511 : INFO : preparing a new chunk of documents
2016-10-09 22:32:31,511 : DEBUG : converting corpus to csc format
2016-10-09 22:32:31,512 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:31,515 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:31,515 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:31,542 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,640 : DEBUG : running 2 power iterations
2016-10-09 22:32:31,679 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,818 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:31,931 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:31,939 : INFO : computing the final decomposition
2016-10-09 22:32:31,939 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:31,942 : INFO : processed documents up to #10
2016-10-09 22:32:31,942 : INFO : topic #0(1.168): 0.194*"beaches" + 0.191*"take" + 0.188*"beach" + 0.164*"dunes" + 0.163*"would" + 0.159*"umm" + 0.159*"anyone" + 0.155*"could" + 0.155*"start" + 0.155*"clean"
2016-10-09 22:32:31,942 : INFO : topic #1(1.031): 0.234*"public" + 0.234*"ridiculous" + 0.211*"suggestions" + 0.181*"one" + -0.160*"would" + 0.157*"please" + 0.137*"license" + 0.137*"camping" + -0.135*"could" + -0.133*"beaches"
2016-10-09 22:32:31,943 : INFO : topic #2(1.008): -0.368*"ridiculous" + -0.368*"public" + 0.353*"suggestions" + -0.199*"speed" + -0.199*"gulf" + -0.199*"times" + 0.177*"happenings" + 0.177*"holidays" + 0.177*"new" + 0.177*"something"
2016-10-09 22:32:31,943 : INFO : topic #3(1.005): -0.327*"suggestions" + -0.235*"booze" + -0.235*"party" + -0.235*"private" + -0.235*"let" + 0.169*"tell" + 0.169*"okay" + 0.168*"license" + 0.168*"camping" + -0.164*"new"
2016-10-09 22:32:31,943 : INFO : topic #4(0.995): -0.325*"ridiculous" + -0.325*"public" + 0.263*"gulf" + 0.263*"times" + 0.263*"speed" + -0.159*"beach" + -0.153*"okay" + -0.153*"tell" + 0.132*"topics" + 0.132*"article"
2016-10-09 22:32:31,943 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:31,944 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:31,945 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:31,946 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,946 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,946 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:31,947 : INFO : saved 10x5336 matrix, density=0.392% (209/53360)
2016-10-09 22:32:31,947 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,947 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,947 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,948 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:31,948 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:31,948 : INFO : accepted corpus with 10 documents, 5336 features, 209 non-zero entries
2016-10-09 22:32:31,948 : INFO : collecting document frequencies
2016-10-09 22:32:31,948 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:31,948 : INFO : calculating IDF weights for 10 documents and 5335 features (209 matrix non-zeros)
2016-10-09 22:32:31,949 : INFO : using serial LSI version on this node
2016-10-09 22:32:31,949 : INFO : updating model with new documents
2016-10-09 22:32:31,949 : INFO : preparing a new chunk of documents
2016-10-09 22:32:31,949 : DEBUG : converting corpus to csc format
2016-10-09 22:32:31,949 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:31,952 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:31,953 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:31,979 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,078 : DEBUG : running 2 power iterations
2016-10-09 22:32:32,117 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,256 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,369 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:32,376 : INFO : computing the final decomposition
2016-10-09 22:32:32,377 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:32,379 : INFO : processed documents up to #10
2016-10-09 22:32:32,380 : INFO : topic #0(1.116): 0.255*"doha" + 0.252*"cars" + 0.177*"would" + 0.168*"much" + 0.154*"best" + 0.146*"price" + 0.146*"toyota" + 0.136*"reliable" + 0.133*"renault" + 0.121*"nissan"
2016-10-09 22:32:32,380 : INFO : topic #1(1.045): -0.257*"much" + 0.252*"doha" + 0.210*"cars" + -0.204*"would" + 0.159*"best" + -0.139*"pay" + -0.136*"thanks" + -0.133*"today" + -0.133*"buying" + -0.133*"bachelor"
2016-10-09 22:32:32,380 : INFO : topic #2(1.023): 0.219*"would" + 0.163*"much" + -0.150*"anyone" + -0.142*"reliable" + -0.141*"years" + 0.140*"toyota" + 0.140*"price" + -0.112*"reputable" + -0.112*"sorry" + -0.112*"interested"
2016-10-09 22:32:32,380 : INFO : topic #3(1.010): 0.259*"anybody" + 0.259*"share" + 0.259*"using" + 0.259*"yes" + 0.259*"maintenance" + 0.259*"performance" + 0.259*"mean" + 0.221*"please" + 0.196*"experience" + 0.195*"renault"
2016-10-09 22:32:32,380 : INFO : topic #4(1.005): 0.147*"reliable" + -0.144*"roof" + -0.144*"happens" + -0.144*"middle" + -0.144*"east" + -0.144*"thin" + -0.144*"light" + -0.144*"quite" + -0.144*"sun" + -0.144*"thank"
2016-10-09 22:32:32,380 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:32,382 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:32,382 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:32,384 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,384 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,384 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:32,384 : INFO : saved 10x5150 matrix, density=0.305% (157/51500)
2016-10-09 22:32:32,384 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,384 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,384 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:32,385 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:32,385 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,385 : INFO : accepted corpus with 10 documents, 5150 features, 157 non-zero entries
2016-10-09 22:32:32,385 : INFO : collecting document frequencies
2016-10-09 22:32:32,385 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:32,385 : INFO : calculating IDF weights for 10 documents and 5149 features (157 matrix non-zeros)
2016-10-09 22:32:32,386 : INFO : using serial LSI version on this node
2016-10-09 22:32:32,386 : INFO : updating model with new documents
2016-10-09 22:32:32,386 : INFO : preparing a new chunk of documents
2016-10-09 22:32:32,386 : DEBUG : converting corpus to csc format
2016-10-09 22:32:32,387 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:32,390 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:32,390 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:32,416 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,515 : DEBUG : running 2 power iterations
2016-10-09 22:32:32,555 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,692 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,804 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:32,812 : INFO : computing the final decomposition
2016-10-09 22:32:32,812 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:32,815 : INFO : processed documents up to #10
2016-10-09 22:32:32,815 : INFO : topic #0(1.209): 0.696*"water" + 0.270*"drinking" + 0.224*"using" + 0.224*"filter" + 0.206*"tap" + 0.183*"bottled" + 0.112*"instead" + 0.112*"opinion" + 0.112*"anybody" + 0.112*"need"
2016-10-09 22:32:32,815 : INFO : topic #1(1.128): -0.276*"plants" + -0.224*"know" + -0.217*"nurseries" + -0.205*"doha" + -0.200*"anyone" + 0.186*"water" + -0.166*"photography" + -0.166*"indoor" + -0.166*"besides" + -0.166*"buy"
2016-10-09 22:32:32,815 : INFO : topic #2(1.024): -0.315*"business" + -0.241*"wanted" + -0.187*"places" + -0.178*"getting" + -0.178*"phone" + -0.178*"answer" + -0.178*"contact" + -0.178*"couple" + -0.178*"numbers" + -0.148*"tried"
2016-10-09 22:32:32,816 : INFO : topic #3(1.011): -0.250*"happening" + -0.212*"tried" + 0.205*"low" + 0.205*"bcz" + 0.205*"told" + 0.205*"doctor" + 0.205*"explain" + 0.194*"business" + -0.179*"getting" + -0.179*"answer"
2016-10-09 22:32:32,816 : INFO : topic #4(1.001): -0.248*"treatment" + -0.238*"explain" + -0.238*"bcz" + -0.238*"doctor" + -0.238*"low" + -0.238*"told" + -0.202*"getting" + -0.202*"contact" + -0.202*"numbers" + -0.202*"couple"
2016-10-09 22:32:32,816 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:32,817 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:32,818 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:32,819 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,819 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,819 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:32,820 : INFO : saved 10x5311 matrix, density=0.333% (177/53110)
2016-10-09 22:32:32,820 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,820 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,820 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:32,820 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:32,821 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:32,821 : INFO : accepted corpus with 10 documents, 5311 features, 177 non-zero entries
2016-10-09 22:32:32,821 : INFO : collecting document frequencies
2016-10-09 22:32:32,821 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:32,821 : INFO : calculating IDF weights for 10 documents and 5310 features (177 matrix non-zeros)
2016-10-09 22:32:32,821 : INFO : using serial LSI version on this node
2016-10-09 22:32:32,821 : INFO : updating model with new documents
2016-10-09 22:32:32,822 : INFO : preparing a new chunk of documents
2016-10-09 22:32:32,822 : DEBUG : converting corpus to csc format
2016-10-09 22:32:32,822 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:32,825 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:32,826 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:32,852 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:32,951 : DEBUG : running 2 power iterations
2016-10-09 22:32:32,990 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,129 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,242 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:33,250 : INFO : computing the final decomposition
2016-10-09 22:32:33,250 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:33,253 : INFO : processed documents up to #10
2016-10-09 22:32:33,253 : INFO : topic #0(1.070): 0.460*"one" + 0.334*"ever" + 0.334*"places" + 0.334*"boring" + 0.323*"public" + 0.323*"ridiculous" + 0.323*"beach" + 0.221*"doha" + 0.075*"ras" + 0.075*"laffan"
2016-10-09 22:32:33,253 : INFO : topic #1(1.069): -0.244*"party" + -0.222*"restaurant" + -0.210*"anyone" + -0.182*"venues" + -0.182*"given" + -0.182*"place" + -0.182*"food" + -0.182*"kfc" + -0.182*"rent" + -0.182*"already"
2016-10-09 22:32:33,253 : INFO : topic #2(1.020): -0.231*"hmc" + -0.205*"laffan" + -0.205*"ras" + -0.154*"training" + -0.154*"salary" + -0.137*"live" + -0.133*"2" + -0.133*"baby" + -0.133*"speech" + -0.133*"son"
2016-10-09 22:32:33,254 : INFO : topic #3(1.016): 0.168*"party" + -0.166*"laffan" + -0.166*"ras" + -0.157*"air" + -0.157*"bad" + -0.157*"gave" + -0.157*"crew" + -0.157*"said" + -0.157*"gulf" + -0.157*"experience"
2016-10-09 22:32:33,254 : INFO : topic #4(1.001): -0.375*"result" + -0.375*"grade" + -0.187*"university" + -0.187*"criteria" + -0.187*"student" + -0.187*"texas" + -0.187*"straight" + -0.187*"anybody" + -0.187*"12" + -0.187*"rejected"
2016-10-09 22:32:33,254 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:33,255 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:33,256 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:33,257 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,257 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,257 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:33,258 : INFO : saved 10x5334 matrix, density=0.422% (225/53340)
2016-10-09 22:32:33,258 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,258 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,258 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:33,259 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:33,259 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,259 : INFO : accepted corpus with 10 documents, 5334 features, 225 non-zero entries
2016-10-09 22:32:33,259 : INFO : collecting document frequencies
2016-10-09 22:32:33,259 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:33,259 : INFO : calculating IDF weights for 10 documents and 5333 features (225 matrix non-zeros)
2016-10-09 22:32:33,259 : INFO : using serial LSI version on this node
2016-10-09 22:32:33,259 : INFO : updating model with new documents
2016-10-09 22:32:33,260 : INFO : preparing a new chunk of documents
2016-10-09 22:32:33,260 : DEBUG : converting corpus to csc format
2016-10-09 22:32:33,260 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:33,263 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:33,263 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:33,290 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,389 : DEBUG : running 2 power iterations
2016-10-09 22:32:33,428 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,567 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,680 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:33,688 : INFO : computing the final decomposition
2016-10-09 22:32:33,688 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:33,691 : INFO : processed documents up to #10
2016-10-09 22:32:33,691 : INFO : topic #0(1.131): 0.168*"back" + 0.166*"american" + 0.162*"schools" + 0.162*"uk" + 0.158*"many" + 0.157*"groups" + 0.157*"private" + 0.135*"home" + 0.133*"qatar" + 0.127*"appreciated"
2016-10-09 22:32:33,692 : INFO : topic #1(1.037): -0.270*"child" + -0.268*"bus" + -0.185*"house" + -0.185*"like" + -0.185*"son" + -0.185*"next" + -0.185*"park" + -0.185*"month" + -0.185*"7yrs" + 0.161*"small"
2016-10-09 22:32:33,692 : INFO : topic #2(1.026): 0.285*"bus" + 0.227*"start" + 0.227*"use" + 0.227*"books" + 0.218*"3" + 0.178*"child" + 0.170*"small" + 0.143*"found" + -0.136*"private" + -0.136*"groups"
2016-10-09 22:32:33,692 : INFO : topic #3(1.002): 0.257*"much" + 0.178*"use" + 0.178*"books" + 0.178*"start" + 0.153*"home" + 0.152*"daughter" + -0.146*"bus" + 0.128*"summer" + 0.128*"toddler" + 0.128*"cannot"
2016-10-09 22:32:33,692 : INFO : topic #4(0.990): 0.202*"much" + 0.200*"thinking" + 0.200*"hello" + 0.200*"international" + 0.200*"family" + 0.200*"british" + 0.200*"anything" + -0.168*"uk" + -0.146*"back" + -0.135*"small"
2016-10-09 22:32:33,692 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:33,693 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:33,694 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:33,696 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,696 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,696 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:33,696 : INFO : saved 10x5246 matrix, density=0.374% (196/52460)
2016-10-09 22:32:33,696 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,696 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,696 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:33,697 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:33,697 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:33,697 : INFO : accepted corpus with 10 documents, 5246 features, 196 non-zero entries
2016-10-09 22:32:33,697 : INFO : collecting document frequencies
2016-10-09 22:32:33,697 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:33,697 : INFO : calculating IDF weights for 10 documents and 5245 features (196 matrix non-zeros)
2016-10-09 22:32:33,698 : INFO : using serial LSI version on this node
2016-10-09 22:32:33,698 : INFO : updating model with new documents
2016-10-09 22:32:33,698 : INFO : preparing a new chunk of documents
2016-10-09 22:32:33,698 : DEBUG : converting corpus to csc format
2016-10-09 22:32:33,699 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:33,702 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:33,702 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:33,728 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:33,827 : DEBUG : running 2 power iterations
2016-10-09 22:32:33,866 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,004 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,118 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:34,125 : INFO : computing the final decomposition
2016-10-09 22:32:34,126 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:34,128 : INFO : processed documents up to #10
2016-10-09 22:32:34,129 : INFO : topic #0(1.141): -0.265*"gratuity" + -0.224*"service" + -0.224*"end" + -0.205*"period" + -0.205*"7" + -0.205*"confirm" + -0.205*"years" + -0.205*"benefits" + -0.194*"working" + -0.182*"qatar"
2016-10-09 22:32:34,129 : INFO : topic #1(1.046): -0.224*"someone" + -0.220*"dinner" + -0.220*"table" + -0.220*"want" + -0.220*"share" + -0.220*"ask" + -0.210*"get" + -0.204*"please" + -0.183*"many" + -0.160*"anybody"
2016-10-09 22:32:34,129 : INFO : topic #2(1.008): 0.294*"good" + 0.252*"also" + 0.252*"deposit" + 0.252*"months" + 0.182*"doha" + 0.147*"person" + 0.147*"deal" + 0.147*"housing" + 0.147*"provide" + 0.147*"transportation"
2016-10-09 22:32:34,129 : INFO : topic #3(1.002): -0.407*"respect" + -0.271*"people" + -0.271*"culture" + -0.271*"think" + 0.155*"anybody" + -0.136*"religion" + -0.136*"feel" + -0.136*"local" + -0.136*"without" + -0.136*"idea"
2016-10-09 22:32:34,129 : INFO : topic #4(1.000): 0.457*"crime" + 0.305*"considered" + 0.305*"wife" + 0.305*"west" + 0.305*"polygamy" + 0.152*"agrees" + 0.152*"besides" + 0.152*"marriage" + 0.152*"islamic" + 0.152*"countries"
2016-10-09 22:32:34,130 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:34,131 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:34,132 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:34,133 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,133 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,133 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:34,133 : INFO : saved 10x5234 matrix, density=0.283% (148/52340)
2016-10-09 22:32:34,133 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,134 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,134 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:34,134 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:34,134 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,134 : INFO : accepted corpus with 10 documents, 5234 features, 148 non-zero entries
2016-10-09 22:32:34,134 : INFO : collecting document frequencies
2016-10-09 22:32:34,134 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:34,135 : INFO : calculating IDF weights for 10 documents and 5233 features (148 matrix non-zeros)
2016-10-09 22:32:34,135 : INFO : using serial LSI version on this node
2016-10-09 22:32:34,135 : INFO : updating model with new documents
2016-10-09 22:32:34,135 : INFO : preparing a new chunk of documents
2016-10-09 22:32:34,135 : DEBUG : converting corpus to csc format
2016-10-09 22:32:34,136 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:34,139 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:34,139 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:34,165 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,264 : DEBUG : running 2 power iterations
2016-10-09 22:32:34,303 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,440 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,553 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:34,561 : INFO : computing the final decomposition
2016-10-09 22:32:34,561 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:34,564 : INFO : processed documents up to #10
2016-10-09 22:32:34,565 : INFO : topic #0(1.059): -0.241*"qatar" + -0.231*"moon" + -0.215*"islam" + -0.195*"hi" + -0.174*"18th" + -0.174*"wanted" + -0.174*"confirm" + -0.174*"national" + -0.174*"december" + -0.174*"thanks"
2016-10-09 22:32:34,565 : INFO : topic #1(1.043): 0.316*"moon" + 0.236*"islam" + 0.183*"right" + -0.172*"hi" + 0.156*"dirty" + 0.156*"world" + 0.156*"idiots" + 0.156*"live" + 0.156*"fool" + -0.156*"confirm"
2016-10-09 22:32:34,565 : INFO : topic #2(1.032): 0.362*"one" + 0.323*"getting" + 0.323*"ones" + 0.323*"waiting" + 0.323*"still" + 0.194*"u" + 0.194*"resale" + 0.194*"etc" + 0.194*"prado" + 0.194*"cost"
2016-10-09 22:32:34,565 : INFO : topic #3(1.007): -0.356*"wearing" + -0.190*"need" + -0.188*"teachers" + -0.178*"simply" + -0.178*"dressed" + -0.178*"however" + -0.178*"respect" + -0.178*"find" + -0.178*"culture" + -0.178*"packed"
2016-10-09 22:32:34,565 : INFO : topic #4(1.000): 0.447*"gym" + 0.447*"earning" + 0.447*"guy" + 0.447*"affordable" + 0.447*"month" + -0.000*"teachers" + -0.000*"wearing" + -0.000*"need" + -0.000*"teacher" + -0.000*"country"
2016-10-09 22:32:34,565 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:34,566 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:34,567 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:34,568 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,569 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,569 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:34,569 : INFO : saved 10x5324 matrix, density=0.383% (204/53240)
2016-10-09 22:32:34,569 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,569 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,569 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:34,570 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:34,570 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:34,570 : INFO : accepted corpus with 10 documents, 5324 features, 204 non-zero entries
2016-10-09 22:32:34,570 : INFO : collecting document frequencies
2016-10-09 22:32:34,570 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:34,570 : INFO : calculating IDF weights for 10 documents and 5323 features (204 matrix non-zeros)
2016-10-09 22:32:34,571 : INFO : using serial LSI version on this node
2016-10-09 22:32:34,571 : INFO : updating model with new documents
2016-10-09 22:32:34,571 : INFO : preparing a new chunk of documents
2016-10-09 22:32:34,571 : DEBUG : converting corpus to csc format
2016-10-09 22:32:34,571 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:34,574 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:34,575 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:34,601 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,700 : DEBUG : running 2 power iterations
2016-10-09 22:32:34,739 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,878 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:34,990 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:34,997 : INFO : computing the final decomposition
2016-10-09 22:32:34,998 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:35,000 : INFO : processed documents up to #10
2016-10-09 22:32:35,001 : INFO : topic #0(1.108): -0.192*"decent" + -0.186*"get" + -0.175*"need" + -0.170*"advance" + -0.165*"directions" + -0.155*"help" + -0.155*"embassy" + -0.155*"appointment" + -0.155*"set" + -0.155*"driving"
2016-10-09 22:32:35,001 : INFO : topic #1(1.041): -0.236*"qatar" + -0.207*"gps" + -0.207*"wanted" + -0.207*"garmin" + -0.183*"english" + -0.183*"books" + -0.183*"" + -0.170*"us" + -0.152*"embassy" + -0.152*"appointment"
2016-10-09 22:32:35,001 : INFO : topic #2(1.020): 0.333*"thai" + 0.222*"food" + -0.177*"al" + -0.177*"taxis" + -0.177*"karwa" + -0.155*"repaire" + 0.152*"shops" + -0.138*"new" + -0.137*"anyone" + -0.115*"lulu"
2016-10-09 22:32:35,001 : INFO : topic #3(1.008): -0.238*"decent" + 0.221*"thai" + -0.158*"really" + -0.158*"ones" + -0.158*"fresh" + -0.158*"bad" + -0.158*"bread" + -0.158*"vegetables" + -0.158*"carrefour" + -0.158*"fruits"
2016-10-09 22:32:35,001 : INFO : topic #4(0.995): 0.177*"maps" + 0.177*"first" + 0.177*"couple" + -0.150*"thai" + 0.142*"decent" + -0.140*"need" + -0.135*"al" + -0.135*"taxis" + -0.135*"karwa" + 0.132*"lulu"
2016-10-09 22:32:35,001 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:35,003 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:35,004 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:35,005 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,005 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,005 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:35,005 : INFO : saved 10x5323 matrix, density=0.385% (205/53230)
2016-10-09 22:32:35,005 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,006 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,006 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,006 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,006 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,006 : INFO : accepted corpus with 10 documents, 5323 features, 205 non-zero entries
2016-10-09 22:32:35,006 : INFO : collecting document frequencies
2016-10-09 22:32:35,007 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:35,007 : INFO : calculating IDF weights for 10 documents and 5322 features (205 matrix non-zeros)
2016-10-09 22:32:35,007 : INFO : using serial LSI version on this node
2016-10-09 22:32:35,007 : INFO : updating model with new documents
2016-10-09 22:32:35,008 : INFO : preparing a new chunk of documents
2016-10-09 22:32:35,008 : DEBUG : converting corpus to csc format
2016-10-09 22:32:35,008 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:35,011 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:35,011 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:35,038 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,137 : DEBUG : running 2 power iterations
2016-10-09 22:32:35,176 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,315 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,428 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:35,436 : INFO : computing the final decomposition
2016-10-09 22:32:35,436 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:35,439 : INFO : processed documents up to #10
2016-10-09 22:32:35,439 : INFO : topic #0(1.177): 0.283*"sponsorship" + 0.177*"visit" + 0.170*"visa" + 0.165*"work" + 0.157*"family" + 0.157*"sponsor" + 0.154*"qatar" + 0.150*"help" + 0.150*"months" + 0.141*"please"
2016-10-09 22:32:35,439 : INFO : topic #1(1.078): -0.402*"sponsorship" + -0.253*"work" + 0.204*"months" + -0.191*"sponsor" + 0.166*"visit" + 0.164*"extend" + 0.164*"anybody" + 0.164*"whether" + 0.164*"maximum" + 0.164*"currently"
2016-10-09 22:32:35,440 : INFO : topic #2(1.029): -0.231*"meet" + -0.231*"keep" + -0.215*"exam" + -0.186*"everyone" + -0.156*"besides" + -0.156*"days" + -0.135*"weeks" + 0.128*"visit" + -0.118*"medical" + -0.115*"english"
2016-10-09 22:32:35,440 : INFO : topic #3(1.022): -0.235*"qatar" + -0.190*"medical" + 0.184*"sponsorship" + -0.169*"bring" + -0.169*"legally" + -0.169*"airways" + -0.169*"married" + -0.169*"noc" + -0.153*"females" + -0.153*"policy"
2016-10-09 22:32:35,440 : INFO : topic #4(1.002): -0.283*"found" + -0.283*"later" + -0.283*"recommendations" + -0.283*"year" + -0.283*"expecting" + -0.283*"deliver" + -0.283*"place" + -0.283*"baby" + -0.283*"best" + -0.283*"doctors"
2016-10-09 22:32:35,440 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:35,441 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:35,442 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:35,443 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,443 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,443 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:35,444 : INFO : saved 10x5334 matrix, density=0.219% (117/53340)
2016-10-09 22:32:35,444 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,444 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,444 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,445 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,445 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,445 : INFO : accepted corpus with 10 documents, 5334 features, 117 non-zero entries
2016-10-09 22:32:35,445 : INFO : collecting document frequencies
2016-10-09 22:32:35,445 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:35,445 : INFO : calculating IDF weights for 10 documents and 5333 features (117 matrix non-zeros)
2016-10-09 22:32:35,445 : INFO : using serial LSI version on this node
2016-10-09 22:32:35,445 : INFO : updating model with new documents
2016-10-09 22:32:35,446 : INFO : preparing a new chunk of documents
2016-10-09 22:32:35,446 : DEBUG : converting corpus to csc format
2016-10-09 22:32:35,446 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:35,449 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:35,449 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:35,476 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,575 : DEBUG : running 2 power iterations
2016-10-09 22:32:35,614 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,754 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:35,868 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:35,875 : INFO : computing the final decomposition
2016-10-09 22:32:35,876 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:35,878 : INFO : processed documents up to #10
2016-10-09 22:32:35,879 : INFO : topic #0(1.193): 0.366*"family" + 0.326*"best" + 0.324*"beach" + 0.320*"qatar" + 0.278*"go" + 0.222*"next" + 0.212*"silent" + 0.212*"maybe" + 0.212*"romantic" + 0.211*"friday"
2016-10-09 22:32:35,879 : INFO : topic #1(1.043): 0.293*"next" + 0.251*"countries" + 0.251*"visited" + 0.251*"plan" + 0.235*"experience" + 0.233*"holiday" + 0.233*"destinations" + -0.209*"beach" + 0.207*"places" + 0.207*"vacation"
2016-10-09 22:32:35,879 : INFO : topic #2(1.030): 0.344*"destinations" + 0.344*"holiday" + 0.316*"experience" + -0.275*"countries" + -0.275*"plan" + -0.275*"visited" + -0.271*"next" + 0.217*"summer" + 0.217*"places" + 0.217*"vacation"
2016-10-09 22:32:35,879 : INFO : topic #3(1.016): 0.257*"lets" + 0.256*"country" + 0.256*"away" + 0.256*"17" + 0.256*"years" + 0.256*"long" + 0.256*"start" + 0.223*"beaches" + -0.150*"family" + 0.130*"destinations"
2016-10-09 22:32:35,879 : INFO : topic #4(0.999): -0.189*"advice" + -0.189*"clues" + -0.189*"moving" + -0.189*"decent" + -0.189*"looking" + -0.189*"ex" + -0.189*"september" + -0.189*"standard" + -0.189*"pro" + -0.189*"info"
2016-10-09 22:32:35,880 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:35,880 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:35,881 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:35,882 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,883 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,883 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:35,883 : INFO : saved 10x5273 matrix, density=0.345% (182/52730)
2016-10-09 22:32:35,883 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,883 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,883 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,884 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:35,884 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:35,884 : INFO : accepted corpus with 10 documents, 5273 features, 182 non-zero entries
2016-10-09 22:32:35,884 : INFO : collecting document frequencies
2016-10-09 22:32:35,884 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:35,884 : INFO : calculating IDF weights for 10 documents and 5272 features (182 matrix non-zeros)
2016-10-09 22:32:35,885 : INFO : using serial LSI version on this node
2016-10-09 22:32:35,885 : INFO : updating model with new documents
2016-10-09 22:32:35,885 : INFO : preparing a new chunk of documents
2016-10-09 22:32:35,885 : DEBUG : converting corpus to csc format
2016-10-09 22:32:35,885 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:35,888 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:35,889 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:35,915 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,014 : DEBUG : running 2 power iterations
2016-10-09 22:32:36,054 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,191 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,305 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:36,313 : INFO : computing the final decomposition
2016-10-09 22:32:36,313 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:36,316 : INFO : processed documents up to #10
2016-10-09 22:32:36,316 : INFO : topic #0(1.092): -0.203*"running" + -0.185*"would" + -0.180*"evening" + -0.178*"place" + -0.174*"night" + -0.164*"corniche" + -0.140*"safe" + -0.135*"good" + -0.135*"hi" + -0.134*"could"
2016-10-09 22:32:36,316 : INFO : topic #1(1.036): -0.303*"running" + -0.239*"www" + -0.239*"com" + 0.199*"evening" + 0.196*"qlers" + 0.196*"see" + 0.196*"lot" + 0.196*"groups" + -0.157*"done" + -0.157*"usually"
2016-10-09 22:32:36,316 : INFO : topic #2(1.026): -0.248*"could" + -0.245*"like" + -0.226*"im" + -0.166*"know" + -0.151*"would" + -0.135*"wear" + 0.131*"groups" + 0.131*"lot" + 0.131*"see" + 0.131*"qlers"
2016-10-09 22:32:36,317 : INFO : topic #3(1.006): -0.283*"ladies" + -0.283*"alone" + -0.283*"move" + 0.283*"today" + -0.231*"safe" + -0.141*"public" + -0.141*"indian" + -0.141*"uae" + -0.141*"life" + -0.141*"comparable"
2016-10-09 22:32:36,317 : INFO : topic #4(1.003): -0.347*"wear" + -0.222*"qlers" + -0.222*"lot" + -0.222*"see" + -0.222*"groups" + -0.161*"evening" + -0.150*"com" + -0.150*"www" + 0.121*"night" + -0.119*"corniche"
2016-10-09 22:32:36,317 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:36,318 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:36,319 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:36,320 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,320 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,320 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:36,321 : INFO : saved 10x5301 matrix, density=0.366% (194/53010)
2016-10-09 22:32:36,321 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,321 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,321 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:36,321 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:36,321 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,322 : INFO : accepted corpus with 10 documents, 5301 features, 194 non-zero entries
2016-10-09 22:32:36,322 : INFO : collecting document frequencies
2016-10-09 22:32:36,322 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:36,322 : INFO : calculating IDF weights for 10 documents and 5300 features (194 matrix non-zeros)
2016-10-09 22:32:36,322 : INFO : using serial LSI version on this node
2016-10-09 22:32:36,322 : INFO : updating model with new documents
2016-10-09 22:32:36,323 : INFO : preparing a new chunk of documents
2016-10-09 22:32:36,323 : DEBUG : converting corpus to csc format
2016-10-09 22:32:36,323 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:36,326 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:36,326 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:36,353 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,451 : DEBUG : running 2 power iterations
2016-10-09 22:32:36,490 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,628 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,742 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:36,750 : INFO : computing the final decomposition
2016-10-09 22:32:36,750 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:36,752 : INFO : processed documents up to #10
2016-10-09 22:32:36,753 : INFO : topic #0(1.153): -0.228*"much" + -0.208*"club" + -0.184*"people" + -0.169*"member" + -0.169*"need" + -0.158*"bars" + -0.157*"enjoy" + -0.157*"dubai" + -0.157*"ways" + -0.157*"doha"
2016-10-09 22:32:36,753 : INFO : topic #1(1.055): -0.198*"think" + -0.184*"night" + 0.176*"bars" + -0.169*"get" + 0.169*"anything" + 0.169*"knows" + 0.169*"anybody" + 0.160*"people" + 0.150*"qatar" + 0.150*"friends"
2016-10-09 22:32:36,753 : INFO : topic #2(1.041): 0.249*"people" + 0.191*"dance" + 0.189*"enjoy" + 0.189*"ways" + 0.189*"dubai" + -0.189*"anything" + -0.189*"knows" + -0.189*"anybody" + -0.182*"friends" + -0.182*"qatar"
2016-10-09 22:32:36,753 : INFO : topic #3(1.011): 0.245*"time" + 0.245*"opens" + 0.179*"friday" + -0.157*"getting" + -0.157*"small" + -0.157*"place" + -0.157*"decent" + -0.157*"hang" + -0.157*"world" + -0.157*"find"
2016-10-09 22:32:36,753 : INFO : topic #4(0.998): 0.198*"time" + 0.198*"opens" + -0.172*"bars" + 0.162*"friday" + -0.156*"5" + -0.156*"drinks" + -0.156*"give" + -0.156*"weekend" + -0.156*"bar" + -0.156*"one"
2016-10-09 22:32:36,754 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:36,755 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:36,756 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:36,757 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,757 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,757 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:36,757 : INFO : saved 10x5305 matrix, density=0.234% (124/53050)
2016-10-09 22:32:36,757 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,757 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,757 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:36,758 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:36,758 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:36,758 : INFO : accepted corpus with 10 documents, 5305 features, 124 non-zero entries
2016-10-09 22:32:36,758 : INFO : collecting document frequencies
2016-10-09 22:32:36,758 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:36,758 : INFO : calculating IDF weights for 10 documents and 5304 features (124 matrix non-zeros)
2016-10-09 22:32:36,759 : INFO : using serial LSI version on this node
2016-10-09 22:32:36,759 : INFO : updating model with new documents
2016-10-09 22:32:36,759 : INFO : preparing a new chunk of documents
2016-10-09 22:32:36,759 : DEBUG : converting corpus to csc format
2016-10-09 22:32:36,759 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:36,762 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:36,763 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:36,789 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:36,888 : DEBUG : running 2 power iterations
2016-10-09 22:32:36,927 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,065 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,178 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:37,186 : INFO : computing the final decomposition
2016-10-09 22:32:37,186 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:37,189 : INFO : processed documents up to #10
2016-10-09 22:32:37,189 : INFO : topic #0(1.092): -0.314*"think" + -0.293*"qlers" + -0.233*"take" + -0.233*"let" + -0.233*"moment" + -0.233*"hear" + -0.226*"ql" + -0.211*"say" + -0.186*"write" + -0.186*"better"
2016-10-09 22:32:37,189 : INFO : topic #1(1.012): -0.362*"points" + 0.253*"something" + 0.233*"hate" + 0.233*"list" + -0.205*"villagio" + -0.205*"open" + 0.190*"joke" + -0.181*"anyone" + -0.181*"tell" + -0.181*"earn"
2016-10-09 22:32:37,189 : INFO : topic #2(1.009): 0.312*"points" + 0.280*"joke" + 0.257*"list" + 0.257*"hate" + 0.201*"villagio" + 0.201*"open" + 0.172*"streets" + 0.158*"women" + 0.156*"earn" + 0.156*"tell"
2016-10-09 22:32:37,189 : INFO : topic #3(1.003): 0.578*"something" + 0.289*"dont" + 0.289*"noticed" + 0.289*"red" + 0.220*"know" + 0.219*"open" + 0.219*"villagio" + 0.204*"points" + 0.164*"yet" + -0.110*"take"
2016-10-09 22:32:37,190 : INFO : topic #4(1.000): -0.476*"still" + -0.238*"mind" + -0.238*"sincere" + -0.238*"men" + -0.238*"words" + -0.238*"rule" + -0.238*"guy" + -0.238*"true" + -0.238*"always" + -0.238*"mean"
2016-10-09 22:32:37,190 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:37,191 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:37,191 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:37,193 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,193 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,193 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:37,193 : INFO : saved 10x5304 matrix, density=0.370% (196/53040)
2016-10-09 22:32:37,193 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,193 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,193 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:37,194 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:37,194 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,194 : INFO : accepted corpus with 10 documents, 5304 features, 196 non-zero entries
2016-10-09 22:32:37,194 : INFO : collecting document frequencies
2016-10-09 22:32:37,194 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:37,194 : INFO : calculating IDF weights for 10 documents and 5303 features (196 matrix non-zeros)
2016-10-09 22:32:37,195 : INFO : using serial LSI version on this node
2016-10-09 22:32:37,195 : INFO : updating model with new documents
2016-10-09 22:32:37,195 : INFO : preparing a new chunk of documents
2016-10-09 22:32:37,195 : DEBUG : converting corpus to csc format
2016-10-09 22:32:37,196 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:37,199 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:37,199 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:37,225 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,324 : DEBUG : running 2 power iterations
2016-10-09 22:32:37,363 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,501 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,615 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:37,623 : INFO : computing the final decomposition
2016-10-09 22:32:37,623 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:37,626 : INFO : processed documents up to #10
2016-10-09 22:32:37,626 : INFO : topic #0(1.114): -0.212*"details" + -0.212*"nursery" + -0.212*"speaking" + -0.204*"french" + -0.192*"contact" + -0.192*"give" + -0.190*"anyone" + -0.189*"know" + -0.163*"lycee" + -0.151*"doha"
2016-10-09 22:32:37,626 : INFO : topic #1(1.042): 0.274*"lycee" + 0.246*"soon" + 0.215*"say" + 0.215*"rumor" + 0.215*"mall" + 0.215*"bar" + 0.215*"heard" + 0.196*"qatar" + 0.177*"get" + -0.150*"beach"
2016-10-09 22:32:37,626 : INFO : topic #2(1.035): -0.294*"give" + -0.182*"contact" + -0.151*"nursery" + -0.151*"speaking" + -0.151*"details" + -0.147*"email" + -0.147*"names" + -0.147*"nurseries" + -0.147*"could" + -0.147*"website"
2016-10-09 22:32:37,626 : INFO : topic #3(1.009): -0.152*"lycee" + -0.152*"moving" + -0.142*"forum" + -0.142*"find" + -0.142*"al" + -0.142*"time" + -0.142*"picture" + -0.142*"compound" + -0.142*"first" + -0.142*"hello"
2016-10-09 22:32:37,627 : INFO : topic #4(1.001): -0.214*"bought" + -0.190*"buy" + -0.190*"flat" + -0.190*"british" + 0.148*"details" + 0.148*"nursery" + 0.148*"speaking" + -0.148*"good" + -0.141*"would" + -0.130*"kindergarten"
2016-10-09 22:32:37,627 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:37,628 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:37,629 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:37,630 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,630 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,630 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:37,630 : INFO : saved 10x5327 matrix, density=0.327% (174/53270)
2016-10-09 22:32:37,631 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,631 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,631 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:37,631 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:37,631 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:37,631 : INFO : accepted corpus with 10 documents, 5327 features, 174 non-zero entries
2016-10-09 22:32:37,632 : INFO : collecting document frequencies
2016-10-09 22:32:37,632 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:37,632 : INFO : calculating IDF weights for 10 documents and 5326 features (174 matrix non-zeros)
2016-10-09 22:32:37,632 : INFO : using serial LSI version on this node
2016-10-09 22:32:37,632 : INFO : updating model with new documents
2016-10-09 22:32:37,633 : INFO : preparing a new chunk of documents
2016-10-09 22:32:37,633 : DEBUG : converting corpus to csc format
2016-10-09 22:32:37,633 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:37,636 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:37,636 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:37,663 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,762 : DEBUG : running 2 power iterations
2016-10-09 22:32:37,801 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:37,939 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,052 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:38,060 : INFO : computing the final decomposition
2016-10-09 22:32:38,060 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:38,063 : INFO : processed documents up to #10
2016-10-09 22:32:38,063 : INFO : topic #0(1.087): -0.234*"without" + -0.202*"buy" + -0.202*"driving" + -0.202*"possible" + -0.202*"folks" + -0.202*"name" + -0.202*"license" + -0.200*"hi" + -0.186*"doha" + -0.175*"car"
2016-10-09 22:32:38,063 : INFO : topic #1(1.037): -0.240*"bus" + -0.222*"company" + -0.222*"suggestions" + -0.178*"rent" + -0.174*"dont" + -0.174*"everytime" + -0.174*"seems" + -0.174*"deposit" + -0.174*"want" + -0.174*"used"
2016-10-09 22:32:38,063 : INFO : topic #2(1.035): 0.364*"bus" + 0.186*"mate" + 0.166*"qatar" + 0.150*"day" + 0.150*"one" + 0.140*"month" + 0.137*"household" + 0.137*"required" + 0.133*"need" + 0.128*"nurse"
2016-10-09 22:32:38,064 : INFO : topic #3(1.017): 0.224*"sponsor" + 0.224*"cancel" + 0.224*"even" + 0.224*"visa" + 0.224*"passport" + 0.211*"guys" + 0.209*"thank" + 0.157*"nurse" + -0.148*"mate" + 0.120*"without"
2016-10-09 22:32:38,064 : INFO : topic #4(0.998): 0.233*"advance" + 0.233*"jobs" + 0.233*"numbers" + 0.233*"workers" + 0.233*"agencies" + 0.233*"list" + 0.233*"construction" + 0.233*"skilled" + 0.233*"phone" + 0.233*"recruiting"
2016-10-09 22:32:38,064 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:38,065 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:38,066 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:38,067 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,067 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,067 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:38,067 : INFO : saved 10x5319 matrix, density=0.243% (129/53190)
2016-10-09 22:32:38,067 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,067 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,068 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,068 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,068 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,068 : INFO : accepted corpus with 10 documents, 5319 features, 129 non-zero entries
2016-10-09 22:32:38,068 : INFO : collecting document frequencies
2016-10-09 22:32:38,068 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:38,069 : INFO : calculating IDF weights for 10 documents and 5318 features (129 matrix non-zeros)
2016-10-09 22:32:38,069 : INFO : using serial LSI version on this node
2016-10-09 22:32:38,069 : INFO : updating model with new documents
2016-10-09 22:32:38,069 : INFO : preparing a new chunk of documents
2016-10-09 22:32:38,069 : DEBUG : converting corpus to csc format
2016-10-09 22:32:38,070 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:38,073 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:38,073 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:38,099 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,198 : DEBUG : running 2 power iterations
2016-10-09 22:32:38,237 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,376 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,488 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:38,496 : INFO : computing the final decomposition
2016-10-09 22:32:38,496 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:38,499 : INFO : processed documents up to #10
2016-10-09 22:32:38,499 : INFO : topic #0(1.171): 0.464*"park" + 0.363*"know" + 0.329*"water" + 0.329*"theme" + 0.238*"qatar" + 0.223*"instead" + 0.223*"would" + 0.154*"parks" + 0.154*"making" + 0.112*"built"
2016-10-09 22:32:38,499 : INFO : topic #1(1.046): 0.357*"ur" + 0.219*"place" + 0.205*"enjoy" + 0.205*"family" + 0.178*"visited" + 0.178*"hi" + 0.178*"best" + 0.178*"friends" + -0.174*"park" + 0.168*"party"
2016-10-09 22:32:38,499 : INFO : topic #2(1.032): -0.225*"ur" + 0.216*"party" + 0.176*"venues" + 0.176*"kfc" + 0.176*"restaurant" + 0.176*"food" + 0.176*"rent" + 0.176*"given" + 0.176*"already" + -0.159*"family"
2016-10-09 22:32:38,499 : INFO : topic #3(1.023): -0.296*"http" + -0.226*"avoid" + -0.226*"bored" + -0.226*"post" + -0.226*"im" + -0.226*"co" + -0.226*"trap" + -0.226*"read" + -0.197*"still" + -0.197*"visit"
2016-10-09 22:32:38,500 : INFO : topic #4(1.010): -0.265*"got" + 0.203*"making" + 0.203*"parks" + -0.150*"doha" + -0.136*"2" + 0.133*"post" + 0.133*"avoid" + 0.133*"bored" + 0.133*"read" + 0.133*"im"
2016-10-09 22:32:38,500 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:38,501 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:38,501 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:38,503 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,503 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,503 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:38,503 : INFO : saved 10x5148 matrix, density=0.420% (216/51480)
2016-10-09 22:32:38,503 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,504 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,504 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,504 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,504 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,504 : INFO : accepted corpus with 10 documents, 5148 features, 216 non-zero entries
2016-10-09 22:32:38,504 : INFO : collecting document frequencies
2016-10-09 22:32:38,504 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:38,505 : INFO : calculating IDF weights for 10 documents and 5147 features (216 matrix non-zeros)
2016-10-09 22:32:38,505 : INFO : using serial LSI version on this node
2016-10-09 22:32:38,505 : INFO : updating model with new documents
2016-10-09 22:32:38,505 : INFO : preparing a new chunk of documents
2016-10-09 22:32:38,505 : DEBUG : converting corpus to csc format
2016-10-09 22:32:38,506 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:38,509 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:38,509 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:38,536 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,634 : DEBUG : running 2 power iterations
2016-10-09 22:32:38,673 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,812 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:38,924 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:38,932 : INFO : computing the final decomposition
2016-10-09 22:32:38,932 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:38,935 : INFO : processed documents up to #10
2016-10-09 22:32:38,935 : INFO : topic #0(1.142): -0.198*"month" + -0.176*"doha" + -0.176*"maximum" + -0.176*"3" + -0.159*"currently" + -0.159*"extend" + -0.159*"whether" + -0.149*"months" + -0.138*"anybody" + -0.136*"salary"
2016-10-09 22:32:38,935 : INFO : topic #1(1.064): 0.363*"salary" + 0.231*"option" + 0.231*"come" + 0.210*"wife" + 0.172*"limitations" + 0.172*"residence" + 0.172*"transfer" + 0.172*"appreciate" + 0.172*"bringing" + 0.172*"regards"
2016-10-09 22:32:38,935 : INFO : topic #2(1.021): 0.214*"pakistanis" + 0.214*"available" + 0.214*"someone" + 0.214*"pakistan" + -0.207*"need" + -0.194*"know" + -0.174*"3months" + -0.174*"want" + -0.174*"sri" + -0.174*"im"
2016-10-09 22:32:38,936 : INFO : topic #3(1.013): 0.250*"process" + 0.250*"change" + 0.146*"someone" + 0.146*"pakistanis" + 0.146*"pakistan" + 0.146*"available" + 0.146*"need" + 0.138*"visas" + 0.125*"u" + 0.125*"job"
2016-10-09 22:32:38,936 : INFO : topic #4(0.998): 0.272*"deliver" + 0.272*"baby" + 0.250*"month" + 0.136*"pregnant" + 0.136*"coming" + 0.136*"back" + 0.136*"charge" + 0.136*"place" + 0.136*"formalities" + 0.136*"friends"
2016-10-09 22:32:38,936 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:38,937 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:38,938 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:38,939 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,939 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,939 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:38,940 : INFO : saved 10x5336 matrix, density=0.232% (124/53360)
2016-10-09 22:32:38,940 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,940 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,940 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,940 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:38,941 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:38,941 : INFO : accepted corpus with 10 documents, 5336 features, 124 non-zero entries
2016-10-09 22:32:38,941 : INFO : collecting document frequencies
2016-10-09 22:32:38,941 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:38,941 : INFO : calculating IDF weights for 10 documents and 5335 features (124 matrix non-zeros)
2016-10-09 22:32:38,941 : INFO : using serial LSI version on this node
2016-10-09 22:32:38,941 : INFO : updating model with new documents
2016-10-09 22:32:38,942 : INFO : preparing a new chunk of documents
2016-10-09 22:32:38,942 : DEBUG : converting corpus to csc format
2016-10-09 22:32:38,942 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:38,945 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:38,945 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:38,972 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,074 : DEBUG : running 2 power iterations
2016-10-09 22:32:39,113 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,253 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,366 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:39,374 : INFO : computing the final decomposition
2016-10-09 22:32:39,374 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:39,376 : INFO : processed documents up to #10
2016-10-09 22:32:39,377 : INFO : topic #0(1.063): -0.343*"ql" + -0.327*"group" + -0.264*"thread" + -0.206*"wives" + -0.206*"back" + -0.206*"honest" + -0.206*"obviously" + -0.182*"please" + -0.172*"locked" + -0.172*"moderator"
2016-10-09 22:32:39,377 : INFO : topic #1(1.037): 0.223*"question" + 0.216*"dish" + 0.207*"simple" + 0.207*"solution" + 0.207*"lol" + -0.195*"advice" + 0.182*"party" + 0.154*"rice" + 0.153*"invited" + 0.153*"wedding"
2016-10-09 22:32:39,377 : INFO : topic #2(1.034): -0.567*"advice" + -0.238*"doha" + -0.238*"christmas" + -0.199*"eve" + -0.199*"new" + -0.199*"thanks" + -0.199*"need" + -0.199*"holidays" + -0.199*"possible" + -0.199*"celebrate"
2016-10-09 22:32:39,377 : INFO : topic #3(1.018): -0.313*"solution" + -0.313*"simple" + -0.313*"lol" + -0.274*"question" + 0.223*"dish" + 0.178*"party" + 0.156*"go" + 0.143*"wedding" + 0.143*"invited" + 0.132*"dinner"
2016-10-09 22:32:39,378 : INFO : topic #4(1.011): -0.304*"go" + 0.226*"group" + -0.208*"obviously" + -0.208*"honest" + -0.208*"back" + -0.208*"wives" + 0.161*"valid" + 0.161*"wants" + 0.161*"say" + 0.161*"reasons"
2016-10-09 22:32:39,378 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:39,379 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:39,379 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:39,381 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,381 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,381 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:39,381 : INFO : saved 10x5299 matrix, density=0.387% (205/52990)
2016-10-09 22:32:39,381 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,381 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,381 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:39,382 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:39,382 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,382 : INFO : accepted corpus with 10 documents, 5299 features, 205 non-zero entries
2016-10-09 22:32:39,382 : INFO : collecting document frequencies
2016-10-09 22:32:39,382 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:39,382 : INFO : calculating IDF weights for 10 documents and 5298 features (205 matrix non-zeros)
2016-10-09 22:32:39,383 : INFO : using serial LSI version on this node
2016-10-09 22:32:39,383 : INFO : updating model with new documents
2016-10-09 22:32:39,383 : INFO : preparing a new chunk of documents
2016-10-09 22:32:39,383 : DEBUG : converting corpus to csc format
2016-10-09 22:32:39,384 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:39,387 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:39,387 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:39,413 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,512 : DEBUG : running 2 power iterations
2016-10-09 22:32:39,552 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,689 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,804 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:39,811 : INFO : computing the final decomposition
2016-10-09 22:32:39,812 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:39,814 : INFO : processed documents up to #10
2016-10-09 22:32:39,815 : INFO : topic #0(1.139): 0.303*"suggestions" + 0.210*"week" + 0.178*"happenings" + 0.178*"new" + 0.175*"please" + 0.170*"holidays" + 0.154*"something" + 0.147*"days" + 0.136*"doha" + 0.136*"wife"
2016-10-09 22:32:39,815 : INFO : topic #1(1.062): 0.253*"ramadan" + 0.214*"comes" + 0.192*"know" + -0.189*"doha" + -0.189*"wife" + 0.170*"would" + -0.158*"places" + -0.138*"holidays" + 0.131*"means" + 0.131*"rest"
2016-10-09 22:32:39,815 : INFO : topic #2(1.020): 0.205*"places" + -0.184*"home" + -0.177*"leave" + 0.169*"doha" + 0.169*"wife" + -0.168*"holiday" + 0.138*"ramadan" + -0.129*"fitr" + -0.127*"go" + -0.123*"exit"
2016-10-09 22:32:39,815 : INFO : topic #3(1.008): 0.284*"please" + 0.270*"suggestions" + 0.260*"new" + 0.260*"happenings" + 0.173*"something" + -0.165*"home" + -0.152*"places" + 0.147*"almost" + 0.147*"evening" + 0.147*"shops"
2016-10-09 22:32:39,815 : INFO : topic #4(0.997): -0.262*"home" + -0.212*"week" + -0.184*"want" + -0.176*"appreciated" + -0.175*"sponsor" + -0.175*"exit" + -0.175*"permit" + -0.167*"suggestions" + 0.144*"holiday" + -0.122*"advice"
2016-10-09 22:32:39,816 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:39,817 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:39,818 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:39,819 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,819 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,819 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:39,819 : INFO : saved 10x5319 matrix, density=0.308% (164/53190)
2016-10-09 22:32:39,819 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,820 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,820 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:39,820 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:39,820 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:39,820 : INFO : accepted corpus with 10 documents, 5319 features, 164 non-zero entries
2016-10-09 22:32:39,820 : INFO : collecting document frequencies
2016-10-09 22:32:39,820 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:39,821 : INFO : calculating IDF weights for 10 documents and 5318 features (164 matrix non-zeros)
2016-10-09 22:32:39,821 : INFO : using serial LSI version on this node
2016-10-09 22:32:39,821 : INFO : updating model with new documents
2016-10-09 22:32:39,821 : INFO : preparing a new chunk of documents
2016-10-09 22:32:39,821 : DEBUG : converting corpus to csc format
2016-10-09 22:32:39,822 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:39,825 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:39,825 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:39,851 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:39,950 : DEBUG : running 2 power iterations
2016-10-09 22:32:39,989 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,127 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,240 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:40,247 : INFO : computing the final decomposition
2016-10-09 22:32:40,248 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:40,250 : INFO : processed documents up to #10
2016-10-09 22:32:40,251 : INFO : topic #0(1.055): 0.267*"driving" + 0.267*"license" + 0.182*"move" + 0.171*"alone" + 0.171*"ladies" + 0.171*"safe" + 0.145*"also" + 0.140*"tell" + 0.129*"hi" + 0.121*"country"
2016-10-09 22:32:40,251 : INFO : topic #1(1.020): 0.245*"win" + 0.245*"guess" + 0.245*"gonna" + 0.222*"tell" + 0.216*"driving" + 0.216*"license" + -0.198*"also" + -0.160*"accept" + -0.160*"bank" + -0.135*"household"
2016-10-09 22:32:40,251 : INFO : topic #2(1.016): -0.212*"alone" + -0.212*"ladies" + -0.212*"safe" + 0.208*"india" + -0.207*"household" + -0.207*"required" + 0.173*"accept" + 0.173*"bank" + -0.146*"hello" + -0.146*"thanks"
2016-10-09 22:32:40,251 : INFO : topic #3(1.005): 0.462*"tata" + 0.462*"available" + 0.263*"gps" + 0.263*"wanted" + 0.263*"garmin" + 0.132*"go" + 0.132*"trip" + 0.132*"know" + 0.132*"outside" + 0.132*"genuine"
2016-10-09 22:32:40,251 : INFO : topic #4(0.999): -0.346*"gonna" + -0.346*"guess" + -0.346*"win" + -0.238*"tell" + -0.156*"gps" + -0.156*"wanted" + -0.156*"garmin" + -0.134*"household" + -0.134*"required" + 0.126*"cargo"
2016-10-09 22:32:40,251 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:40,253 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:40,253 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:40,255 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,255 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,255 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:40,255 : INFO : saved 10x5323 matrix, density=0.340% (181/53230)
2016-10-09 22:32:40,255 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,255 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,255 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:40,256 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:40,256 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,256 : INFO : accepted corpus with 10 documents, 5323 features, 181 non-zero entries
2016-10-09 22:32:40,256 : INFO : collecting document frequencies
2016-10-09 22:32:40,256 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:40,256 : INFO : calculating IDF weights for 10 documents and 5322 features (181 matrix non-zeros)
2016-10-09 22:32:40,257 : INFO : using serial LSI version on this node
2016-10-09 22:32:40,257 : INFO : updating model with new documents
2016-10-09 22:32:40,257 : INFO : preparing a new chunk of documents
2016-10-09 22:32:40,257 : DEBUG : converting corpus to csc format
2016-10-09 22:32:40,257 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:40,260 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:40,261 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:40,287 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,390 : DEBUG : running 2 power iterations
2016-10-09 22:32:40,430 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,569 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,682 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:40,690 : INFO : computing the final decomposition
2016-10-09 22:32:40,690 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:40,693 : INFO : processed documents up to #10
2016-10-09 22:32:40,693 : INFO : topic #0(1.067): -0.258*"rules" + -0.234*"would" + -0.158*"like" + -0.148*"watch" + -0.148*"traffic" + -0.148*"doha" + -0.130*"male" + -0.124*"hi" + -0.117*"http" + -0.117*"www"
2016-10-09 22:32:40,693 : INFO : topic #1(1.015): -0.255*"hijab" + -0.203*"male" + -0.162*"hi" + 0.161*"rules" + -0.160*"share" + -0.131*"thank" + -0.131*"tried" + -0.131*"center" + -0.131*"timings" + -0.131*"help"
2016-10-09 22:32:40,693 : INFO : topic #2(1.011): 0.318*"hijab" + 0.183*"male" + 0.175*"share" + -0.175*"qatar" + 0.159*"making" + 0.159*"wear" + 0.159*"plz" + 0.159*"others" + 0.159*"comments" + 0.159*"muslim"
2016-10-09 22:32:40,694 : INFO : topic #3(1.003): 0.274*"store" + 0.274*"rumor" + 0.274*"liquor" + 0.274*"heard" + -0.217*"qatar" + 0.164*"nations" + 0.137*"near" + 0.137*"pork" + 0.137*"building" + 0.137*"built"
2016-10-09 22:32:40,694 : INFO : topic #4(1.000): -0.324*"silly" + -0.324*"forum" + -0.324*"still" + -0.324*"moderators" + -0.324*"threads" + -0.324*"even" + -0.324*"one" + -0.324*"line" + -0.324*"banned" + 0.134*"reason"
2016-10-09 22:32:40,694 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:40,695 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:40,696 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:40,697 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,697 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,697 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:40,698 : INFO : saved 10x5301 matrix, density=0.253% (134/53010)
2016-10-09 22:32:40,698 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,698 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,698 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:40,698 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:40,698 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:40,699 : INFO : accepted corpus with 10 documents, 5301 features, 134 non-zero entries
2016-10-09 22:32:40,699 : INFO : collecting document frequencies
2016-10-09 22:32:40,699 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:40,699 : INFO : calculating IDF weights for 10 documents and 5300 features (134 matrix non-zeros)
2016-10-09 22:32:40,699 : INFO : using serial LSI version on this node
2016-10-09 22:32:40,699 : INFO : updating model with new documents
2016-10-09 22:32:40,700 : INFO : preparing a new chunk of documents
2016-10-09 22:32:40,700 : DEBUG : converting corpus to csc format
2016-10-09 22:32:40,700 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:40,703 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:40,703 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:40,729 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:40,828 : DEBUG : running 2 power iterations
2016-10-09 22:32:40,867 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,005 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,119 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:41,126 : INFO : computing the final decomposition
2016-10-09 22:32:41,127 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:41,129 : INFO : processed documents up to #10
2016-10-09 22:32:41,130 : INFO : topic #0(1.081): 0.301*"qatar" + 0.228*"anyone" + 0.217*"bar" + 0.211*"help" + 0.211*"indian" + 0.211*"thank" + 0.211*"hello" + 0.211*"find" + 0.190*"friends" + 0.142*"one"
2016-10-09 22:32:41,130 : INFO : topic #1(1.037): 0.248*"qatar" + -0.231*"one" + 0.164*"anyone" + -0.158*"issue" + -0.158*"partner" + -0.158*"hall" + -0.158*"pass" + -0.151*"night" + -0.151*"thinking" + -0.151*"right"
2016-10-09 22:32:41,130 : INFO : topic #2(1.000): -0.408*"broken" + -0.408*"heart" + -0.408*"sweet" + -0.289*"issues" + -0.289*"guys" + -0.289*"ever" + -0.289*"think" + -0.289*"work" + -0.289*"without" + -0.000*"thread"
2016-10-09 22:32:41,130 : INFO : topic #3(1.000): -1.000*"hmm" + -0.000*"favorite" + -0.000*"op" + -0.000*"currently" + -0.000*"detect" + 0.000*"fellow" + 0.000*"root" + -0.000*"advantages" + 0.000*"film" + 0.000*"understanding"
2016-10-09 22:32:41,130 : INFO : topic #4(1.000): 0.408*"heart" + 0.408*"broken" + 0.408*"sweet" + -0.289*"without" + -0.289*"work" + -0.289*"ever" + -0.289*"think" + -0.289*"issues" + -0.289*"guys" + -0.000*"thread"
2016-10-09 22:32:41,131 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:41,131 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:41,132 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:41,133 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,134 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,134 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:41,134 : INFO : saved 10x5305 matrix, density=0.392% (208/53050)
2016-10-09 22:32:41,134 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,134 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,134 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:41,135 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:41,135 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,135 : INFO : accepted corpus with 10 documents, 5305 features, 208 non-zero entries
2016-10-09 22:32:41,135 : INFO : collecting document frequencies
2016-10-09 22:32:41,135 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:41,135 : INFO : calculating IDF weights for 10 documents and 5304 features (208 matrix non-zeros)
2016-10-09 22:32:41,136 : INFO : using serial LSI version on this node
2016-10-09 22:32:41,136 : INFO : updating model with new documents
2016-10-09 22:32:41,136 : INFO : preparing a new chunk of documents
2016-10-09 22:32:41,136 : DEBUG : converting corpus to csc format
2016-10-09 22:32:41,136 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:41,139 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:41,140 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:41,166 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,269 : DEBUG : running 2 power iterations
2016-10-09 22:32:41,308 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,446 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,559 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:41,567 : INFO : computing the final decomposition
2016-10-09 22:32:41,567 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:41,570 : INFO : processed documents up to #10
2016-10-09 22:32:41,570 : INFO : topic #0(1.118): 0.192*"change" + 0.174*"visa" + 0.152*"thanks" + 0.151*"medical" + 0.150*"exam" + 0.150*"get" + 0.146*"ql" + 0.140*"company" + 0.136*"work" + 0.132*"would"
2016-10-09 22:32:41,570 : INFO : topic #1(1.048): -0.245*"change" + 0.179*"get" + 0.174*"advise" + 0.173*"haircut" + 0.173*"town" + 0.173*"boys" + 0.173*"kindly" + 0.171*"best" + 0.150*"car" + 0.150*"seat"
2016-10-09 22:32:41,571 : INFO : topic #2(1.039): -0.297*"ql" + -0.230*"wanna" + -0.230*"delete" + -0.230*"join" + -0.230*"kid" + -0.230*"one" + -0.230*"week" + -0.208*"anyone" + -0.183*"work" + -0.133*"reliable"
2016-10-09 22:32:41,571 : INFO : topic #3(1.020): -0.248*"c" + -0.248*"b" + 0.218*"change" + -0.217*"medical" + -0.197*"exam" + 0.168*"masters" + 0.168*"technician" + 0.168*"profession" + 0.168*"manager" + -0.165*"professionals"
2016-10-09 22:32:41,571 : INFO : topic #4(0.992): 0.240*"reliable" + -0.220*"visa" + 0.185*"car" + 0.185*"seat" + -0.159*"procedure" + -0.159*"entry" + -0.159*"come" + -0.159*"friends" + -0.159*"even" + -0.159*"umrah"
2016-10-09 22:32:41,571 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:41,572 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:41,573 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:41,574 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,574 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,574 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:41,575 : INFO : saved 10x5324 matrix, density=0.222% (118/53240)
2016-10-09 22:32:41,575 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,575 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,575 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:41,575 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:41,576 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:41,576 : INFO : accepted corpus with 10 documents, 5324 features, 118 non-zero entries
2016-10-09 22:32:41,576 : INFO : collecting document frequencies
2016-10-09 22:32:41,576 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:41,576 : INFO : calculating IDF weights for 10 documents and 5323 features (118 matrix non-zeros)
2016-10-09 22:32:41,576 : INFO : using serial LSI version on this node
2016-10-09 22:32:41,576 : INFO : updating model with new documents
2016-10-09 22:32:41,577 : INFO : preparing a new chunk of documents
2016-10-09 22:32:41,577 : DEBUG : converting corpus to csc format
2016-10-09 22:32:41,577 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:41,580 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:41,580 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:41,606 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,705 : DEBUG : running 2 power iterations
2016-10-09 22:32:41,744 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,883 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:41,995 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:42,003 : INFO : computing the final decomposition
2016-10-09 22:32:42,003 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:42,005 : INFO : processed documents up to #10
2016-10-09 22:32:42,006 : INFO : topic #0(1.199): -0.417*"http" + -0.417*"com" + -0.417*"www" + -0.322*"article" + -0.310*"look" + -0.204*"f" + -0.204*"2010" + -0.204*"28" + -0.204*"c" + -0.204*"08"
2016-10-09 22:32:42,006 : INFO : topic #1(1.082): 0.354*"church" + 0.329*"catholic" + 0.245*"qatar" + 0.239*"please" + 0.210*"make" + 0.177*"work" + 0.177*"bring" + 0.177*"bible" + 0.177*"group" + 0.177*"know"
2016-10-09 22:32:42,006 : INFO : topic #2(1.050): 0.348*"first" + 0.287*"came" + 0.287*"egg" + 0.287*"chicken" + 0.218*"makes" + 0.211*"words" + 0.211*"list" + 0.211*"use" + 0.211*"phone" + 0.211*"guess"
2016-10-09 22:32:42,006 : INFO : topic #3(1.001): -0.271*"worst" + -0.271*"avoid" + -0.271*"person" + -0.271*"lesser" + -0.271*"even" + -0.271*"talking" + -0.271*"way" + -0.271*"good" + 0.255*"chicken" + 0.255*"egg"
2016-10-09 22:32:42,006 : INFO : topic #4(1.000): 0.447*"getting" + 0.447*"one" + 0.447*"waiting" + 0.447*"ones" + 0.447*"still" + 0.000*"chicken" + 0.000*"came" + 0.000*"egg" + -0.000*"person" + -0.000*"lesser"
2016-10-09 22:32:42,007 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:42,008 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:42,008 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:42,009 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,009 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,010 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:42,010 : INFO : saved 10x5319 matrix, density=0.306% (163/53190)
2016-10-09 22:32:42,010 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,010 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,010 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,011 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,011 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,011 : INFO : accepted corpus with 10 documents, 5319 features, 163 non-zero entries
2016-10-09 22:32:42,011 : INFO : collecting document frequencies
2016-10-09 22:32:42,011 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:42,011 : INFO : calculating IDF weights for 10 documents and 5318 features (163 matrix non-zeros)
2016-10-09 22:32:42,012 : INFO : using serial LSI version on this node
2016-10-09 22:32:42,012 : INFO : updating model with new documents
2016-10-09 22:32:42,012 : INFO : preparing a new chunk of documents
2016-10-09 22:32:42,012 : DEBUG : converting corpus to csc format
2016-10-09 22:32:42,012 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:42,015 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:42,016 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:42,042 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,141 : DEBUG : running 2 power iterations
2016-10-09 22:32:42,180 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,318 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,431 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:42,439 : INFO : computing the final decomposition
2016-10-09 22:32:42,439 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:42,442 : INFO : processed documents up to #10
2016-10-09 22:32:42,442 : INFO : topic #0(1.181): 0.255*"licence" + 0.245*"driving" + 0.195*"driver" + 0.194*"valid" + 0.162*"visa" + 0.159*"company" + 0.146*"visiting" + 0.138*"anybody" + 0.137*"get" + 0.136*"ur"
2016-10-09 22:32:42,442 : INFO : topic #1(1.060): 0.337*"use" + 0.332*"philippines" + 0.255*"long" + 0.255*"want" + 0.255*"know" + 0.255*"im" + 0.220*"phil" + -0.162*"driving" + -0.161*"valid" + 0.134*"planning"
2016-10-09 22:32:42,443 : INFO : topic #2(1.054): -0.325*"visiting" + -0.312*"egyptian" + -0.312*"work" + 0.176*"dl" + 0.174*"test" + 0.171*"anybody" + 0.154*"thanks" + 0.154*"parking" + 0.154*"trick" + 0.154*"advise"
2016-10-09 22:32:42,443 : INFO : topic #3(1.016): 0.283*"valid" + -0.246*"dl" + 0.232*"ur" + 0.232*"still" + -0.158*"visiting" + -0.133*"licence" + -0.125*"legal" + -0.125*"intend" + -0.125*"week" + -0.125*"car"
2016-10-09 22:32:42,443 : INFO : topic #4(1.001): -0.375*"licence" + -0.242*"company" + 0.218*"dl" + 0.194*"egyptian" + 0.194*"work" + -0.174*"thanks" + -0.174*"advise" + -0.174*"parking" + -0.174*"trick" + -0.169*"driver"
2016-10-09 22:32:42,443 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:42,444 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:42,445 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:42,446 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,446 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,446 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:42,447 : INFO : saved 10x5225 matrix, density=0.243% (127/52250)
2016-10-09 22:32:42,447 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,447 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,447 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,447 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,447 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,448 : INFO : accepted corpus with 10 documents, 5225 features, 127 non-zero entries
2016-10-09 22:32:42,448 : INFO : collecting document frequencies
2016-10-09 22:32:42,448 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:42,448 : INFO : calculating IDF weights for 10 documents and 5224 features (127 matrix non-zeros)
2016-10-09 22:32:42,448 : INFO : using serial LSI version on this node
2016-10-09 22:32:42,448 : INFO : updating model with new documents
2016-10-09 22:32:42,448 : INFO : preparing a new chunk of documents
2016-10-09 22:32:42,449 : DEBUG : converting corpus to csc format
2016-10-09 22:32:42,449 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:42,452 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:42,452 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:42,479 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,578 : DEBUG : running 2 power iterations
2016-10-09 22:32:42,617 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,757 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:42,869 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:42,877 : INFO : computing the final decomposition
2016-10-09 22:32:42,877 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:42,880 : INFO : processed documents up to #10
2016-10-09 22:32:42,880 : INFO : topic #0(1.103): 0.244*"love" + 0.234*"share" + 0.232*"take" + 0.225*"pics" + 0.225*"dubai" + 0.225*"go" + 0.220*"want" + 0.206*"vacation" + 0.187*"eat" + 0.174*"one"
2016-10-09 22:32:42,880 : INFO : topic #1(1.059): 0.402*"animals" + 0.390*"buy" + 0.304*"want" + 0.304*"qatar" + 0.243*"find" + 0.195*"things" + 0.195*"difficult" + 0.152*"life" + 0.152*"someone" + 0.152*"chance"
2016-10-09 22:32:42,881 : INFO : topic #2(1.048): -0.218*"eat" + -0.210*"love" + 0.164*"sponsor" + 0.163*"know" + 0.161*"without" + 0.161*"thank" + 0.161*"visa" + 0.161*"passport" + 0.161*"cancel" + 0.159*"guys"
2016-10-09 22:32:42,881 : INFO : topic #3(1.020): 0.240*"passport" + 0.240*"thank" + 0.240*"cancel" + 0.240*"visa" + 0.240*"without" + 0.216*"sponsor" + 0.188*"guys" + 0.188*"even" + -0.171*"hello" + 0.167*"eat"
2016-10-09 22:32:42,881 : INFO : topic #4(0.999): -0.186*"minimum" + -0.186*"employee" + -0.186*"per" + -0.186*"house" + -0.186*"pay" + -0.186*"account" + -0.186*"introduce" + -0.186*"maids" + -0.186*"directly" + -0.186*"qr"
2016-10-09 22:32:42,881 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:42,882 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:42,883 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:42,884 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,884 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,884 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:42,885 : INFO : saved 10x5216 matrix, density=0.387% (202/52160)
2016-10-09 22:32:42,885 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,885 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,885 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,885 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:42,885 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:42,886 : INFO : accepted corpus with 10 documents, 5216 features, 202 non-zero entries
2016-10-09 22:32:42,886 : INFO : collecting document frequencies
2016-10-09 22:32:42,886 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:42,886 : INFO : calculating IDF weights for 10 documents and 5215 features (202 matrix non-zeros)
2016-10-09 22:32:42,886 : INFO : using serial LSI version on this node
2016-10-09 22:32:42,886 : INFO : updating model with new documents
2016-10-09 22:32:42,887 : INFO : preparing a new chunk of documents
2016-10-09 22:32:42,887 : DEBUG : converting corpus to csc format
2016-10-09 22:32:42,887 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:42,890 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:42,890 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:42,917 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,015 : DEBUG : running 2 power iterations
2016-10-09 22:32:43,055 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,192 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,305 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:43,313 : INFO : computing the final decomposition
2016-10-09 22:32:43,313 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:43,316 : INFO : processed documents up to #10
2016-10-09 22:32:43,316 : INFO : topic #0(1.140): 0.316*"job" + 0.233*"good" + 0.214*"many" + 0.158*"com" + 0.158*"hard" + 0.158*"time" + 0.158*"american" + 0.158*"website" + 0.156*"get" + 0.154*"doha"
2016-10-09 22:32:43,316 : INFO : topic #1(1.069): -0.281*"library" + -0.276*"like" + -0.211*"work" + -0.208*"e" + -0.208*"u" + -0.208*"comparable" + -0.208*"may" + -0.208*"ask" + -0.208*"conditions" + -0.190*"would"
2016-10-09 22:32:43,317 : INFO : topic #2(1.023): -0.348*"petroleum" + 0.266*"library" + -0.228*"im" + -0.210*"trap" + -0.210*"co" + -0.210*"avoid" + -0.210*"http" + -0.210*"read" + -0.210*"bored" + 0.157*"like"
2016-10-09 22:32:43,317 : INFO : topic #3(1.005): -0.261*"library" + -0.229*"accept" + -0.229*"bank" + 0.219*"safe" + 0.219*"expat" + -0.123*"like" + 0.116*"want" + -0.115*"loan" + -0.115*"pay" + -0.115*"option"
2016-10-09 22:32:43,317 : INFO : topic #4(0.999): -0.236*"library" + 0.203*"guide" + 0.203*"consultant" + -0.198*"http" + -0.198*"avoid" + -0.198*"bored" + -0.198*"co" + -0.198*"trap" + -0.198*"read" + 0.168*"accept"
2016-10-09 22:32:43,317 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:43,318 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:43,319 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:43,320 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,321 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,321 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:43,321 : INFO : saved 10x5332 matrix, density=0.326% (174/53320)
2016-10-09 22:32:43,321 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,321 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,321 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:43,322 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:43,322 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,322 : INFO : accepted corpus with 10 documents, 5332 features, 174 non-zero entries
2016-10-09 22:32:43,322 : INFO : collecting document frequencies
2016-10-09 22:32:43,322 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:43,322 : INFO : calculating IDF weights for 10 documents and 5331 features (174 matrix non-zeros)
2016-10-09 22:32:43,323 : INFO : using serial LSI version on this node
2016-10-09 22:32:43,323 : INFO : updating model with new documents
2016-10-09 22:32:43,323 : INFO : preparing a new chunk of documents
2016-10-09 22:32:43,323 : DEBUG : converting corpus to csc format
2016-10-09 22:32:43,323 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:43,326 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:43,327 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:43,353 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,452 : DEBUG : running 2 power iterations
2016-10-09 22:32:43,491 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,631 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,743 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:43,751 : INFO : computing the final decomposition
2016-10-09 22:32:43,751 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:43,754 : INFO : processed documents up to #10
2016-10-09 22:32:43,754 : INFO : topic #0(1.067): -0.278*"jpg" + -0.278*"society" + -0.278*"qatarliving" + -0.278*"dr" + -0.265*"http" + -0.265*"www" + -0.265*"com" + -0.179*"nations" + -0.168*"extend" + -0.168*"big"
2016-10-09 22:32:43,754 : INFO : topic #1(1.029): 0.286*"hijab" + 0.231*"others" + 0.189*"islam" + 0.188*"pm" + 0.188*"person" + 0.188*"involved" + 0.188*"likes" + 0.188*"question" + 0.188*"converted" + 0.188*"intrested"
2016-10-09 22:32:43,754 : INFO : topic #2(1.015): -0.260*"hijab" + 0.205*"people" + 0.198*"us" + 0.198*"important" + 0.198*"think" + 0.198*"drink" + 0.198*"tell" + 0.198*"must" + 0.198*"qatari" + 0.190*"50"
2016-10-09 22:32:43,754 : INFO : topic #3(1.002): -0.343*"crime" + 0.252*"gold" + -0.228*"polygamy" + -0.228*"west" + -0.228*"wife" + -0.228*"considered" + 0.189*"wearing" + 0.189*"golden" + -0.132*"nations" + 0.126*"indian"
2016-10-09 22:32:43,755 : INFO : topic #4(1.000): 0.336*"jesus" + 0.336*"truth" + 0.168*"message" + 0.168*"please" + 0.168*"bible" + 0.168*"rejected" + 0.168*"son" + 0.168*"pardon" + 0.168*"earth" + 0.168*"explain"
2016-10-09 22:32:43,755 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:43,756 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:43,757 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:43,758 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,758 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,758 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:43,759 : INFO : saved 10x5292 matrix, density=0.393% (208/52920)
2016-10-09 22:32:43,759 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,759 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,759 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:43,759 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:43,759 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:43,760 : INFO : accepted corpus with 10 documents, 5292 features, 208 non-zero entries
2016-10-09 22:32:43,760 : INFO : collecting document frequencies
2016-10-09 22:32:43,760 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:43,760 : INFO : calculating IDF weights for 10 documents and 5291 features (208 matrix non-zeros)
2016-10-09 22:32:43,760 : INFO : using serial LSI version on this node
2016-10-09 22:32:43,760 : INFO : updating model with new documents
2016-10-09 22:32:43,761 : INFO : preparing a new chunk of documents
2016-10-09 22:32:43,761 : DEBUG : converting corpus to csc format
2016-10-09 22:32:43,761 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:43,764 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:43,764 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:43,791 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:43,890 : DEBUG : running 2 power iterations
2016-10-09 22:32:43,929 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,067 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,189 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:44,197 : INFO : computing the final decomposition
2016-10-09 22:32:44,197 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:44,200 : INFO : processed documents up to #10
2016-10-09 22:32:44,200 : INFO : topic #0(1.190): 0.268*"exam" + 0.257*"salary" + 0.222*"evaluation" + 0.213*"training" + 0.194*"need" + 0.149*"hmc" + 0.144*"pass" + 0.134*"nurses" + 0.132*"well" + 0.129*"experience"
2016-10-09 22:32:44,201 : INFO : topic #1(1.087): -0.367*"exam" + 0.267*"salary" + -0.202*"evaluation" + -0.188*"pass" + 0.179*"hmc" + -0.175*"sit" + -0.175*"prometric" + -0.156*"regarding" + -0.156*"anyone" + -0.156*"information"
2016-10-09 22:32:44,201 : INFO : topic #2(1.030): -0.357*"training" + -0.201*"license" + -0.201*"4" + -0.201*"get" + -0.187*"need" + 0.172*"qatar" + -0.169*"evaluation" + -0.162*"hmc" + -0.150*"sch" + 0.131*"exam"
2016-10-09 22:32:44,201 : INFO : topic #3(1.000): -0.816*"stage" + -0.408*"verification" + -0.408*"right" + -0.000*"take" + -0.000*"experience" + 0.000*"hmc" + 0.000*"medical" + -0.000*"dont" + -0.000*"even" + -0.000*"work"
2016-10-09 22:32:44,201 : INFO : topic #4(0.998): 0.297*"take" + -0.218*"medical" + -0.180*"salary" + -0.150*"hmc" + 0.149*"even" + 0.149*"lot" + 0.149*"work" + 0.149*"godbless" + 0.149*"necessary" + 0.149*"company"
2016-10-09 22:32:44,201 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:44,202 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:44,203 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:44,205 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,205 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,205 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:44,205 : INFO : saved 10x5308 matrix, density=0.441% (234/53080)
2016-10-09 22:32:44,205 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,206 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,206 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:44,206 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:44,206 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,206 : INFO : accepted corpus with 10 documents, 5308 features, 234 non-zero entries
2016-10-09 22:32:44,206 : INFO : collecting document frequencies
2016-10-09 22:32:44,206 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:44,206 : INFO : calculating IDF weights for 10 documents and 5307 features (234 matrix non-zeros)
2016-10-09 22:32:44,207 : INFO : using serial LSI version on this node
2016-10-09 22:32:44,207 : INFO : updating model with new documents
2016-10-09 22:32:44,207 : INFO : preparing a new chunk of documents
2016-10-09 22:32:44,207 : DEBUG : converting corpus to csc format
2016-10-09 22:32:44,208 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:44,211 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:44,211 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:44,237 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,336 : DEBUG : running 2 power iterations
2016-10-09 22:32:44,375 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,513 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,627 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:44,635 : INFO : computing the final decomposition
2016-10-09 22:32:44,635 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:44,638 : INFO : processed documents up to #10
2016-10-09 22:32:44,638 : INFO : topic #0(1.087): -0.204*"india" + -0.160*"indian" + -0.159*"sunny" + -0.142*"kerala" + -0.139*"asian" + -0.136*"part" + -0.134*"women" + -0.134*"men" + -0.134*"western" + -0.134*"2"
2016-10-09 22:32:44,638 : INFO : topic #1(1.044): 0.208*"indian" + 0.195*"2" + 0.195*"keralites" + 0.153*"india" + 0.151*"marry" + 0.151*"girls" + 0.151*"arab" + 0.151*"getting" + -0.147*"please" + -0.139*"hmc"
2016-10-09 22:32:44,638 : INFO : topic #2(1.025): 0.231*"p" + -0.216*"sunny" + -0.189*"asian" + -0.182*"men" + -0.182*"women" + -0.182*"western" + 0.154*"letter" + 0.154*"" + 0.149*"words" + -0.144*"qatari"
2016-10-09 22:32:44,638 : INFO : topic #3(1.005): 0.246*"india" + -0.235*"hmc" + 0.215*"p" + -0.177*"qbs" + -0.177*"jobs" + -0.177*"heard" + -0.177*"consider" + -0.177*"special" + -0.177*"love" + -0.177*"wonder"
2016-10-09 22:32:44,639 : INFO : topic #4(1.000): 0.229*"getting" + 0.229*"girls" + 0.229*"marry" + 0.229*"arab" + -0.201*"qbs" + -0.201*"love" + -0.201*"consider" + -0.201*"special" + -0.201*"wonder" + -0.201*"really"
2016-10-09 22:32:44,639 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:44,640 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:44,641 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:44,642 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,642 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,642 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:44,643 : INFO : saved 10x5324 matrix, density=0.314% (167/53240)
2016-10-09 22:32:44,643 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,643 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,643 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:44,643 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:44,644 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:44,644 : INFO : accepted corpus with 10 documents, 5324 features, 167 non-zero entries
2016-10-09 22:32:44,644 : INFO : collecting document frequencies
2016-10-09 22:32:44,644 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:44,644 : INFO : calculating IDF weights for 10 documents and 5323 features (167 matrix non-zeros)
2016-10-09 22:32:44,644 : INFO : using serial LSI version on this node
2016-10-09 22:32:44,644 : INFO : updating model with new documents
2016-10-09 22:32:44,645 : INFO : preparing a new chunk of documents
2016-10-09 22:32:44,645 : DEBUG : converting corpus to csc format
2016-10-09 22:32:44,645 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:44,648 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:44,648 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:44,675 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,774 : DEBUG : running 2 power iterations
2016-10-09 22:32:44,813 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:44,951 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,065 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:45,073 : INFO : computing the final decomposition
2016-10-09 22:32:45,073 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:45,076 : INFO : processed documents up to #10
2016-10-09 22:32:45,076 : INFO : topic #0(1.147): 0.384*"buy" + 0.268*"know" + 0.259*"need" + 0.259*"please" + 0.192*"called" + 0.192*"let" + 0.192*"purchase" + 0.192*"knows" + 0.192*"advance" + 0.192*"shop"
2016-10-09 22:32:45,076 : INFO : topic #1(1.080): 0.262*"hi" + 0.253*"get" + 0.232*"machine" + 0.232*"bread" + 0.215*"good" + 0.198*"much" + -0.177*"buy" + 0.175*"find" + 0.163*"thanks" + 0.152*"bicycle"
2016-10-09 22:32:45,076 : INFO : topic #2(1.011): 0.368*"cards" + 0.276*"bank" + -0.217*"dog" + -0.217*"filipino" + 0.184*"qnb" + 0.184*"worked" + 0.184*"commercial" + 0.155*"know" + 0.151*"yes" + -0.140*"buy"
2016-10-09 22:32:45,077 : INFO : topic #3(1.005): -0.215*"dog" + -0.215*"filipino" + -0.202*"like" + -0.202*"around" + -0.202*"qataris" + -0.202*"anything" + 0.176*"machine" + 0.176*"bread" + 0.163*"hi" + -0.153*"idea"
2016-10-09 22:32:45,077 : INFO : topic #4(1.001): 0.255*"cards" + -0.247*"around" + -0.247*"qataris" + -0.247*"anything" + -0.247*"like" + 0.191*"bank" + 0.127*"worked" + 0.127*"commercial" + 0.127*"qnb" + -0.127*"get"
2016-10-09 22:32:45,077 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:45,078 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:45,079 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:45,080 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,080 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,080 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:45,081 : INFO : saved 10x5323 matrix, density=0.368% (196/53230)
2016-10-09 22:32:45,081 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,081 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,081 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,081 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,081 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,082 : INFO : accepted corpus with 10 documents, 5323 features, 196 non-zero entries
2016-10-09 22:32:45,082 : INFO : collecting document frequencies
2016-10-09 22:32:45,082 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:45,082 : INFO : calculating IDF weights for 10 documents and 5322 features (196 matrix non-zeros)
2016-10-09 22:32:45,082 : INFO : using serial LSI version on this node
2016-10-09 22:32:45,082 : INFO : updating model with new documents
2016-10-09 22:32:45,083 : INFO : preparing a new chunk of documents
2016-10-09 22:32:45,083 : DEBUG : converting corpus to csc format
2016-10-09 22:32:45,083 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:45,086 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:45,086 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:45,113 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,212 : DEBUG : running 2 power iterations
2016-10-09 22:32:45,252 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,390 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,503 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:45,510 : INFO : computing the final decomposition
2016-10-09 22:32:45,510 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:45,513 : INFO : processed documents up to #10
2016-10-09 22:32:45,514 : INFO : topic #0(1.160): -0.231*"wife" + -0.203*"company" + -0.179*"even" + -0.179*"please" + -0.168*"sponsor" + -0.167*"know" + -0.164*"children" + -0.164*"government" + -0.161*"months" + -0.161*"change"
2016-10-09 22:32:45,514 : INFO : topic #1(1.042): -0.348*"know" + -0.203*"hi" + -0.171*"wednesday" + -0.171*"success" + -0.171*"managed" + -0.171*"see" + -0.171*"trying" + -0.171*"today" + -0.171*"friends" + -0.171*"end"
2016-10-09 22:32:45,514 : INFO : topic #2(1.026): -0.353*"license" + -0.252*"need" + -0.219*"weekend" + -0.219*"long" + -0.219*"exit" + -0.219*"together" + -0.219*"going" + -0.219*"go" + -0.219*"away" + -0.219*"permit"
2016-10-09 22:32:45,514 : INFO : topic #3(1.010): 0.339*"license" + -0.309*"qatar" + -0.257*"family" + -0.171*"visa" + 0.167*"need" + -0.155*"corporation" + -0.155*"hamad" + -0.155*"female" + -0.155*"allowed" + -0.155*"govt"
2016-10-09 22:32:45,514 : INFO : topic #4(0.996): -0.206*"please" + -0.206*"even" + -0.196*"months" + -0.196*"change" + -0.196*"three" + 0.168*"sponsored" + 0.155*"job" + 0.137*"would" + 0.137*"immediate" + 0.137*"someone"
2016-10-09 22:32:45,514 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:45,515 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:45,516 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:45,518 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,518 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,518 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:45,518 : INFO : saved 10x5208 matrix, density=0.353% (184/52080)
2016-10-09 22:32:45,518 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,518 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,518 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,519 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,519 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,519 : INFO : accepted corpus with 10 documents, 5208 features, 184 non-zero entries
2016-10-09 22:32:45,519 : INFO : collecting document frequencies
2016-10-09 22:32:45,519 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:45,519 : INFO : calculating IDF weights for 10 documents and 5207 features (184 matrix non-zeros)
2016-10-09 22:32:45,520 : INFO : using serial LSI version on this node
2016-10-09 22:32:45,520 : INFO : updating model with new documents
2016-10-09 22:32:45,520 : INFO : preparing a new chunk of documents
2016-10-09 22:32:45,520 : DEBUG : converting corpus to csc format
2016-10-09 22:32:45,521 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:45,524 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:45,524 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:45,550 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,649 : DEBUG : running 2 power iterations
2016-10-09 22:32:45,688 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,827 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:45,939 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:45,947 : INFO : computing the final decomposition
2016-10-09 22:32:45,947 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:45,950 : INFO : processed documents up to #10
2016-10-09 22:32:45,950 : INFO : topic #0(1.121): -0.309*"good" + -0.281*"budget" + -0.231*"maintenance" + -0.216*"shape" + -0.216*"45000" + -0.216*"performance" + -0.181*"best" + -0.128*"advice" + -0.127*"buying" + -0.116*"thank"
2016-10-09 22:32:45,951 : INFO : topic #1(1.055): 0.293*"buying" + -0.232*"good" + 0.225*"advise" + 0.225*"check" + 0.214*"please" + 0.193*"offer" + 0.193*"costs" + 0.193*"u" + 0.193*"process" + 0.193*"porsche"
2016-10-09 22:32:45,951 : INFO : topic #2(1.024): 0.252*"dubai" + 0.239*"possible" + 0.216*"name" + 0.216*"driving" + 0.216*"folks" + 0.216*"license" + 0.216*"without" + 0.191*"cars" + 0.143*"doha" + 0.126*"country"
2016-10-09 22:32:45,951 : INFO : topic #3(1.009): -0.294*"cars" + -0.244*"would" + -0.221*"doha" + 0.191*"license" + 0.191*"name" + 0.191*"folks" + 0.191*"driving" + 0.191*"without" + 0.164*"possible" + -0.137*"prices"
2016-10-09 22:32:45,951 : INFO : topic #4(0.997): -0.345*"right" + 0.264*"cars" + 0.198*"doha" + -0.172*"armada" + -0.172*"available" + -0.172*"cost" + -0.172*"prado" + -0.172*"problems" + -0.172*"wants" + -0.172*"suggestions"
2016-10-09 22:32:45,951 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:45,952 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:45,953 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:45,954 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,955 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,955 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:45,955 : INFO : saved 10x5331 matrix, density=0.413% (220/53310)
2016-10-09 22:32:45,955 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,955 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,955 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,956 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:45,956 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:45,956 : INFO : accepted corpus with 10 documents, 5331 features, 220 non-zero entries
2016-10-09 22:32:45,956 : INFO : collecting document frequencies
2016-10-09 22:32:45,956 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:45,956 : INFO : calculating IDF weights for 10 documents and 5330 features (220 matrix non-zeros)
2016-10-09 22:32:45,957 : INFO : using serial LSI version on this node
2016-10-09 22:32:45,957 : INFO : updating model with new documents
2016-10-09 22:32:45,957 : INFO : preparing a new chunk of documents
2016-10-09 22:32:45,957 : DEBUG : converting corpus to csc format
2016-10-09 22:32:45,958 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:45,961 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:45,961 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:45,987 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,086 : DEBUG : running 2 power iterations
2016-10-09 22:32:46,125 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,264 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,376 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:46,383 : INFO : computing the final decomposition
2016-10-09 22:32:46,383 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:46,386 : INFO : processed documents up to #10
2016-10-09 22:32:46,387 : INFO : topic #0(1.158): 0.294*"best" + 0.290*"pakistani" + 0.218*"school" + 0.194*"thanks" + 0.168*"members" + 0.160*"3" + 0.157*"children" + 0.133*"qatar" + 0.128*"good" + 0.126*"education"
2016-10-09 22:32:46,387 : INFO : topic #1(1.045): 0.286*"schools" + 0.237*"british" + -0.187*"members" + 0.179*"many" + 0.158*"arabic" + 0.158*"really" + 0.158*"solution" + 0.158*"know" + 0.158*"compulsory" + -0.139*"dear"
2016-10-09 22:32:46,387 : INFO : topic #2(1.029): 0.207*"bus" + 0.194*"schools" + 0.185*"many" + -0.162*"3" + 0.152*"child" + -0.150*"international" + 0.147*"british" + -0.134*"location" + 0.132*"members" + -0.131*"planning"
2016-10-09 22:32:46,387 : INFO : topic #3(1.002): -0.403*"bus" + 0.254*"pakistani" + -0.229*"child" + -0.201*"found" + 0.196*"best" + -0.185*"location" + -0.130*"international" + 0.122*"coaching" + 0.122*"b" + 0.122*"quality"
2016-10-09 22:32:46,387 : INFO : topic #4(0.994): 0.306*"pakistani" + 0.273*"bus" + -0.194*"private" + -0.194*"tuition" + 0.168*"children" + 0.137*"found" + 0.126*"best" + -0.124*"members" + 0.113*"child" + 0.108*"thanks"
2016-10-09 22:32:46,387 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:46,389 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:46,390 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:46,391 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,391 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,391 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:46,391 : INFO : saved 10x5279 matrix, density=0.371% (196/52790)
2016-10-09 22:32:46,391 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,392 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,392 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:46,392 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:46,392 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,392 : INFO : accepted corpus with 10 documents, 5279 features, 196 non-zero entries
2016-10-09 22:32:46,392 : INFO : collecting document frequencies
2016-10-09 22:32:46,393 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:46,393 : INFO : calculating IDF weights for 10 documents and 5278 features (196 matrix non-zeros)
2016-10-09 22:32:46,393 : INFO : using serial LSI version on this node
2016-10-09 22:32:46,393 : INFO : updating model with new documents
2016-10-09 22:32:46,393 : INFO : preparing a new chunk of documents
2016-10-09 22:32:46,394 : DEBUG : converting corpus to csc format
2016-10-09 22:32:46,394 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:46,397 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:46,397 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:46,423 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,523 : DEBUG : running 2 power iterations
2016-10-09 22:32:46,562 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,703 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,816 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:46,824 : INFO : computing the final decomposition
2016-10-09 22:32:46,824 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:46,827 : INFO : processed documents up to #10
2016-10-09 22:32:46,827 : INFO : topic #0(1.139): -0.261*"qatar" + -0.223*"anybody" + -0.189*"please" + -0.174*"apply" + -0.171*"embassy" + -0.168*"know" + -0.162*"family" + -0.151*"itz" + -0.137*"tourist" + -0.137*"australian"
2016-10-09 22:32:46,827 : INFO : topic #1(1.047): 0.256*"qatar" + -0.211*"family" + -0.190*"lebanese" + -0.179*"still" + -0.177*"exit" + -0.177*"country" + 0.143*"tourist" + 0.139*"embassy" + 0.135*"anybody" + -0.132*"itz"
2016-10-09 22:32:46,827 : INFO : topic #2(1.042): -0.318*"anybody" + 0.268*"qatar" + 0.199*"tourist" + -0.186*"please" + -0.167*"extend" + -0.167*"month" + -0.167*"maximum" + -0.167*"doha" + -0.167*"whether" + -0.167*"3"
2016-10-09 22:32:46,828 : INFO : topic #3(1.008): 0.207*"us" + 0.207*"anything" + 0.207*"sad" + 0.207*"road" + 0.207*"suggest" + 0.207*"cant" + 0.207*"salaam" + 0.207*"parents" + 0.207*"air" + 0.207*"hear"
2016-10-09 22:32:46,828 : INFO : topic #4(1.003): 0.358*"extension" + 0.179*"system" + 0.179*"4" + 0.179*"passport" + 0.179*"sponsor" + 0.179*"something" + 0.179*"approved" + 0.179*"printed" + 0.179*"really" + 0.179*"form"
2016-10-09 22:32:46,828 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:46,829 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:46,830 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:46,831 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,831 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,831 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:46,831 : INFO : saved 10x5235 matrix, density=0.264% (138/52350)
2016-10-09 22:32:46,832 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,832 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,832 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:46,832 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:46,832 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:46,832 : INFO : accepted corpus with 10 documents, 5235 features, 138 non-zero entries
2016-10-09 22:32:46,833 : INFO : collecting document frequencies
2016-10-09 22:32:46,833 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:46,833 : INFO : calculating IDF weights for 10 documents and 5234 features (138 matrix non-zeros)
2016-10-09 22:32:46,833 : INFO : using serial LSI version on this node
2016-10-09 22:32:46,833 : INFO : updating model with new documents
2016-10-09 22:32:46,833 : INFO : preparing a new chunk of documents
2016-10-09 22:32:46,834 : DEBUG : converting corpus to csc format
2016-10-09 22:32:46,834 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:46,837 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:46,837 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:46,864 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:46,962 : DEBUG : running 2 power iterations
2016-10-09 22:32:47,001 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,140 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,252 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:47,260 : INFO : computing the final decomposition
2016-10-09 22:32:47,260 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:47,263 : INFO : processed documents up to #10
2016-10-09 22:32:47,263 : INFO : topic #0(1.117): 0.281*"accommodation" + 0.277*"expensive" + 0.185*"quality" + 0.185*"standards" + 0.185*"famous" + 0.185*"decorations" + 0.185*"finishing" + 0.184*"qatar" + 0.183*"etc" + 0.166*"good"
2016-10-09 22:32:47,264 : INFO : topic #1(1.049): -0.358*"school" + -0.183*"th" + -0.183*"asked" + -0.183*"entry" + -0.183*"passed" + -0.183*"exam" + -0.183*"recommended" + -0.183*"son" + -0.183*"fees" + -0.182*"doha"
2016-10-09 22:32:47,264 : INFO : topic #2(1.033): 0.255*"thread" + 0.189*"else" + 0.189*"anywhere" + 0.189*"milk" + 0.189*"ps" + 0.189*"dedicated" + 0.175*"soft" + 0.175*"higher" + 0.175*"nice" + 0.175*"buy"
2016-10-09 22:32:47,264 : INFO : topic #3(1.015): -0.171*"thanks" + 0.164*"soft" + 0.164*"higher" + 0.164*"thinking" + 0.164*"buy" + 0.164*"really" + 0.164*"nice" + 0.164*"uk" + -0.162*"guys" + -0.162*"would"
2016-10-09 22:32:47,264 : INFO : topic #4(0.999): 0.258*"concerned" + 0.258*"sick" + 0.258*"sort" + 0.258*"years" + 0.258*"able" + 0.258*"treatment" + 0.258*"health" + 0.258*"might" + 0.258*"insurance" + 0.258*"couple"
2016-10-09 22:32:47,264 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:47,265 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:47,266 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:47,267 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,267 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,267 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:47,268 : INFO : saved 10x5324 matrix, density=0.374% (199/53240)
2016-10-09 22:32:47,268 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,268 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,268 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:47,269 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:47,269 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,269 : INFO : accepted corpus with 10 documents, 5324 features, 199 non-zero entries
2016-10-09 22:32:47,269 : INFO : collecting document frequencies
2016-10-09 22:32:47,269 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:47,269 : INFO : calculating IDF weights for 10 documents and 5323 features (199 matrix non-zeros)
2016-10-09 22:32:47,269 : INFO : using serial LSI version on this node
2016-10-09 22:32:47,270 : INFO : updating model with new documents
2016-10-09 22:32:47,270 : INFO : preparing a new chunk of documents
2016-10-09 22:32:47,270 : DEBUG : converting corpus to csc format
2016-10-09 22:32:47,270 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:47,273 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:47,274 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:47,300 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,399 : DEBUG : running 2 power iterations
2016-10-09 22:32:47,438 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,579 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,691 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:47,699 : INFO : computing the final decomposition
2016-10-09 22:32:47,699 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:47,702 : INFO : processed documents up to #10
2016-10-09 22:32:47,702 : INFO : topic #0(1.091): 0.250*"ql" + 0.178*"work" + 0.161*"qatar" + 0.153*"never" + 0.151*"without" + 0.145*"lucky" + 0.139*"nobody" + 0.139*"xp" + 0.139*"talk" + 0.139*"wonder"
2016-10-09 22:32:47,702 : INFO : topic #1(1.048): 0.294*"qatar" + 0.206*"get" + 0.203*"diseases" + -0.200*"without" + 0.188*"thanks" + 0.180*"lucky" + -0.154*"watch" + -0.154*"look" + -0.154*"com" + -0.154*"youtube"
2016-10-09 22:32:47,702 : INFO : topic #2(1.031): -0.252*"diseases" + 0.232*"ql" + 0.207*"surfing" + 0.207*"everyone" + 0.207*"spend" + 0.207*"hour" + 0.207*"hours" + 0.180*"lucky" + -0.168*"noticed" + 0.152*"many"
2016-10-09 22:32:47,702 : INFO : topic #3(1.020): -0.219*"http" + -0.219*"v" + -0.219*"youtube" + -0.219*"www" + -0.219*"com" + -0.186*"look" + -0.186*"watch" + 0.185*"ql" + 0.172*"work" + -0.167*"qatar"
2016-10-09 22:32:47,703 : INFO : topic #4(1.000): 0.328*"diseases" + -0.251*"speed" + 0.219*"noticed" + -0.168*"qtel" + -0.168*"still" + -0.168*"help" + -0.168*"issue" + -0.138*"bye" + 0.117*"least" + -0.112*"like"
2016-10-09 22:32:47,703 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:47,704 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:47,705 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:47,706 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,706 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,706 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:47,707 : INFO : saved 10x5274 matrix, density=0.411% (217/52740)
2016-10-09 22:32:47,707 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,707 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,707 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:47,708 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:47,708 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:47,708 : INFO : accepted corpus with 10 documents, 5274 features, 217 non-zero entries
2016-10-09 22:32:47,708 : INFO : collecting document frequencies
2016-10-09 22:32:47,708 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:47,708 : INFO : calculating IDF weights for 10 documents and 5273 features (217 matrix non-zeros)
2016-10-09 22:32:47,708 : INFO : using serial LSI version on this node
2016-10-09 22:32:47,709 : INFO : updating model with new documents
2016-10-09 22:32:47,709 : INFO : preparing a new chunk of documents
2016-10-09 22:32:47,709 : DEBUG : converting corpus to csc format
2016-10-09 22:32:47,709 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:47,712 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:47,713 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:47,739 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:47,838 : DEBUG : running 2 power iterations
2016-10-09 22:32:47,877 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:48,015 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:48,128 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:48,135 : INFO : computing the final decomposition
2016-10-09 22:32:48,136 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:48,138 : INFO : processed documents up to #10
2016-10-09 22:32:48,139 : INFO : topic #0(1.059): 0.229*"license" + 0.215*"driving" + 0.210*"anyone" + 0.178*"jazeera" + 0.178*"al" + 0.158*"radio" + 0.158*"night" + 0.157*"please" + 0.155*"tell" + 0.145*"colour"
2016-10-09 22:32:48,139 : INFO : topic #1(1.019): 0.270*"true" + 0.217*"buy" + 0.188*"2" + 0.180*"places" + -0.146*"anyone" + 0.142*"qatar" + -0.131*"blind" + -0.131*"acceptable" + -0.131*"whether" + -0.131*"colour"
2016-10-09 22:32:48,139 : INFO : topic #2(1.010): -0.376*"qar" + -0.240*"license" + 0.224*"jazeera" + 0.224*"al" + -0.188*"000" + -0.183*"driving" + 0.152*"buy" + 0.150*"accommodation" + 0.125*"anyone" + -0.125*"offer"
2016-10-09 22:32:48,139 : INFO : topic #3(1.004): 0.371*"buy" + 0.185*"k" + 0.185*"done" + 0.185*"boxes" + 0.185*"two" + 0.185*"bought" + 0.185*"special" + 0.185*"worst" + 0.185*"sin" + 0.185*"things"
2016-10-09 22:32:48,139 : INFO : topic #4(1.001): 0.415*"2" + 0.207*"bits" + 0.207*"cups" + 0.207*"meat" + 0.207*"plz" + 0.207*"proper" + 0.207*"black" + 0.207*"note" + 0.207*"lovely" + -0.163*"items"
2016-10-09 22:32:48,140 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:48,141 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:48,142 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:48,143 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,143 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,143 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:48,143 : INFO : saved 10x5319 matrix, density=0.182% (97/53190)
2016-10-09 22:32:48,143 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,143 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,143 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,144 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,144 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,144 : INFO : accepted corpus with 10 documents, 5319 features, 97 non-zero entries
2016-10-09 22:32:48,144 : INFO : collecting document frequencies
2016-10-09 22:32:48,144 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:48,144 : INFO : calculating IDF weights for 10 documents and 5318 features (97 matrix non-zeros)
2016-10-09 22:32:48,145 : INFO : using serial LSI version on this node
2016-10-09 22:32:48,145 : INFO : updating model with new documents
2016-10-09 22:32:48,145 : INFO : preparing a new chunk of documents
2016-10-09 22:32:48,145 : DEBUG : converting corpus to csc format
2016-10-09 22:32:48,145 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:48,148 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:32:48,149 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:32:48,175 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:48,275 : DEBUG : running 2 power iterations
2016-10-09 22:32:48,314 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:48,452 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:32:48,566 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:32:48,574 : INFO : computing the final decomposition
2016-10-09 22:32:48,574 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:48,577 : INFO : processed documents up to #10
2016-10-09 22:32:48,577 : INFO : topic #0(1.112): 0.468*"see" + 0.353*"moon" + 0.325*"world" + 0.317*"didnt" + 0.200*"friend" + 0.176*"end" + 0.176*"lot" + 0.176*"round" + 0.158*"also" + 0.158*"vacation"
2016-10-09 22:32:48,577 : INFO : topic #1(1.069): 0.517*"comment" + 0.449*"please" + 0.279*"missing" + 0.279*"authorized" + 0.279*"qlers" + 0.279*"names" + 0.240*"add" + 0.190*"topic" + 0.126*"every" + 0.063*"hijacking"
2016-10-09 22:32:48,577 : INFO : topic #2(1.034): 0.382*"many" + 0.366*"returns" + 0.366*"happy" + 0.366*"party" + 0.359*"boss" + 0.180*"till" + 0.180*"coz" + 0.180*"missed" + 0.180*"infront" + 0.180*"sitting"
2016-10-09 22:32:48,577 : INFO : topic #3(1.015): 0.282*"u" + -0.266*"agree" + -0.266*"data" + -0.266*"per" + -0.266*"filipinos" + -0.266*"men" + -0.266*"part" + -0.259*"world" + 0.177*"didnt" + 0.160*"ql"
2016-10-09 22:32:48,578 : INFO : topic #4(1.000): -1.000*"going" + -0.000*"u" + -0.000*"boss" + -0.000*"topic" + 0.000*"see" + -0.000*"dear" + 0.000*"moon" + -0.000*"every" + 0.000*"didnt" + -0.000*"pic"
2016-10-09 22:32:48,578 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:48,579 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:48,579 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:48,639 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,640 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,640 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:48,640 : INFO : saved 10x5235 matrix, density=0.308% (161/52350)
2016-10-09 22:32:48,640 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,640 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,640 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,641 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,641 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,641 : INFO : accepted corpus with 10 documents, 5235 features, 161 non-zero entries
2016-10-09 22:32:48,641 : INFO : collecting document frequencies
2016-10-09 22:32:48,641 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:48,641 : INFO : calculating IDF weights for 10 documents and 5234 features (161 matrix non-zeros)
2016-10-09 22:32:48,641 : INFO : using serial LSI version on this node
2016-10-09 22:32:48,641 : INFO : updating model with new documents
2016-10-09 22:32:48,642 : INFO : preparing a new chunk of documents
2016-10-09 22:32:48,642 : DEBUG : converting corpus to csc format
2016-10-09 22:32:48,642 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:48,644 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:48,645 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:48,658 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:48,698 : DEBUG : running 2 power iterations
2016-10-09 22:32:48,717 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:48,776 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:48,825 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:48,830 : INFO : computing the final decomposition
2016-10-09 22:32:48,831 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:48,833 : INFO : processed documents up to #10
2016-10-09 22:32:48,833 : INFO : topic #0(1.187): -0.284*"open" + -0.283*"best" + -0.281*"savings" + -0.244*"account" + -0.188*"doha" + -0.175*"hi" + -0.168*"everybody" + -0.163*"using" + -0.156*"soon" + -0.156*"please"
2016-10-09 22:32:48,833 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"ql" + -0.155*"home" + -0.133*"recommend"
2016-10-09 22:32:48,834 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"home" + 0.267*"ql" + -0.246*"services" + -0.246*"islamic" + 0.236*"regards" + -0.153*"banks" + -0.153*"good" + -0.127*"accept" + -0.123*"commercial"
2016-10-09 22:32:48,834 : INFO : topic #3(1.002): 0.271*"islamic" + 0.271*"services" + -0.269*"accept" + -0.179*"transfer" + -0.159*"paid" + -0.159*"overseas" + -0.159*"recommendations" + -0.159*"funds" + -0.159*"used" + -0.159*"use"
2016-10-09 22:32:48,834 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"help" + 0.146*"nice" + 0.146*"see" + 0.146*"everyone" + 0.146*"want" + 0.146*"know" + 0.146*"opening"
2016-10-09 22:32:48,834 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:48,835 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:48,836 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:48,837 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,837 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,837 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:48,837 : INFO : saved 10x5301 matrix, density=0.277% (147/53010)
2016-10-09 22:32:48,838 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,838 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,838 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,838 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:48,838 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:48,838 : INFO : accepted corpus with 10 documents, 5301 features, 147 non-zero entries
2016-10-09 22:32:48,839 : INFO : collecting document frequencies
2016-10-09 22:32:48,839 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:48,839 : INFO : calculating IDF weights for 10 documents and 5300 features (147 matrix non-zeros)
2016-10-09 22:32:48,839 : INFO : using serial LSI version on this node
2016-10-09 22:32:48,839 : INFO : updating model with new documents
2016-10-09 22:32:48,839 : INFO : preparing a new chunk of documents
2016-10-09 22:32:48,840 : DEBUG : converting corpus to csc format
2016-10-09 22:32:48,840 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:48,842 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:48,842 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:48,854 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:48,893 : DEBUG : running 2 power iterations
2016-10-09 22:32:48,913 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:48,973 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,021 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,026 : INFO : computing the final decomposition
2016-10-09 22:32:49,026 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:49,028 : INFO : processed documents up to #10
2016-10-09 22:32:49,029 : INFO : topic #0(1.125): -0.314*"go" + -0.268*"qatar" + -0.258*"catch" + -0.255*"next" + -0.255*"friday" + -0.227*"planning" + -0.213*"know" + -0.163*"place" + -0.149*"beach" + -0.149*"like"
2016-10-09 22:32:49,029 : INFO : topic #1(1.046): -0.257*"shisha" + -0.218*"hi" + -0.202*"family" + 0.193*"planning" + 0.183*"go" + -0.166*"say" + -0.166*"someone" + -0.166*"front" + -0.166*"swimming" + -0.166*"camping"
2016-10-09 22:32:49,029 : INFO : topic #2(1.018): -0.432*"card" + -0.215*"would" + -0.173*"gives" + -0.173*"using" + -0.154*"spend" + -0.134*"massage" + -0.134*"tell" + -0.134*"answers" + -0.134*"1000qr" + -0.134*"mind"
2016-10-09 22:32:49,029 : INFO : topic #3(1.000): 0.382*"reliable" + 0.191*"industrial" + 0.191*"priced" + 0.191*"garage" + 0.191*"looking" + 0.191*"way" + 0.191*"around" + 0.191*"low" + 0.191*"hear" + 0.191*"land"
2016-10-09 22:32:49,029 : INFO : topic #4(1.000): 0.408*"well" + 0.408*"coffee" + 0.408*"view" + 0.408*"plus" + 0.408*"cup" + 0.408*"nice" + -0.000*"reliable" + 0.000*"card" + 0.000*"guys" + 0.000*"plz"
2016-10-09 22:32:49,029 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:49,030 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:49,031 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:49,032 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,032 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,032 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:49,033 : INFO : saved 10x5299 matrix, density=0.228% (121/52990)
2016-10-09 22:32:49,033 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,033 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,033 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,034 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,034 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,034 : INFO : accepted corpus with 10 documents, 5299 features, 121 non-zero entries
2016-10-09 22:32:49,034 : INFO : collecting document frequencies
2016-10-09 22:32:49,034 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:49,034 : INFO : calculating IDF weights for 10 documents and 5298 features (121 matrix non-zeros)
2016-10-09 22:32:49,034 : INFO : using serial LSI version on this node
2016-10-09 22:32:49,034 : INFO : updating model with new documents
2016-10-09 22:32:49,035 : INFO : preparing a new chunk of documents
2016-10-09 22:32:49,035 : DEBUG : converting corpus to csc format
2016-10-09 22:32:49,035 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:49,037 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:49,037 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:49,049 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,088 : DEBUG : running 2 power iterations
2016-10-09 22:32:49,108 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,167 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,215 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,220 : INFO : computing the final decomposition
2016-10-09 22:32:49,221 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:49,223 : INFO : processed documents up to #10
2016-10-09 22:32:49,223 : INFO : topic #0(1.162): 0.309*"go" + 0.246*"best" + 0.220*"next" + 0.220*"friday" + 0.207*"know" + 0.195*"place" + 0.194*"beach" + 0.185*"18" + 0.185*"years" + 0.182*"planning"
2016-10-09 22:32:49,223 : INFO : topic #1(1.081): -0.329*"tourists" + -0.312*"18" + -0.312*"years" + -0.256*"places" + -0.245*"visit" + 0.193*"best" + 0.166*"catch" + 0.161*"go" + 0.159*"place" + 0.154*"next"
2016-10-09 22:32:49,224 : INFO : topic #2(1.014): 0.360*"island" + 0.254*"park" + 0.185*"5" + 0.185*"corniche" + 0.180*"seen" + 0.180*"near" + 0.180*"banana" + 0.180*"2013" + 0.180*"called" + 0.180*"end"
2016-10-09 22:32:49,224 : INFO : topic #3(1.001): 0.387*"time" + 0.387*"quality" + 0.387*"good" + 0.387*"spend" + 0.276*"friends" + -0.202*"suggestions" + 0.200*"place" + -0.153*"silent" + -0.153*"bay" + -0.153*"romantic"
2016-10-09 22:32:49,224 : INFO : topic #4(1.000): 0.577*"destinations" + 0.577*"experience" + 0.577*"holiday" + 0.000*"suggestions" + 0.000*"happenings" + 0.000*"something" + 0.000*"new" + -0.000*"time" + -0.000*"good" + -0.000*"spend"
2016-10-09 22:32:49,224 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:49,225 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:49,226 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:49,227 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,227 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,227 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:49,228 : INFO : saved 10x5200 matrix, density=0.413% (215/52000)
2016-10-09 22:32:49,228 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,228 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,228 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,228 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,228 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,228 : INFO : accepted corpus with 10 documents, 5200 features, 215 non-zero entries
2016-10-09 22:32:49,229 : INFO : collecting document frequencies
2016-10-09 22:32:49,229 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:49,229 : INFO : calculating IDF weights for 10 documents and 5199 features (215 matrix non-zeros)
2016-10-09 22:32:49,229 : INFO : using serial LSI version on this node
2016-10-09 22:32:49,229 : INFO : updating model with new documents
2016-10-09 22:32:49,230 : INFO : preparing a new chunk of documents
2016-10-09 22:32:49,230 : DEBUG : converting corpus to csc format
2016-10-09 22:32:49,230 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:49,232 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:49,232 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:49,244 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,283 : DEBUG : running 2 power iterations
2016-10-09 22:32:49,303 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,361 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,409 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,414 : INFO : computing the final decomposition
2016-10-09 22:32:49,414 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:49,417 : INFO : processed documents up to #10
2016-10-09 22:32:49,417 : INFO : topic #0(1.111): 0.250*"qatar" + 0.196*"good" + 0.177*"also" + 0.159*"know" + 0.153*"doha" + 0.140*"wanted" + 0.128*"housing" + 0.127*"salary" + 0.127*"transportation" + 0.127*"single"
2016-10-09 22:32:49,417 : INFO : topic #1(1.059): -0.364*"month" + -0.265*"per" + -0.256*"mate" + -0.176*"qar" + -0.176*"offered" + -0.151*"day" + -0.151*"left" + -0.128*"email" + -0.128*"500" + -0.128*"unfortunately"
2016-10-09 22:32:49,417 : INFO : topic #2(1.021): 0.246*"possible" + 0.246*"violation" + -0.188*"home" + 0.185*"anyone" + 0.142*"reputable" + 0.142*"threads" + 0.142*"problem" + 0.142*"rent" + 0.142*"thousand" + 0.142*"asked"
2016-10-09 22:32:49,417 : INFO : topic #3(1.004): 0.308*"possible" + 0.308*"violation" + 0.241*"home" + 0.161*"people" + 0.161*"designer" + 0.154*"owner" + 0.154*"transfer" + 0.154*"willing" + 0.154*"new" + 0.154*"accept"
2016-10-09 22:32:49,418 : INFO : topic #4(1.001): 0.387*"good" + 0.194*"12" + 0.194*"provide" + 0.194*"person" + 0.194*"allowance" + 0.194*"deal" + -0.157*"violation" + -0.157*"possible" + 0.154*"company" + -0.149*"weeks"
2016-10-09 22:32:49,418 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:49,419 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:49,420 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:49,421 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,421 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,421 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:49,422 : INFO : saved 10x5335 matrix, density=0.544% (290/53350)
2016-10-09 22:32:49,422 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,422 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,422 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,423 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,423 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,423 : INFO : accepted corpus with 10 documents, 5335 features, 290 non-zero entries
2016-10-09 22:32:49,423 : INFO : collecting document frequencies
2016-10-09 22:32:49,423 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:49,423 : INFO : calculating IDF weights for 10 documents and 5334 features (290 matrix non-zeros)
2016-10-09 22:32:49,423 : INFO : using serial LSI version on this node
2016-10-09 22:32:49,424 : INFO : updating model with new documents
2016-10-09 22:32:49,424 : INFO : preparing a new chunk of documents
2016-10-09 22:32:49,424 : DEBUG : converting corpus to csc format
2016-10-09 22:32:49,424 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:49,426 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:49,426 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:49,438 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,478 : DEBUG : running 2 power iterations
2016-10-09 22:32:49,498 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,557 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,605 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,610 : INFO : computing the final decomposition
2016-10-09 22:32:49,610 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:49,612 : INFO : processed documents up to #10
2016-10-09 22:32:49,613 : INFO : topic #0(1.159): 0.212*"qatar" + 0.212*"petroleum" + 0.181*"000" + 0.142*"interview" + 0.134*"2" + 0.131*"visit" + 0.131*"one" + 0.114*"14" + 0.110*"thank" + 0.109*"yearly"
2016-10-09 22:32:49,613 : INFO : topic #1(1.100): 0.252*"qatar" + 0.252*"petroleum" + -0.230*"000" + 0.164*"visit" + 0.164*"one" + 0.157*"interview" + -0.152*"experience" + -0.148*"14" + -0.138*"2" + 0.122*"process"
2016-10-09 22:32:49,613 : INFO : topic #2(1.026): 0.229*"month" + 0.229*"per" + -0.163*"yearly" + 0.153*"enough" + 0.153*"10" + -0.138*"years" + -0.128*"national" + 0.127*"000" + 0.125*"also" + -0.119*"final"
2016-10-09 22:32:49,613 : INFO : topic #3(1.012): 0.232*"help" + 0.190*"like" + 0.157*"terminated" + 0.157*"mean" + 0.157*"3500" + 0.157*"state" + 0.157*"total" + 0.157*"4000" + 0.157*"period" + 0.157*"anytime"
2016-10-09 22:32:49,613 : INFO : topic #4(0.988): 0.253*"month" + 0.253*"per" + 0.168*"10" + 0.168*"enough" + 0.145*"currently" + 0.145*"40" + 0.145*"talks" + 0.145*"yet" + 0.145*"offers" + 0.145*"manager"
2016-10-09 22:32:49,613 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:49,615 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:49,616 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:49,617 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,617 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,617 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:49,618 : INFO : saved 10x5332 matrix, density=0.338% (180/53320)
2016-10-09 22:32:49,618 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,618 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,618 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,619 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,619 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,619 : INFO : accepted corpus with 10 documents, 5332 features, 180 non-zero entries
2016-10-09 22:32:49,619 : INFO : collecting document frequencies
2016-10-09 22:32:49,619 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:49,619 : INFO : calculating IDF weights for 10 documents and 5331 features (180 matrix non-zeros)
2016-10-09 22:32:49,619 : INFO : using serial LSI version on this node
2016-10-09 22:32:49,619 : INFO : updating model with new documents
2016-10-09 22:32:49,620 : INFO : preparing a new chunk of documents
2016-10-09 22:32:49,620 : DEBUG : converting corpus to csc format
2016-10-09 22:32:49,620 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:49,622 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:49,622 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:49,634 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,674 : DEBUG : running 2 power iterations
2016-10-09 22:32:49,693 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,752 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,800 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,805 : INFO : computing the final decomposition
2016-10-09 22:32:49,805 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:49,808 : INFO : processed documents up to #10
2016-10-09 22:32:49,808 : INFO : topic #0(1.169): 0.279*"doha" + 0.229*"baby" + 0.208*"get" + 0.195*"coming" + 0.188*"vaccination" + 0.181*"vaccinations" + 0.172*"much" + 0.171*"regular" + 0.169*"remaining" + 0.141*"u"
2016-10-09 22:32:49,808 : INFO : topic #1(1.040): 0.260*"would" + 0.188*"coming" + 0.184*"get" + -0.176*"clinic" + -0.176*"u" + -0.168*"regular" + -0.167*"good" + -0.167*"communicate" + -0.167*"recommend" + 0.163*"know"
2016-10-09 22:32:49,808 : INFO : topic #2(1.027): -0.287*"doha" + -0.254*"buy" + -0.254*"selection" + -0.254*"law" + 0.176*"remaining" + -0.173*"good" + -0.173*"communicate" + -0.173*"recommend" + 0.151*"know" + 0.144*"schools"
2016-10-09 22:32:49,808 : INFO : topic #3(1.003): 0.291*"made" + -0.214*"would" + -0.211*"considering" + -0.211*"job" + -0.150*"law" + -0.150*"buy" + -0.150*"selection" + 0.145*"spent" + 0.145*"ones" + 0.145*"nothing"
2016-10-09 22:32:49,808 : INFO : topic #4(1.001): 0.334*"made" + -0.208*"know" + -0.185*"anyone" + -0.185*"schools" + 0.167*"cure" + 0.167*"think" + 0.167*"money" + 0.167*"ones" + 0.167*"someone" + 0.167*"nothing"
2016-10-09 22:32:49,809 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:49,810 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:49,810 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:49,812 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,812 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,812 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:49,812 : INFO : saved 10x5307 matrix, density=0.268% (142/53070)
2016-10-09 22:32:49,812 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,812 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,812 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,813 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:49,813 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:49,813 : INFO : accepted corpus with 10 documents, 5307 features, 142 non-zero entries
2016-10-09 22:32:49,813 : INFO : collecting document frequencies
2016-10-09 22:32:49,813 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:49,813 : INFO : calculating IDF weights for 10 documents and 5306 features (142 matrix non-zeros)
2016-10-09 22:32:49,814 : INFO : using serial LSI version on this node
2016-10-09 22:32:49,814 : INFO : updating model with new documents
2016-10-09 22:32:49,814 : INFO : preparing a new chunk of documents
2016-10-09 22:32:49,814 : DEBUG : converting corpus to csc format
2016-10-09 22:32:49,814 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:49,816 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:49,817 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:49,828 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,868 : DEBUG : running 2 power iterations
2016-10-09 22:32:49,887 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,946 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:49,994 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:49,999 : INFO : computing the final decomposition
2016-10-09 22:32:49,999 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,001 : INFO : processed documents up to #10
2016-10-09 22:32:50,002 : INFO : topic #0(1.165): -0.317*"cold" + -0.302*"curious" + -0.240*"winter" + -0.228*"coming" + -0.204*"doha" + -0.190*"hi" + -0.171*"thank" + -0.163*"november" + -0.163*"share" + -0.163*"october"
2016-10-09 22:32:50,002 : INFO : topic #1(1.056): -0.248*"curious" + 0.208*"coming" + -0.194*"winter" + 0.189*"bring" + -0.175*"doha" + 0.174*"thank" + 0.148*"qatar" + 0.140*"30" + 0.140*"pls" + 0.140*"cloths"
2016-10-09 22:32:50,002 : INFO : topic #2(1.027): 0.288*"normal" + -0.278*"curious" + 0.179*"know" + 0.149*"thanks" + 0.144*"changes" + 0.144*"due" + 0.144*"longer" + 0.144*"issue" + 0.144*"recent" + 0.144*"correct"
2016-10-09 22:32:50,002 : INFO : topic #3(1.000): -0.314*"travel" + -0.314*"also" + -0.157*"europe" + -0.157*"india" + -0.157*"august" + -0.157*"plan" + -0.157*"packages" + -0.157*"visas" + -0.157*"please" + -0.157*"package"
2016-10-09 22:32:50,002 : INFO : topic #4(0.995): 0.269*"woman" + 0.269*"clothes" + 0.269*"jeans" + 0.269*"western" + 0.269*"visiting" + 0.269*"wear" + 0.202*"december" + 0.182*"bring" + 0.158*"safest" + 0.158*"around"
2016-10-09 22:32:50,003 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,003 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,004 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,006 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,006 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,006 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,006 : INFO : saved 10x5309 matrix, density=0.358% (190/53090)
2016-10-09 22:32:50,006 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,006 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,006 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,007 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,007 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,007 : INFO : accepted corpus with 10 documents, 5309 features, 190 non-zero entries
2016-10-09 22:32:50,007 : INFO : collecting document frequencies
2016-10-09 22:32:50,007 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,007 : INFO : calculating IDF weights for 10 documents and 5308 features (190 matrix non-zeros)
2016-10-09 22:32:50,008 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,008 : INFO : updating model with new documents
2016-10-09 22:32:50,008 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,008 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,008 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,010 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,011 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,022 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,062 : DEBUG : running 2 power iterations
2016-10-09 22:32:50,082 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,140 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,188 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:50,193 : INFO : computing the final decomposition
2016-10-09 22:32:50,193 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,195 : INFO : processed documents up to #10
2016-10-09 22:32:50,196 : INFO : topic #0(1.178): -0.315*"puppy" + -0.298*"small" + -0.298*"dog" + -0.296*"would" + -0.261*"buy" + -0.259*"doha" + -0.178*"bring" + -0.170*"dogs" + -0.169*"food" + -0.139*"cat"
2016-10-09 22:32:50,196 : INFO : topic #1(1.046): 0.239*"cat" + -0.213*"puppy" + 0.193*"much" + 0.193*"cost" + -0.178*"small" + -0.178*"dog" + 0.174*"com" + 0.174*"www" + 0.174*"http" + 0.174*"qatarliving"
2016-10-09 22:32:50,196 : INFO : topic #2(1.008): -0.234*"cost" + -0.234*"much" + -0.190*"let" + -0.190*"pup" + -0.190*"know" + -0.148*"place" + -0.148*"qatar" + 0.136*"food" + -0.130*"1" + 0.128*"com"
2016-10-09 22:32:50,196 : INFO : topic #3(1.003): -0.197*"necessary" + -0.197*"stuff" + -0.197*"recommend" + -0.197*"store" + -0.197*"cats" + -0.197*"finding" + -0.197*"successful" + -0.197*"buying" + -0.197*"thanks" + -0.197*"somebody"
2016-10-09 22:32:50,196 : INFO : topic #4(1.000): -0.447*"jesus" + -0.447*"see" + -0.447*"christian" + -0.447*"muslim" + -0.447*"attachment" + 0.000*"rats" + 0.000*"back" + 0.000*"house" + -0.000*"cost" + -0.000*"much"
2016-10-09 22:32:50,196 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,198 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,199 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,200 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,200 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,200 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,201 : INFO : saved 10x5324 matrix, density=0.329% (175/53240)
2016-10-09 22:32:50,201 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,201 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,201 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,202 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,202 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,202 : INFO : accepted corpus with 10 documents, 5324 features, 175 non-zero entries
2016-10-09 22:32:50,202 : INFO : collecting document frequencies
2016-10-09 22:32:50,202 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,202 : INFO : calculating IDF weights for 10 documents and 5323 features (175 matrix non-zeros)
2016-10-09 22:32:50,202 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,202 : INFO : updating model with new documents
2016-10-09 22:32:50,203 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,203 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,203 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,205 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,205 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,217 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,257 : DEBUG : running 2 power iterations
2016-10-09 22:32:50,276 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,334 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,382 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:50,387 : INFO : computing the final decomposition
2016-10-09 22:32:50,387 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,389 : INFO : processed documents up to #10
2016-10-09 22:32:50,390 : INFO : topic #0(1.127): -0.261*"much" + -0.227*"would" + -0.198*"also" + -0.162*"qatar" + -0.160*"loan" + -0.160*"pay" + -0.147*"know" + -0.125*"qr" + -0.124*"thinking" + -0.124*"per"
2016-10-09 22:32:50,390 : INFO : topic #1(1.074): -0.324*"recommend" + -0.324*"anyone" + -0.305*"applied" + -0.305*"window" + -0.223*"place" + 0.182*"law" + 0.182*"selection" + 0.181*"doha" + 0.166*"buy" + -0.159*"welcome"
2016-10-09 22:32:50,390 : INFO : topic #2(1.060): 0.294*"doha" + 0.287*"selection" + 0.287*"law" + 0.268*"buy" + 0.173*"recommend" + 0.173*"anyone" + 0.160*"window" + 0.160*"applied" + -0.126*"much" + -0.108*"would"
2016-10-09 22:32:50,390 : INFO : topic #3(1.014): -0.366*"qr" + -0.314*"wife" + -0.157*"living" + -0.157*"proceed" + -0.157*"14000" + -0.157*"allowance" + -0.157*"civil" + -0.157*"1500" + -0.157*"plan" + -0.157*"enginner"
2016-10-09 22:32:50,391 : INFO : topic #4(0.994): 0.372*"sell" + 0.372*"months" + 0.189*"one" + 0.186*"leaving" + 0.186*"want" + 0.186*"weeks" + 0.186*"long" + 0.186*"value" + 0.186*"prado" + 0.186*"pajero"
2016-10-09 22:32:50,391 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,392 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,393 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,394 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,394 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,394 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,394 : INFO : saved 10x5265 matrix, density=0.346% (182/52650)
2016-10-09 22:32:50,394 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,395 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,395 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,395 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,395 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,395 : INFO : accepted corpus with 10 documents, 5265 features, 182 non-zero entries
2016-10-09 22:32:50,395 : INFO : collecting document frequencies
2016-10-09 22:32:50,395 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,396 : INFO : calculating IDF weights for 10 documents and 5264 features (182 matrix non-zeros)
2016-10-09 22:32:50,396 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,396 : INFO : updating model with new documents
2016-10-09 22:32:50,397 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,397 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,397 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,399 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,399 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,410 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,450 : DEBUG : running 2 power iterations
2016-10-09 22:32:50,469 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,528 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,576 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:50,581 : INFO : computing the final decomposition
2016-10-09 22:32:50,582 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,584 : INFO : processed documents up to #10
2016-10-09 22:32:50,584 : INFO : topic #0(1.125): 0.233*"child" + 0.180*"bus" + 0.171*"seat" + 0.168*"one" + 0.165*"front" + 0.154*"children" + 0.147*"vehicles" + 0.143*"would" + 0.142*"kids" + 0.140*"law"
2016-10-09 22:32:50,584 : INFO : topic #1(1.060): -0.275*"sure" + -0.248*"kids" + 0.216*"child" + -0.210*"would" + 0.201*"bus" + -0.153*"front" + -0.144*"treat" + -0.144*"bring" + -0.144*"seats" + -0.144*"available"
2016-10-09 22:32:50,584 : INFO : topic #2(1.041): -0.349*"baby" + -0.269*"sign" + 0.236*"bus" + -0.230*"stores" + -0.230*"everything" + -0.179*"board" + 0.136*"child" + 0.136*"school" + -0.119*"doha" + 0.118*"found"
2016-10-09 22:32:50,585 : INFO : topic #3(1.029): 0.368*"buy" + 0.368*"selection" + 0.300*"law" + 0.212*"doha" + 0.206*"qatar" + -0.157*"one" + -0.150*"seat" + -0.140*"sign" + -0.130*"baby" + -0.127*"question"
2016-10-09 22:32:50,585 : INFO : topic #4(1.020): 0.245*"one" + 0.160*"seat" + 0.159*"selection" + 0.159*"buy" + -0.159*"sure" + 0.153*"law" + -0.153*"bus" + -0.153*"school" + -0.142*"son" + -0.142*"7yrs"
2016-10-09 22:32:50,585 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,586 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,587 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,588 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,588 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,588 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,589 : INFO : saved 10x5287 matrix, density=0.361% (191/52870)
2016-10-09 22:32:50,589 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,589 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,589 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,589 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,589 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,590 : INFO : accepted corpus with 10 documents, 5287 features, 191 non-zero entries
2016-10-09 22:32:50,590 : INFO : collecting document frequencies
2016-10-09 22:32:50,590 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,590 : INFO : calculating IDF weights for 10 documents and 5286 features (191 matrix non-zeros)
2016-10-09 22:32:50,590 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,590 : INFO : updating model with new documents
2016-10-09 22:32:50,591 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,591 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,591 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,593 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,593 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,605 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,644 : DEBUG : running 2 power iterations
2016-10-09 22:32:50,664 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,722 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,771 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:50,776 : INFO : computing the final decomposition
2016-10-09 22:32:50,776 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,778 : INFO : processed documents up to #10
2016-10-09 22:32:50,778 : INFO : topic #0(1.168): 0.194*"beaches" + 0.191*"take" + 0.188*"beach" + 0.164*"dunes" + 0.163*"would" + 0.159*"anyone" + 0.159*"umm" + 0.155*"could" + 0.155*"start" + 0.155*"clean"
2016-10-09 22:32:50,779 : INFO : topic #1(1.031): -0.234*"public" + -0.234*"ridiculous" + -0.211*"suggestions" + -0.181*"one" + 0.160*"would" + -0.157*"please" + -0.137*"camping" + -0.137*"license" + 0.135*"could" + 0.133*"beaches"
2016-10-09 22:32:50,779 : INFO : topic #2(1.008): -0.368*"public" + -0.368*"ridiculous" + 0.353*"suggestions" + -0.199*"speed" + -0.199*"times" + -0.199*"gulf" + 0.177*"new" + 0.177*"happenings" + 0.177*"something" + 0.177*"holidays"
2016-10-09 22:32:50,779 : INFO : topic #3(1.005): -0.327*"suggestions" + -0.235*"booze" + -0.235*"let" + -0.235*"party" + -0.235*"private" + 0.169*"tell" + 0.169*"okay" + 0.168*"license" + 0.168*"camping" + -0.164*"holidays"
2016-10-09 22:32:50,779 : INFO : topic #4(0.995): -0.325*"public" + -0.325*"ridiculous" + 0.263*"speed" + 0.263*"gulf" + 0.263*"times" + -0.159*"beach" + -0.153*"okay" + -0.153*"tell" + 0.132*"asp" + 0.132*"according"
2016-10-09 22:32:50,779 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,780 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,781 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,783 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,783 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,783 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,783 : INFO : saved 10x5336 matrix, density=0.392% (209/53360)
2016-10-09 22:32:50,783 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,783 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,783 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,784 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,784 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,784 : INFO : accepted corpus with 10 documents, 5336 features, 209 non-zero entries
2016-10-09 22:32:50,784 : INFO : collecting document frequencies
2016-10-09 22:32:50,784 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,784 : INFO : calculating IDF weights for 10 documents and 5335 features (209 matrix non-zeros)
2016-10-09 22:32:50,785 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,785 : INFO : updating model with new documents
2016-10-09 22:32:50,785 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,785 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,786 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,787 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,788 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,799 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,839 : DEBUG : running 2 power iterations
2016-10-09 22:32:50,858 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,917 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:50,965 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:50,970 : INFO : computing the final decomposition
2016-10-09 22:32:50,970 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:50,972 : INFO : processed documents up to #10
2016-10-09 22:32:50,972 : INFO : topic #0(1.116): 0.255*"doha" + 0.252*"cars" + 0.177*"would" + 0.168*"much" + 0.154*"best" + 0.146*"toyota" + 0.146*"price" + 0.136*"reliable" + 0.133*"renault" + 0.121*"nissan"
2016-10-09 22:32:50,973 : INFO : topic #1(1.045): -0.257*"much" + 0.252*"doha" + 0.210*"cars" + -0.204*"would" + 0.159*"best" + -0.139*"pay" + -0.136*"thanks" + -0.133*"qlers" + -0.133*"thinking" + -0.133*"month"
2016-10-09 22:32:50,973 : INFO : topic #2(1.023): 0.219*"would" + 0.163*"much" + -0.150*"anyone" + -0.142*"reliable" + -0.141*"years" + 0.140*"toyota" + 0.140*"price" + -0.112*"problem" + -0.112*"reputable" + -0.112*"threads"
2016-10-09 22:32:50,973 : INFO : topic #3(1.010): 0.259*"share" + 0.259*"anybody" + 0.259*"maintenance" + 0.259*"mean" + 0.259*"yes" + 0.259*"performance" + 0.259*"using" + 0.221*"please" + 0.196*"experience" + 0.195*"renault"
2016-10-09 22:32:50,973 : INFO : topic #4(1.005): 0.147*"reliable" + -0.144*"middle" + -0.144*"covering" + -0.144*"east" + -0.144*"inside" + -0.144*"shown" + -0.144*"happens" + -0.144*"quite" + -0.144*"photo" + -0.144*"material"
2016-10-09 22:32:50,973 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:50,974 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:50,975 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:50,976 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,977 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,977 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:50,977 : INFO : saved 10x5150 matrix, density=0.305% (157/51500)
2016-10-09 22:32:50,977 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,977 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,977 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,978 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:50,978 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:50,978 : INFO : accepted corpus with 10 documents, 5150 features, 157 non-zero entries
2016-10-09 22:32:50,978 : INFO : collecting document frequencies
2016-10-09 22:32:50,978 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:50,978 : INFO : calculating IDF weights for 10 documents and 5149 features (157 matrix non-zeros)
2016-10-09 22:32:50,979 : INFO : using serial LSI version on this node
2016-10-09 22:32:50,979 : INFO : updating model with new documents
2016-10-09 22:32:50,979 : INFO : preparing a new chunk of documents
2016-10-09 22:32:50,979 : DEBUG : converting corpus to csc format
2016-10-09 22:32:50,979 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:50,981 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:50,981 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:50,993 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,033 : DEBUG : running 2 power iterations
2016-10-09 22:32:51,053 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,112 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,160 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:51,165 : INFO : computing the final decomposition
2016-10-09 22:32:51,165 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:51,167 : INFO : processed documents up to #10
2016-10-09 22:32:51,167 : INFO : topic #0(1.209): 0.696*"water" + 0.270*"drinking" + 0.224*"using" + 0.224*"filter" + 0.206*"tap" + 0.183*"bottled" + 0.112*"shop" + 0.112*"anybody" + 0.112*"need" + 0.112*"instead"
2016-10-09 22:32:51,168 : INFO : topic #1(1.128): -0.276*"plants" + -0.224*"know" + -0.217*"nurseries" + -0.205*"doha" + -0.200*"anyone" + 0.186*"water" + -0.166*"photography" + -0.166*"besides" + -0.166*"buy" + -0.166*"indoor"
2016-10-09 22:32:51,168 : INFO : topic #2(1.024): -0.315*"business" + -0.241*"wanted" + -0.187*"places" + -0.178*"getting" + -0.178*"answer" + -0.178*"contact" + -0.178*"couple" + -0.178*"phone" + -0.178*"numbers" + -0.148*"tried"
2016-10-09 22:32:51,168 : INFO : topic #3(1.011): -0.250*"happening" + -0.212*"tried" + 0.205*"low" + 0.205*"doctor" + 0.205*"bcz" + 0.205*"explain" + 0.205*"told" + 0.194*"business" + -0.179*"getting" + -0.179*"answer"
2016-10-09 22:32:51,168 : INFO : topic #4(1.001): 0.248*"treatment" + 0.238*"bcz" + 0.238*"doctor" + 0.238*"low" + 0.238*"told" + 0.238*"explain" + 0.202*"getting" + 0.202*"answer" + 0.202*"phone" + 0.202*"contact"
2016-10-09 22:32:51,168 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:51,169 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:51,170 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:51,171 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,171 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,171 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:51,172 : INFO : saved 10x5311 matrix, density=0.333% (177/53110)
2016-10-09 22:32:51,172 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,172 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,172 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,173 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,173 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,173 : INFO : accepted corpus with 10 documents, 5311 features, 177 non-zero entries
2016-10-09 22:32:51,173 : INFO : collecting document frequencies
2016-10-09 22:32:51,173 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:51,173 : INFO : calculating IDF weights for 10 documents and 5310 features (177 matrix non-zeros)
2016-10-09 22:32:51,173 : INFO : using serial LSI version on this node
2016-10-09 22:32:51,173 : INFO : updating model with new documents
2016-10-09 22:32:51,174 : INFO : preparing a new chunk of documents
2016-10-09 22:32:51,174 : DEBUG : converting corpus to csc format
2016-10-09 22:32:51,174 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:51,176 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:51,176 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:51,188 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,228 : DEBUG : running 2 power iterations
2016-10-09 22:32:51,247 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,306 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,354 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:51,359 : INFO : computing the final decomposition
2016-10-09 22:32:51,359 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:51,362 : INFO : processed documents up to #10
2016-10-09 22:32:51,362 : INFO : topic #0(1.070): 0.460*"one" + 0.334*"places" + 0.334*"ever" + 0.334*"boring" + 0.323*"public" + 0.323*"beach" + 0.323*"ridiculous" + 0.221*"doha" + 0.075*"laffan" + 0.075*"ras"
2016-10-09 22:32:51,362 : INFO : topic #1(1.069): -0.244*"party" + -0.222*"restaurant" + -0.210*"anyone" + -0.182*"rent" + -0.182*"place" + -0.182*"food" + -0.182*"already" + -0.182*"given" + -0.182*"venues" + -0.182*"kfc"
2016-10-09 22:32:51,362 : INFO : topic #2(1.020): -0.231*"hmc" + -0.205*"ras" + -0.205*"laffan" + -0.154*"training" + -0.154*"salary" + -0.137*"live" + -0.133*"speech" + -0.133*"baby" + -0.133*"2" + -0.133*"son"
2016-10-09 22:32:51,363 : INFO : topic #3(1.016): 0.168*"party" + -0.166*"laffan" + -0.166*"ras" + -0.157*"airline" + -0.157*"gave" + -0.157*"service" + -0.157*"staff" + -0.157*"said" + -0.157*"air" + -0.157*"airways"
2016-10-09 22:32:51,363 : INFO : topic #4(1.001): -0.375*"grade" + -0.375*"result" + -0.187*"anybody" + -0.187*"straight" + -0.187*"12" + -0.187*"rejected" + -0.187*"cause" + -0.187*"looking" + -0.187*"student" + -0.187*"texas"
2016-10-09 22:32:51,363 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:51,364 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:51,365 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:51,366 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,366 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,366 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:51,367 : INFO : saved 10x5334 matrix, density=0.422% (225/53340)
2016-10-09 22:32:51,367 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,367 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,367 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,367 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,368 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,368 : INFO : accepted corpus with 10 documents, 5334 features, 225 non-zero entries
2016-10-09 22:32:51,368 : INFO : collecting document frequencies
2016-10-09 22:32:51,368 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:51,368 : INFO : calculating IDF weights for 10 documents and 5333 features (225 matrix non-zeros)
2016-10-09 22:32:51,368 : INFO : using serial LSI version on this node
2016-10-09 22:32:51,368 : INFO : updating model with new documents
2016-10-09 22:32:51,369 : INFO : preparing a new chunk of documents
2016-10-09 22:32:51,369 : DEBUG : converting corpus to csc format
2016-10-09 22:32:51,369 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:51,371 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:51,371 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:51,383 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,423 : DEBUG : running 2 power iterations
2016-10-09 22:32:51,442 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,501 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,550 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:51,555 : INFO : computing the final decomposition
2016-10-09 22:32:51,555 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:51,557 : INFO : processed documents up to #10
2016-10-09 22:32:51,557 : INFO : topic #0(1.131): -0.168*"back" + -0.166*"american" + -0.162*"schools" + -0.162*"uk" + -0.158*"many" + -0.157*"private" + -0.157*"groups" + -0.135*"home" + -0.133*"qatar" + -0.127*"appreciated"
2016-10-09 22:32:51,557 : INFO : topic #1(1.037): 0.270*"child" + 0.268*"bus" + 0.185*"like" + 0.185*"house" + 0.185*"next" + 0.185*"park" + 0.185*"month" + 0.185*"7yrs" + 0.185*"son" + -0.161*"small"
2016-10-09 22:32:51,558 : INFO : topic #2(1.026): -0.285*"bus" + -0.227*"use" + -0.227*"books" + -0.227*"start" + -0.218*"3" + -0.178*"child" + -0.170*"small" + -0.143*"found" + 0.136*"groups" + 0.136*"private"
2016-10-09 22:32:51,558 : INFO : topic #3(1.002): -0.257*"much" + -0.178*"use" + -0.178*"books" + -0.178*"start" + -0.153*"home" + -0.152*"daughter" + 0.146*"bus" + -0.128*"17" + -0.128*"better" + -0.128*"evening"
2016-10-09 22:32:51,558 : INFO : topic #4(0.990): 0.202*"much" + 0.200*"hello" + 0.200*"thinking" + 0.200*"family" + 0.200*"british" + 0.200*"international" + 0.200*"anything" + -0.168*"uk" + -0.146*"back" + -0.135*"small"
2016-10-09 22:32:51,558 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:51,559 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:51,560 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:51,561 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,562 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,562 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:51,562 : INFO : saved 10x5246 matrix, density=0.374% (196/52460)
2016-10-09 22:32:51,562 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,562 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,562 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,563 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,563 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,563 : INFO : accepted corpus with 10 documents, 5246 features, 196 non-zero entries
2016-10-09 22:32:51,563 : INFO : collecting document frequencies
2016-10-09 22:32:51,563 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:51,563 : INFO : calculating IDF weights for 10 documents and 5245 features (196 matrix non-zeros)
2016-10-09 22:32:51,564 : INFO : using serial LSI version on this node
2016-10-09 22:32:51,564 : INFO : updating model with new documents
2016-10-09 22:32:51,564 : INFO : preparing a new chunk of documents
2016-10-09 22:32:51,564 : DEBUG : converting corpus to csc format
2016-10-09 22:32:51,564 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:51,566 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:51,567 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:51,578 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,618 : DEBUG : running 2 power iterations
2016-10-09 22:32:51,638 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,696 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,745 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:51,750 : INFO : computing the final decomposition
2016-10-09 22:32:51,750 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:51,752 : INFO : processed documents up to #10
2016-10-09 22:32:51,752 : INFO : topic #0(1.141): 0.265*"gratuity" + 0.224*"service" + 0.224*"end" + 0.205*"period" + 0.205*"7" + 0.205*"confirm" + 0.205*"years" + 0.205*"benefits" + 0.194*"working" + 0.182*"qatar"
2016-10-09 22:32:51,752 : INFO : topic #1(1.046): 0.224*"someone" + 0.220*"share" + 0.220*"dinner" + 0.220*"ask" + 0.220*"want" + 0.220*"table" + 0.210*"get" + 0.204*"please" + 0.183*"many" + 0.160*"anybody"
2016-10-09 22:32:51,753 : INFO : topic #2(1.008): 0.294*"good" + 0.252*"deposit" + 0.252*"months" + 0.252*"also" + 0.182*"doha" + 0.147*"allowance" + 0.147*"12" + 0.147*"transportation" + 0.147*"provide" + 0.147*"person"
2016-10-09 22:32:51,753 : INFO : topic #3(1.002): -0.407*"respect" + -0.271*"think" + -0.271*"culture" + -0.271*"people" + 0.155*"anybody" + -0.136*"open" + -0.136*"idea" + -0.136*"noticed" + -0.136*"try" + -0.136*"much"
2016-10-09 22:32:51,753 : INFO : topic #4(1.000): 0.457*"crime" + 0.305*"west" + 0.305*"wife" + 0.305*"considered" + 0.305*"polygamy" + 0.152*"permanent" + 0.152*"girlfriend" + 0.152*"serious" + 0.152*"prohibited" + 0.152*"sex"
2016-10-09 22:32:51,753 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:51,754 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:51,755 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:51,756 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,756 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,757 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:51,757 : INFO : saved 10x5234 matrix, density=0.283% (148/52340)
2016-10-09 22:32:51,757 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,757 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,757 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,758 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,758 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,758 : INFO : accepted corpus with 10 documents, 5234 features, 148 non-zero entries
2016-10-09 22:32:51,758 : INFO : collecting document frequencies
2016-10-09 22:32:51,758 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:51,758 : INFO : calculating IDF weights for 10 documents and 5233 features (148 matrix non-zeros)
2016-10-09 22:32:51,758 : INFO : using serial LSI version on this node
2016-10-09 22:32:51,758 : INFO : updating model with new documents
2016-10-09 22:32:51,759 : INFO : preparing a new chunk of documents
2016-10-09 22:32:51,759 : DEBUG : converting corpus to csc format
2016-10-09 22:32:51,759 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:51,761 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:51,761 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:51,773 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,813 : DEBUG : running 2 power iterations
2016-10-09 22:32:51,833 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,891 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:51,942 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:51,947 : INFO : computing the final decomposition
2016-10-09 22:32:51,947 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:51,949 : INFO : processed documents up to #10
2016-10-09 22:32:51,950 : INFO : topic #0(1.059): -0.241*"qatar" + -0.231*"moon" + -0.215*"islam" + -0.195*"hi" + -0.174*"national" + -0.174*"18th" + -0.174*"confirm" + -0.174*"thanks" + -0.174*"december" + -0.174*"wanted"
2016-10-09 22:32:51,950 : INFO : topic #1(1.043): 0.316*"moon" + 0.236*"islam" + 0.183*"right" + -0.172*"hi" + 0.156*"fool" + 0.156*"idiots" + 0.156*"live" + 0.156*"world" + 0.156*"dirty" + -0.156*"18th"
2016-10-09 22:32:51,950 : INFO : topic #2(1.032): 0.362*"one" + 0.323*"still" + 0.323*"waiting" + 0.323*"ones" + 0.323*"getting" + 0.194*"pajero" + 0.194*"value" + 0.194*"best" + 0.194*"u" + 0.194*"doha"
2016-10-09 22:32:51,950 : INFO : topic #3(1.007): -0.356*"wearing" + -0.190*"need" + -0.188*"teachers" + -0.178*"women" + -0.178*"simply" + -0.178*"many" + -0.178*"culture" + -0.178*"conservatively" + -0.178*"respect" + -0.178*"long"
2016-10-09 22:32:51,950 : INFO : topic #4(1.000): 0.447*"gym" + 0.447*"month" + 0.447*"earning" + 0.447*"affordable" + 0.447*"guy" + 0.000*"wearing" + 0.000*"simply" + 0.000*"find" + 0.000*"disrespectful" + 0.000*"purchase"
2016-10-09 22:32:51,950 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:51,951 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:51,952 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:51,953 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,954 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,954 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:51,954 : INFO : saved 10x5324 matrix, density=0.383% (204/53240)
2016-10-09 22:32:51,954 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,954 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,954 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,955 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:51,955 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:51,955 : INFO : accepted corpus with 10 documents, 5324 features, 204 non-zero entries
2016-10-09 22:32:51,955 : INFO : collecting document frequencies
2016-10-09 22:32:51,955 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:51,955 : INFO : calculating IDF weights for 10 documents and 5323 features (204 matrix non-zeros)
2016-10-09 22:32:51,956 : INFO : using serial LSI version on this node
2016-10-09 22:32:51,956 : INFO : updating model with new documents
2016-10-09 22:32:51,956 : INFO : preparing a new chunk of documents
2016-10-09 22:32:51,956 : DEBUG : converting corpus to csc format
2016-10-09 22:32:51,956 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:51,958 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:51,959 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:51,970 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,010 : DEBUG : running 2 power iterations
2016-10-09 22:32:52,029 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,088 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,136 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:52,141 : INFO : computing the final decomposition
2016-10-09 22:32:52,141 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:52,144 : INFO : processed documents up to #10
2016-10-09 22:32:52,144 : INFO : topic #0(1.108): 0.192*"decent" + 0.186*"get" + 0.175*"need" + 0.170*"advance" + 0.165*"directions" + 0.155*"embassy" + 0.155*"driving" + 0.155*"set" + 0.155*"help" + 0.155*"appointment"
2016-10-09 22:32:52,144 : INFO : topic #1(1.041): 0.236*"qatar" + 0.207*"wanted" + 0.207*"gps" + 0.207*"garmin" + 0.183*"books" + 0.183*"" + 0.183*"english" + 0.170*"us" + 0.152*"set" + 0.152*"driving"
2016-10-09 22:32:52,144 : INFO : topic #2(1.020): -0.333*"thai" + -0.222*"food" + 0.177*"taxis" + 0.177*"karwa" + 0.177*"al" + 0.155*"repaire" + -0.152*"shops" + 0.138*"new" + 0.137*"anyone" + 0.115*"lulu"
2016-10-09 22:32:52,144 : INFO : topic #3(1.008): -0.238*"decent" + 0.221*"thai" + -0.158*"ones" + -0.158*"bread" + -0.158*"bad" + -0.158*"fruits" + -0.158*"vegetables" + -0.158*"really" + -0.158*"fresh" + -0.158*"carrefour"
2016-10-09 22:32:52,145 : INFO : topic #4(0.995): -0.177*"maps" + -0.177*"first" + -0.177*"couple" + 0.150*"thai" + -0.142*"decent" + 0.140*"need" + 0.135*"al" + 0.135*"taxis" + 0.135*"karwa" + -0.132*"lulu"
2016-10-09 22:32:52,145 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:52,146 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:52,147 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:52,148 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,148 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,148 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:52,148 : INFO : saved 10x5323 matrix, density=0.385% (205/53230)
2016-10-09 22:32:52,149 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,149 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,149 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,149 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,149 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,149 : INFO : accepted corpus with 10 documents, 5323 features, 205 non-zero entries
2016-10-09 22:32:52,150 : INFO : collecting document frequencies
2016-10-09 22:32:52,150 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:52,150 : INFO : calculating IDF weights for 10 documents and 5322 features (205 matrix non-zeros)
2016-10-09 22:32:52,150 : INFO : using serial LSI version on this node
2016-10-09 22:32:52,150 : INFO : updating model with new documents
2016-10-09 22:32:52,151 : INFO : preparing a new chunk of documents
2016-10-09 22:32:52,151 : DEBUG : converting corpus to csc format
2016-10-09 22:32:52,151 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:52,153 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:52,153 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:52,165 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,205 : DEBUG : running 2 power iterations
2016-10-09 22:32:52,224 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,284 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,332 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:52,337 : INFO : computing the final decomposition
2016-10-09 22:32:52,337 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:52,339 : INFO : processed documents up to #10
2016-10-09 22:32:52,339 : INFO : topic #0(1.177): -0.283*"sponsorship" + -0.177*"visit" + -0.170*"visa" + -0.165*"work" + -0.157*"family" + -0.157*"sponsor" + -0.154*"qatar" + -0.150*"help" + -0.150*"months" + -0.141*"please"
2016-10-09 22:32:52,340 : INFO : topic #1(1.078): 0.402*"sponsorship" + 0.253*"work" + -0.204*"months" + 0.191*"sponsor" + -0.166*"visit" + -0.164*"currently" + -0.164*"maximum" + -0.164*"whether" + -0.164*"anybody" + -0.164*"extend"
2016-10-09 22:32:52,340 : INFO : topic #2(1.029): 0.231*"meet" + 0.231*"keep" + 0.215*"exam" + 0.186*"everyone" + 0.156*"days" + 0.156*"besides" + 0.135*"weeks" + -0.128*"visit" + 0.118*"medical" + 0.115*"english"
2016-10-09 22:32:52,340 : INFO : topic #3(1.022): -0.235*"qatar" + -0.190*"medical" + 0.184*"sponsorship" + -0.169*"noc" + -0.169*"legally" + -0.169*"bring" + -0.169*"married" + -0.169*"airways" + -0.153*"10000" + -0.153*"policy"
2016-10-09 22:32:52,340 : INFO : topic #4(1.002): -0.283*"year" + -0.283*"place" + -0.283*"best" + -0.283*"expecting" + -0.283*"baby" + -0.283*"deliver" + -0.283*"doctors" + -0.283*"recommendations" + -0.283*"found" + -0.283*"later"
2016-10-09 22:32:52,340 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:52,341 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:52,342 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:52,343 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,344 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,344 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:52,344 : INFO : saved 10x5334 matrix, density=0.219% (117/53340)
2016-10-09 22:32:52,344 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,344 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,344 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,344 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,344 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,344 : INFO : accepted corpus with 10 documents, 5334 features, 117 non-zero entries
2016-10-09 22:32:52,345 : INFO : collecting document frequencies
2016-10-09 22:32:52,345 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:52,345 : INFO : calculating IDF weights for 10 documents and 5333 features (117 matrix non-zeros)
2016-10-09 22:32:52,345 : INFO : using serial LSI version on this node
2016-10-09 22:32:52,345 : INFO : updating model with new documents
2016-10-09 22:32:52,345 : INFO : preparing a new chunk of documents
2016-10-09 22:32:52,345 : DEBUG : converting corpus to csc format
2016-10-09 22:32:52,346 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:52,347 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:52,348 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:52,359 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,399 : DEBUG : running 2 power iterations
2016-10-09 22:32:52,418 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,477 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,525 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:52,530 : INFO : computing the final decomposition
2016-10-09 22:32:52,530 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:52,533 : INFO : processed documents up to #10
2016-10-09 22:32:52,533 : INFO : topic #0(1.193): 0.366*"family" + 0.326*"best" + 0.324*"beach" + 0.320*"qatar" + 0.278*"go" + 0.222*"next" + 0.212*"silent" + 0.212*"maybe" + 0.212*"romantic" + 0.211*"friday"
2016-10-09 22:32:52,533 : INFO : topic #1(1.043): 0.293*"next" + 0.251*"visited" + 0.251*"plan" + 0.251*"countries" + 0.235*"experience" + 0.233*"destinations" + 0.233*"holiday" + -0.209*"beach" + 0.207*"places" + 0.207*"vacation"
2016-10-09 22:32:52,533 : INFO : topic #2(1.030): -0.344*"holiday" + -0.344*"destinations" + -0.316*"experience" + 0.275*"visited" + 0.275*"plan" + 0.275*"countries" + 0.271*"next" + -0.217*"summer" + -0.217*"vacation" + -0.217*"places"
2016-10-09 22:32:52,534 : INFO : topic #3(1.016): -0.257*"lets" + -0.256*"start" + -0.256*"17" + -0.256*"years" + -0.256*"country" + -0.256*"long" + -0.256*"away" + -0.223*"beaches" + 0.150*"family" + -0.130*"holiday"
2016-10-09 22:32:52,534 : INFO : topic #4(0.999): 0.189*"get" + 0.189*"ex" + 0.189*"standard" + 0.189*"also" + 0.189*"clues" + 0.189*"contacts" + 0.189*"expect" + 0.189*"basic" + 0.189*"decent" + 0.189*"looking"
2016-10-09 22:32:52,534 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:52,535 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:52,535 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:52,537 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,537 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,537 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:52,537 : INFO : saved 10x5273 matrix, density=0.345% (182/52730)
2016-10-09 22:32:52,537 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,537 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,538 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,538 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,538 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,538 : INFO : accepted corpus with 10 documents, 5273 features, 182 non-zero entries
2016-10-09 22:32:52,538 : INFO : collecting document frequencies
2016-10-09 22:32:52,538 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:52,538 : INFO : calculating IDF weights for 10 documents and 5272 features (182 matrix non-zeros)
2016-10-09 22:32:52,539 : INFO : using serial LSI version on this node
2016-10-09 22:32:52,539 : INFO : updating model with new documents
2016-10-09 22:32:52,539 : INFO : preparing a new chunk of documents
2016-10-09 22:32:52,539 : DEBUG : converting corpus to csc format
2016-10-09 22:32:52,540 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:52,542 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:52,542 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:52,553 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,593 : DEBUG : running 2 power iterations
2016-10-09 22:32:52,613 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,672 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,758 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:52,764 : INFO : computing the final decomposition
2016-10-09 22:32:52,764 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:52,767 : INFO : processed documents up to #10
2016-10-09 22:32:52,767 : INFO : topic #0(1.092): 0.203*"running" + 0.185*"would" + 0.180*"evening" + 0.178*"place" + 0.174*"night" + 0.164*"corniche" + 0.140*"safe" + 0.135*"hi" + 0.135*"good" + 0.134*"could"
2016-10-09 22:32:52,768 : INFO : topic #1(1.036): 0.303*"running" + 0.239*"com" + 0.239*"www" + -0.199*"evening" + -0.196*"qlers" + -0.196*"groups" + -0.196*"see" + -0.196*"lot" + 0.157*"done" + 0.157*"suggestions"
2016-10-09 22:32:52,768 : INFO : topic #2(1.026): 0.248*"could" + 0.245*"like" + 0.226*"im" + 0.166*"know" + 0.151*"would" + 0.135*"wear" + -0.131*"groups" + -0.131*"lot" + -0.131*"qlers" + -0.131*"see"
2016-10-09 22:32:52,768 : INFO : topic #3(1.006): 0.283*"move" + 0.283*"ladies" + 0.283*"alone" + -0.283*"today" + 0.231*"safe" + 0.141*"public" + 0.141*"uae" + 0.141*"hello" + 0.141*"comparable" + 0.141*"transport"
2016-10-09 22:32:52,768 : INFO : topic #4(1.003): -0.347*"wear" + -0.222*"see" + -0.222*"qlers" + -0.222*"lot" + -0.222*"groups" + -0.161*"evening" + -0.150*"www" + -0.150*"com" + 0.121*"night" + -0.119*"corniche"
2016-10-09 22:32:52,768 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:52,769 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:52,770 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:52,772 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,772 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,772 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:52,772 : INFO : saved 10x5301 matrix, density=0.366% (194/53010)
2016-10-09 22:32:52,772 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,772 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,772 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,773 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:52,773 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:52,773 : INFO : accepted corpus with 10 documents, 5301 features, 194 non-zero entries
2016-10-09 22:32:52,773 : INFO : collecting document frequencies
2016-10-09 22:32:52,773 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:52,774 : INFO : calculating IDF weights for 10 documents and 5300 features (194 matrix non-zeros)
2016-10-09 22:32:52,774 : INFO : using serial LSI version on this node
2016-10-09 22:32:52,774 : INFO : updating model with new documents
2016-10-09 22:32:52,775 : INFO : preparing a new chunk of documents
2016-10-09 22:32:52,775 : DEBUG : converting corpus to csc format
2016-10-09 22:32:52,775 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:52,777 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:52,778 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:52,789 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,845 : DEBUG : running 2 power iterations
2016-10-09 22:32:52,867 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,948 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:52,997 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:53,002 : INFO : computing the final decomposition
2016-10-09 22:32:53,002 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:53,004 : INFO : processed documents up to #10
2016-10-09 22:32:53,005 : INFO : topic #0(1.153): 0.228*"much" + 0.208*"club" + 0.184*"people" + 0.169*"member" + 0.169*"need" + 0.158*"bars" + 0.157*"ways" + 0.157*"enjoy" + 0.157*"dubai" + 0.157*"doha"
2016-10-09 22:32:53,005 : INFO : topic #1(1.055): 0.198*"think" + 0.184*"night" + -0.176*"bars" + 0.169*"get" + -0.169*"knows" + -0.169*"anybody" + -0.169*"anything" + -0.160*"people" + -0.150*"friends" + -0.150*"qatar"
2016-10-09 22:32:53,005 : INFO : topic #2(1.041): -0.249*"people" + -0.191*"dance" + -0.189*"ways" + -0.189*"enjoy" + -0.189*"dubai" + 0.189*"knows" + 0.189*"anything" + 0.189*"anybody" + 0.182*"friends" + 0.182*"qatar"
2016-10-09 22:32:53,005 : INFO : topic #3(1.011): -0.245*"opens" + -0.245*"time" + -0.179*"friday" + 0.157*"world" + 0.157*"place" + 0.157*"find" + 0.157*"date" + 0.157*"females" + 0.157*"hang" + 0.157*"w"
2016-10-09 22:32:53,006 : INFO : topic #4(0.998): -0.198*"time" + -0.198*"opens" + 0.172*"bars" + -0.162*"friday" + 0.156*"bar" + 0.156*"5" + 0.156*"one" + 0.156*"criteria" + 0.156*"give" + 0.156*"weekend"
2016-10-09 22:32:53,006 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:53,007 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:53,008 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:53,009 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,009 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,009 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:53,009 : INFO : saved 10x5305 matrix, density=0.234% (124/53050)
2016-10-09 22:32:53,009 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,009 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,009 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,010 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,010 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,010 : INFO : accepted corpus with 10 documents, 5305 features, 124 non-zero entries
2016-10-09 22:32:53,010 : INFO : collecting document frequencies
2016-10-09 22:32:53,010 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:53,010 : INFO : calculating IDF weights for 10 documents and 5304 features (124 matrix non-zeros)
2016-10-09 22:32:53,011 : INFO : using serial LSI version on this node
2016-10-09 22:32:53,011 : INFO : updating model with new documents
2016-10-09 22:32:53,011 : INFO : preparing a new chunk of documents
2016-10-09 22:32:53,011 : DEBUG : converting corpus to csc format
2016-10-09 22:32:53,012 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:53,013 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:53,014 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:53,025 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,066 : DEBUG : running 2 power iterations
2016-10-09 22:32:53,085 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,145 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,218 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:53,224 : INFO : computing the final decomposition
2016-10-09 22:32:53,224 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:53,226 : INFO : processed documents up to #10
2016-10-09 22:32:53,227 : INFO : topic #0(1.092): -0.314*"think" + -0.293*"qlers" + -0.233*"let" + -0.233*"hear" + -0.233*"moment" + -0.233*"take" + -0.226*"ql" + -0.211*"say" + -0.186*"active" + -0.186*"fun"
2016-10-09 22:32:53,227 : INFO : topic #1(1.012): -0.362*"points" + 0.253*"something" + 0.233*"list" + 0.233*"hate" + -0.205*"villagio" + -0.205*"open" + 0.190*"joke" + -0.181*"tell" + -0.181*"anyone" + -0.181*"earn"
2016-10-09 22:32:53,227 : INFO : topic #2(1.009): 0.312*"points" + 0.280*"joke" + 0.257*"list" + 0.257*"hate" + 0.201*"open" + 0.201*"villagio" + 0.172*"streets" + 0.158*"women" + 0.156*"tell" + 0.156*"anyone"
2016-10-09 22:32:53,227 : INFO : topic #3(1.003): 0.578*"something" + 0.289*"noticed" + 0.289*"dont" + 0.289*"red" + 0.220*"know" + 0.219*"villagio" + 0.219*"open" + 0.204*"points" + 0.164*"yet" + -0.110*"moment"
2016-10-09 22:32:53,228 : INFO : topic #4(1.000): -0.397*"still" + 0.296*"come" + -0.198*"true" + -0.198*"sincere" + -0.198*"men" + -0.198*"rule" + -0.198*"mean" + -0.198*"number" + -0.198*"guy" + -0.198*"mind"
2016-10-09 22:32:53,228 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:53,229 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:53,229 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:53,231 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,231 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,231 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:53,232 : INFO : saved 10x5304 matrix, density=0.370% (196/53040)
2016-10-09 22:32:53,232 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,232 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,232 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,232 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,232 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,232 : INFO : accepted corpus with 10 documents, 5304 features, 196 non-zero entries
2016-10-09 22:32:53,233 : INFO : collecting document frequencies
2016-10-09 22:32:53,233 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:53,233 : INFO : calculating IDF weights for 10 documents and 5303 features (196 matrix non-zeros)
2016-10-09 22:32:53,233 : INFO : using serial LSI version on this node
2016-10-09 22:32:53,233 : INFO : updating model with new documents
2016-10-09 22:32:53,234 : INFO : preparing a new chunk of documents
2016-10-09 22:32:53,234 : DEBUG : converting corpus to csc format
2016-10-09 22:32:53,234 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:53,236 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:53,236 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:53,248 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,291 : DEBUG : running 2 power iterations
2016-10-09 22:32:53,312 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,371 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,419 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:53,424 : INFO : computing the final decomposition
2016-10-09 22:32:53,425 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:53,427 : INFO : processed documents up to #10
2016-10-09 22:32:53,427 : INFO : topic #0(1.114): 0.212*"nursery" + 0.212*"details" + 0.212*"speaking" + 0.204*"french" + 0.192*"contact" + 0.192*"give" + 0.190*"anyone" + 0.189*"know" + 0.163*"lycee" + 0.151*"doha"
2016-10-09 22:32:53,427 : INFO : topic #1(1.042): -0.274*"lycee" + -0.246*"soon" + -0.215*"rumor" + -0.215*"heard" + -0.215*"bar" + -0.215*"mall" + -0.215*"say" + -0.196*"qatar" + -0.177*"get" + 0.150*"beach"
2016-10-09 22:32:53,428 : INFO : topic #2(1.035): 0.294*"give" + 0.182*"contact" + 0.151*"details" + 0.151*"speaking" + 0.151*"nursery" + 0.147*"address" + 0.147*"names" + 0.147*"email" + 0.147*"nurseries" + 0.147*"could"
2016-10-09 22:32:53,428 : INFO : topic #3(1.009): 0.152*"lycee" + 0.152*"moving" + 0.142*"forum" + 0.142*"villa" + 0.142*"find" + 0.142*"compound" + 0.142*"time" + 0.142*"first" + 0.142*"picture" + 0.142*"hello"
2016-10-09 22:32:53,428 : INFO : topic #4(1.001): 0.214*"bought" + 0.190*"buy" + 0.190*"british" + 0.190*"flat" + -0.148*"details" + -0.148*"nursery" + -0.148*"speaking" + 0.148*"good" + 0.141*"would" + 0.130*"kindergarten"
2016-10-09 22:32:53,428 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:53,429 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:53,430 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:53,431 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,432 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,432 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:53,432 : INFO : saved 10x5327 matrix, density=0.327% (174/53270)
2016-10-09 22:32:53,432 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,432 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,432 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,432 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,432 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,433 : INFO : accepted corpus with 10 documents, 5327 features, 174 non-zero entries
2016-10-09 22:32:53,433 : INFO : collecting document frequencies
2016-10-09 22:32:53,433 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:53,433 : INFO : calculating IDF weights for 10 documents and 5326 features (174 matrix non-zeros)
2016-10-09 22:32:53,433 : INFO : using serial LSI version on this node
2016-10-09 22:32:53,433 : INFO : updating model with new documents
2016-10-09 22:32:53,434 : INFO : preparing a new chunk of documents
2016-10-09 22:32:53,434 : DEBUG : converting corpus to csc format
2016-10-09 22:32:53,434 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:53,436 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:53,436 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:53,448 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,487 : DEBUG : running 2 power iterations
2016-10-09 22:32:53,507 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,566 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,614 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:53,619 : INFO : computing the final decomposition
2016-10-09 22:32:53,619 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:53,621 : INFO : processed documents up to #10
2016-10-09 22:32:53,622 : INFO : topic #0(1.087): -0.234*"without" + -0.202*"driving" + -0.202*"buy" + -0.202*"possible" + -0.202*"name" + -0.202*"folks" + -0.202*"license" + -0.200*"hi" + -0.186*"doha" + -0.175*"car"
2016-10-09 22:32:53,622 : INFO : topic #1(1.037): -0.240*"bus" + -0.222*"suggestions" + -0.222*"company" + -0.178*"rent" + -0.174*"seems" + -0.174*"dont" + -0.174*"deposit" + -0.174*"keep" + -0.174*"everytime" + -0.174*"making"
2016-10-09 22:32:53,622 : INFO : topic #2(1.035): -0.364*"bus" + -0.186*"mate" + -0.166*"qatar" + -0.150*"one" + -0.150*"day" + -0.140*"month" + -0.137*"required" + -0.137*"household" + -0.133*"need" + -0.128*"nurse"
2016-10-09 22:32:53,622 : INFO : topic #3(1.017): -0.224*"even" + -0.224*"visa" + -0.224*"cancel" + -0.224*"sponsor" + -0.224*"passport" + -0.211*"guys" + -0.209*"thank" + -0.157*"nurse" + 0.148*"mate" + -0.120*"without"
2016-10-09 22:32:53,622 : INFO : topic #4(0.998): -0.233*"numbers" + -0.233*"recruiting" + -0.233*"jobs" + -0.233*"list" + -0.233*"skilled" + -0.233*"workers" + -0.233*"agencies" + -0.233*"phone" + -0.233*"construction" + -0.233*"advance"
2016-10-09 22:32:53,623 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:53,624 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:53,624 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:53,626 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,626 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,626 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:53,626 : INFO : saved 10x5319 matrix, density=0.243% (129/53190)
2016-10-09 22:32:53,626 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,626 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,626 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,627 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,627 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,627 : INFO : accepted corpus with 10 documents, 5319 features, 129 non-zero entries
2016-10-09 22:32:53,627 : INFO : collecting document frequencies
2016-10-09 22:32:53,627 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:53,627 : INFO : calculating IDF weights for 10 documents and 5318 features (129 matrix non-zeros)
2016-10-09 22:32:53,627 : INFO : using serial LSI version on this node
2016-10-09 22:32:53,627 : INFO : updating model with new documents
2016-10-09 22:32:53,628 : INFO : preparing a new chunk of documents
2016-10-09 22:32:53,628 : DEBUG : converting corpus to csc format
2016-10-09 22:32:53,628 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:53,630 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:53,630 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:53,642 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,682 : DEBUG : running 2 power iterations
2016-10-09 22:32:53,701 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,760 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,812 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:53,817 : INFO : computing the final decomposition
2016-10-09 22:32:53,817 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:53,820 : INFO : processed documents up to #10
2016-10-09 22:32:53,820 : INFO : topic #0(1.171): -0.464*"park" + -0.363*"know" + -0.329*"theme" + -0.329*"water" + -0.238*"qatar" + -0.223*"instead" + -0.223*"would" + -0.154*"making" + -0.154*"parks" + -0.112*"built"
2016-10-09 22:32:53,820 : INFO : topic #1(1.046): 0.357*"ur" + 0.219*"place" + 0.205*"family" + 0.205*"enjoy" + 0.178*"visited" + 0.178*"best" + 0.178*"hi" + 0.178*"friends" + -0.174*"park" + 0.168*"party"
2016-10-09 22:32:53,820 : INFO : topic #2(1.032): -0.225*"ur" + 0.216*"party" + 0.176*"food" + 0.176*"rent" + 0.176*"given" + 0.176*"already" + 0.176*"venues" + 0.176*"restaurant" + 0.176*"kfc" + -0.159*"family"
2016-10-09 22:32:53,820 : INFO : topic #3(1.023): -0.296*"http" + -0.226*"read" + -0.226*"im" + -0.226*"avoid" + -0.226*"trap" + -0.226*"bored" + -0.226*"co" + -0.226*"post" + -0.197*"watch" + -0.197*"found"
2016-10-09 22:32:53,821 : INFO : topic #4(1.010): -0.265*"got" + 0.203*"making" + 0.203*"parks" + -0.150*"doha" + -0.136*"2" + 0.133*"avoid" + 0.133*"bored" + 0.133*"post" + 0.133*"read" + 0.133*"im"
2016-10-09 22:32:53,821 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:53,822 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:53,822 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:53,824 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,824 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,824 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:53,824 : INFO : saved 10x5148 matrix, density=0.420% (216/51480)
2016-10-09 22:32:53,824 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,824 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,824 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,825 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:53,825 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:53,825 : INFO : accepted corpus with 10 documents, 5148 features, 216 non-zero entries
2016-10-09 22:32:53,825 : INFO : collecting document frequencies
2016-10-09 22:32:53,825 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:53,825 : INFO : calculating IDF weights for 10 documents and 5147 features (216 matrix non-zeros)
2016-10-09 22:32:53,826 : INFO : using serial LSI version on this node
2016-10-09 22:32:53,826 : INFO : updating model with new documents
2016-10-09 22:32:53,826 : INFO : preparing a new chunk of documents
2016-10-09 22:32:53,826 : DEBUG : converting corpus to csc format
2016-10-09 22:32:53,827 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:53,828 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:53,829 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:53,840 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,880 : DEBUG : running 2 power iterations
2016-10-09 22:32:53,899 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:53,958 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,006 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,011 : INFO : computing the final decomposition
2016-10-09 22:32:54,011 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,013 : INFO : processed documents up to #10
2016-10-09 22:32:54,013 : INFO : topic #0(1.142): 0.198*"month" + 0.176*"doha" + 0.176*"maximum" + 0.176*"3" + 0.159*"whether" + 0.159*"currently" + 0.159*"extend" + 0.149*"months" + 0.138*"anybody" + 0.136*"salary"
2016-10-09 22:32:54,014 : INFO : topic #1(1.064): -0.363*"salary" + -0.231*"come" + -0.231*"option" + -0.210*"wife" + -0.172*"residence" + -0.172*"transfer" + -0.172*"appreciate" + -0.172*"staying" + -0.172*"family" + -0.172*"bringing"
2016-10-09 22:32:54,014 : INFO : topic #2(1.021): -0.214*"pakistanis" + -0.214*"available" + -0.214*"pakistan" + -0.214*"someone" + 0.207*"need" + 0.194*"know" + 0.174*"want" + 0.174*"apply" + 0.174*"3months" + 0.174*"lanka"
2016-10-09 22:32:54,014 : INFO : topic #3(1.013): -0.250*"change" + -0.250*"process" + -0.146*"someone" + -0.146*"available" + -0.146*"pakistan" + -0.146*"pakistanis" + -0.146*"need" + -0.138*"visas" + -0.125*"search" + -0.125*"find"
2016-10-09 22:32:54,014 : INFO : topic #4(0.998): -0.272*"deliver" + -0.272*"baby" + -0.250*"month" + -0.136*"delivery" + -0.136*"native" + -0.136*"friends" + -0.136*"4" + -0.136*"charge" + -0.136*"place" + -0.136*"shud"
2016-10-09 22:32:54,014 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,015 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,016 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,018 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,018 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,018 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,018 : INFO : saved 10x5336 matrix, density=0.232% (124/53360)
2016-10-09 22:32:54,018 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,018 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,018 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,019 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,019 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,019 : INFO : accepted corpus with 10 documents, 5336 features, 124 non-zero entries
2016-10-09 22:32:54,019 : INFO : collecting document frequencies
2016-10-09 22:32:54,019 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,019 : INFO : calculating IDF weights for 10 documents and 5335 features (124 matrix non-zeros)
2016-10-09 22:32:54,020 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,020 : INFO : updating model with new documents
2016-10-09 22:32:54,020 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,020 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,020 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,022 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,022 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:54,034 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,074 : DEBUG : running 2 power iterations
2016-10-09 22:32:54,093 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,152 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,201 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,206 : INFO : computing the final decomposition
2016-10-09 22:32:54,206 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,208 : INFO : processed documents up to #10
2016-10-09 22:32:54,208 : INFO : topic #0(1.063): -0.343*"ql" + -0.327*"group" + -0.264*"thread" + -0.206*"wives" + -0.206*"back" + -0.206*"honest" + -0.206*"obviously" + -0.182*"please" + -0.172*"forum" + -0.172*"main"
2016-10-09 22:32:54,209 : INFO : topic #1(1.037): 0.223*"question" + 0.216*"dish" + 0.207*"simple" + 0.207*"lol" + 0.207*"solution" + -0.195*"advice" + 0.182*"party" + 0.154*"rice" + 0.153*"wedding" + 0.153*"invited"
2016-10-09 22:32:54,209 : INFO : topic #2(1.034): -0.567*"advice" + -0.238*"christmas" + -0.238*"doha" + -0.199*"need" + -0.199*"year" + -0.199*"possible" + -0.199*"celebrate" + -0.199*"eve" + -0.199*"new" + -0.199*"holidays"
2016-10-09 22:32:54,209 : INFO : topic #3(1.018): -0.313*"simple" + -0.313*"lol" + -0.313*"solution" + -0.274*"question" + 0.223*"dish" + 0.178*"party" + 0.156*"go" + 0.143*"invited" + 0.143*"wedding" + 0.132*"dinner"
2016-10-09 22:32:54,209 : INFO : topic #4(1.011): -0.304*"go" + 0.226*"group" + -0.208*"obviously" + -0.208*"honest" + -0.208*"back" + -0.208*"wives" + 0.161*"b" + 0.161*"say" + 0.161*"wants" + 0.161*"want"
2016-10-09 22:32:54,209 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,210 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,211 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,212 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,212 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,212 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,213 : INFO : saved 10x5299 matrix, density=0.387% (205/52990)
2016-10-09 22:32:54,213 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,213 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,213 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,213 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,213 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,213 : INFO : accepted corpus with 10 documents, 5299 features, 205 non-zero entries
2016-10-09 22:32:54,213 : INFO : collecting document frequencies
2016-10-09 22:32:54,213 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,213 : INFO : calculating IDF weights for 10 documents and 5298 features (205 matrix non-zeros)
2016-10-09 22:32:54,214 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,214 : INFO : updating model with new documents
2016-10-09 22:32:54,214 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,214 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,215 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,217 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,217 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:54,228 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,268 : DEBUG : running 2 power iterations
2016-10-09 22:32:54,287 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,346 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,394 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,399 : INFO : computing the final decomposition
2016-10-09 22:32:54,399 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,401 : INFO : processed documents up to #10
2016-10-09 22:32:54,402 : INFO : topic #0(1.139): 0.303*"suggestions" + 0.210*"week" + 0.178*"happenings" + 0.178*"new" + 0.175*"please" + 0.170*"holidays" + 0.154*"something" + 0.147*"days" + 0.136*"doha" + 0.136*"wife"
2016-10-09 22:32:54,402 : INFO : topic #1(1.062): 0.253*"ramadan" + 0.214*"comes" + 0.192*"know" + -0.189*"wife" + -0.189*"doha" + 0.170*"would" + -0.158*"places" + -0.138*"holidays" + 0.131*"whole" + 0.131*"october"
2016-10-09 22:32:54,402 : INFO : topic #2(1.020): 0.205*"places" + -0.184*"home" + -0.177*"leave" + 0.169*"doha" + 0.169*"wife" + -0.168*"holiday" + 0.138*"ramadan" + -0.129*"fitr" + -0.127*"go" + -0.123*"sponsor"
2016-10-09 22:32:54,402 : INFO : topic #3(1.008): -0.284*"please" + -0.270*"suggestions" + -0.260*"new" + -0.260*"happenings" + -0.173*"something" + 0.165*"home" + 0.152*"places" + -0.147*"come" + -0.147*"plans" + -0.147*"closed"
2016-10-09 22:32:54,402 : INFO : topic #4(0.997): 0.262*"home" + 0.212*"week" + 0.184*"want" + 0.176*"appreciated" + 0.175*"permit" + 0.175*"exit" + 0.175*"sponsor" + 0.167*"suggestions" + -0.144*"holiday" + 0.122*"advice"
2016-10-09 22:32:54,402 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,403 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,404 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,406 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,406 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,406 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,406 : INFO : saved 10x5319 matrix, density=0.308% (164/53190)
2016-10-09 22:32:54,406 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,406 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,406 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,407 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,407 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,407 : INFO : accepted corpus with 10 documents, 5319 features, 164 non-zero entries
2016-10-09 22:32:54,407 : INFO : collecting document frequencies
2016-10-09 22:32:54,407 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,407 : INFO : calculating IDF weights for 10 documents and 5318 features (164 matrix non-zeros)
2016-10-09 22:32:54,408 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,408 : INFO : updating model with new documents
2016-10-09 22:32:54,408 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,408 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,408 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,410 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,411 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:54,422 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,462 : DEBUG : running 2 power iterations
2016-10-09 22:32:54,481 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,541 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,589 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,594 : INFO : computing the final decomposition
2016-10-09 22:32:54,594 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,596 : INFO : processed documents up to #10
2016-10-09 22:32:54,596 : INFO : topic #0(1.055): -0.267*"license" + -0.267*"driving" + -0.182*"move" + -0.171*"safe" + -0.171*"ladies" + -0.171*"alone" + -0.145*"also" + -0.140*"tell" + -0.129*"hi" + -0.121*"country"
2016-10-09 22:32:54,596 : INFO : topic #1(1.020): -0.245*"gonna" + -0.245*"win" + -0.245*"guess" + -0.222*"tell" + -0.216*"license" + -0.216*"driving" + 0.198*"also" + 0.160*"bank" + 0.160*"accept" + 0.135*"household"
2016-10-09 22:32:54,597 : INFO : topic #2(1.016): 0.212*"alone" + 0.212*"safe" + 0.212*"ladies" + -0.208*"india" + 0.207*"required" + 0.207*"household" + -0.173*"bank" + -0.173*"accept" + 0.146*"hello" + 0.146*"thanks"
2016-10-09 22:32:54,597 : INFO : topic #3(1.005): -0.462*"tata" + -0.462*"available" + -0.263*"garmin" + -0.263*"wanted" + -0.263*"gps" + -0.132*"installed" + -0.132*"dealer" + -0.132*"case" + -0.132*"know" + -0.132*"vehicle"
2016-10-09 22:32:54,597 : INFO : topic #4(0.999): 0.346*"guess" + 0.346*"gonna" + 0.346*"win" + 0.238*"tell" + 0.156*"gps" + 0.156*"wanted" + 0.156*"garmin" + 0.134*"required" + 0.134*"household" + -0.126*"singapore"
2016-10-09 22:32:54,597 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,598 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,599 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,600 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,600 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,600 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,601 : INFO : saved 10x5323 matrix, density=0.340% (181/53230)
2016-10-09 22:32:54,601 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,601 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,601 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,601 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,601 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,602 : INFO : accepted corpus with 10 documents, 5323 features, 181 non-zero entries
2016-10-09 22:32:54,602 : INFO : collecting document frequencies
2016-10-09 22:32:54,602 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,602 : INFO : calculating IDF weights for 10 documents and 5322 features (181 matrix non-zeros)
2016-10-09 22:32:54,602 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,602 : INFO : updating model with new documents
2016-10-09 22:32:54,603 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,603 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,603 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,605 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,605 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:54,617 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,657 : DEBUG : running 2 power iterations
2016-10-09 22:32:54,676 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,735 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,783 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,788 : INFO : computing the final decomposition
2016-10-09 22:32:54,789 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,791 : INFO : processed documents up to #10
2016-10-09 22:32:54,791 : INFO : topic #0(1.067): 0.258*"rules" + 0.234*"would" + 0.158*"like" + 0.148*"traffic" + 0.148*"doha" + 0.148*"watch" + 0.130*"male" + 0.124*"hi" + 0.117*"www" + 0.117*"http"
2016-10-09 22:32:54,791 : INFO : topic #1(1.015): 0.255*"hijab" + 0.203*"male" + 0.162*"hi" + -0.161*"rules" + 0.160*"share" + 0.131*"weight" + 0.131*"rates" + 0.131*"tried" + 0.131*"timings" + 0.131*"loss"
2016-10-09 22:32:54,792 : INFO : topic #2(1.011): -0.318*"hijab" + -0.183*"male" + -0.175*"share" + 0.175*"qatar" + -0.159*"comments" + -0.159*"women" + -0.159*"others" + -0.159*"wear" + -0.159*"womens" + -0.159*"plz"
2016-10-09 22:32:54,792 : INFO : topic #3(1.003): -0.274*"liquor" + -0.274*"heard" + -0.274*"rumor" + -0.274*"store" + 0.217*"qatar" + -0.164*"nations" + -0.137*"else" + -0.137*"building" + -0.137*"near" + -0.137*"sell"
2016-10-09 22:32:54,792 : INFO : topic #4(1.000): -0.339*"know" + -0.339*"let" + -0.339*"reason" + -0.270*"even" + -0.270*"forum" + -0.270*"silly" + -0.270*"still" + -0.270*"one" + -0.270*"moderators" + -0.270*"threads"
2016-10-09 22:32:54,792 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,793 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,794 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,795 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,795 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,795 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,796 : INFO : saved 10x5301 matrix, density=0.253% (134/53010)
2016-10-09 22:32:54,796 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,796 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,796 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,796 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,796 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,797 : INFO : accepted corpus with 10 documents, 5301 features, 134 non-zero entries
2016-10-09 22:32:54,797 : INFO : collecting document frequencies
2016-10-09 22:32:54,797 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,797 : INFO : calculating IDF weights for 10 documents and 5300 features (134 matrix non-zeros)
2016-10-09 22:32:54,797 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,797 : INFO : updating model with new documents
2016-10-09 22:32:54,798 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,798 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,798 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,800 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,800 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:54,812 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,851 : DEBUG : running 2 power iterations
2016-10-09 22:32:54,870 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,929 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:54,977 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:54,982 : INFO : computing the final decomposition
2016-10-09 22:32:54,982 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:54,984 : INFO : processed documents up to #10
2016-10-09 22:32:54,985 : INFO : topic #0(1.081): 0.301*"qatar" + 0.228*"anyone" + 0.217*"bar" + 0.211*"help" + 0.211*"hello" + 0.211*"thank" + 0.211*"find" + 0.211*"indian" + 0.190*"friends" + 0.142*"one"
2016-10-09 22:32:54,985 : INFO : topic #1(1.037): 0.248*"qatar" + -0.231*"one" + 0.164*"anyone" + -0.158*"pass" + -0.158*"partner" + -0.158*"hall" + -0.158*"issue" + -0.151*"night" + -0.151*"stop" + -0.151*"someone"
2016-10-09 22:32:54,985 : INFO : topic #2(1.000): -0.408*"work" + -0.408*"ever" + -0.408*"think" + -0.408*"guys" + -0.408*"issues" + -0.408*"without" + 0.000*"heart" + 0.000*"broken" + 0.000*"sweet" + 0.000*"help"
2016-10-09 22:32:54,985 : INFO : topic #3(1.000): 1.000*"hmm" + -0.000*"film" + -0.000*"certain" + 0.000*"polite" + 0.000*"song" + -0.000*"apartment" + -0.000*"tour" + -0.000*"bumper" + -0.000*"currently" + -0.000*"op"
2016-10-09 22:32:54,985 : INFO : topic #4(1.000): 0.577*"heart" + 0.577*"broken" + 0.577*"sweet" + 0.000*"issues" + 0.000*"think" + 0.000*"ever" + 0.000*"without" + 0.000*"work" + 0.000*"guys" + -0.000*"thread"
2016-10-09 22:32:54,985 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:54,986 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:54,987 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:54,988 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,988 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,988 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:54,989 : INFO : saved 10x5305 matrix, density=0.392% (208/53050)
2016-10-09 22:32:54,989 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,989 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,989 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,990 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:54,990 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:54,990 : INFO : accepted corpus with 10 documents, 5305 features, 208 non-zero entries
2016-10-09 22:32:54,990 : INFO : collecting document frequencies
2016-10-09 22:32:54,990 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:54,990 : INFO : calculating IDF weights for 10 documents and 5304 features (208 matrix non-zeros)
2016-10-09 22:32:54,990 : INFO : using serial LSI version on this node
2016-10-09 22:32:54,990 : INFO : updating model with new documents
2016-10-09 22:32:54,991 : INFO : preparing a new chunk of documents
2016-10-09 22:32:54,991 : DEBUG : converting corpus to csc format
2016-10-09 22:32:54,991 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:54,993 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:54,993 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,005 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,046 : DEBUG : running 2 power iterations
2016-10-09 22:32:55,065 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,124 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,172 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:55,177 : INFO : computing the final decomposition
2016-10-09 22:32:55,177 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:55,179 : INFO : processed documents up to #10
2016-10-09 22:32:55,180 : INFO : topic #0(1.118): -0.192*"change" + -0.174*"visa" + -0.152*"thanks" + -0.151*"medical" + -0.150*"exam" + -0.150*"get" + -0.146*"ql" + -0.140*"company" + -0.136*"work" + -0.132*"would"
2016-10-09 22:32:55,180 : INFO : topic #1(1.048): 0.245*"change" + -0.179*"get" + -0.174*"advise" + -0.173*"haircut" + -0.173*"kindly" + -0.173*"town" + -0.173*"boys" + -0.171*"best" + -0.150*"car" + -0.150*"seat"
2016-10-09 22:32:55,180 : INFO : topic #2(1.039): 0.297*"ql" + 0.230*"week" + 0.230*"kid" + 0.230*"join" + 0.230*"delete" + 0.230*"one" + 0.230*"wanna" + 0.208*"anyone" + 0.183*"work" + 0.133*"reliable"
2016-10-09 22:32:55,180 : INFO : topic #3(1.020): 0.248*"b" + 0.248*"c" + -0.218*"change" + 0.217*"medical" + 0.197*"exam" + -0.168*"manager" + -0.168*"masters" + -0.168*"profession" + -0.168*"technician" + 0.165*"tested"
2016-10-09 22:32:55,181 : INFO : topic #4(0.992): -0.240*"reliable" + 0.220*"visa" + -0.185*"car" + -0.185*"seat" + 0.159*"saudi" + 0.159*"want" + 0.159*"come" + 0.159*"procedure" + 0.159*"entry" + 0.159*"umrah"
2016-10-09 22:32:55,181 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:55,182 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:55,183 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:55,184 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,184 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,184 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:55,184 : INFO : saved 10x5324 matrix, density=0.222% (118/53240)
2016-10-09 22:32:55,184 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,184 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,185 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,185 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,185 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,185 : INFO : accepted corpus with 10 documents, 5324 features, 118 non-zero entries
2016-10-09 22:32:55,185 : INFO : collecting document frequencies
2016-10-09 22:32:55,185 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:55,185 : INFO : calculating IDF weights for 10 documents and 5323 features (118 matrix non-zeros)
2016-10-09 22:32:55,186 : INFO : using serial LSI version on this node
2016-10-09 22:32:55,186 : INFO : updating model with new documents
2016-10-09 22:32:55,186 : INFO : preparing a new chunk of documents
2016-10-09 22:32:55,186 : DEBUG : converting corpus to csc format
2016-10-09 22:32:55,186 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:55,188 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:55,189 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,200 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,240 : DEBUG : running 2 power iterations
2016-10-09 22:32:55,259 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,318 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,366 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:55,371 : INFO : computing the final decomposition
2016-10-09 22:32:55,371 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:55,373 : INFO : processed documents up to #10
2016-10-09 22:32:55,373 : INFO : topic #0(1.199): -0.417*"http" + -0.417*"com" + -0.417*"www" + -0.322*"article" + -0.310*"look" + -0.204*"f" + -0.204*"28" + -0.204*"c" + -0.204*"08" + -0.204*"bin"
2016-10-09 22:32:55,373 : INFO : topic #1(1.082): 0.354*"church" + 0.329*"catholic" + 0.245*"qatar" + 0.239*"please" + 0.210*"make" + 0.177*"bible" + 0.177*"work" + 0.177*"cell" + 0.177*"group" + 0.177*"thanks"
2016-10-09 22:32:55,374 : INFO : topic #2(1.050): 0.348*"first" + 0.287*"chicken" + 0.287*"came" + 0.287*"egg" + 0.218*"makes" + 0.211*"guess" + 0.211*"happened" + 0.211*"phone" + 0.211*"dumb" + 0.211*"list"
2016-10-09 22:32:55,374 : INFO : topic #3(1.001): -0.271*"worst" + -0.271*"avoid" + -0.271*"lesser" + -0.271*"person" + -0.271*"good" + -0.271*"talking" + -0.271*"even" + -0.271*"way" + 0.255*"came" + 0.255*"egg"
2016-10-09 22:32:55,374 : INFO : topic #4(1.000): -0.447*"getting" + -0.447*"waiting" + -0.447*"ones" + -0.447*"one" + -0.447*"still" + 0.000*"way" + 0.000*"even" + 0.000*"lesser" + 0.000*"avoid" + 0.000*"talking"
2016-10-09 22:32:55,374 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:55,375 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:55,376 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:55,377 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,377 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,377 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:55,377 : INFO : saved 10x5319 matrix, density=0.306% (163/53190)
2016-10-09 22:32:55,377 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,378 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,378 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,378 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,378 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,378 : INFO : accepted corpus with 10 documents, 5319 features, 163 non-zero entries
2016-10-09 22:32:55,378 : INFO : collecting document frequencies
2016-10-09 22:32:55,378 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:55,379 : INFO : calculating IDF weights for 10 documents and 5318 features (163 matrix non-zeros)
2016-10-09 22:32:55,379 : INFO : using serial LSI version on this node
2016-10-09 22:32:55,379 : INFO : updating model with new documents
2016-10-09 22:32:55,379 : INFO : preparing a new chunk of documents
2016-10-09 22:32:55,379 : DEBUG : converting corpus to csc format
2016-10-09 22:32:55,380 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:55,381 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:55,382 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,393 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,433 : DEBUG : running 2 power iterations
2016-10-09 22:32:55,453 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,511 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,560 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:55,565 : INFO : computing the final decomposition
2016-10-09 22:32:55,565 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:55,567 : INFO : processed documents up to #10
2016-10-09 22:32:55,568 : INFO : topic #0(1.181): -0.255*"licence" + -0.245*"driving" + -0.195*"driver" + -0.194*"valid" + -0.162*"visa" + -0.159*"company" + -0.146*"visiting" + -0.138*"anybody" + -0.137*"get" + -0.136*"ur"
2016-10-09 22:32:55,568 : INFO : topic #1(1.060): -0.337*"use" + -0.332*"philippines" + -0.255*"want" + -0.255*"long" + -0.255*"know" + -0.255*"im" + -0.220*"phil" + 0.162*"driving" + 0.161*"valid" + -0.134*"planning"
2016-10-09 22:32:55,568 : INFO : topic #2(1.054): 0.325*"visiting" + 0.312*"egyptian" + 0.312*"work" + -0.176*"dl" + -0.174*"test" + -0.171*"anybody" + -0.154*"advise" + -0.154*"trick" + -0.154*"parking" + -0.154*"thanks"
2016-10-09 22:32:55,568 : INFO : topic #3(1.016): -0.283*"valid" + 0.246*"dl" + -0.232*"still" + -0.232*"ur" + 0.158*"visiting" + 0.133*"licence" + 0.125*"week" + 0.125*"rent" + 0.125*"using" + 0.125*"intend"
2016-10-09 22:32:55,568 : INFO : topic #4(1.001): -0.375*"licence" + -0.242*"company" + 0.218*"dl" + 0.194*"egyptian" + 0.194*"work" + -0.174*"parking" + -0.174*"trick" + -0.174*"advise" + -0.174*"thanks" + -0.169*"driver"
2016-10-09 22:32:55,568 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:55,569 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:55,570 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:55,571 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,572 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,572 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:55,572 : INFO : saved 10x5225 matrix, density=0.243% (127/52250)
2016-10-09 22:32:55,572 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,572 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,572 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,573 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,573 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,573 : INFO : accepted corpus with 10 documents, 5225 features, 127 non-zero entries
2016-10-09 22:32:55,573 : INFO : collecting document frequencies
2016-10-09 22:32:55,573 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:55,573 : INFO : calculating IDF weights for 10 documents and 5224 features (127 matrix non-zeros)
2016-10-09 22:32:55,574 : INFO : using serial LSI version on this node
2016-10-09 22:32:55,574 : INFO : updating model with new documents
2016-10-09 22:32:55,574 : INFO : preparing a new chunk of documents
2016-10-09 22:32:55,574 : DEBUG : converting corpus to csc format
2016-10-09 22:32:55,574 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:55,576 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:55,576 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,588 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,628 : DEBUG : running 2 power iterations
2016-10-09 22:32:55,647 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,706 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,754 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:55,759 : INFO : computing the final decomposition
2016-10-09 22:32:55,759 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:55,761 : INFO : processed documents up to #10
2016-10-09 22:32:55,761 : INFO : topic #0(1.103): -0.244*"love" + -0.234*"share" + -0.232*"take" + -0.225*"go" + -0.225*"pics" + -0.225*"dubai" + -0.220*"want" + -0.206*"vacation" + -0.187*"eat" + -0.174*"one"
2016-10-09 22:32:55,762 : INFO : topic #1(1.059): -0.402*"animals" + -0.390*"buy" + -0.304*"want" + -0.304*"qatar" + -0.243*"find" + -0.195*"difficult" + -0.195*"things" + -0.152*"life" + -0.152*"chance" + -0.152*"someone"
2016-10-09 22:32:55,762 : INFO : topic #2(1.048): 0.218*"eat" + 0.210*"love" + -0.164*"sponsor" + -0.163*"know" + -0.161*"visa" + -0.161*"without" + -0.161*"passport" + -0.161*"cancel" + -0.161*"thank" + -0.159*"even"
2016-10-09 22:32:55,762 : INFO : topic #3(1.020): -0.240*"passport" + -0.240*"visa" + -0.240*"thank" + -0.240*"without" + -0.240*"cancel" + -0.216*"sponsor" + -0.188*"guys" + -0.188*"even" + 0.171*"hello" + -0.167*"eat"
2016-10-09 22:32:55,762 : INFO : topic #4(0.999): 0.186*"minimum" + 0.186*"maids" + 0.186*"month" + 0.186*"qatari" + 0.186*"qr" + 0.186*"bank" + 0.186*"introduce" + 0.186*"information" + 0.186*"account" + 0.186*"employee"
2016-10-09 22:32:55,762 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:55,763 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:55,764 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:55,765 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,765 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,765 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:55,766 : INFO : saved 10x5216 matrix, density=0.387% (202/52160)
2016-10-09 22:32:55,766 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,766 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,766 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,766 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,766 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,767 : INFO : accepted corpus with 10 documents, 5216 features, 202 non-zero entries
2016-10-09 22:32:55,767 : INFO : collecting document frequencies
2016-10-09 22:32:55,767 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:55,767 : INFO : calculating IDF weights for 10 documents and 5215 features (202 matrix non-zeros)
2016-10-09 22:32:55,767 : INFO : using serial LSI version on this node
2016-10-09 22:32:55,767 : INFO : updating model with new documents
2016-10-09 22:32:55,768 : INFO : preparing a new chunk of documents
2016-10-09 22:32:55,768 : DEBUG : converting corpus to csc format
2016-10-09 22:32:55,768 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:55,770 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:55,770 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,782 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,822 : DEBUG : running 2 power iterations
2016-10-09 22:32:55,841 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,900 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:55,948 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:55,953 : INFO : computing the final decomposition
2016-10-09 22:32:55,953 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:55,955 : INFO : processed documents up to #10
2016-10-09 22:32:55,955 : INFO : topic #0(1.140): 0.316*"job" + 0.233*"good" + 0.214*"many" + 0.158*"com" + 0.158*"website" + 0.158*"time" + 0.158*"hard" + 0.158*"american" + 0.156*"get" + 0.154*"doha"
2016-10-09 22:32:55,956 : INFO : topic #1(1.069): -0.281*"library" + -0.276*"like" + -0.211*"work" + -0.208*"ask" + -0.208*"u" + -0.208*"conditions" + -0.208*"comparable" + -0.208*"e" + -0.208*"may" + -0.190*"would"
2016-10-09 22:32:55,956 : INFO : topic #2(1.023): -0.348*"petroleum" + 0.266*"library" + -0.228*"im" + -0.210*"trap" + -0.210*"http" + -0.210*"bored" + -0.210*"avoid" + -0.210*"co" + -0.210*"read" + 0.157*"like"
2016-10-09 22:32:55,956 : INFO : topic #3(1.005): 0.261*"library" + 0.229*"bank" + 0.229*"accept" + -0.219*"expat" + -0.219*"safe" + 0.123*"like" + -0.116*"want" + 0.115*"currently" + 0.115*"problem" + 0.115*"personal"
2016-10-09 22:32:55,956 : INFO : topic #4(0.999): -0.236*"library" + 0.203*"guide" + 0.203*"consultant" + -0.198*"read" + -0.198*"bored" + -0.198*"co" + -0.198*"avoid" + -0.198*"trap" + -0.198*"http" + 0.168*"bank"
2016-10-09 22:32:55,956 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:55,957 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:55,958 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:55,960 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,960 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,960 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:55,960 : INFO : saved 10x5332 matrix, density=0.326% (174/53320)
2016-10-09 22:32:55,960 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,960 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,960 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,961 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:55,961 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:55,961 : INFO : accepted corpus with 10 documents, 5332 features, 174 non-zero entries
2016-10-09 22:32:55,961 : INFO : collecting document frequencies
2016-10-09 22:32:55,961 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:55,961 : INFO : calculating IDF weights for 10 documents and 5331 features (174 matrix non-zeros)
2016-10-09 22:32:55,962 : INFO : using serial LSI version on this node
2016-10-09 22:32:55,962 : INFO : updating model with new documents
2016-10-09 22:32:55,962 : INFO : preparing a new chunk of documents
2016-10-09 22:32:55,962 : DEBUG : converting corpus to csc format
2016-10-09 22:32:55,962 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:55,964 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:55,965 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:55,976 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,016 : DEBUG : running 2 power iterations
2016-10-09 22:32:56,035 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,094 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,143 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:56,148 : INFO : computing the final decomposition
2016-10-09 22:32:56,148 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:56,150 : INFO : processed documents up to #10
2016-10-09 22:32:56,150 : INFO : topic #0(1.067): -0.278*"society" + -0.278*"qatarliving" + -0.278*"dr" + -0.278*"jpg" + -0.265*"www" + -0.265*"com" + -0.265*"http" + -0.179*"nations" + -0.168*"extend" + -0.168*"another"
2016-10-09 22:32:56,150 : INFO : topic #1(1.029): 0.286*"hijab" + 0.231*"others" + 0.189*"islam" + 0.188*"basically" + 0.188*"question" + 0.188*"person" + 0.188*"intrested" + 0.188*"process" + 0.188*"likes" + 0.188*"involved"
2016-10-09 22:32:56,151 : INFO : topic #2(1.015): -0.260*"hijab" + 0.205*"people" + 0.198*"think" + 0.198*"must" + 0.198*"us" + 0.198*"qatari" + 0.198*"drink" + 0.198*"tell" + 0.198*"important" + 0.190*"done"
2016-10-09 22:32:56,151 : INFO : topic #3(1.002): -0.343*"crime" + 0.252*"gold" + -0.228*"polygamy" + -0.228*"considered" + -0.228*"west" + -0.228*"wife" + 0.189*"wearing" + 0.189*"golden" + -0.132*"nations" + 0.126*"accessories"
2016-10-09 22:32:56,151 : INFO : topic #4(1.000): 0.336*"truth" + 0.336*"jesus" + 0.168*"love" + 0.168*"posts" + 0.168*"bible" + 0.168*"enemies" + 0.168*"earth" + 0.168*"rejected" + 0.168*"happened" + 0.168*"discussion"
2016-10-09 22:32:56,151 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:56,152 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:56,153 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:56,154 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,154 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,154 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:56,155 : INFO : saved 10x5292 matrix, density=0.393% (208/52920)
2016-10-09 22:32:56,155 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,155 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,155 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,156 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,156 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,156 : INFO : accepted corpus with 10 documents, 5292 features, 208 non-zero entries
2016-10-09 22:32:56,156 : INFO : collecting document frequencies
2016-10-09 22:32:56,156 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:56,156 : INFO : calculating IDF weights for 10 documents and 5291 features (208 matrix non-zeros)
2016-10-09 22:32:56,156 : INFO : using serial LSI version on this node
2016-10-09 22:32:56,156 : INFO : updating model with new documents
2016-10-09 22:32:56,157 : INFO : preparing a new chunk of documents
2016-10-09 22:32:56,157 : DEBUG : converting corpus to csc format
2016-10-09 22:32:56,157 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:56,159 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:56,159 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:56,171 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,211 : DEBUG : running 2 power iterations
2016-10-09 22:32:56,230 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,289 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,337 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:56,342 : INFO : computing the final decomposition
2016-10-09 22:32:56,342 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:56,344 : INFO : processed documents up to #10
2016-10-09 22:32:56,345 : INFO : topic #0(1.190): 0.268*"exam" + 0.257*"salary" + 0.222*"evaluation" + 0.213*"training" + 0.194*"need" + 0.149*"hmc" + 0.144*"pass" + 0.134*"nurses" + 0.132*"well" + 0.129*"experience"
2016-10-09 22:32:56,345 : INFO : topic #1(1.087): -0.367*"exam" + 0.267*"salary" + -0.202*"evaluation" + -0.188*"pass" + 0.179*"hmc" + -0.175*"prometric" + -0.175*"sit" + -0.156*"giving" + -0.156*"information" + -0.156*"requirement"
2016-10-09 22:32:56,345 : INFO : topic #2(1.030): -0.357*"training" + -0.201*"get" + -0.201*"license" + -0.201*"4" + -0.187*"need" + 0.172*"qatar" + -0.169*"evaluation" + -0.162*"hmc" + -0.150*"sch" + 0.131*"exam"
2016-10-09 22:32:56,345 : INFO : topic #3(1.000): -0.816*"stage" + -0.408*"verification" + -0.408*"right" + 0.000*"medical" + 0.000*"hmc" + -0.000*"take" + 0.000*"would" + 0.000*"finished" + 0.000*"interested" + 0.000*"make"
2016-10-09 22:32:56,345 : INFO : topic #4(0.998): 0.297*"take" + -0.218*"medical" + -0.180*"salary" + -0.150*"hmc" + 0.149*"currently" + 0.149*"allowed" + 0.149*"construction" + 0.149*"required" + 0.149*"necessary" + 0.149*"even"
2016-10-09 22:32:56,345 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:56,347 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:56,347 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:56,349 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,349 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,349 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:56,350 : INFO : saved 10x5308 matrix, density=0.441% (234/53080)
2016-10-09 22:32:56,350 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,350 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,350 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,350 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,350 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,350 : INFO : accepted corpus with 10 documents, 5308 features, 234 non-zero entries
2016-10-09 22:32:56,351 : INFO : collecting document frequencies
2016-10-09 22:32:56,351 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:56,351 : INFO : calculating IDF weights for 10 documents and 5307 features (234 matrix non-zeros)
2016-10-09 22:32:56,351 : INFO : using serial LSI version on this node
2016-10-09 22:32:56,351 : INFO : updating model with new documents
2016-10-09 22:32:56,352 : INFO : preparing a new chunk of documents
2016-10-09 22:32:56,352 : DEBUG : converting corpus to csc format
2016-10-09 22:32:56,352 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:56,354 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:56,354 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:56,366 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,405 : DEBUG : running 2 power iterations
2016-10-09 22:32:56,425 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,484 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,533 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:56,538 : INFO : computing the final decomposition
2016-10-09 22:32:56,538 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:56,540 : INFO : processed documents up to #10
2016-10-09 22:32:56,541 : INFO : topic #0(1.087): 0.204*"india" + 0.160*"indian" + 0.159*"sunny" + 0.142*"kerala" + 0.139*"asian" + 0.136*"part" + 0.134*"men" + 0.134*"women" + 0.134*"western" + 0.134*"keralites"
2016-10-09 22:32:56,541 : INFO : topic #1(1.044): -0.208*"indian" + -0.195*"keralites" + -0.195*"2" + -0.153*"india" + -0.151*"getting" + -0.151*"marry" + -0.151*"girls" + -0.151*"arab" + 0.147*"please" + 0.139*"hmc"
2016-10-09 22:32:56,541 : INFO : topic #2(1.025): -0.231*"p" + 0.216*"sunny" + 0.189*"asian" + 0.182*"men" + 0.182*"women" + 0.182*"western" + -0.154*"letter" + -0.154*"" + -0.149*"words" + 0.144*"sex"
2016-10-09 22:32:56,541 : INFO : topic #3(1.005): -0.246*"india" + 0.235*"hmc" + -0.215*"p" + 0.177*"special" + 0.177*"jobs" + 0.177*"radio" + 0.177*"consider" + 0.177*"qbs" + 0.177*"heard" + 0.177*"wonder"
2016-10-09 22:32:56,541 : INFO : topic #4(1.000): -0.229*"getting" + -0.229*"girls" + -0.229*"arab" + -0.229*"marry" + 0.201*"jobs" + 0.201*"qbs" + 0.201*"heard" + 0.201*"radio" + 0.201*"special" + 0.201*"consider"
2016-10-09 22:32:56,541 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:56,543 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:56,544 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:56,545 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,545 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,545 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:56,545 : INFO : saved 10x5324 matrix, density=0.314% (167/53240)
2016-10-09 22:32:56,545 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,545 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,545 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,546 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,546 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,546 : INFO : accepted corpus with 10 documents, 5324 features, 167 non-zero entries
2016-10-09 22:32:56,546 : INFO : collecting document frequencies
2016-10-09 22:32:56,546 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:56,546 : INFO : calculating IDF weights for 10 documents and 5323 features (167 matrix non-zeros)
2016-10-09 22:32:56,547 : INFO : using serial LSI version on this node
2016-10-09 22:32:56,547 : INFO : updating model with new documents
2016-10-09 22:32:56,547 : INFO : preparing a new chunk of documents
2016-10-09 22:32:56,547 : DEBUG : converting corpus to csc format
2016-10-09 22:32:56,547 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:56,549 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:56,550 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:56,561 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,601 : DEBUG : running 2 power iterations
2016-10-09 22:32:56,621 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,680 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,729 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:56,734 : INFO : computing the final decomposition
2016-10-09 22:32:56,735 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:56,737 : INFO : processed documents up to #10
2016-10-09 22:32:56,737 : INFO : topic #0(1.147): -0.384*"buy" + -0.268*"know" + -0.259*"need" + -0.259*"please" + -0.192*"purchase" + -0.192*"knows" + -0.192*"shop" + -0.192*"let" + -0.192*"advance" + -0.192*"called"
2016-10-09 22:32:56,737 : INFO : topic #1(1.080): -0.262*"hi" + -0.253*"get" + -0.232*"machine" + -0.232*"bread" + -0.215*"good" + -0.198*"much" + 0.177*"buy" + -0.175*"find" + -0.163*"thanks" + -0.152*"either"
2016-10-09 22:32:56,737 : INFO : topic #2(1.011): 0.368*"cards" + 0.276*"bank" + -0.217*"filipino" + -0.217*"dog" + 0.184*"worked" + 0.184*"commercial" + 0.184*"qnb" + 0.155*"know" + 0.151*"yes" + -0.140*"buy"
2016-10-09 22:32:56,738 : INFO : topic #3(1.005): -0.215*"filipino" + -0.215*"dog" + -0.202*"qataris" + -0.202*"around" + -0.202*"like" + -0.202*"anything" + 0.176*"machine" + 0.176*"bread" + 0.163*"hi" + -0.153*"idea"
2016-10-09 22:32:56,738 : INFO : topic #4(1.001): 0.255*"cards" + -0.247*"around" + -0.247*"like" + -0.247*"anything" + -0.247*"qataris" + 0.191*"bank" + 0.127*"commercial" + 0.127*"qnb" + 0.127*"worked" + -0.127*"get"
2016-10-09 22:32:56,738 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:56,739 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:56,740 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:56,741 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,741 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,741 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:56,742 : INFO : saved 10x5323 matrix, density=0.368% (196/53230)
2016-10-09 22:32:56,742 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,742 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,742 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,742 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,742 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,743 : INFO : accepted corpus with 10 documents, 5323 features, 196 non-zero entries
2016-10-09 22:32:56,743 : INFO : collecting document frequencies
2016-10-09 22:32:56,743 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:56,743 : INFO : calculating IDF weights for 10 documents and 5322 features (196 matrix non-zeros)
2016-10-09 22:32:56,743 : INFO : using serial LSI version on this node
2016-10-09 22:32:56,743 : INFO : updating model with new documents
2016-10-09 22:32:56,744 : INFO : preparing a new chunk of documents
2016-10-09 22:32:56,744 : DEBUG : converting corpus to csc format
2016-10-09 22:32:56,744 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:56,746 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:56,746 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:56,758 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,798 : DEBUG : running 2 power iterations
2016-10-09 22:32:56,817 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,876 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,924 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:56,929 : INFO : computing the final decomposition
2016-10-09 22:32:56,929 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:56,931 : INFO : processed documents up to #10
2016-10-09 22:32:56,932 : INFO : topic #0(1.160): 0.231*"wife" + 0.203*"company" + 0.179*"even" + 0.179*"please" + 0.168*"sponsor" + 0.167*"know" + 0.164*"government" + 0.164*"children" + 0.161*"change" + 0.161*"months"
2016-10-09 22:32:56,932 : INFO : topic #1(1.042): 0.348*"know" + 0.203*"hi" + 0.171*"colleagues" + 0.171*"meeting" + 0.171*"success" + 0.171*"see" + 0.171*"today" + 0.171*"end" + 0.171*"friends" + 0.171*"rejected"
2016-10-09 22:32:56,932 : INFO : topic #2(1.026): 0.353*"license" + 0.252*"need" + 0.219*"away" + 0.219*"going" + 0.219*"weekend" + 0.219*"exit" + 0.219*"go" + 0.219*"long" + 0.219*"together" + 0.219*"permit"
2016-10-09 22:32:56,932 : INFO : topic #3(1.010): -0.339*"license" + 0.309*"qatar" + 0.257*"family" + 0.171*"visa" + -0.167*"need" + 0.155*"gets" + 0.155*"hamad" + 0.155*"policy" + 0.155*"10000" + 0.155*"females"
2016-10-09 22:32:56,932 : INFO : topic #4(0.996): 0.206*"please" + 0.206*"even" + 0.196*"three" + 0.196*"months" + 0.196*"change" + -0.168*"sponsored" + -0.155*"job" + -0.137*"someone" + -0.137*"received" + -0.137*"appreciate"
2016-10-09 22:32:56,932 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:56,934 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:56,934 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:56,936 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,936 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,936 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:56,936 : INFO : saved 10x5208 matrix, density=0.353% (184/52080)
2016-10-09 22:32:56,936 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,936 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,936 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,937 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:56,937 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:56,937 : INFO : accepted corpus with 10 documents, 5208 features, 184 non-zero entries
2016-10-09 22:32:56,937 : INFO : collecting document frequencies
2016-10-09 22:32:56,937 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:56,937 : INFO : calculating IDF weights for 10 documents and 5207 features (184 matrix non-zeros)
2016-10-09 22:32:56,938 : INFO : using serial LSI version on this node
2016-10-09 22:32:56,938 : INFO : updating model with new documents
2016-10-09 22:32:56,938 : INFO : preparing a new chunk of documents
2016-10-09 22:32:56,938 : DEBUG : converting corpus to csc format
2016-10-09 22:32:56,939 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:56,940 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:56,941 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:56,952 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:56,992 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,011 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,070 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,118 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:57,123 : INFO : computing the final decomposition
2016-10-09 22:32:57,123 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:57,125 : INFO : processed documents up to #10
2016-10-09 22:32:57,126 : INFO : topic #0(1.121): 0.309*"good" + 0.281*"budget" + 0.231*"maintenance" + 0.216*"performance" + 0.216*"45000" + 0.216*"shape" + 0.181*"best" + 0.128*"advice" + 0.127*"buying" + 0.116*"thank"
2016-10-09 22:32:57,126 : INFO : topic #1(1.055): -0.293*"buying" + 0.232*"good" + -0.225*"advise" + -0.225*"check" + -0.214*"please" + -0.193*"servicing" + -0.193*"offer" + -0.193*"costs" + -0.193*"look" + -0.193*"porsche"
2016-10-09 22:32:57,126 : INFO : topic #2(1.024): -0.252*"dubai" + -0.239*"possible" + -0.216*"without" + -0.216*"driving" + -0.216*"folks" + -0.216*"license" + -0.216*"name" + -0.191*"cars" + -0.143*"doha" + -0.126*"dealer"
2016-10-09 22:32:57,126 : INFO : topic #3(1.009): 0.294*"cars" + 0.244*"would" + 0.221*"doha" + -0.191*"without" + -0.191*"license" + -0.191*"folks" + -0.191*"name" + -0.191*"driving" + -0.164*"possible" + 0.137*"prices"
2016-10-09 22:32:57,126 : INFO : topic #4(0.997): 0.345*"right" + -0.264*"cars" + -0.198*"doha" + 0.172*"available" + 0.172*"cost" + 0.172*"prado" + 0.172*"problems" + 0.172*"armada" + 0.172*"dad" + 0.172*"wants"
2016-10-09 22:32:57,126 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:57,127 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:57,128 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:57,130 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,130 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,130 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:57,130 : INFO : saved 10x5331 matrix, density=0.413% (220/53310)
2016-10-09 22:32:57,130 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,130 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,131 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,131 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,131 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,131 : INFO : accepted corpus with 10 documents, 5331 features, 220 non-zero entries
2016-10-09 22:32:57,131 : INFO : collecting document frequencies
2016-10-09 22:32:57,131 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:57,131 : INFO : calculating IDF weights for 10 documents and 5330 features (220 matrix non-zeros)
2016-10-09 22:32:57,132 : INFO : using serial LSI version on this node
2016-10-09 22:32:57,132 : INFO : updating model with new documents
2016-10-09 22:32:57,132 : INFO : preparing a new chunk of documents
2016-10-09 22:32:57,132 : DEBUG : converting corpus to csc format
2016-10-09 22:32:57,133 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:57,135 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:57,135 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:57,146 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,186 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,205 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,264 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,313 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:57,318 : INFO : computing the final decomposition
2016-10-09 22:32:57,318 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:57,320 : INFO : processed documents up to #10
2016-10-09 22:32:57,320 : INFO : topic #0(1.158): 0.294*"best" + 0.290*"pakistani" + 0.218*"school" + 0.194*"thanks" + 0.168*"members" + 0.160*"3" + 0.157*"children" + 0.133*"qatar" + 0.128*"good" + 0.126*"education"
2016-10-09 22:32:57,320 : INFO : topic #1(1.045): 0.286*"schools" + 0.237*"british" + -0.187*"members" + 0.179*"many" + 0.158*"really" + 0.158*"know" + 0.158*"compulsory" + 0.158*"solution" + 0.158*"arabic" + -0.139*"dear"
2016-10-09 22:32:57,321 : INFO : topic #2(1.029): 0.207*"bus" + 0.194*"schools" + 0.185*"many" + -0.162*"3" + 0.152*"child" + -0.150*"international" + 0.147*"british" + -0.134*"location" + 0.132*"members" + -0.131*"planning"
2016-10-09 22:32:57,321 : INFO : topic #3(1.002): -0.403*"bus" + 0.254*"pakistani" + -0.229*"child" + -0.201*"found" + 0.196*"best" + -0.185*"location" + -0.130*"international" + 0.122*"c" + 0.122*"coaching" + 0.122*"managed"
2016-10-09 22:32:57,321 : INFO : topic #4(0.994): 0.306*"pakistani" + 0.273*"bus" + -0.194*"tuition" + -0.194*"private" + 0.168*"children" + 0.137*"found" + 0.126*"best" + -0.124*"members" + 0.113*"child" + 0.108*"thanks"
2016-10-09 22:32:57,321 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:57,322 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:57,323 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:57,324 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,325 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,325 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:57,325 : INFO : saved 10x5279 matrix, density=0.371% (196/52790)
2016-10-09 22:32:57,325 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,325 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,325 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,326 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,326 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,326 : INFO : accepted corpus with 10 documents, 5279 features, 196 non-zero entries
2016-10-09 22:32:57,326 : INFO : collecting document frequencies
2016-10-09 22:32:57,326 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:57,326 : INFO : calculating IDF weights for 10 documents and 5278 features (196 matrix non-zeros)
2016-10-09 22:32:57,327 : INFO : using serial LSI version on this node
2016-10-09 22:32:57,327 : INFO : updating model with new documents
2016-10-09 22:32:57,327 : INFO : preparing a new chunk of documents
2016-10-09 22:32:57,327 : DEBUG : converting corpus to csc format
2016-10-09 22:32:57,327 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:57,329 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:57,330 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:57,341 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,381 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,400 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,459 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,507 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:57,512 : INFO : computing the final decomposition
2016-10-09 22:32:57,512 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:57,514 : INFO : processed documents up to #10
2016-10-09 22:32:57,514 : INFO : topic #0(1.139): -0.261*"qatar" + -0.223*"anybody" + -0.189*"please" + -0.174*"apply" + -0.171*"embassy" + -0.168*"know" + -0.162*"family" + -0.151*"itz" + -0.137*"tourist" + -0.137*"australian"
2016-10-09 22:32:57,514 : INFO : topic #1(1.047): 0.256*"qatar" + -0.211*"family" + -0.190*"lebanese" + -0.179*"still" + -0.177*"exit" + -0.177*"country" + 0.143*"tourist" + 0.139*"embassy" + 0.135*"anybody" + -0.132*"itz"
2016-10-09 22:32:57,515 : INFO : topic #2(1.042): -0.318*"anybody" + 0.268*"qatar" + 0.199*"tourist" + -0.186*"please" + -0.167*"whether" + -0.167*"month" + -0.167*"3" + -0.167*"doha" + -0.167*"currently" + -0.167*"maximum"
2016-10-09 22:32:57,515 : INFO : topic #3(1.008): 0.207*"air" + 0.207*"hear" + 0.207*"road" + 0.207*"suggest" + 0.207*"salaam" + 0.207*"cant" + 0.207*"parents" + 0.207*"come" + 0.207*"sad" + 0.207*"us"
2016-10-09 22:32:57,515 : INFO : topic #4(1.003): 0.358*"extension" + 0.179*"approved" + 0.179*"system" + 0.179*"missed" + 0.179*"printed" + 0.179*"really" + 0.179*"comment" + 0.179*"recently" + 0.179*"posted" + 0.179*"4"
2016-10-09 22:32:57,515 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:57,516 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:57,517 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:57,518 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,518 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,518 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:57,519 : INFO : saved 10x5235 matrix, density=0.264% (138/52350)
2016-10-09 22:32:57,519 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,519 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,519 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,520 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,520 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,520 : INFO : accepted corpus with 10 documents, 5235 features, 138 non-zero entries
2016-10-09 22:32:57,520 : INFO : collecting document frequencies
2016-10-09 22:32:57,520 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:57,520 : INFO : calculating IDF weights for 10 documents and 5234 features (138 matrix non-zeros)
2016-10-09 22:32:57,520 : INFO : using serial LSI version on this node
2016-10-09 22:32:57,520 : INFO : updating model with new documents
2016-10-09 22:32:57,521 : INFO : preparing a new chunk of documents
2016-10-09 22:32:57,521 : DEBUG : converting corpus to csc format
2016-10-09 22:32:57,521 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:57,523 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:57,523 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:57,535 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,575 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,594 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,653 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,701 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:57,706 : INFO : computing the final decomposition
2016-10-09 22:32:57,706 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:57,708 : INFO : processed documents up to #10
2016-10-09 22:32:57,709 : INFO : topic #0(1.117): 0.281*"accommodation" + 0.277*"expensive" + 0.185*"standards" + 0.185*"quality" + 0.185*"finishing" + 0.185*"famous" + 0.185*"decorations" + 0.184*"qatar" + 0.183*"etc" + 0.166*"facilities"
2016-10-09 22:32:57,709 : INFO : topic #1(1.049): -0.358*"school" + -0.183*"fees" + -0.183*"son" + -0.183*"passed" + -0.183*"exam" + -0.183*"recommended" + -0.183*"entry" + -0.183*"th" + -0.183*"asked" + -0.182*"doha"
2016-10-09 22:32:57,709 : INFO : topic #2(1.033): 0.255*"thread" + 0.189*"milk" + 0.189*"anywhere" + 0.189*"ps" + 0.189*"dedicated" + 0.189*"else" + 0.175*"buy" + 0.175*"soft" + 0.175*"uk" + 0.175*"nice"
2016-10-09 22:32:57,709 : INFO : topic #3(1.015): -0.171*"thanks" + 0.164*"nice" + 0.164*"uk" + 0.164*"buy" + 0.164*"higher" + 0.164*"soft" + 0.164*"really" + 0.164*"thinking" + -0.162*"advise" + -0.162*"cost"
2016-10-09 22:32:57,709 : INFO : topic #4(0.999): 0.258*"sort" + 0.258*"insurance" + 0.258*"without" + 0.258*"living" + 0.258*"health" + 0.258*"concerned" + 0.258*"treatment" + 0.258*"couple" + 0.258*"sick" + 0.258*"got"
2016-10-09 22:32:57,709 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:57,710 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:57,711 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:57,712 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,713 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,713 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:57,713 : INFO : saved 10x5324 matrix, density=0.374% (199/53240)
2016-10-09 22:32:57,713 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,713 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,713 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,714 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,714 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,714 : INFO : accepted corpus with 10 documents, 5324 features, 199 non-zero entries
2016-10-09 22:32:57,714 : INFO : collecting document frequencies
2016-10-09 22:32:57,714 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:57,714 : INFO : calculating IDF weights for 10 documents and 5323 features (199 matrix non-zeros)
2016-10-09 22:32:57,715 : INFO : using serial LSI version on this node
2016-10-09 22:32:57,715 : INFO : updating model with new documents
2016-10-09 22:32:57,715 : INFO : preparing a new chunk of documents
2016-10-09 22:32:57,715 : DEBUG : converting corpus to csc format
2016-10-09 22:32:57,715 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:57,717 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:57,717 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:57,729 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,769 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,788 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,847 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,895 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:57,900 : INFO : computing the final decomposition
2016-10-09 22:32:57,900 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:57,903 : INFO : processed documents up to #10
2016-10-09 22:32:57,903 : INFO : topic #0(1.091): 0.250*"ql" + 0.178*"work" + 0.161*"qatar" + 0.153*"never" + 0.151*"without" + 0.145*"lucky" + 0.139*"today" + 0.139*"xp" + 0.139*"talk" + 0.139*"nobody"
2016-10-09 22:32:57,903 : INFO : topic #1(1.048): 0.294*"qatar" + 0.206*"get" + 0.203*"diseases" + -0.200*"without" + 0.188*"thanks" + 0.180*"lucky" + -0.154*"look" + -0.154*"watch" + -0.154*"youtube" + -0.154*"http"
2016-10-09 22:32:57,903 : INFO : topic #2(1.031): -0.252*"diseases" + 0.232*"ql" + 0.207*"hour" + 0.207*"hours" + 0.207*"surfing" + 0.207*"spend" + 0.207*"everyone" + 0.180*"lucky" + -0.168*"noticed" + 0.152*"many"
2016-10-09 22:32:57,904 : INFO : topic #3(1.020): -0.219*"com" + -0.219*"http" + -0.219*"v" + -0.219*"youtube" + -0.219*"www" + -0.186*"look" + -0.186*"watch" + 0.185*"ql" + 0.172*"work" + -0.167*"qatar"
2016-10-09 22:32:57,904 : INFO : topic #4(1.000): 0.328*"diseases" + -0.251*"speed" + 0.219*"noticed" + -0.168*"issue" + -0.168*"still" + -0.168*"help" + -0.168*"qtel" + -0.138*"bye" + 0.117*"least" + -0.112*"like"
2016-10-09 22:32:57,904 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:57,905 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:57,906 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:57,907 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,907 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,907 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:57,908 : INFO : saved 10x5274 matrix, density=0.411% (217/52740)
2016-10-09 22:32:57,908 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,908 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,908 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,909 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:57,909 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:57,909 : INFO : accepted corpus with 10 documents, 5274 features, 217 non-zero entries
2016-10-09 22:32:57,909 : INFO : collecting document frequencies
2016-10-09 22:32:57,909 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:57,909 : INFO : calculating IDF weights for 10 documents and 5273 features (217 matrix non-zeros)
2016-10-09 22:32:57,909 : INFO : using serial LSI version on this node
2016-10-09 22:32:57,909 : INFO : updating model with new documents
2016-10-09 22:32:57,910 : INFO : preparing a new chunk of documents
2016-10-09 22:32:57,910 : DEBUG : converting corpus to csc format
2016-10-09 22:32:57,910 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:57,912 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:57,912 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:57,924 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:57,964 : DEBUG : running 2 power iterations
2016-10-09 22:32:57,983 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:58,042 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:58,091 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:58,096 : INFO : computing the final decomposition
2016-10-09 22:32:58,096 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:58,098 : INFO : processed documents up to #10
2016-10-09 22:32:58,098 : INFO : topic #0(1.059): 0.229*"license" + 0.215*"driving" + 0.210*"anyone" + 0.178*"jazeera" + 0.178*"al" + 0.158*"radio" + 0.158*"night" + 0.157*"please" + 0.155*"tell" + 0.145*"qp"
2016-10-09 22:32:58,098 : INFO : topic #1(1.019): -0.270*"true" + -0.217*"buy" + -0.188*"2" + -0.180*"places" + 0.146*"anyone" + -0.142*"qatar" + 0.131*"blind" + 0.131*"acceptable" + 0.131*"whether" + 0.131*"hey"
2016-10-09 22:32:58,099 : INFO : topic #2(1.010): -0.376*"qar" + -0.240*"license" + 0.224*"jazeera" + 0.224*"al" + -0.188*"000" + -0.183*"driving" + 0.152*"buy" + 0.150*"accommodation" + 0.125*"anyone" + -0.125*"basic"
2016-10-09 22:32:58,099 : INFO : topic #3(1.004): -0.371*"buy" + -0.185*"sort" + -0.185*"find" + -0.185*"things" + -0.185*"difficult" + -0.185*"worst" + -0.185*"sin" + -0.185*"boxes" + -0.185*"bought" + -0.185*"two"
2016-10-09 22:32:58,099 : INFO : topic #4(1.001): 0.415*"2" + 0.207*"note" + 0.207*"lovely" + 0.207*"black" + 0.207*"proper" + 0.207*"cups" + 0.207*"meat" + 0.207*"bits" + 0.207*"plz" + -0.163*"expect"
2016-10-09 22:32:58,099 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:58,100 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:58,101 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:32:58,102 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:58,102 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:58,102 : INFO : PROGRESS: saving document #0
2016-10-09 22:32:58,103 : INFO : saved 10x5319 matrix, density=0.182% (97/53190)
2016-10-09 22:32:58,103 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:58,103 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:58,103 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:58,103 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:32:58,103 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:32:58,104 : INFO : accepted corpus with 10 documents, 5319 features, 97 non-zero entries
2016-10-09 22:32:58,104 : INFO : collecting document frequencies
2016-10-09 22:32:58,104 : INFO : PROGRESS: processing document #0
2016-10-09 22:32:58,104 : INFO : calculating IDF weights for 10 documents and 5318 features (97 matrix non-zeros)
2016-10-09 22:32:58,104 : INFO : using serial LSI version on this node
2016-10-09 22:32:58,104 : INFO : updating model with new documents
2016-10-09 22:32:58,104 : INFO : preparing a new chunk of documents
2016-10-09 22:32:58,105 : DEBUG : converting corpus to csc format
2016-10-09 22:32:58,105 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:32:58,107 : INFO : 1st phase: constructing (5337, 300) action matrix
2016-10-09 22:32:58,107 : INFO : orthonormalizing (5337, 300) action matrix
2016-10-09 22:32:58,119 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:58,159 : DEBUG : running 2 power iterations
2016-10-09 22:32:58,178 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:58,237 : DEBUG : computing QR of (5337, 300) dense matrix
2016-10-09 22:32:58,285 : INFO : 2nd phase: running dense svd on (300, 10) matrix
2016-10-09 22:32:58,290 : INFO : computing the final decomposition
2016-10-09 22:32:58,290 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:32:58,293 : INFO : processed documents up to #10
2016-10-09 22:32:58,293 : INFO : topic #0(1.112): 0.468*"see" + 0.353*"moon" + 0.325*"world" + 0.317*"didnt" + 0.200*"friend" + 0.176*"round" + 0.176*"end" + 0.176*"lot" + 0.158*"long" + 0.158*"time"
2016-10-09 22:32:58,293 : INFO : topic #1(1.069): 0.517*"comment" + 0.449*"please" + 0.279*"missing" + 0.279*"authorized" + 0.279*"names" + 0.279*"qlers" + 0.240*"add" + 0.190*"topic" + 0.126*"every" + 0.063*"hijacked"
2016-10-09 22:32:58,293 : INFO : topic #2(1.034): 0.382*"many" + 0.366*"returns" + 0.366*"happy" + 0.366*"party" + 0.359*"boss" + 0.180*"jpg" + 0.180*"lol" + 0.180*"till" + 0.180*"coz" + 0.180*"com"
2016-10-09 22:32:58,293 : INFO : topic #3(1.015): -0.282*"u" + 0.266*"men" + 0.266*"data" + 0.266*"filipinos" + 0.266*"per" + 0.266*"agree" + 0.266*"part" + 0.259*"world" + -0.177*"didnt" + -0.160*"ql"
2016-10-09 22:32:58,294 : INFO : topic #4(1.000): 1.000*"going" + 0.000*"topic" + -0.000*"comment" + 0.000*"every" + 0.000*"hijacked" + 0.000*"dont" + 0.000*"im" + 0.000*"seems" + 0.000*"points" + 0.000*"bit"
2016-10-09 22:32:58,294 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:32:58,294 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:32:58,295 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:43:58,583 : INFO : adding document #0 to Dictionary(0 unique tokens: [])
2016-10-09 22:43:58,866 : INFO : built Dictionary(11949 unique tokens: ['hearing', 'software', 'closing', 'convinced', 'sylvan']...) from 4880 documents (total 186045 corpus positions)
2016-10-09 22:43:58,872 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:43:58,875 : DEBUG : rebuilding dictionary, shrinking gaps
2016-10-09 22:43:58,879 : INFO : saving Dictionary object under ./tmp/LsiModel/LsiModel.dict, separately None
2016-10-09 22:43:58,941 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:58,941 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:58,941 : INFO : PROGRESS: saving document #0
2016-10-09 22:43:58,941 : INFO : saved 10x5329 matrix, density=0.302% (161/53290)
2016-10-09 22:43:58,941 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:58,942 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:58,942 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:43:58,942 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:43:58,942 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:58,943 : INFO : accepted corpus with 10 documents, 5329 features, 161 non-zero entries
2016-10-09 22:43:58,943 : INFO : collecting document frequencies
2016-10-09 22:43:58,943 : INFO : PROGRESS: processing document #0
2016-10-09 22:43:58,943 : INFO : calculating IDF weights for 10 documents and 5328 features (161 matrix non-zeros)
2016-10-09 22:43:58,944 : INFO : using serial LSI version on this node
2016-10-09 22:43:58,944 : INFO : updating model with new documents
2016-10-09 22:43:58,944 : INFO : preparing a new chunk of documents
2016-10-09 22:43:58,944 : DEBUG : converting corpus to csc format
2016-10-09 22:43:58,945 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:43:58,945 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:43:58,947 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:43:58,999 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:43:59,164 : DEBUG : running 2 power iterations
2016-10-09 22:43:59,219 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:43:59,407 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:43:59,570 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:43:59,582 : INFO : computing the final decomposition
2016-10-09 22:43:59,582 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:43:59,586 : INFO : processed documents up to #10
2016-10-09 22:43:59,587 : INFO : topic #0(1.187): 0.284*"open" + 0.283*"best" + 0.281*"savings" + 0.244*"account" + 0.188*"doha" + 0.175*"hi" + 0.168*"everybody" + 0.163*"using" + 0.156*"possible" + 0.156*"deal"
2016-10-09 22:43:59,588 : INFO : topic #1(1.090): -0.378*"card" + -0.339*"using" + -0.263*"would" + 0.197*"savings" + 0.185*"open" + -0.175*"gives" + 0.167*"best" + -0.155*"home" + -0.155*"ql" + -0.133*"sort"
2016-10-09 22:43:59,588 : INFO : topic #2(1.027): 0.402*"using" + 0.267*"home" + 0.267*"ql" + -0.246*"services" + -0.246*"islamic" + 0.236*"regards" + -0.153*"good" + -0.153*"banks" + -0.127*"accept" + -0.123*"idea"
2016-10-09 22:43:59,588 : INFO : topic #3(1.002): 0.271*"services" + 0.271*"islamic" + -0.269*"accept" + -0.179*"transfer" + -0.159*"recommendations" + -0.159*"use" + -0.159*"overseas" + -0.159*"used" + -0.159*"funds" + -0.159*"paid"
2016-10-09 22:43:59,588 : INFO : topic #4(0.998): 0.280*"accept" + 0.200*"personal" + 0.146*"regards" + 0.146*"someone" + 0.146*"know" + 0.146*"weekend" + 0.146*"help" + 0.146*"nice" + 0.146*"greetings" + 0.146*"see"
2016-10-09 22:43:59,588 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:43:59,589 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:43:59,590 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:43:59,592 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:59,592 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:59,592 : INFO : PROGRESS: saving document #0
2016-10-09 22:43:59,592 : INFO : saved 10x5329 matrix, density=0.276% (147/53290)
2016-10-09 22:43:59,592 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:59,592 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:59,592 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:43:59,593 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:43:59,593 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:43:59,593 : INFO : accepted corpus with 10 documents, 5329 features, 147 non-zero entries
2016-10-09 22:43:59,593 : INFO : collecting document frequencies
2016-10-09 22:43:59,593 : INFO : PROGRESS: processing document #0
2016-10-09 22:43:59,593 : INFO : calculating IDF weights for 10 documents and 5328 features (147 matrix non-zeros)
2016-10-09 22:43:59,594 : INFO : using serial LSI version on this node
2016-10-09 22:43:59,594 : INFO : updating model with new documents
2016-10-09 22:43:59,594 : INFO : preparing a new chunk of documents
2016-10-09 22:43:59,594 : DEBUG : converting corpus to csc format
2016-10-09 22:43:59,594 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:43:59,598 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:43:59,598 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:43:59,632 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:43:59,759 : DEBUG : running 2 power iterations
2016-10-09 22:43:59,800 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:43:59,940 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,061 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:00,069 : INFO : computing the final decomposition
2016-10-09 22:44:00,069 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:00,072 : INFO : processed documents up to #10
2016-10-09 22:44:00,072 : INFO : topic #0(1.125): 0.314*"go" + 0.268*"qatar" + 0.258*"catch" + 0.255*"friday" + 0.255*"next" + 0.227*"planning" + 0.213*"know" + 0.163*"place" + 0.149*"beach" + 0.149*"like"
2016-10-09 22:44:00,072 : INFO : topic #1(1.046): 0.257*"shisha" + 0.218*"hi" + 0.202*"family" + -0.193*"planning" + -0.183*"go" + 0.166*"north" + 0.166*"front" + 0.166*"swimming" + 0.166*"say" + 0.166*"quiet"
2016-10-09 22:44:00,073 : INFO : topic #2(1.018): -0.432*"card" + -0.215*"would" + -0.173*"using" + -0.173*"gives" + -0.154*"spend" + -0.134*"mind" + -0.134*"plz" + -0.134*"guys" + -0.134*"massage" + -0.134*"want"
2016-10-09 22:44:00,073 : INFO : topic #3(1.000): 0.382*"reliable" + 0.191*"priced" + 0.191*"low" + 0.191*"experience" + 0.191*"hard" + 0.191*"also" + 0.191*"qatarliving" + 0.191*"around" + 0.191*"cruiser" + 0.191*"members"
2016-10-09 22:44:00,073 : INFO : topic #4(1.000): -0.408*"cup" + -0.408*"plus" + -0.408*"view" + -0.408*"well" + -0.408*"nice" + -0.408*"coffee" + 0.000*"reliable" + -0.000*"card" + -0.000*"would" + -0.000*"shisha"
2016-10-09 22:44:00,073 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:00,074 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:00,075 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:00,076 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,076 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,076 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:00,076 : INFO : saved 10x5327 matrix, density=0.227% (121/53270)
2016-10-09 22:44:00,077 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,077 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,077 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:00,077 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:00,077 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,077 : INFO : accepted corpus with 10 documents, 5327 features, 121 non-zero entries
2016-10-09 22:44:00,078 : INFO : collecting document frequencies
2016-10-09 22:44:00,078 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:00,078 : INFO : calculating IDF weights for 10 documents and 5326 features (121 matrix non-zeros)
2016-10-09 22:44:00,078 : INFO : using serial LSI version on this node
2016-10-09 22:44:00,078 : INFO : updating model with new documents
2016-10-09 22:44:00,078 : INFO : preparing a new chunk of documents
2016-10-09 22:44:00,078 : DEBUG : converting corpus to csc format
2016-10-09 22:44:00,079 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:00,082 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:00,082 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:00,110 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,224 : DEBUG : running 2 power iterations
2016-10-09 22:44:00,266 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,416 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,529 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:00,537 : INFO : computing the final decomposition
2016-10-09 22:44:00,538 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:00,541 : INFO : processed documents up to #10
2016-10-09 22:44:00,541 : INFO : topic #0(1.162): 0.309*"go" + 0.246*"best" + 0.220*"friday" + 0.220*"next" + 0.207*"know" + 0.195*"place" + 0.194*"beach" + 0.185*"18" + 0.185*"years" + 0.182*"planning"
2016-10-09 22:44:00,541 : INFO : topic #1(1.081): -0.329*"tourists" + -0.312*"18" + -0.312*"years" + -0.256*"places" + -0.245*"visit" + 0.193*"best" + 0.166*"catch" + 0.161*"go" + 0.159*"place" + 0.154*"friday"
2016-10-09 22:44:00,541 : INFO : topic #2(1.014): 0.360*"island" + 0.254*"park" + 0.185*"5" + 0.185*"corniche" + 0.180*"called" + 0.180*"anyone" + 0.180*"end" + 0.180*"resort" + 0.180*"near" + 0.180*"seen"
2016-10-09 22:44:00,541 : INFO : topic #3(1.001): 0.387*"good" + 0.387*"quality" + 0.387*"spend" + 0.387*"time" + 0.276*"friends" + -0.202*"suggestions" + 0.200*"place" + -0.153*"maybe" + -0.153*"bay" + -0.153*"romantic"
2016-10-09 22:44:00,542 : INFO : topic #4(1.000): 0.577*"holiday" + 0.577*"experience" + 0.577*"destinations" + 0.000*"suggestions" + 0.000*"new" + 0.000*"something" + 0.000*"happenings" + 0.000*"holidays" + 0.000*"please" + -0.000*"tourists"
2016-10-09 22:44:00,542 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:00,543 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:00,543 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:00,545 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,545 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,545 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:00,545 : INFO : saved 10x5322 matrix, density=0.404% (215/53220)
2016-10-09 22:44:00,545 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,545 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,546 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:00,546 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:00,546 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,546 : INFO : accepted corpus with 10 documents, 5322 features, 215 non-zero entries
2016-10-09 22:44:00,546 : INFO : collecting document frequencies
2016-10-09 22:44:00,546 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:00,547 : INFO : calculating IDF weights for 10 documents and 5321 features (215 matrix non-zeros)
2016-10-09 22:44:00,547 : INFO : using serial LSI version on this node
2016-10-09 22:44:00,547 : INFO : updating model with new documents
2016-10-09 22:44:00,547 : INFO : preparing a new chunk of documents
2016-10-09 22:44:00,547 : DEBUG : converting corpus to csc format
2016-10-09 22:44:00,548 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:00,551 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:00,551 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:00,578 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,680 : DEBUG : running 2 power iterations
2016-10-09 22:44:00,720 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,866 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:00,982 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:00,990 : INFO : computing the final decomposition
2016-10-09 22:44:00,990 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:00,994 : INFO : processed documents up to #10
2016-10-09 22:44:00,994 : INFO : topic #0(1.111): -0.250*"qatar" + -0.196*"good" + -0.177*"also" + -0.159*"know" + -0.153*"doha" + -0.140*"wanted" + -0.128*"housing" + -0.127*"single" + -0.127*"salary" + -0.127*"transportation"
2016-10-09 22:44:00,994 : INFO : topic #1(1.059): -0.364*"month" + -0.265*"per" + -0.256*"mate" + -0.176*"qar" + -0.176*"offered" + -0.151*"left" + -0.151*"day" + -0.128*"unable" + -0.128*"wondering" + -0.128*"ask"
2016-10-09 22:44:00,994 : INFO : topic #2(1.021): 0.246*"violation" + 0.246*"possible" + -0.188*"home" + 0.185*"anyone" + 0.142*"friend" + 0.142*"old" + 0.142*"times" + 0.142*"thousand" + 0.142*"threads" + 0.142*"rent"
2016-10-09 22:44:00,995 : INFO : topic #3(1.004): 0.308*"possible" + 0.308*"violation" + 0.241*"home" + 0.161*"designer" + 0.161*"people" + 0.154*"owner" + 0.154*"willing" + 0.154*"accept" + 0.154*"transfer" + 0.154*"new"
2016-10-09 22:44:00,995 : INFO : topic #4(1.001): 0.387*"good" + 0.194*"12" + 0.194*"deal" + 0.194*"allowance" + 0.194*"provide" + 0.194*"person" + -0.157*"possible" + -0.157*"violation" + 0.154*"company" + -0.149*"trying"
2016-10-09 22:44:00,995 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:00,996 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:00,997 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:00,999 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,999 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:00,999 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:00,999 : INFO : saved 10x5324 matrix, density=0.545% (290/53240)
2016-10-09 22:44:00,999 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,000 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,000 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,000 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,000 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,000 : INFO : accepted corpus with 10 documents, 5324 features, 290 non-zero entries
2016-10-09 22:44:01,000 : INFO : collecting document frequencies
2016-10-09 22:44:01,000 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:01,001 : INFO : calculating IDF weights for 10 documents and 5323 features (290 matrix non-zeros)
2016-10-09 22:44:01,001 : INFO : using serial LSI version on this node
2016-10-09 22:44:01,001 : INFO : updating model with new documents
2016-10-09 22:44:01,002 : INFO : preparing a new chunk of documents
2016-10-09 22:44:01,002 : DEBUG : converting corpus to csc format
2016-10-09 22:44:01,002 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:01,005 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:01,006 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:01,033 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,135 : DEBUG : running 2 power iterations
2016-10-09 22:44:01,175 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,322 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,438 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:01,445 : INFO : computing the final decomposition
2016-10-09 22:44:01,446 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:01,448 : INFO : processed documents up to #10
2016-10-09 22:44:01,449 : INFO : topic #0(1.159): -0.212*"petroleum" + -0.212*"qatar" + -0.181*"000" + -0.142*"interview" + -0.134*"2" + -0.131*"one" + -0.131*"visit" + -0.114*"14" + -0.110*"thank" + -0.109*"yearly"
2016-10-09 22:44:01,449 : INFO : topic #1(1.100): -0.252*"petroleum" + -0.252*"qatar" + 0.230*"000" + -0.164*"one" + -0.164*"visit" + -0.157*"interview" + 0.152*"experience" + 0.148*"14" + 0.138*"2" + -0.122*"process"
2016-10-09 22:44:01,449 : INFO : topic #2(1.026): -0.229*"month" + -0.229*"per" + 0.163*"yearly" + -0.153*"10" + -0.153*"enough" + 0.138*"years" + 0.128*"national" + -0.127*"000" + -0.125*"also" + 0.119*"final"
2016-10-09 22:44:01,449 : INFO : topic #3(1.012): -0.232*"help" + -0.190*"like" + -0.157*"mean" + -0.157*"3500" + -0.157*"anytime" + -0.157*"terminated" + -0.157*"period" + -0.157*"4000" + -0.157*"state" + -0.157*"total"
2016-10-09 22:44:01,449 : INFO : topic #4(0.988): -0.253*"month" + -0.253*"per" + -0.168*"10" + -0.168*"enough" + -0.145*"anybody" + -0.145*"info" + -0.145*"uk" + -0.145*"currently" + -0.145*"talks" + -0.145*"advice"
2016-10-09 22:44:01,450 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:01,451 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:01,452 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:01,454 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,454 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,454 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:01,454 : INFO : saved 10x5327 matrix, density=0.338% (180/53270)
2016-10-09 22:44:01,454 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,454 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,454 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,455 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,455 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,455 : INFO : accepted corpus with 10 documents, 5327 features, 180 non-zero entries
2016-10-09 22:44:01,455 : INFO : collecting document frequencies
2016-10-09 22:44:01,455 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:01,455 : INFO : calculating IDF weights for 10 documents and 5326 features (180 matrix non-zeros)
2016-10-09 22:44:01,456 : INFO : using serial LSI version on this node
2016-10-09 22:44:01,456 : INFO : updating model with new documents
2016-10-09 22:44:01,456 : INFO : preparing a new chunk of documents
2016-10-09 22:44:01,456 : DEBUG : converting corpus to csc format
2016-10-09 22:44:01,456 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:01,460 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:01,460 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:01,487 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,589 : DEBUG : running 2 power iterations
2016-10-09 22:44:01,631 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,772 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:01,889 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:01,897 : INFO : computing the final decomposition
2016-10-09 22:44:01,898 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:01,900 : INFO : processed documents up to #10
2016-10-09 22:44:01,901 : INFO : topic #0(1.169): 0.279*"doha" + 0.229*"baby" + 0.208*"get" + 0.195*"coming" + 0.188*"vaccination" + 0.181*"vaccinations" + 0.172*"much" + 0.171*"regular" + 0.169*"remaining" + 0.141*"clinic"
2016-10-09 22:44:01,901 : INFO : topic #1(1.040): -0.260*"would" + -0.188*"coming" + -0.184*"get" + 0.176*"u" + 0.176*"clinic" + 0.168*"regular" + 0.167*"communicate" + 0.167*"good" + 0.167*"recommend" + -0.163*"know"
2016-10-09 22:44:01,901 : INFO : topic #2(1.027): 0.287*"doha" + 0.254*"law" + 0.254*"selection" + 0.254*"buy" + -0.176*"remaining" + 0.173*"recommend" + 0.173*"good" + 0.173*"communicate" + -0.151*"know" + -0.144*"schools"
2016-10-09 22:44:01,901 : INFO : topic #3(1.003): -0.291*"made" + 0.214*"would" + 0.211*"job" + 0.211*"considering" + 0.150*"law" + 0.150*"selection" + 0.150*"buy" + -0.145*"money" + -0.145*"lot" + -0.145*"ones"
2016-10-09 22:44:01,901 : INFO : topic #4(1.001): -0.334*"made" + 0.208*"know" + 0.185*"anyone" + 0.185*"schools" + -0.167*"money" + -0.167*"think" + -0.167*"wonder" + -0.167*"lot" + -0.167*"cure" + -0.167*"spent"
2016-10-09 22:44:01,902 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:01,903 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:01,904 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:01,905 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,905 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,905 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:01,905 : INFO : saved 10x5322 matrix, density=0.267% (142/53220)
2016-10-09 22:44:01,905 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,906 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,906 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,906 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:01,906 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:01,906 : INFO : accepted corpus with 10 documents, 5322 features, 142 non-zero entries
2016-10-09 22:44:01,906 : INFO : collecting document frequencies
2016-10-09 22:44:01,907 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:01,907 : INFO : calculating IDF weights for 10 documents and 5321 features (142 matrix non-zeros)
2016-10-09 22:44:01,907 : INFO : using serial LSI version on this node
2016-10-09 22:44:01,907 : INFO : updating model with new documents
2016-10-09 22:44:01,907 : INFO : preparing a new chunk of documents
2016-10-09 22:44:01,908 : DEBUG : converting corpus to csc format
2016-10-09 22:44:01,908 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:01,911 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:01,911 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:01,938 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,039 : DEBUG : running 2 power iterations
2016-10-09 22:44:02,079 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,220 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,339 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:02,348 : INFO : computing the final decomposition
2016-10-09 22:44:02,348 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:02,351 : INFO : processed documents up to #10
2016-10-09 22:44:02,351 : INFO : topic #0(1.165): -0.317*"cold" + -0.302*"curious" + -0.240*"winter" + -0.228*"coming" + -0.204*"doha" + -0.190*"hi" + -0.171*"thank" + -0.163*"already" + -0.163*"october" + -0.163*"november"
2016-10-09 22:44:02,351 : INFO : topic #1(1.056): -0.248*"curious" + 0.208*"coming" + -0.194*"winter" + 0.189*"bring" + -0.175*"doha" + 0.174*"thank" + 0.148*"qatar" + 0.140*"30" + 0.140*"dress" + 0.140*"pls"
2016-10-09 22:44:02,352 : INFO : topic #2(1.027): 0.288*"normal" + -0.278*"curious" + 0.179*"know" + 0.149*"thanks" + 0.144*"told" + 0.144*"recent" + 0.144*"rid" + 0.144*"week" + 0.144*"due" + 0.144*"dust"
2016-10-09 22:44:02,352 : INFO : topic #3(1.000): -0.314*"also" + -0.314*"travel" + -0.157*"august" + -0.157*"packages" + -0.157*"package" + -0.157*"plan" + -0.157*"please" + -0.157*"vegetarian" + -0.157*"required" + -0.157*"india"
2016-10-09 22:44:02,352 : INFO : topic #4(0.995): 0.269*"western" + 0.269*"clothes" + 0.269*"jeans" + 0.269*"visiting" + 0.269*"wear" + 0.269*"woman" + 0.202*"december" + 0.182*"bring" + 0.158*"pool" + 0.158*"lap"
2016-10-09 22:44:02,352 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:02,353 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:02,354 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:02,355 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,355 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,356 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:02,356 : INFO : saved 10x5327 matrix, density=0.357% (190/53270)
2016-10-09 22:44:02,356 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,356 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,356 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:02,357 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:02,357 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,357 : INFO : accepted corpus with 10 documents, 5327 features, 190 non-zero entries
2016-10-09 22:44:02,357 : INFO : collecting document frequencies
2016-10-09 22:44:02,357 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:02,357 : INFO : calculating IDF weights for 10 documents and 5326 features (190 matrix non-zeros)
2016-10-09 22:44:02,358 : INFO : using serial LSI version on this node
2016-10-09 22:44:02,358 : INFO : updating model with new documents
2016-10-09 22:44:02,358 : INFO : preparing a new chunk of documents
2016-10-09 22:44:02,358 : DEBUG : converting corpus to csc format
2016-10-09 22:44:02,359 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:02,362 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:02,363 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:02,389 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,496 : DEBUG : running 2 power iterations
2016-10-09 22:44:02,536 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,681 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,800 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:02,808 : INFO : computing the final decomposition
2016-10-09 22:44:02,808 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:02,811 : INFO : processed documents up to #10
2016-10-09 22:44:02,811 : INFO : topic #0(1.178): -0.315*"puppy" + -0.298*"small" + -0.298*"dog" + -0.296*"would" + -0.261*"buy" + -0.259*"doha" + -0.178*"bring" + -0.170*"dogs" + -0.169*"food" + -0.139*"cat"
2016-10-09 22:44:02,811 : INFO : topic #1(1.046): 0.239*"cat" + -0.213*"puppy" + 0.193*"cost" + 0.193*"much" + -0.178*"small" + -0.178*"dog" + 0.174*"com" + 0.174*"http" + 0.174*"www" + 0.174*"qatarliving"
2016-10-09 22:44:02,812 : INFO : topic #2(1.008): -0.234*"much" + -0.234*"cost" + -0.190*"let" + -0.190*"pup" + -0.190*"know" + -0.148*"qatar" + -0.148*"place" + 0.136*"food" + -0.130*"1" + 0.128*"com"
2016-10-09 22:44:02,812 : INFO : topic #3(1.003): -0.197*"cats" + -0.197*"recommend" + -0.197*"successful" + -0.197*"buying" + -0.197*"finding" + -0.197*"somebody" + -0.197*"stuff" + -0.197*"thanks" + -0.197*"store" + -0.197*"necessary"
2016-10-09 22:44:02,812 : INFO : topic #4(1.000): 0.447*"christian" + 0.447*"attachment" + 0.447*"jesus" + 0.447*"see" + 0.447*"muslim" + -0.000*"let" + -0.000*"know" + -0.000*"pup" + 0.000*"rats" + 0.000*"back"
2016-10-09 22:44:02,812 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:02,813 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:02,814 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:02,815 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,815 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,816 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:02,816 : INFO : saved 10x5322 matrix, density=0.329% (175/53220)
2016-10-09 22:44:02,816 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,816 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,816 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:02,817 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:02,817 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:02,817 : INFO : accepted corpus with 10 documents, 5322 features, 175 non-zero entries
2016-10-09 22:44:02,817 : INFO : collecting document frequencies
2016-10-09 22:44:02,817 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:02,817 : INFO : calculating IDF weights for 10 documents and 5321 features (175 matrix non-zeros)
2016-10-09 22:44:02,818 : INFO : using serial LSI version on this node
2016-10-09 22:44:02,818 : INFO : updating model with new documents
2016-10-09 22:44:02,818 : INFO : preparing a new chunk of documents
2016-10-09 22:44:02,818 : DEBUG : converting corpus to csc format
2016-10-09 22:44:02,818 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:02,821 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:02,822 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:02,849 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:02,949 : DEBUG : running 2 power iterations
2016-10-09 22:44:02,989 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,129 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,249 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:03,257 : INFO : computing the final decomposition
2016-10-09 22:44:03,257 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:03,261 : INFO : processed documents up to #10
2016-10-09 22:44:03,261 : INFO : topic #0(1.127): -0.261*"much" + -0.227*"would" + -0.198*"also" + -0.162*"qatar" + -0.160*"pay" + -0.160*"loan" + -0.147*"know" + -0.125*"qr" + -0.124*"buying" + -0.124*"per"
2016-10-09 22:44:03,261 : INFO : topic #1(1.074): -0.324*"recommend" + -0.324*"anyone" + -0.305*"window" + -0.305*"applied" + -0.223*"place" + 0.182*"law" + 0.182*"selection" + 0.181*"doha" + 0.166*"buy" + -0.159*"apartment"
2016-10-09 22:44:03,261 : INFO : topic #2(1.060): 0.294*"doha" + 0.287*"selection" + 0.287*"law" + 0.268*"buy" + 0.173*"recommend" + 0.173*"anyone" + 0.160*"window" + 0.160*"applied" + -0.126*"much" + -0.108*"would"
2016-10-09 22:44:03,261 : INFO : topic #3(1.014): -0.366*"qr" + -0.314*"wife" + -0.157*"8000" + -0.157*"proceed" + -0.157*"enginner" + -0.157*"relocate" + -0.157*"allowance" + -0.157*"house" + -0.157*"work" + -0.157*"1500"
2016-10-09 22:44:03,262 : INFO : topic #4(0.994): 0.372*"months" + 0.372*"sell" + 0.189*"one" + 0.186*"want" + 0.186*"leaving" + 0.186*"weeks" + 0.186*"long" + 0.186*"resale" + 0.186*"prefer" + 0.186*"etc"
2016-10-09 22:44:03,262 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:03,263 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:03,264 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:03,265 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,265 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,265 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:03,265 : INFO : saved 10x5322 matrix, density=0.342% (182/53220)
2016-10-09 22:44:03,266 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,266 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,266 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:03,266 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:03,266 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,266 : INFO : accepted corpus with 10 documents, 5322 features, 182 non-zero entries
2016-10-09 22:44:03,266 : INFO : collecting document frequencies
2016-10-09 22:44:03,266 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:03,266 : INFO : calculating IDF weights for 10 documents and 5321 features (182 matrix non-zeros)
2016-10-09 22:44:03,267 : INFO : using serial LSI version on this node
2016-10-09 22:44:03,267 : INFO : updating model with new documents
2016-10-09 22:44:03,267 : INFO : preparing a new chunk of documents
2016-10-09 22:44:03,267 : DEBUG : converting corpus to csc format
2016-10-09 22:44:03,268 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:03,271 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:03,271 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:03,299 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,402 : DEBUG : running 2 power iterations
2016-10-09 22:44:03,443 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,587 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,701 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:03,710 : INFO : computing the final decomposition
2016-10-09 22:44:03,710 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:03,713 : INFO : processed documents up to #10
2016-10-09 22:44:03,713 : INFO : topic #0(1.125): 0.233*"child" + 0.180*"bus" + 0.171*"seat" + 0.168*"one" + 0.165*"front" + 0.154*"children" + 0.147*"vehicles" + 0.143*"would" + 0.142*"kids" + 0.140*"law"
2016-10-09 22:44:03,713 : INFO : topic #1(1.060): -0.275*"sure" + -0.248*"kids" + 0.216*"child" + -0.210*"would" + 0.201*"bus" + -0.153*"front" + -0.144*"brands" + -0.144*"worried" + -0.144*"airlines" + -0.144*"available"
2016-10-09 22:44:03,714 : INFO : topic #2(1.041): -0.349*"baby" + -0.269*"sign" + 0.236*"bus" + -0.230*"everything" + -0.230*"stores" + -0.179*"board" + 0.136*"child" + 0.136*"school" + -0.119*"doha" + 0.118*"found"
2016-10-09 22:44:03,714 : INFO : topic #3(1.029): 0.368*"selection" + 0.368*"buy" + 0.300*"law" + 0.212*"doha" + 0.206*"qatar" + -0.157*"one" + -0.150*"seat" + -0.140*"sign" + -0.130*"baby" + -0.127*"saw"
2016-10-09 22:44:03,714 : INFO : topic #4(1.020): 0.245*"one" + 0.160*"seat" + 0.159*"buy" + 0.159*"selection" + -0.159*"sure" + 0.153*"law" + -0.153*"bus" + -0.153*"school" + -0.142*"place" + -0.142*"son"
2016-10-09 22:44:03,714 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:03,715 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:03,716 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:03,717 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,717 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,718 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:03,718 : INFO : saved 10x5322 matrix, density=0.359% (191/53220)
2016-10-09 22:44:03,718 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,718 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,718 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:03,719 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:03,719 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:03,719 : INFO : accepted corpus with 10 documents, 5322 features, 191 non-zero entries
2016-10-09 22:44:03,719 : INFO : collecting document frequencies
2016-10-09 22:44:03,719 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:03,719 : INFO : calculating IDF weights for 10 documents and 5321 features (191 matrix non-zeros)
2016-10-09 22:44:03,720 : INFO : using serial LSI version on this node
2016-10-09 22:44:03,720 : INFO : updating model with new documents
2016-10-09 22:44:03,720 : INFO : preparing a new chunk of documents
2016-10-09 22:44:03,720 : DEBUG : converting corpus to csc format
2016-10-09 22:44:03,720 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:03,723 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:03,724 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:03,751 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:03,852 : DEBUG : running 2 power iterations
2016-10-09 22:44:03,892 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,032 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,146 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:04,154 : INFO : computing the final decomposition
2016-10-09 22:44:04,154 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:04,157 : INFO : processed documents up to #10
2016-10-09 22:44:04,157 : INFO : topic #0(1.168): 0.194*"beaches" + 0.191*"take" + 0.188*"beach" + 0.164*"dunes" + 0.163*"would" + 0.159*"umm" + 0.159*"anyone" + 0.155*"could" + 0.155*"start" + 0.155*"clean"
2016-10-09 22:44:04,157 : INFO : topic #1(1.031): 0.234*"public" + 0.234*"ridiculous" + 0.211*"suggestions" + 0.181*"one" + -0.160*"would" + 0.157*"please" + 0.137*"camping" + 0.137*"license" + -0.135*"could" + -0.133*"beaches"
2016-10-09 22:44:04,158 : INFO : topic #2(1.008): -0.368*"ridiculous" + -0.368*"public" + 0.353*"suggestions" + -0.199*"times" + -0.199*"gulf" + -0.199*"speed" + 0.177*"holidays" + 0.177*"something" + 0.177*"new" + 0.177*"happenings"
2016-10-09 22:44:04,158 : INFO : topic #3(1.005): 0.327*"suggestions" + 0.235*"party" + 0.235*"booze" + 0.235*"let" + 0.235*"private" + -0.169*"okay" + -0.169*"tell" + -0.168*"license" + -0.168*"camping" + 0.164*"something"
2016-10-09 22:44:04,158 : INFO : topic #4(0.995): -0.325*"ridiculous" + -0.325*"public" + 0.263*"times" + 0.263*"gulf" + 0.263*"speed" + -0.159*"beach" + -0.153*"okay" + -0.153*"tell" + 0.132*"hell" + 0.132*"topics"
2016-10-09 22:44:04,158 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:04,159 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:04,160 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:04,162 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,162 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,162 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:04,162 : INFO : saved 10x5322 matrix, density=0.393% (209/53220)
2016-10-09 22:44:04,162 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,162 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,162 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:04,163 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:04,163 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,163 : INFO : accepted corpus with 10 documents, 5322 features, 209 non-zero entries
2016-10-09 22:44:04,163 : INFO : collecting document frequencies
2016-10-09 22:44:04,163 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:04,163 : INFO : calculating IDF weights for 10 documents and 5321 features (209 matrix non-zeros)
2016-10-09 22:44:04,164 : INFO : using serial LSI version on this node
2016-10-09 22:44:04,164 : INFO : updating model with new documents
2016-10-09 22:44:04,164 : INFO : preparing a new chunk of documents
2016-10-09 22:44:04,164 : DEBUG : converting corpus to csc format
2016-10-09 22:44:04,165 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:04,168 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:04,168 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:04,194 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,299 : DEBUG : running 2 power iterations
2016-10-09 22:44:04,340 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,481 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,596 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:04,604 : INFO : computing the final decomposition
2016-10-09 22:44:04,604 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:04,607 : INFO : processed documents up to #10
2016-10-09 22:44:04,607 : INFO : topic #0(1.116): 0.255*"doha" + 0.252*"cars" + 0.177*"would" + 0.168*"much" + 0.154*"best" + 0.146*"toyota" + 0.146*"price" + 0.136*"reliable" + 0.133*"renault" + 0.121*"nissan"
2016-10-09 22:44:04,608 : INFO : topic #1(1.045): -0.257*"much" + 0.252*"doha" + 0.210*"cars" + -0.204*"would" + 0.159*"best" + -0.139*"pay" + -0.136*"thanks" + -0.133*"first" + -0.133*"per" + -0.133*"thinking"
2016-10-09 22:44:04,608 : INFO : topic #2(1.023): 0.219*"would" + 0.163*"much" + -0.150*"anyone" + -0.142*"reliable" + -0.141*"years" + 0.140*"price" + 0.140*"toyota" + -0.112*"problem" + -0.112*"threads" + -0.112*"absolutely"
2016-10-09 22:44:04,608 : INFO : topic #3(1.010): 0.259*"mean" + 0.259*"anybody" + 0.259*"yes" + 0.259*"share" + 0.259*"performance" + 0.259*"using" + 0.259*"maintenance" + 0.221*"please" + 0.196*"experience" + 0.195*"renault"
2016-10-09 22:44:04,608 : INFO : topic #4(1.005): -0.147*"reliable" + 0.144*"shown" + 0.144*"sun" + 0.144*"roof" + 0.144*"direct" + 0.144*"covering" + 0.144*"middle" + 0.144*"photo" + 0.144*"thank" + 0.144*"thin"
2016-10-09 22:44:04,608 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:04,609 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:04,610 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:04,612 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,612 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,612 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:04,612 : INFO : saved 10x5322 matrix, density=0.295% (157/53220)
2016-10-09 22:44:04,612 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,612 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,612 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:04,613 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:04,613 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:04,613 : INFO : accepted corpus with 10 documents, 5322 features, 157 non-zero entries
2016-10-09 22:44:04,613 : INFO : collecting document frequencies
2016-10-09 22:44:04,613 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:04,613 : INFO : calculating IDF weights for 10 documents and 5321 features (157 matrix non-zeros)
2016-10-09 22:44:04,614 : INFO : using serial LSI version on this node
2016-10-09 22:44:04,614 : INFO : updating model with new documents
2016-10-09 22:44:04,614 : INFO : preparing a new chunk of documents
2016-10-09 22:44:04,614 : DEBUG : converting corpus to csc format
2016-10-09 22:44:04,614 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:04,618 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:04,618 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:04,644 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,747 : DEBUG : running 2 power iterations
2016-10-09 22:44:04,787 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:04,930 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,043 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:05,051 : INFO : computing the final decomposition
2016-10-09 22:44:05,051 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:05,054 : INFO : processed documents up to #10
2016-10-09 22:44:05,054 : INFO : topic #0(1.209): 0.696*"water" + 0.270*"drinking" + 0.224*"filter" + 0.224*"using" + 0.206*"tap" + 0.183*"bottled" + 0.112*"buying" + 0.112*"anybody" + 0.112*"instead" + 0.112*"need"
2016-10-09 22:44:05,054 : INFO : topic #1(1.128): -0.276*"plants" + -0.224*"know" + -0.217*"nurseries" + -0.205*"doha" + -0.200*"anyone" + 0.186*"water" + -0.166*"supermarket" + -0.166*"also" + -0.166*"photography" + -0.166*"buy"
2016-10-09 22:44:05,055 : INFO : topic #2(1.024): -0.315*"business" + -0.241*"wanted" + -0.187*"places" + -0.178*"numbers" + -0.178*"contact" + -0.178*"answer" + -0.178*"phone" + -0.178*"couple" + -0.178*"getting" + -0.148*"tried"
2016-10-09 22:44:05,055 : INFO : topic #3(1.011): -0.250*"happening" + -0.212*"tried" + 0.205*"low" + 0.205*"bcz" + 0.205*"explain" + 0.205*"told" + 0.205*"doctor" + 0.194*"business" + -0.179*"phone" + -0.179*"contact"
2016-10-09 22:44:05,055 : INFO : topic #4(1.001): -0.248*"treatment" + -0.238*"low" + -0.238*"bcz" + -0.238*"told" + -0.238*"explain" + -0.238*"doctor" + -0.202*"couple" + -0.202*"contact" + -0.202*"answer" + -0.202*"phone"
2016-10-09 22:44:05,055 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:05,056 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:05,057 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:05,058 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,058 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,058 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:05,059 : INFO : saved 10x5327 matrix, density=0.332% (177/53270)
2016-10-09 22:44:05,059 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,059 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,059 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,059 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,060 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,060 : INFO : accepted corpus with 10 documents, 5327 features, 177 non-zero entries
2016-10-09 22:44:05,060 : INFO : collecting document frequencies
2016-10-09 22:44:05,060 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:05,060 : INFO : calculating IDF weights for 10 documents and 5326 features (177 matrix non-zeros)
2016-10-09 22:44:05,060 : INFO : using serial LSI version on this node
2016-10-09 22:44:05,060 : INFO : updating model with new documents
2016-10-09 22:44:05,061 : INFO : preparing a new chunk of documents
2016-10-09 22:44:05,061 : DEBUG : converting corpus to csc format
2016-10-09 22:44:05,061 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:05,064 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:05,064 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:05,091 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,190 : DEBUG : running 2 power iterations
2016-10-09 22:44:05,229 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,372 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,490 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:05,498 : INFO : computing the final decomposition
2016-10-09 22:44:05,498 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:05,501 : INFO : processed documents up to #10
2016-10-09 22:44:05,502 : INFO : topic #0(1.070): -0.460*"one" + -0.334*"places" + -0.334*"ever" + -0.334*"boring" + -0.323*"ridiculous" + -0.323*"public" + -0.323*"beach" + -0.221*"doha" + -0.075*"laffan" + -0.075*"ras"
2016-10-09 22:44:05,502 : INFO : topic #1(1.069): 0.244*"party" + 0.222*"restaurant" + 0.210*"anyone" + 0.182*"given" + 0.182*"already" + 0.182*"place" + 0.182*"kfc" + 0.182*"venues" + 0.182*"rent" + 0.182*"food"
2016-10-09 22:44:05,502 : INFO : topic #2(1.020): 0.231*"hmc" + 0.205*"laffan" + 0.205*"ras" + 0.154*"training" + 0.154*"salary" + 0.137*"live" + 0.133*"2" + 0.133*"son" + 0.133*"baby" + 0.133*"speech"
2016-10-09 22:44:05,502 : INFO : topic #3(1.016): -0.168*"party" + 0.166*"ras" + 0.166*"laffan" + 0.157*"gave" + 0.157*"bad" + 0.157*"airways" + 0.157*"staff" + 0.157*"experience" + 0.157*"crew" + 0.157*"prefer"
2016-10-09 22:44:05,503 : INFO : topic #4(1.001): 0.375*"result" + 0.375*"grade" + 0.187*"12" + 0.187*"university" + 0.187*"criteria" + 0.187*"cause" + 0.187*"selection" + 0.187*"sat" + 0.187*"looking" + 0.187*"rejected"
2016-10-09 22:44:05,503 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:05,504 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:05,505 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:05,506 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,506 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,506 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:05,507 : INFO : saved 10x5327 matrix, density=0.422% (225/53270)
2016-10-09 22:44:05,507 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,507 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,507 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,508 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,508 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,508 : INFO : accepted corpus with 10 documents, 5327 features, 225 non-zero entries
2016-10-09 22:44:05,508 : INFO : collecting document frequencies
2016-10-09 22:44:05,508 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:05,508 : INFO : calculating IDF weights for 10 documents and 5326 features (225 matrix non-zeros)
2016-10-09 22:44:05,509 : INFO : using serial LSI version on this node
2016-10-09 22:44:05,509 : INFO : updating model with new documents
2016-10-09 22:44:05,509 : INFO : preparing a new chunk of documents
2016-10-09 22:44:05,509 : DEBUG : converting corpus to csc format
2016-10-09 22:44:05,509 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:05,512 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:05,513 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:05,539 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,641 : DEBUG : running 2 power iterations
2016-10-09 22:44:05,679 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,824 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:05,940 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:05,948 : INFO : computing the final decomposition
2016-10-09 22:44:05,948 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:05,951 : INFO : processed documents up to #10
2016-10-09 22:44:05,951 : INFO : topic #0(1.131): -0.168*"back" + -0.166*"american" + -0.162*"schools" + -0.162*"uk" + -0.158*"many" + -0.157*"groups" + -0.157*"private" + -0.135*"home" + -0.133*"qatar" + -0.127*"appreciated"
2016-10-09 22:44:05,951 : INFO : topic #1(1.037): 0.270*"child" + 0.268*"bus" + 0.185*"son" + 0.185*"next" + 0.185*"month" + 0.185*"like" + 0.185*"7yrs" + 0.185*"park" + 0.185*"house" + -0.161*"small"
2016-10-09 22:44:05,952 : INFO : topic #2(1.026): -0.285*"bus" + -0.227*"use" + -0.227*"books" + -0.227*"start" + -0.218*"3" + -0.178*"child" + -0.170*"small" + -0.143*"found" + 0.136*"private" + 0.136*"groups"
2016-10-09 22:44:05,952 : INFO : topic #3(1.002): -0.257*"much" + -0.178*"use" + -0.178*"books" + -0.178*"start" + -0.153*"home" + -0.152*"daughter" + 0.146*"bus" + -0.128*"likes" + -0.128*"day" + -0.128*"europe"
2016-10-09 22:44:05,952 : INFO : topic #4(0.990): 0.202*"much" + 0.200*"anything" + 0.200*"thinking" + 0.200*"hello" + 0.200*"family" + 0.200*"international" + 0.200*"british" + -0.168*"uk" + -0.146*"back" + -0.135*"small"
2016-10-09 22:44:05,952 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:05,953 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:05,954 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:05,956 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,956 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,956 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:05,956 : INFO : saved 10x5313 matrix, density=0.369% (196/53130)
2016-10-09 22:44:05,956 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,956 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,957 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,957 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:05,957 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:05,957 : INFO : accepted corpus with 10 documents, 5313 features, 196 non-zero entries
2016-10-09 22:44:05,957 : INFO : collecting document frequencies
2016-10-09 22:44:05,957 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:05,958 : INFO : calculating IDF weights for 10 documents and 5312 features (196 matrix non-zeros)
2016-10-09 22:44:05,958 : INFO : using serial LSI version on this node
2016-10-09 22:44:05,958 : INFO : updating model with new documents
2016-10-09 22:44:05,958 : INFO : preparing a new chunk of documents
2016-10-09 22:44:05,958 : DEBUG : converting corpus to csc format
2016-10-09 22:44:05,959 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:05,962 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:05,962 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:05,988 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,088 : DEBUG : running 2 power iterations
2016-10-09 22:44:06,127 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,267 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,386 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:06,395 : INFO : computing the final decomposition
2016-10-09 22:44:06,395 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:06,398 : INFO : processed documents up to #10
2016-10-09 22:44:06,398 : INFO : topic #0(1.141): -0.265*"gratuity" + -0.224*"service" + -0.224*"end" + -0.205*"period" + -0.205*"7" + -0.205*"confirm" + -0.205*"years" + -0.205*"benefits" + -0.194*"working" + -0.182*"qatar"
2016-10-09 22:44:06,398 : INFO : topic #1(1.046): -0.224*"someone" + -0.220*"table" + -0.220*"want" + -0.220*"ask" + -0.220*"dinner" + -0.220*"share" + -0.210*"get" + -0.204*"please" + -0.183*"many" + -0.160*"anybody"
2016-10-09 22:44:06,398 : INFO : topic #2(1.008): 0.294*"good" + 0.252*"also" + 0.252*"deposit" + 0.252*"months" + 0.182*"doha" + 0.147*"live" + 0.147*"deal" + 0.147*"single" + 0.147*"housing" + 0.147*"12"
2016-10-09 22:44:06,398 : INFO : topic #3(1.002): 0.407*"respect" + 0.271*"think" + 0.271*"culture" + 0.271*"people" + -0.155*"anybody" + 0.136*"take" + 0.136*"others" + 0.136*"much" + 0.136*"feel" + 0.136*"local"
2016-10-09 22:44:06,399 : INFO : topic #4(1.000): -0.457*"crime" + -0.305*"considered" + -0.305*"polygamy" + -0.305*"wife" + -0.305*"west" + -0.152*"equally" + -0.152*"prohibited" + -0.152*"even" + -0.152*"islamic" + -0.152*"prostitution"
2016-10-09 22:44:06,399 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:06,400 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:06,401 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:06,402 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,402 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,402 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:06,403 : INFO : saved 10x5325 matrix, density=0.278% (148/53250)
2016-10-09 22:44:06,403 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,403 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,403 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:06,403 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:06,403 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,404 : INFO : accepted corpus with 10 documents, 5325 features, 148 non-zero entries
2016-10-09 22:44:06,404 : INFO : collecting document frequencies
2016-10-09 22:44:06,404 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:06,404 : INFO : calculating IDF weights for 10 documents and 5324 features (148 matrix non-zeros)
2016-10-09 22:44:06,404 : INFO : using serial LSI version on this node
2016-10-09 22:44:06,404 : INFO : updating model with new documents
2016-10-09 22:44:06,405 : INFO : preparing a new chunk of documents
2016-10-09 22:44:06,405 : DEBUG : converting corpus to csc format
2016-10-09 22:44:06,405 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:06,408 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:06,408 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:06,435 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,537 : DEBUG : running 2 power iterations
2016-10-09 22:44:06,578 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,719 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,837 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:06,845 : INFO : computing the final decomposition
2016-10-09 22:44:06,846 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:06,848 : INFO : processed documents up to #10
2016-10-09 22:44:06,849 : INFO : topic #0(1.059): 0.241*"qatar" + 0.231*"moon" + 0.215*"islam" + 0.195*"hi" + 0.174*"december" + 0.174*"national" + 0.174*"wanted" + 0.174*"18th" + 0.174*"thanks" + 0.174*"confirm"
2016-10-09 22:44:06,849 : INFO : topic #1(1.043): -0.316*"moon" + -0.236*"islam" + -0.183*"right" + 0.172*"hi" + -0.156*"world" + -0.156*"dirty" + -0.156*"idiots" + -0.156*"live" + -0.156*"fool" + 0.156*"national"
2016-10-09 22:44:06,849 : INFO : topic #2(1.032): -0.362*"one" + -0.323*"getting" + -0.323*"ones" + -0.323*"still" + -0.323*"waiting" + -0.194*"resale" + -0.194*"best" + -0.194*"doha" + -0.194*"cost" + -0.194*"pajero"
2016-10-09 22:44:06,849 : INFO : topic #3(1.007): 0.356*"wearing" + 0.190*"need" + 0.188*"teachers" + 0.178*"women" + 0.178*"long" + 0.178*"conservatively" + 0.178*"however" + 0.178*"family" + 0.178*"purchase" + 0.178*"stay"
2016-10-09 22:44:06,849 : INFO : topic #4(1.000): -0.447*"guy" + -0.447*"month" + -0.447*"earning" + -0.447*"gym" + -0.447*"affordable" + 0.000*"wearing" + 0.000*"many" + 0.000*"simply" + 0.000*"purchase" + 0.000*"conservatively"
2016-10-09 22:44:06,850 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:06,851 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:06,851 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:06,853 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,853 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,853 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:06,853 : INFO : saved 10x5322 matrix, density=0.383% (204/53220)
2016-10-09 22:44:06,853 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,853 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,854 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:06,854 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:06,854 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:06,854 : INFO : accepted corpus with 10 documents, 5322 features, 204 non-zero entries
2016-10-09 22:44:06,854 : INFO : collecting document frequencies
2016-10-09 22:44:06,854 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:06,854 : INFO : calculating IDF weights for 10 documents and 5321 features (204 matrix non-zeros)
2016-10-09 22:44:06,855 : INFO : using serial LSI version on this node
2016-10-09 22:44:06,855 : INFO : updating model with new documents
2016-10-09 22:44:06,855 : INFO : preparing a new chunk of documents
2016-10-09 22:44:06,855 : DEBUG : converting corpus to csc format
2016-10-09 22:44:06,856 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:06,859 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:06,859 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:06,886 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:06,986 : DEBUG : running 2 power iterations
2016-10-09 22:44:07,026 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,165 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,283 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:07,291 : INFO : computing the final decomposition
2016-10-09 22:44:07,291 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:07,294 : INFO : processed documents up to #10
2016-10-09 22:44:07,294 : INFO : topic #0(1.108): -0.192*"decent" + -0.186*"get" + -0.175*"need" + -0.170*"advance" + -0.165*"directions" + -0.155*"driving" + -0.155*"embassy" + -0.155*"appointment" + -0.155*"help" + -0.155*"set"
2016-10-09 22:44:07,294 : INFO : topic #1(1.041): -0.236*"qatar" + -0.207*"gps" + -0.207*"garmin" + -0.207*"wanted" + -0.183*"" + -0.183*"english" + -0.183*"books" + -0.170*"us" + -0.152*"driving" + -0.152*"appointment"
2016-10-09 22:44:07,294 : INFO : topic #2(1.020): 0.333*"thai" + 0.222*"food" + -0.177*"karwa" + -0.177*"al" + -0.177*"taxis" + -0.155*"repaire" + 0.152*"shops" + -0.138*"new" + -0.137*"anyone" + -0.115*"lulu"
2016-10-09 22:44:07,295 : INFO : topic #3(1.008): 0.238*"decent" + -0.221*"thai" + 0.158*"really" + 0.158*"carrefour" + 0.158*"ones" + 0.158*"vegetables" + 0.158*"fruits" + 0.158*"bad" + 0.158*"fresh" + 0.158*"bread"
2016-10-09 22:44:07,295 : INFO : topic #4(0.995): -0.177*"first" + -0.177*"maps" + -0.177*"couple" + 0.150*"thai" + -0.142*"decent" + 0.140*"need" + 0.135*"karwa" + 0.135*"taxis" + 0.135*"al" + -0.132*"lulu"
2016-10-09 22:44:07,295 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:07,296 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:07,297 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:07,299 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,299 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,299 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:07,299 : INFO : saved 10x5327 matrix, density=0.385% (205/53270)
2016-10-09 22:44:07,299 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,299 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,299 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:07,300 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:07,300 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,300 : INFO : accepted corpus with 10 documents, 5327 features, 205 non-zero entries
2016-10-09 22:44:07,300 : INFO : collecting document frequencies
2016-10-09 22:44:07,300 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:07,300 : INFO : calculating IDF weights for 10 documents and 5326 features (205 matrix non-zeros)
2016-10-09 22:44:07,301 : INFO : using serial LSI version on this node
2016-10-09 22:44:07,301 : INFO : updating model with new documents
2016-10-09 22:44:07,301 : INFO : preparing a new chunk of documents
2016-10-09 22:44:07,301 : DEBUG : converting corpus to csc format
2016-10-09 22:44:07,302 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:07,305 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:07,305 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:07,332 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,437 : DEBUG : running 2 power iterations
2016-10-09 22:44:07,478 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,619 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,735 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:07,744 : INFO : computing the final decomposition
2016-10-09 22:44:07,744 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:07,747 : INFO : processed documents up to #10
2016-10-09 22:44:07,747 : INFO : topic #0(1.177): -0.283*"sponsorship" + -0.177*"visit" + -0.170*"visa" + -0.165*"work" + -0.157*"family" + -0.157*"sponsor" + -0.154*"qatar" + -0.150*"help" + -0.150*"months" + -0.141*"please"
2016-10-09 22:44:07,748 : INFO : topic #1(1.078): 0.402*"sponsorship" + 0.253*"work" + -0.204*"months" + 0.191*"sponsor" + -0.166*"visit" + -0.164*"whether" + -0.164*"anybody" + -0.164*"currently" + -0.164*"maximum" + -0.164*"extend"
2016-10-09 22:44:07,748 : INFO : topic #2(1.029): 0.231*"keep" + 0.231*"meet" + 0.215*"exam" + 0.186*"everyone" + 0.156*"besides" + 0.156*"days" + 0.135*"weeks" + -0.128*"visit" + 0.118*"medical" + 0.115*"occupied"
2016-10-09 22:44:07,748 : INFO : topic #3(1.022): -0.235*"qatar" + -0.190*"medical" + 0.184*"sponsorship" + -0.169*"noc" + -0.169*"bring" + -0.169*"legally" + -0.169*"married" + -0.169*"airways" + -0.153*"husbands" + -0.153*"gets"
2016-10-09 22:44:07,748 : INFO : topic #4(1.002): -0.283*"best" + -0.283*"recommendations" + -0.283*"later" + -0.283*"deliver" + -0.283*"found" + -0.283*"doctors" + -0.283*"place" + -0.283*"expecting" + -0.283*"baby" + -0.283*"year"
2016-10-09 22:44:07,748 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:07,749 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:07,750 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:07,752 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,752 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,752 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:07,752 : INFO : saved 10x5322 matrix, density=0.220% (117/53220)
2016-10-09 22:44:07,752 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,752 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,752 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:07,753 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:07,753 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:07,753 : INFO : accepted corpus with 10 documents, 5322 features, 117 non-zero entries
2016-10-09 22:44:07,753 : INFO : collecting document frequencies
2016-10-09 22:44:07,753 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:07,753 : INFO : calculating IDF weights for 10 documents and 5321 features (117 matrix non-zeros)
2016-10-09 22:44:07,754 : INFO : using serial LSI version on this node
2016-10-09 22:44:07,754 : INFO : updating model with new documents
2016-10-09 22:44:07,754 : INFO : preparing a new chunk of documents
2016-10-09 22:44:07,754 : DEBUG : converting corpus to csc format
2016-10-09 22:44:07,754 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:07,757 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:07,758 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:07,785 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:07,887 : DEBUG : running 2 power iterations
2016-10-09 22:44:07,927 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,066 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,179 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:08,187 : INFO : computing the final decomposition
2016-10-09 22:44:08,188 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:08,190 : INFO : processed documents up to #10
2016-10-09 22:44:08,191 : INFO : topic #0(1.193): -0.366*"family" + -0.326*"best" + -0.324*"beach" + -0.320*"qatar" + -0.278*"go" + -0.222*"next" + -0.212*"romantic" + -0.212*"maybe" + -0.212*"silent" + -0.211*"friday"
2016-10-09 22:44:08,191 : INFO : topic #1(1.043): -0.293*"next" + -0.251*"countries" + -0.251*"visited" + -0.251*"plan" + -0.235*"experience" + -0.233*"holiday" + -0.233*"destinations" + 0.209*"beach" + -0.207*"places" + -0.207*"vacation"
2016-10-09 22:44:08,191 : INFO : topic #2(1.030): 0.344*"destinations" + 0.344*"holiday" + 0.316*"experience" + -0.275*"countries" + -0.275*"visited" + -0.275*"plan" + -0.271*"next" + 0.217*"vacation" + 0.217*"summer" + 0.217*"places"
2016-10-09 22:44:08,191 : INFO : topic #3(1.016): 0.257*"lets" + 0.256*"long" + 0.256*"away" + 0.256*"start" + 0.256*"years" + 0.256*"17" + 0.256*"country" + 0.223*"beaches" + -0.150*"family" + 0.130*"holiday"
2016-10-09 22:44:08,191 : INFO : topic #4(0.999): -0.189*"advice" + -0.189*"ex" + -0.189*"us" + -0.189*"get" + -0.189*"decent" + -0.189*"moving" + -0.189*"standard" + -0.189*"expect" + -0.189*"pro" + -0.189*"also"
2016-10-09 22:44:08,191 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:08,192 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:08,193 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:08,195 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,195 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,195 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:08,195 : INFO : saved 10x5322 matrix, density=0.342% (182/53220)
2016-10-09 22:44:08,195 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,195 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,195 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:08,196 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:08,196 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,196 : INFO : accepted corpus with 10 documents, 5322 features, 182 non-zero entries
2016-10-09 22:44:08,196 : INFO : collecting document frequencies
2016-10-09 22:44:08,196 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:08,196 : INFO : calculating IDF weights for 10 documents and 5321 features (182 matrix non-zeros)
2016-10-09 22:44:08,197 : INFO : using serial LSI version on this node
2016-10-09 22:44:08,197 : INFO : updating model with new documents
2016-10-09 22:44:08,197 : INFO : preparing a new chunk of documents
2016-10-09 22:44:08,197 : DEBUG : converting corpus to csc format
2016-10-09 22:44:08,198 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:08,201 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:08,201 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:08,227 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,331 : DEBUG : running 2 power iterations
2016-10-09 22:44:08,372 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,512 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,628 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:08,635 : INFO : computing the final decomposition
2016-10-09 22:44:08,636 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:08,639 : INFO : processed documents up to #10
2016-10-09 22:44:08,639 : INFO : topic #0(1.092): 0.203*"running" + 0.185*"would" + 0.180*"evening" + 0.178*"place" + 0.174*"night" + 0.164*"corniche" + 0.140*"safe" + 0.135*"good" + 0.135*"hi" + 0.134*"could"
2016-10-09 22:44:08,639 : INFO : topic #1(1.036): 0.303*"running" + 0.239*"com" + 0.239*"www" + -0.199*"evening" + -0.196*"qlers" + -0.196*"lot" + -0.196*"see" + -0.196*"groups" + 0.157*"done" + 0.157*"also"
2016-10-09 22:44:08,639 : INFO : topic #2(1.026): -0.248*"could" + -0.245*"like" + -0.226*"im" + -0.166*"know" + -0.151*"would" + -0.135*"wear" + 0.131*"groups" + 0.131*"qlers" + 0.131*"see" + 0.131*"lot"
2016-10-09 22:44:08,639 : INFO : topic #3(1.006): 0.283*"alone" + 0.283*"move" + 0.283*"ladies" + -0.283*"today" + 0.231*"safe" + 0.141*"life" + 0.141*"comparable" + 0.141*"transport" + 0.141*"indian" + 0.141*"used"
2016-10-09 22:44:08,640 : INFO : topic #4(1.003): -0.347*"wear" + -0.222*"groups" + -0.222*"qlers" + -0.222*"see" + -0.222*"lot" + -0.161*"evening" + -0.150*"com" + -0.150*"www" + 0.121*"night" + -0.119*"corniche"
2016-10-09 22:44:08,640 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:08,641 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:08,642 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:08,643 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,643 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,643 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:08,644 : INFO : saved 10x5335 matrix, density=0.364% (194/53350)
2016-10-09 22:44:08,644 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,644 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,644 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:08,644 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:08,645 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:08,645 : INFO : accepted corpus with 10 documents, 5335 features, 194 non-zero entries
2016-10-09 22:44:08,645 : INFO : collecting document frequencies
2016-10-09 22:44:08,645 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:08,645 : INFO : calculating IDF weights for 10 documents and 5334 features (194 matrix non-zeros)
2016-10-09 22:44:08,645 : INFO : using serial LSI version on this node
2016-10-09 22:44:08,645 : INFO : updating model with new documents
2016-10-09 22:44:08,646 : INFO : preparing a new chunk of documents
2016-10-09 22:44:08,646 : DEBUG : converting corpus to csc format
2016-10-09 22:44:08,646 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:08,649 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:08,649 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:08,676 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,779 : DEBUG : running 2 power iterations
2016-10-09 22:44:08,824 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:08,964 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,082 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:09,090 : INFO : computing the final decomposition
2016-10-09 22:44:09,091 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:09,093 : INFO : processed documents up to #10
2016-10-09 22:44:09,094 : INFO : topic #0(1.153): -0.228*"much" + -0.208*"club" + -0.184*"people" + -0.169*"need" + -0.169*"member" + -0.158*"bars" + -0.157*"enjoy" + -0.157*"dubai" + -0.157*"ways" + -0.157*"doha"
2016-10-09 22:44:09,094 : INFO : topic #1(1.055): -0.198*"think" + -0.184*"night" + 0.176*"bars" + -0.169*"get" + 0.169*"anybody" + 0.169*"knows" + 0.169*"anything" + 0.160*"people" + 0.150*"qatar" + 0.150*"friends"
2016-10-09 22:44:09,094 : INFO : topic #2(1.041): 0.249*"people" + 0.191*"dance" + 0.189*"dubai" + 0.189*"enjoy" + 0.189*"ways" + -0.189*"anybody" + -0.189*"knows" + -0.189*"anything" + -0.182*"friends" + -0.182*"qatar"
2016-10-09 22:44:09,094 : INFO : topic #3(1.011): 0.245*"time" + 0.245*"opens" + 0.179*"friday" + -0.157*"getting" + -0.157*"work" + -0.157*"days" + -0.157*"although" + -0.157*"w" + -0.157*"pretty" + -0.157*"world"
2016-10-09 22:44:09,094 : INFO : topic #4(0.998): 0.198*"opens" + 0.198*"time" + -0.172*"bars" + 0.162*"friday" + -0.156*"nt" + -0.156*"5" + -0.156*"weekend" + -0.156*"one" + -0.156*"give" + -0.156*"planning"
2016-10-09 22:44:09,095 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:09,096 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:09,097 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:09,098 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,098 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,098 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:09,098 : INFO : saved 10x5313 matrix, density=0.233% (124/53130)
2016-10-09 22:44:09,098 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,099 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,099 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,099 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,099 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,099 : INFO : accepted corpus with 10 documents, 5313 features, 124 non-zero entries
2016-10-09 22:44:09,099 : INFO : collecting document frequencies
2016-10-09 22:44:09,100 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:09,100 : INFO : calculating IDF weights for 10 documents and 5312 features (124 matrix non-zeros)
2016-10-09 22:44:09,100 : INFO : using serial LSI version on this node
2016-10-09 22:44:09,100 : INFO : updating model with new documents
2016-10-09 22:44:09,100 : INFO : preparing a new chunk of documents
2016-10-09 22:44:09,100 : DEBUG : converting corpus to csc format
2016-10-09 22:44:09,101 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:09,104 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:09,104 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:09,130 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,232 : DEBUG : running 2 power iterations
2016-10-09 22:44:09,272 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,414 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,534 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:09,542 : INFO : computing the final decomposition
2016-10-09 22:44:09,542 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:09,545 : INFO : processed documents up to #10
2016-10-09 22:44:09,545 : INFO : topic #0(1.092): -0.314*"think" + -0.293*"qlers" + -0.233*"take" + -0.233*"moment" + -0.233*"hear" + -0.233*"let" + -0.226*"ql" + -0.211*"say" + -0.186*"better" + -0.186*"write"
2016-10-09 22:44:09,546 : INFO : topic #1(1.012): -0.362*"points" + 0.253*"something" + 0.233*"hate" + 0.233*"list" + -0.205*"open" + -0.205*"villagio" + 0.190*"joke" + -0.181*"anyone" + -0.181*"tell" + -0.181*"earn"
2016-10-09 22:44:09,546 : INFO : topic #2(1.009): 0.312*"points" + 0.280*"joke" + 0.257*"hate" + 0.257*"list" + 0.201*"open" + 0.201*"villagio" + 0.172*"streets" + 0.158*"women" + 0.156*"earn" + 0.156*"tell"
2016-10-09 22:44:09,546 : INFO : topic #3(1.003): 0.578*"something" + 0.289*"noticed" + 0.289*"red" + 0.289*"dont" + 0.220*"know" + 0.219*"villagio" + 0.219*"open" + 0.204*"points" + 0.164*"yet" + -0.110*"moment"
2016-10-09 22:44:09,546 : INFO : topic #4(1.000): -0.372*"come" + -0.322*"still" + -0.186*"turn" + -0.186*"best" + -0.186*"nothing" + -0.186*"4" + -0.186*"little" + -0.186*"canal" + -0.186*"pie" + -0.186*"regret"
2016-10-09 22:44:09,546 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:09,547 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:09,548 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:09,549 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,549 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,549 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:09,550 : INFO : saved 10x5322 matrix, density=0.368% (196/53220)
2016-10-09 22:44:09,550 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,550 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,550 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,551 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,551 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,551 : INFO : accepted corpus with 10 documents, 5322 features, 196 non-zero entries
2016-10-09 22:44:09,551 : INFO : collecting document frequencies
2016-10-09 22:44:09,551 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:09,551 : INFO : calculating IDF weights for 10 documents and 5321 features (196 matrix non-zeros)
2016-10-09 22:44:09,551 : INFO : using serial LSI version on this node
2016-10-09 22:44:09,551 : INFO : updating model with new documents
2016-10-09 22:44:09,552 : INFO : preparing a new chunk of documents
2016-10-09 22:44:09,552 : DEBUG : converting corpus to csc format
2016-10-09 22:44:09,552 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:09,555 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:09,556 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:09,583 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,687 : DEBUG : running 2 power iterations
2016-10-09 22:44:09,726 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,866 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:09,981 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:09,989 : INFO : computing the final decomposition
2016-10-09 22:44:09,989 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:09,992 : INFO : processed documents up to #10
2016-10-09 22:44:09,992 : INFO : topic #0(1.114): 0.212*"nursery" + 0.212*"speaking" + 0.212*"details" + 0.204*"french" + 0.192*"contact" + 0.192*"give" + 0.190*"anyone" + 0.189*"know" + 0.163*"lycee" + 0.151*"doha"
2016-10-09 22:44:09,993 : INFO : topic #1(1.042): -0.274*"lycee" + -0.246*"soon" + -0.215*"mall" + -0.215*"heard" + -0.215*"bar" + -0.215*"rumor" + -0.215*"say" + -0.196*"qatar" + -0.177*"get" + 0.150*"beach"
2016-10-09 22:44:09,993 : INFO : topic #2(1.035): 0.294*"give" + 0.182*"contact" + 0.151*"details" + 0.151*"nursery" + 0.151*"speaking" + 0.147*"could" + 0.147*"baby" + 0.147*"nurseries" + 0.147*"names" + 0.147*"address"
2016-10-09 22:44:09,993 : INFO : topic #3(1.009): 0.152*"lycee" + 0.152*"moving" + 0.142*"forum" + 0.142*"time" + 0.142*"al" + 0.142*"villa" + 0.142*"looking" + 0.142*"hello" + 0.142*"compound" + 0.142*"first"
2016-10-09 22:44:09,993 : INFO : topic #4(1.001): 0.214*"bought" + 0.190*"british" + 0.190*"buy" + 0.190*"flat" + -0.148*"details" + -0.148*"speaking" + -0.148*"nursery" + 0.148*"good" + 0.141*"would" + 0.130*"kindergarten"
2016-10-09 22:44:09,993 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:09,995 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:09,996 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:09,997 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,997 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,997 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:09,998 : INFO : saved 10x5332 matrix, density=0.326% (174/53320)
2016-10-09 22:44:09,998 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,998 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,998 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,998 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:09,998 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:09,999 : INFO : accepted corpus with 10 documents, 5332 features, 174 non-zero entries
2016-10-09 22:44:09,999 : INFO : collecting document frequencies
2016-10-09 22:44:09,999 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:09,999 : INFO : calculating IDF weights for 10 documents and 5331 features (174 matrix non-zeros)
2016-10-09 22:44:09,999 : INFO : using serial LSI version on this node
2016-10-09 22:44:09,999 : INFO : updating model with new documents
2016-10-09 22:44:10,000 : INFO : preparing a new chunk of documents
2016-10-09 22:44:10,000 : DEBUG : converting corpus to csc format
2016-10-09 22:44:10,000 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:10,003 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:10,003 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:10,030 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,134 : DEBUG : running 2 power iterations
2016-10-09 22:44:10,174 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,316 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,431 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:10,439 : INFO : computing the final decomposition
2016-10-09 22:44:10,439 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:10,442 : INFO : processed documents up to #10
2016-10-09 22:44:10,442 : INFO : topic #0(1.087): 0.234*"without" + 0.202*"buy" + 0.202*"driving" + 0.202*"possible" + 0.202*"folks" + 0.202*"license" + 0.202*"name" + 0.200*"hi" + 0.186*"doha" + 0.175*"car"
2016-10-09 22:44:10,442 : INFO : topic #1(1.037): 0.240*"bus" + 0.222*"company" + 0.222*"suggestions" + 0.178*"rent" + 0.174*"call" + 0.174*"office" + 0.174*"deposit" + 0.174*"dont" + 0.174*"used" + 0.174*"everytime"
2016-10-09 22:44:10,443 : INFO : topic #2(1.035): 0.364*"bus" + 0.186*"mate" + 0.166*"qatar" + 0.150*"day" + 0.150*"one" + 0.140*"month" + 0.137*"household" + 0.137*"required" + 0.133*"need" + 0.128*"nurse"
2016-10-09 22:44:10,443 : INFO : topic #3(1.017): 0.224*"passport" + 0.224*"cancel" + 0.224*"even" + 0.224*"sponsor" + 0.224*"visa" + 0.211*"guys" + 0.209*"thank" + 0.157*"nurse" + -0.148*"mate" + 0.120*"without"
2016-10-09 22:44:10,443 : INFO : topic #4(0.998): 0.233*"recruiting" + 0.233*"numbers" + 0.233*"list" + 0.233*"workers" + 0.233*"construction" + 0.233*"advance" + 0.233*"jobs" + 0.233*"skilled" + 0.233*"phone" + 0.233*"agencies"
2016-10-09 22:44:10,443 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:10,444 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:10,445 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:10,446 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,446 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,446 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:10,447 : INFO : saved 10x5322 matrix, density=0.242% (129/53220)
2016-10-09 22:44:10,447 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,447 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,447 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:10,447 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:10,448 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,448 : INFO : accepted corpus with 10 documents, 5322 features, 129 non-zero entries
2016-10-09 22:44:10,448 : INFO : collecting document frequencies
2016-10-09 22:44:10,448 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:10,448 : INFO : calculating IDF weights for 10 documents and 5321 features (129 matrix non-zeros)
2016-10-09 22:44:10,448 : INFO : using serial LSI version on this node
2016-10-09 22:44:10,448 : INFO : updating model with new documents
2016-10-09 22:44:10,449 : INFO : preparing a new chunk of documents
2016-10-09 22:44:10,449 : DEBUG : converting corpus to csc format
2016-10-09 22:44:10,449 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:10,452 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:10,452 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:10,479 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,588 : DEBUG : running 2 power iterations
2016-10-09 22:44:10,634 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,776 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:10,889 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:10,897 : INFO : computing the final decomposition
2016-10-09 22:44:10,897 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:10,900 : INFO : processed documents up to #10
2016-10-09 22:44:10,900 : INFO : topic #0(1.171): -0.464*"park" + -0.363*"know" + -0.329*"water" + -0.329*"theme" + -0.238*"qatar" + -0.223*"would" + -0.223*"instead" + -0.154*"parks" + -0.154*"making" + -0.112*"mall"
2016-10-09 22:44:10,901 : INFO : topic #1(1.046): 0.357*"ur" + 0.219*"place" + 0.205*"family" + 0.205*"enjoy" + 0.178*"visited" + 0.178*"friends" + 0.178*"best" + 0.178*"hi" + -0.174*"park" + 0.168*"party"
2016-10-09 22:44:10,901 : INFO : topic #2(1.032): -0.225*"ur" + 0.216*"party" + 0.176*"given" + 0.176*"rent" + 0.176*"food" + 0.176*"kfc" + 0.176*"already" + 0.176*"venues" + 0.176*"restaurant" + -0.159*"enjoy"
2016-10-09 22:44:10,901 : INFO : topic #3(1.023): -0.296*"http" + -0.226*"post" + -0.226*"co" + -0.226*"im" + -0.226*"trap" + -0.226*"avoid" + -0.226*"bored" + -0.226*"read" + -0.197*"v" + -0.197*"www"
2016-10-09 22:44:10,901 : INFO : topic #4(1.010): -0.265*"got" + 0.203*"parks" + 0.203*"making" + -0.150*"doha" + -0.136*"2" + 0.133*"co" + 0.133*"trap" + 0.133*"read" + 0.133*"post" + 0.133*"avoid"
2016-10-09 22:44:10,901 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:10,902 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:10,903 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:10,904 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,904 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,905 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:10,905 : INFO : saved 10x5327 matrix, density=0.405% (216/53270)
2016-10-09 22:44:10,905 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,905 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,905 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:10,906 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:10,906 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:10,906 : INFO : accepted corpus with 10 documents, 5327 features, 216 non-zero entries
2016-10-09 22:44:10,906 : INFO : collecting document frequencies
2016-10-09 22:44:10,906 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:10,906 : INFO : calculating IDF weights for 10 documents and 5326 features (216 matrix non-zeros)
2016-10-09 22:44:10,907 : INFO : using serial LSI version on this node
2016-10-09 22:44:10,907 : INFO : updating model with new documents
2016-10-09 22:44:10,907 : INFO : preparing a new chunk of documents
2016-10-09 22:44:10,907 : DEBUG : converting corpus to csc format
2016-10-09 22:44:10,907 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:10,910 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:10,911 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:10,937 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,042 : DEBUG : running 2 power iterations
2016-10-09 22:44:11,081 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,220 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,334 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:11,342 : INFO : computing the final decomposition
2016-10-09 22:44:11,342 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:11,345 : INFO : processed documents up to #10
2016-10-09 22:44:11,345 : INFO : topic #0(1.142): -0.198*"month" + -0.176*"maximum" + -0.176*"doha" + -0.176*"3" + -0.159*"whether" + -0.159*"extend" + -0.159*"currently" + -0.149*"months" + -0.138*"anybody" + -0.136*"salary"
2016-10-09 22:44:11,345 : INFO : topic #1(1.064): 0.363*"salary" + 0.231*"option" + 0.231*"come" + 0.210*"wife" + 0.172*"bringing" + 0.172*"limitations" + 0.172*"appreciate" + 0.172*"family" + 0.172*"residence" + 0.172*"regards"
2016-10-09 22:44:11,345 : INFO : topic #2(1.021): 0.214*"available" + 0.214*"pakistanis" + 0.214*"pakistan" + 0.214*"someone" + -0.207*"need" + -0.194*"know" + -0.174*"sri" + -0.174*"3months" + -0.174*"want" + -0.174*"lanka"
2016-10-09 22:44:11,346 : INFO : topic #3(1.013): 0.250*"process" + 0.250*"change" + 0.146*"available" + 0.146*"someone" + 0.146*"pakistan" + 0.146*"pakistanis" + 0.146*"need" + 0.138*"visas" + 0.125*"idea" + 0.125*"regarding"
2016-10-09 22:44:11,346 : INFO : topic #4(0.998): 0.272*"baby" + 0.272*"deliver" + 0.250*"month" + 0.136*"native" + 0.136*"place" + 0.136*"friends" + 0.136*"highly" + 0.136*"pregnant" + 0.136*"shud" + 0.136*"charge"
2016-10-09 22:44:11,346 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:11,347 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:11,348 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:11,349 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,349 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,349 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:11,350 : INFO : saved 10x5313 matrix, density=0.233% (124/53130)
2016-10-09 22:44:11,350 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,350 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,350 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:11,351 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:11,351 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,351 : INFO : accepted corpus with 10 documents, 5313 features, 124 non-zero entries
2016-10-09 22:44:11,351 : INFO : collecting document frequencies
2016-10-09 22:44:11,351 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:11,351 : INFO : calculating IDF weights for 10 documents and 5312 features (124 matrix non-zeros)
2016-10-09 22:44:11,351 : INFO : using serial LSI version on this node
2016-10-09 22:44:11,351 : INFO : updating model with new documents
2016-10-09 22:44:11,352 : INFO : preparing a new chunk of documents
2016-10-09 22:44:11,352 : DEBUG : converting corpus to csc format
2016-10-09 22:44:11,352 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:11,355 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:11,355 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:11,382 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,486 : DEBUG : running 2 power iterations
2016-10-09 22:44:11,526 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,665 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,779 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:11,787 : INFO : computing the final decomposition
2016-10-09 22:44:11,787 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:11,790 : INFO : processed documents up to #10
2016-10-09 22:44:11,790 : INFO : topic #0(1.063): 0.343*"ql" + 0.327*"group" + 0.264*"thread" + 0.206*"honest" + 0.206*"obviously" + 0.206*"wives" + 0.206*"back" + 0.182*"please" + 0.172*"locked" + 0.172*"forum"
2016-10-09 22:44:11,790 : INFO : topic #1(1.037): -0.223*"question" + -0.216*"dish" + -0.207*"simple" + -0.207*"solution" + -0.207*"lol" + 0.195*"advice" + -0.182*"party" + -0.154*"rice" + -0.153*"invited" + -0.153*"wedding"
2016-10-09 22:44:11,790 : INFO : topic #2(1.034): 0.567*"advice" + 0.238*"christmas" + 0.238*"doha" + 0.199*"like" + 0.199*"eve" + 0.199*"new" + 0.199*"possible" + 0.199*"need" + 0.199*"year" + 0.199*"celebrate"
2016-10-09 22:44:11,791 : INFO : topic #3(1.018): 0.313*"simple" + 0.313*"solution" + 0.313*"lol" + 0.274*"question" + -0.223*"dish" + -0.178*"party" + -0.156*"go" + -0.143*"wedding" + -0.143*"invited" + -0.132*"dinner"
2016-10-09 22:44:11,791 : INFO : topic #4(1.011): 0.304*"go" + -0.226*"group" + 0.208*"honest" + 0.208*"back" + 0.208*"obviously" + 0.208*"wives" + -0.161*"b" + -0.161*"wants" + -0.161*"want" + -0.161*"say"
2016-10-09 22:44:11,791 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:11,792 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:11,793 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:11,794 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,794 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,794 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:11,795 : INFO : saved 10x5327 matrix, density=0.385% (205/53270)
2016-10-09 22:44:11,795 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,795 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,795 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:11,795 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:11,795 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:11,796 : INFO : accepted corpus with 10 documents, 5327 features, 205 non-zero entries
2016-10-09 22:44:11,796 : INFO : collecting document frequencies
2016-10-09 22:44:11,796 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:11,796 : INFO : calculating IDF weights for 10 documents and 5326 features (205 matrix non-zeros)
2016-10-09 22:44:11,796 : INFO : using serial LSI version on this node
2016-10-09 22:44:11,796 : INFO : updating model with new documents
2016-10-09 22:44:11,797 : INFO : preparing a new chunk of documents
2016-10-09 22:44:11,797 : DEBUG : converting corpus to csc format
2016-10-09 22:44:11,797 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:11,800 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:11,800 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:11,826 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:11,929 : DEBUG : running 2 power iterations
2016-10-09 22:44:11,969 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,119 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,231 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:12,239 : INFO : computing the final decomposition
2016-10-09 22:44:12,239 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:12,242 : INFO : processed documents up to #10
2016-10-09 22:44:12,242 : INFO : topic #0(1.139): 0.303*"suggestions" + 0.210*"week" + 0.178*"new" + 0.178*"happenings" + 0.175*"please" + 0.170*"holidays" + 0.154*"something" + 0.147*"days" + 0.136*"doha" + 0.136*"wife"
2016-10-09 22:44:12,242 : INFO : topic #1(1.062): 0.253*"ramadan" + 0.214*"comes" + 0.192*"know" + -0.189*"wife" + -0.189*"doha" + 0.170*"would" + -0.158*"places" + -0.138*"holidays" + 0.131*"whole" + 0.131*"islamic"
2016-10-09 22:44:12,243 : INFO : topic #2(1.020): 0.205*"places" + -0.184*"home" + -0.177*"leave" + 0.169*"wife" + 0.169*"doha" + -0.168*"holiday" + 0.138*"ramadan" + -0.129*"fitr" + -0.127*"go" + -0.123*"sponsor"
2016-10-09 22:44:12,243 : INFO : topic #3(1.008): -0.284*"please" + -0.270*"suggestions" + -0.260*"happenings" + -0.260*"new" + -0.173*"something" + 0.165*"home" + 0.152*"places" + -0.147*"plans" + -0.147*"guys" + -0.147*"come"
2016-10-09 22:44:12,243 : INFO : topic #4(0.997): 0.262*"home" + 0.212*"week" + 0.184*"want" + 0.176*"appreciated" + 0.175*"exit" + 0.175*"permit" + 0.175*"sponsor" + 0.167*"suggestions" + -0.144*"holiday" + 0.122*"advice"
2016-10-09 22:44:12,243 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:12,244 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:12,245 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:12,246 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,247 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,247 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:12,247 : INFO : saved 10x5322 matrix, density=0.308% (164/53220)
2016-10-09 22:44:12,247 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,247 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,247 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:12,248 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:12,248 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,248 : INFO : accepted corpus with 10 documents, 5322 features, 164 non-zero entries
2016-10-09 22:44:12,248 : INFO : collecting document frequencies
2016-10-09 22:44:12,248 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:12,248 : INFO : calculating IDF weights for 10 documents and 5321 features (164 matrix non-zeros)
2016-10-09 22:44:12,249 : INFO : using serial LSI version on this node
2016-10-09 22:44:12,249 : INFO : updating model with new documents
2016-10-09 22:44:12,249 : INFO : preparing a new chunk of documents
2016-10-09 22:44:12,249 : DEBUG : converting corpus to csc format
2016-10-09 22:44:12,249 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:12,252 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:12,253 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:12,279 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,379 : DEBUG : running 2 power iterations
2016-10-09 22:44:12,418 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,562 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,679 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:12,687 : INFO : computing the final decomposition
2016-10-09 22:44:12,688 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:12,691 : INFO : processed documents up to #10
2016-10-09 22:44:12,691 : INFO : topic #0(1.055): -0.267*"license" + -0.267*"driving" + -0.182*"move" + -0.171*"alone" + -0.171*"ladies" + -0.171*"safe" + -0.145*"also" + -0.140*"tell" + -0.129*"hi" + -0.121*"anybody"
2016-10-09 22:44:12,691 : INFO : topic #1(1.020): -0.245*"gonna" + -0.245*"guess" + -0.245*"win" + -0.222*"tell" + -0.216*"license" + -0.216*"driving" + 0.198*"also" + 0.160*"accept" + 0.160*"bank" + 0.135*"required"
2016-10-09 22:44:12,691 : INFO : topic #2(1.016): 0.212*"alone" + 0.212*"safe" + 0.212*"ladies" + -0.208*"india" + 0.207*"household" + 0.207*"required" + -0.173*"bank" + -0.173*"accept" + 0.146*"thanks" + 0.146*"hello"
2016-10-09 22:44:12,691 : INFO : topic #3(1.005): -0.462*"tata" + -0.462*"available" + -0.263*"wanted" + -0.263*"gps" + -0.263*"garmin" + -0.132*"case" + -0.132*"genuine" + -0.132*"short" + -0.132*"know" + -0.132*"trip"
2016-10-09 22:44:12,692 : INFO : topic #4(0.999): 0.346*"gonna" + 0.346*"win" + 0.346*"guess" + 0.238*"tell" + 0.156*"gps" + 0.156*"wanted" + 0.156*"garmin" + 0.134*"required" + 0.134*"household" + -0.126*"numbers"
2016-10-09 22:44:12,692 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:12,693 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:12,694 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:12,695 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,695 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,695 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:12,695 : INFO : saved 10x5325 matrix, density=0.340% (181/53250)
2016-10-09 22:44:12,696 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,696 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,696 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:12,696 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:12,696 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:12,696 : INFO : accepted corpus with 10 documents, 5325 features, 181 non-zero entries
2016-10-09 22:44:12,696 : INFO : collecting document frequencies
2016-10-09 22:44:12,697 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:12,697 : INFO : calculating IDF weights for 10 documents and 5324 features (181 matrix non-zeros)
2016-10-09 22:44:12,697 : INFO : using serial LSI version on this node
2016-10-09 22:44:12,697 : INFO : updating model with new documents
2016-10-09 22:44:12,697 : INFO : preparing a new chunk of documents
2016-10-09 22:44:12,698 : DEBUG : converting corpus to csc format
2016-10-09 22:44:12,698 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:12,701 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:12,701 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:12,727 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:12,828 : DEBUG : running 2 power iterations
2016-10-09 22:44:12,867 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,009 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,126 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:13,134 : INFO : computing the final decomposition
2016-10-09 22:44:13,134 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:13,137 : INFO : processed documents up to #10
2016-10-09 22:44:13,138 : INFO : topic #0(1.067): -0.258*"rules" + -0.234*"would" + -0.158*"like" + -0.148*"traffic" + -0.148*"watch" + -0.148*"doha" + -0.130*"male" + -0.124*"hi" + -0.117*"www" + -0.117*"http"
2016-10-09 22:44:13,138 : INFO : topic #1(1.015): -0.255*"hijab" + -0.203*"male" + -0.162*"hi" + 0.161*"rules" + -0.160*"share" + -0.131*"loss" + -0.131*"center" + -0.131*"timings" + -0.131*"thank" + -0.131*"rates"
2016-10-09 22:44:13,138 : INFO : topic #2(1.011): 0.318*"hijab" + 0.183*"male" + 0.175*"share" + -0.175*"qatar" + 0.159*"wear" + 0.159*"plz" + 0.159*"muslim" + 0.159*"women" + 0.159*"others" + 0.159*"making"
2016-10-09 22:44:13,138 : INFO : topic #3(1.003): 0.274*"liquor" + 0.274*"heard" + 0.274*"store" + 0.274*"rumor" + -0.217*"qatar" + 0.164*"nations" + 0.137*"near" + 0.137*"pork" + 0.137*"built" + 0.137*"sell"
2016-10-09 22:44:13,138 : INFO : topic #4(1.000): 0.324*"reason" + 0.324*"know" + 0.324*"let" + 0.276*"one" + 0.276*"silly" + 0.276*"forum" + 0.276*"even" + 0.276*"banned" + 0.276*"still" + 0.276*"line"
2016-10-09 22:44:13,138 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:13,140 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:13,140 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:13,142 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,142 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,142 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:13,142 : INFO : saved 10x5322 matrix, density=0.252% (134/53220)
2016-10-09 22:44:13,142 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,142 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,142 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:13,143 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:13,143 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,143 : INFO : accepted corpus with 10 documents, 5322 features, 134 non-zero entries
2016-10-09 22:44:13,143 : INFO : collecting document frequencies
2016-10-09 22:44:13,143 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:13,143 : INFO : calculating IDF weights for 10 documents and 5321 features (134 matrix non-zeros)
2016-10-09 22:44:13,144 : INFO : using serial LSI version on this node
2016-10-09 22:44:13,144 : INFO : updating model with new documents
2016-10-09 22:44:13,144 : INFO : preparing a new chunk of documents
2016-10-09 22:44:13,144 : DEBUG : converting corpus to csc format
2016-10-09 22:44:13,144 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:13,147 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:13,148 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:13,174 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,277 : DEBUG : running 2 power iterations
2016-10-09 22:44:13,318 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,456 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,576 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:13,584 : INFO : computing the final decomposition
2016-10-09 22:44:13,584 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:13,587 : INFO : processed documents up to #10
2016-10-09 22:44:13,587 : INFO : topic #0(1.081): -0.301*"qatar" + -0.228*"anyone" + -0.217*"bar" + -0.211*"help" + -0.211*"hello" + -0.211*"indian" + -0.211*"find" + -0.211*"thank" + -0.190*"friends" + -0.142*"one"
2016-10-09 22:44:13,588 : INFO : topic #1(1.037): 0.248*"qatar" + -0.231*"one" + 0.164*"anyone" + -0.158*"hall" + -0.158*"partner" + -0.158*"pass" + -0.158*"issue" + -0.151*"someone" + -0.151*"know" + -0.151*"thinking"
2016-10-09 22:44:13,588 : INFO : topic #2(1.000): 0.516*"broken" + 0.516*"sweet" + 0.516*"heart" + 0.183*"guys" + 0.183*"work" + 0.183*"issues" + 0.183*"ever" + 0.183*"think" + 0.183*"without" + 0.000*"saturday"
2016-10-09 22:44:13,588 : INFO : topic #3(1.000): -1.000*"hmm" + 0.000*"collections" + 0.000*"kia" + 0.000*"downloaded" + -0.000*"egg" + -0.000*"chicken" + 0.000*"nobody" + -0.000*"educated" + 0.000*"brands" + 0.000*"parcels"
2016-10-09 22:44:13,588 : INFO : topic #4(1.000): -0.365*"think" + -0.365*"guys" + -0.365*"issues" + -0.365*"ever" + -0.365*"work" + -0.365*"without" + 0.258*"broken" + 0.258*"sweet" + 0.258*"heart" + -0.000*"saturday"
2016-10-09 22:44:13,588 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:13,589 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:13,590 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:13,591 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,591 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,591 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:13,592 : INFO : saved 10x5322 matrix, density=0.391% (208/53220)
2016-10-09 22:44:13,592 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,592 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,592 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:13,593 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:13,593 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:13,593 : INFO : accepted corpus with 10 documents, 5322 features, 208 non-zero entries
2016-10-09 22:44:13,593 : INFO : collecting document frequencies
2016-10-09 22:44:13,593 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:13,593 : INFO : calculating IDF weights for 10 documents and 5321 features (208 matrix non-zeros)
2016-10-09 22:44:13,593 : INFO : using serial LSI version on this node
2016-10-09 22:44:13,594 : INFO : updating model with new documents
2016-10-09 22:44:13,594 : INFO : preparing a new chunk of documents
2016-10-09 22:44:13,594 : DEBUG : converting corpus to csc format
2016-10-09 22:44:13,594 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:13,597 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:13,598 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:13,624 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,725 : DEBUG : running 2 power iterations
2016-10-09 22:44:13,764 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:13,904 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,022 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:14,032 : INFO : computing the final decomposition
2016-10-09 22:44:14,032 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:14,035 : INFO : processed documents up to #10
2016-10-09 22:44:14,035 : INFO : topic #0(1.118): 0.192*"change" + 0.174*"visa" + 0.152*"thanks" + 0.151*"medical" + 0.150*"exam" + 0.150*"get" + 0.146*"ql" + 0.140*"company" + 0.136*"work" + 0.132*"would"
2016-10-09 22:44:14,036 : INFO : topic #1(1.048): -0.245*"change" + 0.179*"get" + 0.174*"advise" + 0.173*"kindly" + 0.173*"haircut" + 0.173*"boys" + 0.173*"town" + 0.171*"best" + 0.150*"car" + 0.150*"seat"
2016-10-09 22:44:14,036 : INFO : topic #2(1.039): -0.297*"ql" + -0.230*"kid" + -0.230*"wanna" + -0.230*"join" + -0.230*"delete" + -0.230*"one" + -0.230*"week" + -0.208*"anyone" + -0.183*"work" + -0.133*"reliable"
2016-10-09 22:44:14,036 : INFO : topic #3(1.020): -0.248*"c" + -0.248*"b" + 0.218*"change" + -0.217*"medical" + -0.197*"exam" + 0.168*"technician" + 0.168*"profession" + 0.168*"masters" + 0.168*"manager" + -0.165*"say"
2016-10-09 22:44:14,036 : INFO : topic #4(0.992): 0.240*"reliable" + -0.220*"visa" + 0.185*"seat" + 0.185*"car" + -0.159*"even" + -0.159*"saudi" + -0.159*"friends" + -0.159*"come" + -0.159*"want" + -0.159*"entry"
2016-10-09 22:44:14,036 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:14,037 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:14,038 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:14,040 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,040 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,040 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:14,040 : INFO : saved 10x5258 matrix, density=0.224% (118/52580)
2016-10-09 22:44:14,040 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,040 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,040 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,041 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,041 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,041 : INFO : accepted corpus with 10 documents, 5258 features, 118 non-zero entries
2016-10-09 22:44:14,041 : INFO : collecting document frequencies
2016-10-09 22:44:14,041 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:14,041 : INFO : calculating IDF weights for 10 documents and 5257 features (118 matrix non-zeros)
2016-10-09 22:44:14,042 : INFO : using serial LSI version on this node
2016-10-09 22:44:14,042 : INFO : updating model with new documents
2016-10-09 22:44:14,042 : INFO : preparing a new chunk of documents
2016-10-09 22:44:14,042 : DEBUG : converting corpus to csc format
2016-10-09 22:44:14,042 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:14,045 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:14,046 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:14,072 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,176 : DEBUG : running 2 power iterations
2016-10-09 22:44:14,216 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,358 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,473 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:14,480 : INFO : computing the final decomposition
2016-10-09 22:44:14,480 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:14,484 : INFO : processed documents up to #10
2016-10-09 22:44:14,484 : INFO : topic #0(1.199): -0.417*"http" + -0.417*"www" + -0.417*"com" + -0.322*"article" + -0.310*"look" + -0.204*"c" + -0.204*"28" + -0.204*"08" + -0.204*"f" + -0.204*"2010"
2016-10-09 22:44:14,484 : INFO : topic #1(1.082): 0.354*"church" + 0.329*"catholic" + 0.245*"qatar" + 0.239*"please" + 0.210*"make" + 0.177*"assigned" + 0.177*"bring" + 0.177*"know" + 0.177*"let" + 0.177*"cell"
2016-10-09 22:44:14,484 : INFO : topic #2(1.050): 0.348*"first" + 0.287*"chicken" + 0.287*"egg" + 0.287*"came" + 0.218*"makes" + 0.211*"crazy" + 0.211*"happened" + 0.211*"phone" + 0.211*"dumb" + 0.211*"list"
2016-10-09 22:44:14,484 : INFO : topic #3(1.001): -0.271*"talking" + -0.271*"way" + -0.271*"good" + -0.271*"avoid" + -0.271*"person" + -0.271*"lesser" + -0.271*"even" + -0.271*"worst" + 0.255*"chicken" + 0.255*"came"
2016-10-09 22:44:14,485 : INFO : topic #4(1.000): 0.447*"ones" + 0.447*"still" + 0.447*"one" + 0.447*"getting" + 0.447*"waiting" + -0.000*"came" + -0.000*"egg" + -0.000*"chicken" + 0.000*"talking" + 0.000*"worst"
2016-10-09 22:44:14,485 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:14,486 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:14,486 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:14,487 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,488 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,488 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:14,488 : INFO : saved 10x5322 matrix, density=0.306% (163/53220)
2016-10-09 22:44:14,488 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,488 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,488 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,489 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,489 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,489 : INFO : accepted corpus with 10 documents, 5322 features, 163 non-zero entries
2016-10-09 22:44:14,489 : INFO : collecting document frequencies
2016-10-09 22:44:14,489 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:14,489 : INFO : calculating IDF weights for 10 documents and 5321 features (163 matrix non-zeros)
2016-10-09 22:44:14,490 : INFO : using serial LSI version on this node
2016-10-09 22:44:14,490 : INFO : updating model with new documents
2016-10-09 22:44:14,490 : INFO : preparing a new chunk of documents
2016-10-09 22:44:14,490 : DEBUG : converting corpus to csc format
2016-10-09 22:44:14,490 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:14,493 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:14,494 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:14,520 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,626 : DEBUG : running 2 power iterations
2016-10-09 22:44:14,665 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,812 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:14,928 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:14,936 : INFO : computing the final decomposition
2016-10-09 22:44:14,937 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:14,940 : INFO : processed documents up to #10
2016-10-09 22:44:14,940 : INFO : topic #0(1.181): 0.255*"licence" + 0.245*"driving" + 0.195*"driver" + 0.194*"valid" + 0.162*"visa" + 0.159*"company" + 0.146*"visiting" + 0.138*"anybody" + 0.137*"get" + 0.136*"ur"
2016-10-09 22:44:14,940 : INFO : topic #1(1.060): 0.337*"use" + 0.332*"philippines" + 0.255*"im" + 0.255*"want" + 0.255*"long" + 0.255*"know" + 0.220*"phil" + -0.162*"driving" + -0.161*"valid" + 0.134*"planning"
2016-10-09 22:44:14,940 : INFO : topic #2(1.054): -0.325*"visiting" + -0.312*"egyptian" + -0.312*"work" + 0.176*"dl" + 0.174*"test" + 0.171*"anybody" + 0.154*"advise" + 0.154*"thanks" + 0.154*"parking" + 0.154*"trick"
2016-10-09 22:44:14,940 : INFO : topic #3(1.016): 0.283*"valid" + -0.246*"dl" + 0.232*"still" + 0.232*"ur" + -0.158*"visiting" + -0.133*"licence" + -0.125*"intend" + -0.125*"usa" + -0.125*"rent" + -0.125*"legal"
2016-10-09 22:44:14,941 : INFO : topic #4(1.001): 0.375*"licence" + 0.242*"company" + -0.218*"dl" + -0.194*"work" + -0.194*"egyptian" + 0.174*"thanks" + 0.174*"trick" + 0.174*"advise" + 0.174*"parking" + 0.169*"driver"
2016-10-09 22:44:14,941 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:14,942 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:14,943 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:14,944 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,944 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,944 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:14,944 : INFO : saved 10x5329 matrix, density=0.238% (127/53290)
2016-10-09 22:44:14,944 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,944 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,944 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,945 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:14,945 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:14,945 : INFO : accepted corpus with 10 documents, 5329 features, 127 non-zero entries
2016-10-09 22:44:14,945 : INFO : collecting document frequencies
2016-10-09 22:44:14,945 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:14,945 : INFO : calculating IDF weights for 10 documents and 5328 features (127 matrix non-zeros)
2016-10-09 22:44:14,946 : INFO : using serial LSI version on this node
2016-10-09 22:44:14,946 : INFO : updating model with new documents
2016-10-09 22:44:14,946 : INFO : preparing a new chunk of documents
2016-10-09 22:44:14,946 : DEBUG : converting corpus to csc format
2016-10-09 22:44:14,946 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:14,949 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:14,950 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:14,976 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,077 : DEBUG : running 2 power iterations
2016-10-09 22:44:15,117 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,265 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,381 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:15,389 : INFO : computing the final decomposition
2016-10-09 22:44:15,389 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:15,392 : INFO : processed documents up to #10
2016-10-09 22:44:15,393 : INFO : topic #0(1.103): 0.244*"love" + 0.234*"share" + 0.232*"take" + 0.225*"dubai" + 0.225*"go" + 0.225*"pics" + 0.220*"want" + 0.206*"vacation" + 0.187*"eat" + 0.174*"one"
2016-10-09 22:44:15,393 : INFO : topic #1(1.059): 0.402*"animals" + 0.390*"buy" + 0.304*"want" + 0.304*"qatar" + 0.243*"find" + 0.195*"difficult" + 0.195*"things" + 0.152*"chance" + 0.152*"life" + 0.152*"someone"
2016-10-09 22:44:15,393 : INFO : topic #2(1.048): -0.218*"eat" + -0.210*"love" + 0.164*"sponsor" + 0.163*"know" + 0.161*"thank" + 0.161*"cancel" + 0.161*"passport" + 0.161*"without" + 0.161*"visa" + 0.159*"even"
2016-10-09 22:44:15,393 : INFO : topic #3(1.020): 0.240*"visa" + 0.240*"cancel" + 0.240*"thank" + 0.240*"without" + 0.240*"passport" + 0.216*"sponsor" + 0.188*"guys" + 0.188*"even" + -0.171*"hello" + 0.167*"eat"
2016-10-09 22:44:15,393 : INFO : topic #4(0.999): -0.186*"directly" + -0.186*"house" + -0.186*"month" + -0.186*"introduce" + -0.186*"bank" + -0.186*"account" + -0.186*"per" + -0.186*"maids" + -0.186*"told" + -0.186*"qr"
2016-10-09 22:44:15,393 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:15,394 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:15,395 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:15,397 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,397 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,397 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:15,397 : INFO : saved 10x5327 matrix, density=0.379% (202/53270)
2016-10-09 22:44:15,397 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,397 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,397 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:15,398 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:15,398 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,398 : INFO : accepted corpus with 10 documents, 5327 features, 202 non-zero entries
2016-10-09 22:44:15,398 : INFO : collecting document frequencies
2016-10-09 22:44:15,398 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:15,398 : INFO : calculating IDF weights for 10 documents and 5326 features (202 matrix non-zeros)
2016-10-09 22:44:15,399 : INFO : using serial LSI version on this node
2016-10-09 22:44:15,399 : INFO : updating model with new documents
2016-10-09 22:44:15,399 : INFO : preparing a new chunk of documents
2016-10-09 22:44:15,399 : DEBUG : converting corpus to csc format
2016-10-09 22:44:15,400 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:15,403 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:15,403 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:15,429 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,533 : DEBUG : running 2 power iterations
2016-10-09 22:44:15,573 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,719 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,831 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:15,838 : INFO : computing the final decomposition
2016-10-09 22:44:15,839 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:15,842 : INFO : processed documents up to #10
2016-10-09 22:44:15,842 : INFO : topic #0(1.140): 0.316*"job" + 0.233*"good" + 0.214*"many" + 0.158*"american" + 0.158*"com" + 0.158*"hard" + 0.158*"time" + 0.158*"website" + 0.156*"get" + 0.154*"doha"
2016-10-09 22:44:15,842 : INFO : topic #1(1.069): -0.281*"library" + -0.276*"like" + -0.211*"work" + -0.208*"u" + -0.208*"e" + -0.208*"comparable" + -0.208*"ask" + -0.208*"conditions" + -0.208*"may" + -0.190*"would"
2016-10-09 22:44:15,842 : INFO : topic #2(1.023): -0.348*"petroleum" + 0.266*"library" + -0.228*"im" + -0.210*"http" + -0.210*"read" + -0.210*"trap" + -0.210*"bored" + -0.210*"avoid" + -0.210*"co" + 0.157*"like"
2016-10-09 22:44:15,842 : INFO : topic #3(1.005): -0.261*"library" + -0.229*"accept" + -0.229*"bank" + 0.219*"expat" + 0.219*"safe" + -0.123*"like" + 0.116*"want" + -0.115*"us" + -0.115*"one" + -0.115*"informed"
2016-10-09 22:44:15,843 : INFO : topic #4(0.999): 0.236*"library" + -0.203*"consultant" + -0.203*"guide" + 0.198*"read" + 0.198*"http" + 0.198*"avoid" + 0.198*"co" + 0.198*"trap" + 0.198*"bored" + -0.168*"bank"
2016-10-09 22:44:15,843 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:15,844 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:15,845 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:15,846 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,846 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,846 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:15,847 : INFO : saved 10x5327 matrix, density=0.327% (174/53270)
2016-10-09 22:44:15,847 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,847 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,847 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:15,847 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:15,847 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:15,848 : INFO : accepted corpus with 10 documents, 5327 features, 174 non-zero entries
2016-10-09 22:44:15,848 : INFO : collecting document frequencies
2016-10-09 22:44:15,848 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:15,848 : INFO : calculating IDF weights for 10 documents and 5326 features (174 matrix non-zeros)
2016-10-09 22:44:15,848 : INFO : using serial LSI version on this node
2016-10-09 22:44:15,848 : INFO : updating model with new documents
2016-10-09 22:44:15,849 : INFO : preparing a new chunk of documents
2016-10-09 22:44:15,849 : DEBUG : converting corpus to csc format
2016-10-09 22:44:15,849 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:15,852 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:15,852 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:15,878 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:15,979 : DEBUG : running 2 power iterations
2016-10-09 22:44:16,018 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,162 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,282 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:16,290 : INFO : computing the final decomposition
2016-10-09 22:44:16,290 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:16,293 : INFO : processed documents up to #10
2016-10-09 22:44:16,293 : INFO : topic #0(1.067): -0.278*"jpg" + -0.278*"qatarliving" + -0.278*"society" + -0.278*"dr" + -0.265*"http" + -0.265*"www" + -0.265*"com" + -0.179*"nations" + -0.168*"freeze" + -0.168*"watch"
2016-10-09 22:44:16,293 : INFO : topic #1(1.029): 0.286*"hijab" + 0.231*"others" + 0.189*"islam" + 0.188*"basically" + 0.188*"person" + 0.188*"converted" + 0.188*"likes" + 0.188*"involved" + 0.188*"pm" + 0.188*"process"
2016-10-09 22:44:16,294 : INFO : topic #2(1.015): -0.260*"hijab" + 0.205*"people" + 0.198*"us" + 0.198*"qatari" + 0.198*"must" + 0.198*"drink" + 0.198*"important" + 0.198*"tell" + 0.198*"think" + 0.190*"50"
2016-10-09 22:44:16,294 : INFO : topic #3(1.002): -0.343*"crime" + 0.252*"gold" + -0.228*"considered" + -0.228*"polygamy" + -0.228*"west" + -0.228*"wife" + 0.189*"wearing" + 0.189*"golden" + -0.132*"nations" + 0.126*"accessories"
2016-10-09 22:44:16,294 : INFO : topic #4(1.000): 0.362*"gold" + 0.272*"golden" + 0.272*"wearing" + 0.272*"crime" + 0.181*"accessories" + 0.181*"indian" + 0.181*"considered" + 0.181*"west" + 0.181*"polygamy" + 0.181*"wife"
2016-10-09 22:44:16,294 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:16,295 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:16,296 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:16,297 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,298 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,298 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:16,298 : INFO : saved 10x5322 matrix, density=0.391% (208/53220)
2016-10-09 22:44:16,298 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,298 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,298 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:16,299 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:16,299 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,299 : INFO : accepted corpus with 10 documents, 5322 features, 208 non-zero entries
2016-10-09 22:44:16,299 : INFO : collecting document frequencies
2016-10-09 22:44:16,299 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:16,299 : INFO : calculating IDF weights for 10 documents and 5321 features (208 matrix non-zeros)
2016-10-09 22:44:16,300 : INFO : using serial LSI version on this node
2016-10-09 22:44:16,300 : INFO : updating model with new documents
2016-10-09 22:44:16,300 : INFO : preparing a new chunk of documents
2016-10-09 22:44:16,300 : DEBUG : converting corpus to csc format
2016-10-09 22:44:16,301 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:16,304 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:16,304 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:16,330 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,437 : DEBUG : running 2 power iterations
2016-10-09 22:44:16,476 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,623 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,741 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:16,749 : INFO : computing the final decomposition
2016-10-09 22:44:16,749 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:16,752 : INFO : processed documents up to #10
2016-10-09 22:44:16,752 : INFO : topic #0(1.190): 0.268*"exam" + 0.257*"salary" + 0.222*"evaluation" + 0.213*"training" + 0.194*"need" + 0.149*"hmc" + 0.144*"pass" + 0.134*"nurses" + 0.132*"well" + 0.129*"experience"
2016-10-09 22:44:16,753 : INFO : topic #1(1.087): -0.367*"exam" + 0.267*"salary" + -0.202*"evaluation" + -0.188*"pass" + 0.179*"hmc" + -0.175*"prometric" + -0.175*"sit" + -0.156*"anyone" + -0.156*"giving" + -0.156*"regarding"
2016-10-09 22:44:16,753 : INFO : topic #2(1.030): -0.357*"training" + -0.201*"4" + -0.201*"get" + -0.201*"license" + -0.187*"need" + 0.172*"qatar" + -0.169*"evaluation" + -0.162*"hmc" + -0.150*"sch" + 0.131*"exam"
2016-10-09 22:44:16,753 : INFO : topic #3(1.000): -0.816*"stage" + -0.408*"verification" + -0.408*"right" + 0.000*"take" + -0.000*"medical" + -0.000*"hmc" + -0.000*"salary" + -0.000*"doha" + -0.000*"would" + -0.000*"many"
2016-10-09 22:44:16,753 : INFO : topic #4(0.998): 0.297*"take" + -0.218*"medical" + -0.180*"salary" + -0.150*"hmc" + 0.149*"currently" + 0.149*"company" + 0.149*"work" + 0.149*"even" + 0.149*"lot" + 0.149*"required"
2016-10-09 22:44:16,753 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:16,755 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:16,756 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:16,757 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,757 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,757 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:16,758 : INFO : saved 10x5327 matrix, density=0.439% (234/53270)
2016-10-09 22:44:16,758 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,758 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,758 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:16,758 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:16,758 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:16,759 : INFO : accepted corpus with 10 documents, 5327 features, 234 non-zero entries
2016-10-09 22:44:16,759 : INFO : collecting document frequencies
2016-10-09 22:44:16,759 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:16,759 : INFO : calculating IDF weights for 10 documents and 5326 features (234 matrix non-zeros)
2016-10-09 22:44:16,759 : INFO : using serial LSI version on this node
2016-10-09 22:44:16,759 : INFO : updating model with new documents
2016-10-09 22:44:16,760 : INFO : preparing a new chunk of documents
2016-10-09 22:44:16,760 : DEBUG : converting corpus to csc format
2016-10-09 22:44:16,760 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:16,763 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:16,763 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:16,790 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:16,892 : DEBUG : running 2 power iterations
2016-10-09 22:44:16,931 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,073 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,189 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:17,199 : INFO : computing the final decomposition
2016-10-09 22:44:17,199 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:17,203 : INFO : processed documents up to #10
2016-10-09 22:44:17,203 : INFO : topic #0(1.087): 0.204*"india" + 0.160*"indian" + 0.159*"sunny" + 0.142*"kerala" + 0.139*"asian" + 0.136*"part" + 0.134*"men" + 0.134*"western" + 0.134*"women" + 0.134*"keralites"
2016-10-09 22:44:17,203 : INFO : topic #1(1.044): -0.208*"indian" + -0.195*"keralites" + -0.195*"2" + -0.153*"india" + -0.151*"getting" + -0.151*"marry" + -0.151*"girls" + -0.151*"arab" + 0.147*"please" + 0.139*"hmc"
2016-10-09 22:44:17,203 : INFO : topic #2(1.025): -0.231*"p" + 0.216*"sunny" + 0.189*"asian" + 0.182*"women" + 0.182*"men" + 0.182*"western" + -0.154*"letter" + -0.154*"" + -0.149*"words" + 0.144*"sex"
2016-10-09 22:44:17,203 : INFO : topic #3(1.005): -0.246*"india" + 0.235*"hmc" + -0.215*"p" + 0.177*"jobs" + 0.177*"radio" + 0.177*"qbs" + 0.177*"special" + 0.177*"heard" + 0.177*"really" + 0.177*"love"
2016-10-09 22:44:17,204 : INFO : topic #4(1.000): -0.229*"marry" + -0.229*"girls" + -0.229*"arab" + -0.229*"getting" + 0.201*"heard" + 0.201*"love" + 0.201*"really" + 0.201*"special" + 0.201*"radio" + 0.201*"consider"
2016-10-09 22:44:17,204 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:17,205 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:17,206 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:17,207 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,207 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,207 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:17,208 : INFO : saved 10x5329 matrix, density=0.313% (167/53290)
2016-10-09 22:44:17,208 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,208 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,208 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:17,208 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:17,209 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,209 : INFO : accepted corpus with 10 documents, 5329 features, 167 non-zero entries
2016-10-09 22:44:17,209 : INFO : collecting document frequencies
2016-10-09 22:44:17,209 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:17,209 : INFO : calculating IDF weights for 10 documents and 5328 features (167 matrix non-zeros)
2016-10-09 22:44:17,209 : INFO : using serial LSI version on this node
2016-10-09 22:44:17,209 : INFO : updating model with new documents
2016-10-09 22:44:17,210 : INFO : preparing a new chunk of documents
2016-10-09 22:44:17,210 : DEBUG : converting corpus to csc format
2016-10-09 22:44:17,210 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:17,213 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:17,213 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:17,240 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,345 : DEBUG : running 2 power iterations
2016-10-09 22:44:17,384 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,528 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,642 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:17,650 : INFO : computing the final decomposition
2016-10-09 22:44:17,650 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:17,653 : INFO : processed documents up to #10
2016-10-09 22:44:17,653 : INFO : topic #0(1.147): -0.384*"buy" + -0.268*"know" + -0.259*"please" + -0.259*"need" + -0.192*"called" + -0.192*"advance" + -0.192*"knows" + -0.192*"let" + -0.192*"shop" + -0.192*"purchase"
2016-10-09 22:44:17,653 : INFO : topic #1(1.080): -0.262*"hi" + -0.253*"get" + -0.232*"bread" + -0.232*"machine" + -0.215*"good" + -0.198*"much" + 0.177*"buy" + -0.175*"find" + -0.163*"thanks" + -0.152*"bicycle"
2016-10-09 22:44:17,654 : INFO : topic #2(1.011): 0.368*"cards" + 0.276*"bank" + -0.217*"filipino" + -0.217*"dog" + 0.184*"commercial" + 0.184*"worked" + 0.184*"qnb" + 0.155*"know" + 0.151*"yes" + -0.140*"buy"
2016-10-09 22:44:17,654 : INFO : topic #3(1.005): 0.215*"dog" + 0.215*"filipino" + 0.202*"around" + 0.202*"like" + 0.202*"anything" + 0.202*"qataris" + -0.176*"machine" + -0.176*"bread" + -0.163*"hi" + 0.153*"idea"
2016-10-09 22:44:17,654 : INFO : topic #4(1.001): -0.255*"cards" + 0.247*"like" + 0.247*"around" + 0.247*"anything" + 0.247*"qataris" + -0.191*"bank" + -0.127*"qnb" + -0.127*"worked" + -0.127*"commercial" + 0.127*"get"
2016-10-09 22:44:17,654 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:17,655 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:17,656 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:17,657 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,657 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,657 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:17,658 : INFO : saved 10x5322 matrix, density=0.368% (196/53220)
2016-10-09 22:44:17,658 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,658 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,658 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:17,659 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:17,659 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:17,659 : INFO : accepted corpus with 10 documents, 5322 features, 196 non-zero entries
2016-10-09 22:44:17,659 : INFO : collecting document frequencies
2016-10-09 22:44:17,659 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:17,659 : INFO : calculating IDF weights for 10 documents and 5321 features (196 matrix non-zeros)
2016-10-09 22:44:17,659 : INFO : using serial LSI version on this node
2016-10-09 22:44:17,660 : INFO : updating model with new documents
2016-10-09 22:44:17,660 : INFO : preparing a new chunk of documents
2016-10-09 22:44:17,660 : DEBUG : converting corpus to csc format
2016-10-09 22:44:17,660 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:17,663 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:17,663 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:17,690 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,793 : DEBUG : running 2 power iterations
2016-10-09 22:44:17,833 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:17,975 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,091 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:18,099 : INFO : computing the final decomposition
2016-10-09 22:44:18,099 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:18,102 : INFO : processed documents up to #10
2016-10-09 22:44:18,102 : INFO : topic #0(1.160): -0.231*"wife" + -0.203*"company" + -0.179*"even" + -0.179*"please" + -0.168*"sponsor" + -0.167*"know" + -0.164*"government" + -0.164*"children" + -0.161*"months" + -0.161*"three"
2016-10-09 22:44:18,102 : INFO : topic #1(1.042): -0.348*"know" + -0.203*"hi" + -0.171*"trying" + -0.171*"success" + -0.171*"end" + -0.171*"see" + -0.171*"managed" + -0.171*"wednesday" + -0.171*"today" + -0.171*"application"
2016-10-09 22:44:18,103 : INFO : topic #2(1.026): -0.353*"license" + -0.252*"need" + -0.219*"exit" + -0.219*"weekend" + -0.219*"go" + -0.219*"long" + -0.219*"going" + -0.219*"permit" + -0.219*"together" + -0.219*"away"
2016-10-09 22:44:18,103 : INFO : topic #3(1.010): -0.339*"license" + 0.309*"qatar" + 0.257*"family" + 0.171*"visa" + -0.167*"need" + 0.155*"rules" + 0.155*"kind" + 0.155*"policy" + 0.155*"qr" + 0.155*"medical"
2016-10-09 22:44:18,103 : INFO : topic #4(0.996): 0.206*"please" + 0.206*"even" + 0.196*"months" + 0.196*"change" + 0.196*"three" + -0.168*"sponsored" + -0.155*"job" + -0.137*"problem" + -0.137*"appreciate" + -0.137*"would"
2016-10-09 22:44:18,103 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:18,104 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:18,105 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:18,106 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,107 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,107 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:18,107 : INFO : saved 10x5331 matrix, density=0.345% (184/53310)
2016-10-09 22:44:18,107 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,107 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,107 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:18,108 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:18,108 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,108 : INFO : accepted corpus with 10 documents, 5331 features, 184 non-zero entries
2016-10-09 22:44:18,108 : INFO : collecting document frequencies
2016-10-09 22:44:18,108 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:18,108 : INFO : calculating IDF weights for 10 documents and 5330 features (184 matrix non-zeros)
2016-10-09 22:44:18,109 : INFO : using serial LSI version on this node
2016-10-09 22:44:18,109 : INFO : updating model with new documents
2016-10-09 22:44:18,109 : INFO : preparing a new chunk of documents
2016-10-09 22:44:18,109 : DEBUG : converting corpus to csc format
2016-10-09 22:44:18,109 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:18,112 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:18,113 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:18,139 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,240 : DEBUG : running 2 power iterations
2016-10-09 22:44:18,279 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,422 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,541 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:18,548 : INFO : computing the final decomposition
2016-10-09 22:44:18,548 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:18,551 : INFO : processed documents up to #10
2016-10-09 22:44:18,552 : INFO : topic #0(1.121): -0.309*"good" + -0.281*"budget" + -0.231*"maintenance" + -0.216*"shape" + -0.216*"45000" + -0.216*"performance" + -0.181*"best" + -0.128*"advice" + -0.127*"buying" + -0.116*"thank"
2016-10-09 22:44:18,552 : INFO : topic #1(1.055): 0.293*"buying" + -0.232*"good" + 0.225*"advise" + 0.225*"check" + 0.214*"please" + 0.193*"servicing" + 0.193*"u" + 0.193*"process" + 0.193*"porsche" + 0.193*"look"
2016-10-09 22:44:18,552 : INFO : topic #2(1.024): 0.252*"dubai" + 0.239*"possible" + 0.216*"without" + 0.216*"license" + 0.216*"folks" + 0.216*"driving" + 0.216*"name" + 0.191*"cars" + 0.143*"doha" + 0.126*"get"
2016-10-09 22:44:18,552 : INFO : topic #3(1.009): -0.294*"cars" + -0.244*"would" + -0.221*"doha" + 0.191*"name" + 0.191*"folks" + 0.191*"license" + 0.191*"driving" + 0.191*"without" + 0.164*"possible" + -0.137*"prices"
2016-10-09 22:44:18,552 : INFO : topic #4(0.997): -0.345*"right" + 0.264*"cars" + 0.198*"doha" + -0.172*"dad" + -0.172*"armada" + -0.172*"available" + -0.172*"wants" + -0.172*"suv" + -0.172*"suggestions" + -0.172*"japan"
2016-10-09 22:44:18,552 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:18,554 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:18,555 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:18,556 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,556 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,556 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:18,557 : INFO : saved 10x5327 matrix, density=0.413% (220/53270)
2016-10-09 22:44:18,557 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,557 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,557 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:18,557 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:18,557 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:18,558 : INFO : accepted corpus with 10 documents, 5327 features, 220 non-zero entries
2016-10-09 22:44:18,558 : INFO : collecting document frequencies
2016-10-09 22:44:18,558 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:18,558 : INFO : calculating IDF weights for 10 documents and 5326 features (220 matrix non-zeros)
2016-10-09 22:44:18,558 : INFO : using serial LSI version on this node
2016-10-09 22:44:18,558 : INFO : updating model with new documents
2016-10-09 22:44:18,559 : INFO : preparing a new chunk of documents
2016-10-09 22:44:18,559 : DEBUG : converting corpus to csc format
2016-10-09 22:44:18,559 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:18,563 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:18,563 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:18,590 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,692 : DEBUG : running 2 power iterations
2016-10-09 22:44:18,731 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,871 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:18,987 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:18,997 : INFO : computing the final decomposition
2016-10-09 22:44:18,997 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:19,000 : INFO : processed documents up to #10
2016-10-09 22:44:19,000 : INFO : topic #0(1.158): -0.294*"best" + -0.290*"pakistani" + -0.218*"school" + -0.194*"thanks" + -0.168*"members" + -0.160*"3" + -0.157*"children" + -0.133*"qatar" + -0.128*"good" + -0.126*"planning"
2016-10-09 22:44:19,000 : INFO : topic #1(1.045): -0.286*"schools" + -0.237*"british" + 0.187*"members" + -0.179*"many" + -0.158*"really" + -0.158*"compulsory" + -0.158*"arabic" + -0.158*"solution" + -0.158*"know" + 0.139*"dear"
2016-10-09 22:44:19,000 : INFO : topic #2(1.029): -0.207*"bus" + -0.194*"schools" + -0.185*"many" + 0.162*"3" + -0.152*"child" + 0.150*"international" + -0.147*"british" + 0.134*"location" + -0.132*"members" + 0.131*"education"
2016-10-09 22:44:19,001 : INFO : topic #3(1.002): 0.403*"bus" + -0.254*"pakistani" + 0.229*"child" + 0.201*"found" + -0.196*"best" + 0.185*"location" + 0.130*"international" + -0.122*"b" + -0.122*"quality" + -0.122*"c"
2016-10-09 22:44:19,001 : INFO : topic #4(0.994): -0.306*"pakistani" + -0.273*"bus" + 0.194*"private" + 0.194*"tuition" + -0.168*"children" + -0.137*"found" + -0.126*"best" + 0.124*"members" + -0.113*"child" + -0.108*"thanks"
2016-10-09 22:44:19,001 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:19,002 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:19,003 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:19,004 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,005 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,005 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:19,005 : INFO : saved 10x5327 matrix, density=0.368% (196/53270)
2016-10-09 22:44:19,005 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,005 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,005 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,006 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,006 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,006 : INFO : accepted corpus with 10 documents, 5327 features, 196 non-zero entries
2016-10-09 22:44:19,006 : INFO : collecting document frequencies
2016-10-09 22:44:19,006 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:19,006 : INFO : calculating IDF weights for 10 documents and 5326 features (196 matrix non-zeros)
2016-10-09 22:44:19,007 : INFO : using serial LSI version on this node
2016-10-09 22:44:19,007 : INFO : updating model with new documents
2016-10-09 22:44:19,007 : INFO : preparing a new chunk of documents
2016-10-09 22:44:19,007 : DEBUG : converting corpus to csc format
2016-10-09 22:44:19,007 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:19,010 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:19,011 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:19,037 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,141 : DEBUG : running 2 power iterations
2016-10-09 22:44:19,180 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,321 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,436 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:19,444 : INFO : computing the final decomposition
2016-10-09 22:44:19,444 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:19,447 : INFO : processed documents up to #10
2016-10-09 22:44:19,447 : INFO : topic #0(1.139): 0.261*"qatar" + 0.223*"anybody" + 0.189*"please" + 0.174*"apply" + 0.171*"embassy" + 0.168*"know" + 0.162*"family" + 0.151*"itz" + 0.137*"tourist" + 0.137*"australian"
2016-10-09 22:44:19,447 : INFO : topic #1(1.047): 0.256*"qatar" + -0.211*"family" + -0.190*"lebanese" + -0.179*"still" + -0.177*"exit" + -0.177*"country" + 0.143*"tourist" + 0.139*"embassy" + 0.135*"anybody" + -0.132*"itz"
2016-10-09 22:44:19,448 : INFO : topic #2(1.042): -0.318*"anybody" + 0.268*"qatar" + 0.199*"tourist" + -0.186*"please" + -0.167*"doha" + -0.167*"whether" + -0.167*"extend" + -0.167*"3" + -0.167*"currently" + -0.167*"maximum"
2016-10-09 22:44:19,448 : INFO : topic #3(1.008): 0.207*"parents" + 0.207*"air" + 0.207*"us" + 0.207*"come" + 0.207*"sad" + 0.207*"hear" + 0.207*"cant" + 0.207*"salaam" + 0.207*"suggest" + 0.207*"road"
2016-10-09 22:44:19,448 : INFO : topic #4(1.003): 0.358*"extension" + 0.179*"sponsor" + 0.179*"approved" + 0.179*"extended" + 0.179*"brother" + 0.179*"something" + 0.179*"printed" + 0.179*"system" + 0.179*"4" + 0.179*"comment"
2016-10-09 22:44:19,448 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:19,449 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:19,450 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:19,451 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,451 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,451 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:19,452 : INFO : saved 10x5329 matrix, density=0.259% (138/53290)
2016-10-09 22:44:19,452 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,452 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,452 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,453 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,453 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,453 : INFO : accepted corpus with 10 documents, 5329 features, 138 non-zero entries
2016-10-09 22:44:19,453 : INFO : collecting document frequencies
2016-10-09 22:44:19,453 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:19,453 : INFO : calculating IDF weights for 10 documents and 5328 features (138 matrix non-zeros)
2016-10-09 22:44:19,453 : INFO : using serial LSI version on this node
2016-10-09 22:44:19,453 : INFO : updating model with new documents
2016-10-09 22:44:19,454 : INFO : preparing a new chunk of documents
2016-10-09 22:44:19,454 : DEBUG : converting corpus to csc format
2016-10-09 22:44:19,454 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:19,457 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:19,457 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:19,485 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,593 : DEBUG : running 2 power iterations
2016-10-09 22:44:19,634 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,775 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:19,889 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:19,896 : INFO : computing the final decomposition
2016-10-09 22:44:19,896 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:19,899 : INFO : processed documents up to #10
2016-10-09 22:44:19,900 : INFO : topic #0(1.117): -0.281*"accommodation" + -0.277*"expensive" + -0.185*"decorations" + -0.185*"standards" + -0.185*"quality" + -0.185*"finishing" + -0.185*"famous" + -0.184*"qatar" + -0.183*"etc" + -0.166*"facilities"
2016-10-09 22:44:19,900 : INFO : topic #1(1.049): 0.358*"school" + 0.183*"exam" + 0.183*"fees" + 0.183*"passed" + 0.183*"asked" + 0.183*"recommended" + 0.183*"son" + 0.183*"th" + 0.183*"entry" + 0.182*"doha"
2016-10-09 22:44:19,900 : INFO : topic #2(1.033): -0.255*"thread" + -0.189*"else" + -0.189*"anywhere" + -0.189*"ps" + -0.189*"dedicated" + -0.189*"milk" + -0.175*"nice" + -0.175*"really" + -0.175*"uk" + -0.175*"soft"
2016-10-09 22:44:19,900 : INFO : topic #3(1.015): -0.171*"thanks" + 0.164*"soft" + 0.164*"nice" + 0.164*"higher" + 0.164*"thinking" + 0.164*"really" + 0.164*"buy" + 0.164*"uk" + -0.162*"advise" + -0.162*"7"
2016-10-09 22:44:19,900 : INFO : topic #4(0.999): 0.258*"years" + 0.258*"sick" + 0.258*"health" + 0.258*"sort" + 0.258*"concerned" + 0.258*"able" + 0.258*"afford" + 0.258*"living" + 0.258*"might" + 0.258*"insurance"
2016-10-09 22:44:19,900 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:19,901 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:19,902 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:19,904 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,904 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,904 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:19,904 : INFO : saved 10x5327 matrix, density=0.374% (199/53270)
2016-10-09 22:44:19,904 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,904 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,904 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,905 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:19,905 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:19,905 : INFO : accepted corpus with 10 documents, 5327 features, 199 non-zero entries
2016-10-09 22:44:19,905 : INFO : collecting document frequencies
2016-10-09 22:44:19,905 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:19,905 : INFO : calculating IDF weights for 10 documents and 5326 features (199 matrix non-zeros)
2016-10-09 22:44:19,906 : INFO : using serial LSI version on this node
2016-10-09 22:44:19,906 : INFO : updating model with new documents
2016-10-09 22:44:19,906 : INFO : preparing a new chunk of documents
2016-10-09 22:44:19,906 : DEBUG : converting corpus to csc format
2016-10-09 22:44:19,906 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:19,910 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:19,910 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:19,936 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,040 : DEBUG : running 2 power iterations
2016-10-09 22:44:20,079 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,227 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,343 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:20,351 : INFO : computing the final decomposition
2016-10-09 22:44:20,351 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:20,354 : INFO : processed documents up to #10
2016-10-09 22:44:20,354 : INFO : topic #0(1.091): -0.250*"ql" + -0.178*"work" + -0.161*"qatar" + -0.153*"never" + -0.151*"without" + -0.145*"lucky" + -0.139*"today" + -0.139*"xp" + -0.139*"experiences" + -0.139*"happened"
2016-10-09 22:44:20,354 : INFO : topic #1(1.048): 0.294*"qatar" + 0.206*"get" + 0.203*"diseases" + -0.200*"without" + 0.188*"thanks" + 0.180*"lucky" + -0.154*"watch" + -0.154*"look" + -0.154*"http" + -0.154*"www"
2016-10-09 22:44:20,354 : INFO : topic #2(1.031): -0.252*"diseases" + 0.232*"ql" + 0.207*"hour" + 0.207*"surfing" + 0.207*"hours" + 0.207*"everyone" + 0.207*"spend" + 0.180*"lucky" + -0.168*"noticed" + 0.152*"many"
2016-10-09 22:44:20,354 : INFO : topic #3(1.020): -0.219*"http" + -0.219*"youtube" + -0.219*"com" + -0.219*"v" + -0.219*"www" + -0.186*"look" + -0.186*"watch" + 0.185*"ql" + 0.172*"work" + -0.167*"qatar"
2016-10-09 22:44:20,355 : INFO : topic #4(1.000): 0.328*"diseases" + -0.251*"speed" + 0.219*"noticed" + -0.168*"still" + -0.168*"issue" + -0.168*"help" + -0.168*"qtel" + -0.138*"bye" + 0.117*"least" + -0.112*"like"
2016-10-09 22:44:20,355 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:20,356 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:20,357 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:20,358 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,358 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,358 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:20,359 : INFO : saved 10x5329 matrix, density=0.407% (217/53290)
2016-10-09 22:44:20,359 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,359 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,359 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:20,360 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:20,360 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,360 : INFO : accepted corpus with 10 documents, 5329 features, 217 non-zero entries
2016-10-09 22:44:20,360 : INFO : collecting document frequencies
2016-10-09 22:44:20,360 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:20,360 : INFO : calculating IDF weights for 10 documents and 5328 features (217 matrix non-zeros)
2016-10-09 22:44:20,360 : INFO : using serial LSI version on this node
2016-10-09 22:44:20,361 : INFO : updating model with new documents
2016-10-09 22:44:20,361 : INFO : preparing a new chunk of documents
2016-10-09 22:44:20,361 : DEBUG : converting corpus to csc format
2016-10-09 22:44:20,361 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:20,364 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:20,365 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:20,391 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,493 : DEBUG : running 2 power iterations
2016-10-09 22:44:20,532 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,673 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,791 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:20,799 : INFO : computing the final decomposition
2016-10-09 22:44:20,800 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:20,803 : INFO : processed documents up to #10
2016-10-09 22:44:20,803 : INFO : topic #0(1.059): 0.229*"license" + 0.215*"driving" + 0.210*"anyone" + 0.178*"al" + 0.178*"jazeera" + 0.158*"radio" + 0.158*"night" + 0.157*"please" + 0.155*"tell" + 0.145*"engineer"
2016-10-09 22:44:20,804 : INFO : topic #1(1.019): 0.270*"true" + 0.217*"buy" + 0.188*"2" + 0.180*"places" + -0.146*"anyone" + 0.142*"qatar" + -0.131*"hey" + -0.131*"acceptable" + -0.131*"whether" + -0.131*"qp"
2016-10-09 22:44:20,804 : INFO : topic #2(1.010): -0.376*"qar" + -0.240*"license" + 0.224*"al" + 0.224*"jazeera" + -0.188*"000" + -0.183*"driving" + 0.152*"buy" + 0.150*"accommodation" + 0.125*"anyone" + -0.125*"allowance"
2016-10-09 22:44:20,804 : INFO : topic #3(1.004): 0.371*"buy" + 0.185*"things" + 0.185*"find" + 0.185*"sort" + 0.185*"difficult" + 0.185*"boxes" + 0.185*"sin" + 0.185*"two" + 0.185*"done" + 0.185*"special"
2016-10-09 22:44:20,804 : INFO : topic #4(1.001): 0.415*"2" + 0.207*"meat" + 0.207*"black" + 0.207*"bits" + 0.207*"lovely" + 0.207*"plz" + 0.207*"note" + 0.207*"cups" + 0.207*"proper" + -0.163*"items"
2016-10-09 22:44:20,804 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:20,806 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:20,806 : DEBUG : PROGRESS: at document #0/10
2016-10-09 22:44:20,808 : INFO : storing corpus in Matrix Market format to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,808 : INFO : saving sparse matrix to ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,808 : INFO : PROGRESS: saving document #0
2016-10-09 22:44:20,808 : INFO : saved 10x5270 matrix, density=0.184% (97/52700)
2016-10-09 22:44:20,808 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,808 : DEBUG : closing ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,808 : INFO : saving MmCorpus index to ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:20,809 : INFO : loaded corpus index from ./tmp/LsiModel/LsiModel.mm.index
2016-10-09 22:44:20,809 : INFO : initializing corpus reader from ./tmp/LsiModel/LsiModel.mm
2016-10-09 22:44:20,809 : INFO : accepted corpus with 10 documents, 5270 features, 97 non-zero entries
2016-10-09 22:44:20,809 : INFO : collecting document frequencies
2016-10-09 22:44:20,809 : INFO : PROGRESS: processing document #0
2016-10-09 22:44:20,809 : INFO : calculating IDF weights for 10 documents and 5269 features (97 matrix non-zeros)
2016-10-09 22:44:20,810 : INFO : using serial LSI version on this node
2016-10-09 22:44:20,810 : INFO : updating model with new documents
2016-10-09 22:44:20,810 : INFO : preparing a new chunk of documents
2016-10-09 22:44:20,810 : DEBUG : converting corpus to csc format
2016-10-09 22:44:20,810 : INFO : using 100 extra samples and 2 power iterations
2016-10-09 22:44:20,814 : INFO : 1st phase: constructing (5337, 500) action matrix
2016-10-09 22:44:20,815 : INFO : orthonormalizing (5337, 500) action matrix
2016-10-09 22:44:20,841 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:20,943 : DEBUG : running 2 power iterations
2016-10-09 22:44:20,982 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:21,125 : DEBUG : computing QR of (5337, 500) dense matrix
2016-10-09 22:44:21,245 : INFO : 2nd phase: running dense svd on (500, 10) matrix
2016-10-09 22:44:21,252 : INFO : computing the final decomposition
2016-10-09 22:44:21,253 : INFO : keeping 10 factors (discarding 0.000% of energy spectrum)
2016-10-09 22:44:21,255 : INFO : processed documents up to #10
2016-10-09 22:44:21,256 : INFO : topic #0(1.112): 0.468*"see" + 0.353*"moon" + 0.325*"world" + 0.317*"didnt" + 0.200*"friend" + 0.176*"lot" + 0.176*"end" + 0.176*"round" + 0.158*"also" + 0.158*"long"
2016-10-09 22:44:21,256 : INFO : topic #1(1.069): 0.517*"comment" + 0.449*"please" + 0.279*"names" + 0.279*"qlers" + 0.279*"authorized" + 0.279*"missing" + 0.240*"add" + 0.190*"topic" + 0.126*"every" + 0.063*"ideas"
2016-10-09 22:44:21,256 : INFO : topic #2(1.034): -0.382*"many" + -0.366*"returns" + -0.366*"party" + -0.366*"happy" + -0.359*"boss" + -0.180*"infront" + -0.180*"thinking" + -0.180*"coz" + -0.180*"jpg" + -0.180*"till"
2016-10-09 22:44:21,256 : INFO : topic #3(1.015): -0.282*"u" + 0.266*"filipinos" + 0.266*"per" + 0.266*"men" + 0.266*"part" + 0.266*"agree" + 0.266*"data" + 0.259*"world" + -0.177*"didnt" + -0.160*"ql"
2016-10-09 22:44:21,256 : INFO : topic #4(1.000): 1.000*"going" + 0.000*"comment" + 0.000*"returns" + 0.000*"happy" + 0.000*"party" + -0.000*"topic" + 0.000*"many" + -0.000*"every" + 0.000*"please" + 0.000*"see"
2016-10-09 22:44:21,257 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)
2016-10-09 22:44:21,257 : INFO : creating matrix with 10 documents and 10 features
2016-10-09 22:44:21,258 : DEBUG : PROGRESS: at document #0/10
